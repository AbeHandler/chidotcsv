<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Papers and Notes | CHI 2013</title><base href="http://chi2013.acm.org/">
<link rel="stylesheet" type="text/css" href="https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/css/style_sheet.css" media="screen, print">
<style type="text/css">
<!--
.style1 {color: #660033}
-->
</style>
<link rel="profile" href="http://gmpg.org/xfn/11" />
<link rel="stylesheet" type="text/css" media="all" href="https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/style.css" />
<link rel="pingback" href="http://chi2013.acm.org/wordpress/xmlrpc.php" />

<!-- This site is optimized with the Yoast WordPress SEO plugin v1.2.7 - http://yoast.com/wordpress/seo/ -->
<link rel="canonical" href="https://chi2013.acm.org/program/by-venues/papers-and-notes/" />
<meta property='og:locale' content='en_us'/>
<meta property='og:title' content='Papers and Notes - CHI 2013'/>
<meta property='og:url' content='https://chi2013.acm.org/program/by-venues/papers-and-notes/'/>
<meta property='og:site_name' content='CHI 2013'/>
<meta property='og:type' content='article'/>
<!-- / Yoast WordPress SEO plugin. -->

<link rel="alternate" type="application/rss+xml" title="CHI 2013 &raquo; Feed" href="https://chi2013.acm.org/feed/" />
<link rel="alternate" type="application/rss+xml" title="CHI 2013 &raquo; Comments Feed" href="https://chi2013.acm.org/comments/feed/" />
<script type='text/javascript' src='https://chi2013.acm.org/wordpress/wp-includes/js/jquery/jquery.js?ver=1.7.2'></script>
<script type='text/javascript' src='http://chi2013.acm.org/wordpress/wp-content/plugins/jquery-vertical-accordion-menu/js/jquery.hoverIntent.minified.js?ver=3.4.1'></script>
<script type='text/javascript' src='http://chi2013.acm.org/wordpress/wp-content/plugins/jquery-vertical-accordion-menu/js/jquery.cookie.js?ver=3.4.1'></script>
<script type='text/javascript' src='http://chi2013.acm.org/wordpress/wp-content/plugins/jquery-vertical-accordion-menu/js/jquery.dcjqaccordion.2.9.js?ver=3.4.1'></script>
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://chi2013.acm.org/wordpress/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://chi2013.acm.org/wordpress/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 3.4.1" />

<!-- Bad Behavior 2.2.13 run time: 81.767 ms -->
<script type="text/javascript">
<!--
function bb2_addLoadEvent(func) {
	var oldonload = window.onload;
	if (typeof window.onload != 'function') {
		window.onload = func;
	} else {
		window.onload = function() {
			oldonload();
			func();
		}
	}
}

bb2_addLoadEvent(function() {
	for ( i=0; i < document.forms.length; i++ ) {
		if (document.forms[i].method == 'post') {
			var myElement = document.createElement('input');
			myElement.setAttribute('type', 'hidden');
			myElement.name = 'bb2_screener_';
			myElement.value = '1633181775 75.166.212.214';
			document.forms[i].appendChild(myElement);
		}
	}
});
// --></script>
		<script src="http://chi2013.acm.org/wordpress/wp-content/uploads/2013/04/findtlc.js"></script>
</head>


					</head>

<body>

<div id="wrapper" style="overflow: visible; "><!--####  wrapper  ###-->

	<div id="top-menu"><!--menu-->
    
    		              <div id="icon_area"><!--icon area-->
                
                
                		<ul>
                        
                        	<li><a href="https://www.facebook.com/acmchi" title="CHI on Facebook"><img src="https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/facebook.png" alt="facebook icon"></a></li>
                                <li><a href="http://twitter.com/sig_chi" title="CHI on Twitter"><img src="https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/twitter.png" alt="twitter icon"></a></li>
				<li><a href="https://plus.google.com/s/CHI2013" title="CHI on Google+"><img src="https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/gplus.png" width="20px" alt="google+ icon"></a></li>
                		</ul>
          		</div><!--icon area-->

	<div id="nav_top"><!--menu top--> 
                <ul id="nav">
					<li class="page_item page-item-2"><a href="https://chi2013.acm.org/">Welcome</a></li>
<li class="page_item page-item-9 current_page_ancestor"><a href="https://chi2013.acm.org/program/">Program</a></li>
<li class="page_item page-item-12"><a href="https://chi2013.acm.org/attending/">Attending</a></li>
<li class="page_item page-item-15"><a href="https://chi2013.acm.org/authors/">Authors</a></li>
<li class="page_item page-item-28"><a href="https://chi2013.acm.org/organizers/">Organizers</a></li>
<li class="page_item page-item-18"><a href="https://chi2013.acm.org/sponsorship/">Sponsorship</a></li>
<li class="page_item page-item-21"><a href="https://chi2013.acm.org/exhibiting/">Exhibiting</a></li>
<li class="page_item page-item-31"><a href="https://chi2013.acm.org/press/">Press</a></li>
<li class="page_item page-item-25"><a href="https://chi2013.acm.org/recruiting/">Recruiting</a></li>
<li class="page_item page-item-64"><a href="https://chi2013.acm.org/communities/">Communities</a></li>
                </ul>
                    
                                   
               <ul id="subnav">
                    <li class="page_item page-item-1428 current_page_ancestor current_page_parent"><a href="https://chi2013.acm.org/program/by-venues/">By venues</a></li>
<li class="page_item page-item-1655"><a href="https://chi2013.acm.org/program/by-day/">By day</a></li>
<li class="page_item page-item-1745"><a href="https://chi2013.acm.org/program/best-of-chi/">Best of CHI</a></li>
<li class="page_item page-item-2105"><a href="https://chi2013.acm.org/program/industry-days/">Industry Days</a></li>
<li class="page_item page-item-2110"><a href="https://chi2013.acm.org/program/mobile-apps/">Mobile Apps</a></li>
<li class="page_item page-item-2404"><a href="https://chi2013.acm.org/program/my-chi/">myCHI</a></li>
<li class="page_item page-item-2043"><a href="https://chi2013.acm.org/program/video-previews/">Video Previews</a></li>
<li class="page_item page-item-2042"><a href="https://chi2013.acm.org/program/3-letter-codes/">3-Letter Codes</a></li>
                </ul>
                     

<!-- testing grandchild code                                       
-->
                   <!-- testing code -->

                    
<!-- end testing code -->

<!--              	 	<ul>
                        
                       <li><a href="index.html" class="active">Welcome</a></li>
                        <li class="grey"><a href="#">Program</a></li>
					   <li class="grey"><a href="#">Attending</a></li>
                       <li class="grey"><a href="#">Authors</a></li>
                       <li class="grey"><a href="#">Sponsorship</a></li>
					    <li class="grey"><a href="#">Exhibiting</a></li>
						<li class="grey"><a href="#">Recruiting</a><a href="#">Organizers</a></li>
						<li class="grey"><a href="#">Press</a></li>
						<div align="left"><a href="#"></a></div>
						 
					
           	  </ul>-->
                     
                     
      </div><!--menu top end--> 
            
	</div><!--menu end-->
  <!--header-->
    <!--header end-->
<div id="banner" style="overflow: visible; "><!--banner-->
        		 <!--img src="https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/header1.jpg" alt="" style="overflow: visible; "-->
        		 <img src="https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/banner/home.jpg" alt="" style="overflow: visible; ">
  </div><!--banner end-->
  <!-- breadcrumbs -->
<div id="breadcrumbs">
    &gt; <a href="https://chi2013.acm.org/program/">Program</a> &gt; <a href="https://chi2013.acm.org/program/by-venues/">By venues</a> &gt; <a href="https://chi2013.acm.org/program/by-venues/papers-and-notes/">Papers and Notes</a>     </div>
  <!-- end breadcrumbs -->              
        
        <div id="content_wrapper" style="overflow: visible; "><!-- content wrapper-->
                    
                   <div id="content_laft" style="overflow: visible; opacity: 1; ">		<div id="secondary" class="widget-area" role="complementary">
								<div id="recent-posts-2" class="widget widget_recent_entries">		<h1 class="widget-title">News</h1>		<ul>
				<li><a href="https://chi2013.acm.org/chi-2013-awards/" title="&lt;img src=&quot;http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/best.png&quot;&gt; CHI 2013 Awards"><img src="http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/best.png"> CHI 2013 Awards</a></li>
				<li><a href="https://chi2013.acm.org/what-to-attend-mychi/" title="What to attend: MyCHI">What to attend: MyCHI</a></li>
				<li><a href="https://chi2013.acm.org/watch-the-video-previews/" title="Watch the Video Previews">Watch the Video Previews</a></li>
				</ul>
		</div><div id="text-5" class="widget widget_text"><h1 class="widget-title">3-letter codes</h1>			<div class="textwidget"><label for="tlc">Enter code:</label><input id="tlc" type="text" size="3" onchange="gotoTLC()" /><button onclick="gotoTLC()">Go</button></div>
		</div><div id="search-3" class="widget widget_search"><h1 class="widget-title">Search</h1><form role="search" method="get" id="searchform" action="https://chi2013.acm.org/" >
	<div><label class="screen-reader-text" for="s">Search for:</label>
	<input type="text" value="" name="s" id="s" />
	<input type="submit" id="searchsubmit" value="Search" />
	</div>
	</form></div><div id="nav_menu-2" class="widget widget_nav_menu"><h1 class="widget-title">Communities</h1><div class="menu-communities-container"><ul id="menu-communities" class="menu"><li id="menu-item-77" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-77"><a href="https://chi2013.acm.org/communities/design/">Design</a></li>
<li id="menu-item-76" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-76"><a href="https://chi2013.acm.org/communities/engineering/">Engineering</a></li>
<li id="menu-item-75" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-75"><a href="https://chi2013.acm.org/communities/management/">Management</a></li>
<li id="menu-item-74" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-74"><a href="https://chi2013.acm.org/communities/user-experience/">User Experience</a></li>
<li id="menu-item-88" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-88"><a href="https://chi2013.acm.org/communities/hci-for-kids/">Child-Computer Interaction</a></li>
<li id="menu-item-631" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-631"><a href="https://chi2013.acm.org/communities/digital-arts/">Digital Arts</a></li>
<li id="menu-item-94" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-94"><a href="https://chi2013.acm.org/communities/entertainment/">Games &#038; Entertainment</a></li>
<li id="menu-item-93" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-93"><a href="https://chi2013.acm.org/communities/health/">Health</a></li>
<li id="menu-item-92" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-92"><a href="https://chi2013.acm.org/communities/sustainability/">Sustainability</a></li>
<li id="menu-item-576" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-576"><a href="https://chi2013.acm.org/communities/hci4d/">HCI4D</a></li>
</ul></div></div>		</div><!-- #secondary .widget-area -->                     
                   </div><!--content laft end-->
                
        <!-- c-ao 23jan13 adjustment for page id 1213 to make it wider -->
	<!-- mbl 12feb13 changed test for page id with test for custom field 'wide' -->
        		
		<div id="content_wide" style="overflow:visible; "><!--content wide-->
		                
                		<!--<h1>Welcome to CHI 2013</h1>-->
                        
                        <p class="text" style="overflow: visible; "> 
                          <span class="style1" style="overflow: visible; opacity: 1; ">
<h1 class="page-title TG-pagepage-title TG-page-title">Papers and Notes</h1>
								




				<div id="post-1435" class="post-1435 page type-page status-publish hentry" >
									<div class="entry-content">
						<style>
a { color: rgb(100, 79, 76);}
h3 { margin-bottom: 2px;}
div.chair {font-style: italic;}
.presentation {line-height: 1.4; margin-bottom: 12px; color: rgb(102, 0, 51);}
.presentation .title {font-weight: bold;}
.presentation .authors {font-style: italic;}
.presentation .authorList {display: none;}
.presentation .authorList > span {display: block;}
.presentation .cbStatement {padding: 24px 0px;}
.presentation .abstract {display: none; padding: 24px 0px;}
.presentation .author { font-style: italic;}
.time { background-color: rgb(100, 79, 76); color: rgb(246, 243, 226); padding: 2px 5px;}
span.when { float: right; margin-left: 15px; font-family: sans-serif; font-size: 9pt;}
span.award { display: inline-block; float: left; margin-left: -50px; height: 34px; width: 34px; background-repeat:no-repeat;}
span.best { background-image: url('http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/best.png');}
span.honorable { background-image: url('http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/honorable.png');}
span.repliCHI { clear: left; height: 51px; width: 51px; background-image: url('http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/repliCHI.png');}
span.room { display: inline-block; float: right; padding-top: 1px; font-family: sans-serif; font-size: 14px; font-weight: normal;}
span.room:before { content: 'Room: ';}
</style>
<p><script type='text/javascript'>
function toggleAll() { var $=jQuery; $('.authors').toggle(); $('.authorList').toggle(); $('.cbStatement').toggle(); $('.abstract').toggle(); }
</script></p>
<p><a href='javascript:toggleAll()'>Show / hide full affiliations and abstracts</a> (May take a few seconds.)</p>
<p><span class='letterCode' style='float:left'>IWC</span>&nbsp;Enter a <a href='http://chi2013.acm.org/3-letter-codes/'>3-letter code</a> in the search box of the CHI 2013 mobile app to go to the corresponding session or presentation. <br/>&nbsp;When clickable, a 3-letter code links to the <a href='http://chi2013.acm.org/previews'>Video Previews</a> web site.</p>
<p><script type="text/javascript">
	function filterCommunity(community) { var $=jQuery; if (community == "all") { $(".presentation").show(); $(".session").show(); } else {$(".presentation").hide(); $(".presentation."+community).show(); $(".session").hide(); $(".session."+community).show()};}
	</script></p>
<table>
<tr>
<td><input type="radio" name="community" onchange="filterCommunity('all')" value="all" checked>All communities</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('design')" value="design">Design (156)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('engineering')" value="engineering">Engineering (50)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('management')" value="management">Management (6)</input></td>
</tr>
<tr>
<td><input type="radio" name="community" onchange="filterCommunity('ux')" value="ux">User Experience (106)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('cci')" value="cci">Child-Computer Interaction (16)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('arts')" value="arts">Digital Arts (13)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('games')" value="games">Games and Entertainment (36)</input></td>
</tr>
<tr>
<td><input type="radio" name="community" onchange="filterCommunity('health')" value="health">Health (31)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('sustainability')" value="sustainability">Sustainability (17)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('HCI4D')" value="HCI4D">HCI for Development (19)</input></td>
</tr>
</table>
<ul>
<li id="NQB"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#NQB"><span class="letterCode" style="float:right">NQB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NQB">Tue. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466182">How Low Can You Go? Human Limits in Small Unidirectional Mouse Movements</a></span><br />
<span class="authors">J. Aceituno (Inria Lille, FR), G. Casiez, N. Roussel</span>
<div class="authorList"><span><span class="author">J. Aceituno</span> (Inria Lille, FR)</span><span><span class="author">G. Casiez</span> (LIFL &#038; INRIA Lille, Univ. of Lille, FR)</span><span><span class="author">N. Roussel</span> (Inria, FR)</span></div>
<p><span class="cbStatement">Presents an experimental protocol and corresponding findings for the mouse for measuring the smallest unidirectional movement people can perform. Details recommendation guidelines for user interfaces and devices design.</span><span class="abstract">Computer mouse sensors keep increasing in resolution. The smallest displacement they can detect gets smaller, but little is known on our ability to control such small movements. Small target acquisition has been previously tackled, but the findings do not apply to the problem of finding the useful resolution of a user with a mouse, which corresponds to the smallest displacement (s)he can reliably produce with that device. We detail this definition and provide an associated experimental protocol to measure it. We then report on the results of a study suggesting that high-end mice are not likely to be used to their full potential. We further comment on the different strategies used by participants to acheive best performance, and derive implications for user interfaces.</span></li>
<li id="PGU"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PGU"><span class="letterCode" style="float:right">PGU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGU">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466246">Benevolent Deception in Human Computer Interaction</a></span><br />
<span class="authors">E. Adar (Univ. of Michigan, USA), D. Tan, J. Teevan</span>
<div class="authorList"><span><span class="author">E. Adar</span> (Univ. of Michigan, USA)</span><span><span class="author">D. Tan</span> (Microsoft Research, USA)</span><span><span class="author">J. Teevan</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">In this work we analyze deception intended to help the user.  Using a criminology-inspired metaphor we describe the means, motive, and opportunities for deception and ideas for future research.</span><span class="abstract">Though it has been asserted that “good design is honest,” [42] deception exists throughout human-computer interaction research and practice. Because of the stigma associated with deception—in many cases rightfully so—the research community has focused its energy on eradicating malicious deception, and ignored instances in which deception is positively employed. In this paper we present the notion of benevolent deception, deception aimed at benefitting the user as well as the developer. We frame our discussion using a criminology-inspired model and ground components in various examples. We assert that this provides us with a set of tools and principles that not only helps us with system and interface design, but that opens new research areas. After all, as Cockton claims in his 2004 paper “Value-Centered HCI” [13], “Traditional disciplines have delivered truth. The goal of HCI is to deliver value.”</span></li>
<li id="NMQ"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#NMQ"><span class="letterCode" style="float:right">NMQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NMQ">Wed. 4pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481418">Leading People to Longer Queries</a></span><br />
<span class="authors">E. Agapie (Harvard Univ., USA), G. Golovchinsky, P. Qvarfordt</span>
<div class="authorList"><span><span class="author">E. Agapie</span> (Harvard Univ., USA)</span><span><span class="author">G. Golovchinsky</span> (FX Palo Alto Laboatory, Inc., USA)</span><span><span class="author">P. Qvarfordt</span> (FX Palo Alto Laboatory, Inc., USA)</span></div>
<p><span class="cbStatement">An experiment to test the effects of halos on query length was conducted. Results suggest that the interface may be effective for eliciting longer queries.  </span><span class="abstract">Although longer queries can produce better results for information seeking tasks, people tend to type short queries. We created an interface designed to encourage people to type longer queries, and evaluated it in two Mechanical Turk experiments. Results suggest that our interface manipulation may be effective for eliciting longer queries.  </span></li>
<li id="PTJ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PTJ"><span class="letterCode" style="float:right">PTJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PTJ">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481306">Exploring the Effects of Space and Place on Engagement with an Interactive Installation</a></span><br />
<span class="authors">I. Akpan (Univ. College London, UK), P. Marshall, J. Bird, D. Harrison</span>
<div class="authorList"><span><span class="author">I. Akpan</span> (Univ. College London, UK)</span><span><span class="author">P. Marshall</span> (Univ. College London, UK)</span><span><span class="author">J. Bird</span> (Univ. College London, UK)</span><span><span class="author">D. Harrison</span> (Univ. College London, UK)</span></div>
<p><span class="cbStatement">We studied how people engaged with the same interactive installation in ten situations with varying spatial and social properties. The main finding across these studies is that place trumps space</span><span class="abstract">Very little research has concurrently explored the influence of both physical space and social context (or place) on the way people engage with a public interactive display. We addressed this issue with a novel approach: studying how people engaged with the same interactive installation in ten situations with varying spatial and social properties. The main finding across these studies is that place trumps space: a conducive social context could overcome a poor physical space and encourage interaction; conversely, an inappropriate social context could inhibit interaction in spaces that might normally facilitate engagement. We discuss this finding in terms of the salience of the display within the space, the visibility of incidental interactions with the installation, the different understandings of place that people can have in the same location and the role of emergent champions and comperes in encouraging interaction.</span></li>
<li id="PPD"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PPD"><span class="letterCode" style="float:right">PPD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PPD">Mon. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470724">Weighted Graph Comparison Techniques for Brain Connectivity Analysis</a></span><br />
<span class="authors">B. Alper (Univ. of California, Santa Barbara, USA), B. Bach, N. Henry Riche, T. Isenberg, J. Fekete</span>
<div class="authorList"><span><span class="author">B. Alper</span> (Univ. of California, Santa Barbara, USA)</span><span><span class="author">B. Bach</span> (INRIA, FR)</span><span><span class="author">N. Henry Riche</span> (Microsoft Research, USA)</span><span><span class="author">T. Isenberg</span> (INRIA, FR)</span><span><span class="author">J. Fekete</span> (INRIA, FR)</span></div>
<p><span class="cbStatement">This paper presents the design and evaluation of two visualizations for comparing weighted graphs. Results have implications for the design of brain connectivity analysis and other graph visualization tools.</span><span class="abstract">The analysis of brain connectivity is a vast field in neuroscience with a frequent use of visual representations and an increasing need for visual analysis tools. Based on an in-depth literature review and interviews with neuroscientists, we explore high-level brain connectivity analysis tasks that need to  be supported by dedicated visual analysis tools. A significant example of such a task is the comparison of different connectivity data in the form of weighted graphs. Several approaches have been suggested for graph comparison within information visualization, but the comparison of weighted graphs has not  been addressed. We explored the design space of applicable visual representations and present augmented adjacency matrix and node-link visualizations. To assess which representation best support weighted graph comparison tasks, we performed a controlled experiment. Our findings suggest that matrices support these tasks well, outperforming node-link diagrams. These results have significant implications for the design of brain connectivity analysis tools that require weighted graph comparisons. They can also inform the design of visual analysis tools in other domains, e.g. comparison of weighted social networks or biological pathways.</span></li>
<li id="PGG"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGG"><span class="letterCode" style="float:right">PGG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGG">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466226">Interaction Techniques for Creating and Exchanging Content with Public Displays</a></span><br />
<span class="authors">F. Alt (Univ. of Stuttgart, DE), A. Sahami, T. Kubitza, A. Schmidt</span>
<div class="authorList"><span><span class="author">F. Alt</span> (Univ. of Stuttgart, DE)</span><span><span class="author">A. Sahami</span> (Univ. of Stuttgart, DE)</span><span><span class="author">T. Kubitza</span> (Univ. of Stuttgart, DE)</span><span><span class="author">A. Schmidt</span> (Univ. of Stuttgart, DE)</span></div>
<p><span class="cbStatement">This paper presents Digifieds, a digital public notice area. We compare interaction techniques for exchanging content with public displays and show that user preferences are based on situation and privacy awareness.</span><span class="abstract">Falling hardware prices and ever more displays being connected to the Internet will lead to large public display networks, potentially forming a novel communication medium. We envision that such networks are not restricted to display owners and advertisers anymore, but allow also passersby (e.g., customers) to exchange content, similar to traditional public notice areas, such as bulletin boards. In this context it is crucial to understand emerging practices and provide easy and straight forward interaction techniques to be used for creating and exchanging content. In this paper, we present Digifieds, a digital public notice area we built to investigate and compare possible interaction techniques. Based on a lab study we show that using direct touch at the display as well as using the mobile phone as a complementing interaction technology are most suitable. Direct touch at the display closely resembles the interaction known from classic bulletin boards and provides the highest usability. Mobile phones preserve the users&#8217; privacy as they exchange (sensitive) data with the display and at the same time allow content to be created on-the-go or to be retrieved. </span></li>
<li id="NJS"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#NJS"><span class="letterCode" style="float:right">NJS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NJS">Tue. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466161">PT Viz: Towards a Wearable Device for Visualizing Knee Rehabilitation Exercises</a></span><br />
<span class="authors">S. Ananthanarayan (Univ. of Colorado, USA), M. Sheh, A. Chien, H. Profita, K. Siek</span>
<div class="authorList"><span><span class="author">S. Ananthanarayan</span> (Univ. of Colorado, USA)</span><span><span class="author">M. Sheh</span> (Univ. of Colorado, USA)</span><span><span class="author">A. Chien</span> (Univ. of Colorado, USA)</span><span><span class="author">H. Profita</span> (Univ. of Colorado, USA)</span><span><span class="author">K. Siek</span> (Univ. of Colorado, USA)</span></div>
<p><span class="cbStatement">PT Viz is a wearable electronic prototype for visualizing knee rehabilitation that was used to explore the needs of physical therapy patients when performing exercises away from the clinic. </span><span class="abstract">We present a wearable sensory display for visualizing knee rehabilitation as part of an in-home physical therapy program. Currently, patients undergoing knee rehabilitation have limited ways of assessing exercise form and extent of movement at home. To address this issue, we developed an exploratory wearable electronic prototype to visualize knee bend. We evaluated the device with physical therapy patients to get feedback on the design and to help us understand some of the challenges they face. We discovered that our current design is better suited for patients recovering from surgery as opposed to patients with chronic conditions.</span></li>
<li id="PPX"class="presentation games"><a href="http://chi2013.acm.org/previews/paper.html#PPX"><span class="letterCode" style="float:right">PPX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PPX">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470764">A Trace-based Framework for Analyzing and Synthesizing Educational Progressions</a></span><br />
<span class="authors">E. Andersen (Univ. of Washington, USA), S. Gulwani, Z. Popovic</span>
<div class="authorList"><span><span class="author">E. Andersen</span> (Univ. of Washington, USA)</span><span><span class="author">S. Gulwani</span> (Microsoft, USA)</span><span><span class="author">Z. Popovic</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">Proposes a framework for using program execution traces to automatically analyze and synthesize progressions of practice problems for any procedural task, focusing on grade-school mathematics and learning games.</span><span class="abstract">A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods.</span></li>
<li id="PAK"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PAK"><span class="letterCode" style="float:right">PAK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PAK">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466143">Learning and Performance with Gesture Guides</a></span><br />
<span class="authors">F. Anderson (Univ. of Alberta, CA), W. Bischof</span>
<div class="authorList"><span><span class="author">F. Anderson</span> (Univ. of Alberta, CA)</span><span><span class="author">W. Bischof</span> (Univ. of Alberta, CA)</span></div>
<p><span class="cbStatement">Existing gesture guides show a tradeoff between performance and learning. A novel guide mitigates this tradeoff. New evaluation methods, and implications for gesture design are proposed.</span><span class="abstract">Gesture-based interfaces are becoming more prevalent and complex, requiring non-trivial learning of gesture sets. Many methods for learning gestures have been proposed, but they are often evaluated with short-term recall tests that measure user performance, rather than learning. We evaluated four types of gesture guides using a retention and transfer paradigm common in motor learning experiments and found results different from those typically reported with recall tests. The results indicate that many guide systems with higher levels of guidance exhibit high performance benefits while the guide is being used, but are ultimately detrimental to user learning. We propose an adaptive guide that does not suffer from these drawbacks, and that enables a smooth transition from novice to expert. The results contrasting learning and performance can be ex-plained by the guidance hypothesis. They have important implications for the design and evaluation of future gesture learning systems.</span></li>
<li id="PAT"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PAT"><span class="letterCode" style="float:right">PAT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAT">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481411">Play it by Ear: A Case for Serendipitous Discovery of Places with Musicons</a></span><br />
<span class="authors">A. Ankolekar (Hewlett Packard, USA), T. Sandholm, L. Yu</span>
<div class="authorList"><span><span class="author">A. Ankolekar</span> (Hewlett Packard, USA)</span><span><span class="author">T. Sandholm</span> (Hewlett Packard, USA)</span><span><span class="author">L. Yu</span> (Pomona College, USA)</span></div>
<p><span class="cbStatement">Field study investigating user performance and emotional engagement of various audio-based cues, especially musicons, during POI discovery. Helps location-based service designers design more enjoyable cues for serendipitous journeys.</span><span class="abstract">Current location-based services (LBS) typically allow users to locate points of interest (POI) in their vicinity but can detract from the user&#8217;s emotional experience of exploring a new location. In this paper, we examine how cues in the form of popular music (musicons) can emotionally engage users and enhance their experience of discovering nearby POIs serendipitously in unfamiliar places. The primary contribution of this paper is a field study, in which we evaluate the performance and emotional engagement of different types of audio-based cues for directing users&#8217; attention to specific POIs. Musicons and mixed-modality cues performed close to visual and speech cues, and significantly better than auditory icons, for POI identification while creating a much more pleasant and engaging user experience. We conclude that cues for POI discovery need not always be as explicit as the baseline visual cues. Indeed, the most challenging cues, auditory icons, led to a heightened sense of autonomy.</span></li>
<li id="PQF"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PQF"><span class="letterCode" style="float:right">PQF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQF">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466144">Your Left Hand Can Do It Too! Investigating Intermanual, Symmetric Gesture Transfer on Touchscreens</a></span><br />
<span class="authors">M. Annett (Univ. of Alberta, CA), W. Bischof</span>
<div class="authorList"><span><span class="author">M. Annett</span> (Univ. of Alberta, CA)</span><span><span class="author">W. Bischof</span> (Univ. of Alberta, CA)</span></div>
<p><span class="cbStatement">This work examines intermanual gesture transfer, i.e., learning a gesture with one hand and performing it with the other. It was found that stroke-based gestures transfer, and do so symmetrically.</span><span class="abstract">This work examines intermanual gesture transfer, i.e., learning a gesture with one hand and performing it with the other. Using a traditional retention and transfer paradigm from the motor learning literature, participants learned four gestures on a touchscreen. The study found that touchscreen gestures transfer, and do so symmetrically. Regardless of the hand used during training, gestures were performed with a comparable level of error and speed by the untrained hand, even after 24 hours. In addition, the form of a gesture, i.e., its length or curvature, was found to have no influence on transferability. These results have important implications for the design of stroke-based ges- tural interfaces: acquisition could occur with either hand and it is possible to interchange the hand used to perform gestures. The work concludes with a discussion of these implications and highlights how they can be applied to ges- ture learning and current gestural systems.</span></li>
<li id="PJM"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PJM"><span class="letterCode" style="float:right">PJM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJM">Tue. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466158">Analyzing User-Generated YouTube Videos to Understand Touchscreen Use by People with Motor Impairments</a></span><br />
<span class="authors">L. Anthony (Univ. of Maryland, Baltimore County, USA), Y. Kim, L. Findlater</span>
<div class="authorList"><span><span class="author">L. Anthony</span> (Univ. of Maryland, Baltimore County, USA)</span><span><span class="author">Y. Kim</span> (Univ. of Maryland, USA)</span><span><span class="author">L. Findlater</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">To inform accessible touchscreen design, we analyzed 187 YouTube videos depicting people with physical disabilities interacting with mobile touchscreen devices. We report on challenges observed and user-initiated adaptations being made.</span><span class="abstract">Most work on the usability of touchscreen interaction for people with motor impairments has focused on lab studies with relatively few participants and small cross-sections of the population. To develop a richer characterization of use, we turned to a previously untapped source of data: YouTube videos. We collected and analyzed 187 non-commercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mainstream mobile touchscreen device. We coded the videos along a range of dimensions to characterize the interaction, the challenges encountered, and the adaptations being adopted in daily use. To complement the video data, we also invited the video uploaders to complete a survey on their ongoing use of touchscreen technology. Our findings show that, while many people with motor impairments find these devices empowering, accessibility issues still exist. In addition to providing implications for more accessible touchscreen design, we reflect on the application of user-generated content to study user interface design.</span></li>
<li id="PHM"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PHM"><span class="letterCode" style="float:right">PHM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PHM">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466221">Tactile Perceptions of Digital Textiles: A Design Research Approach</a></span><br />
<span class="authors">D. Atkinson (Brunel Univ., UK), P. Orzechowski, B. Petreca, N. Bianchi-Berthouze, P. Watkins, S. Baurley, S. Padilla, M. Chantler</span>
<div class="authorList"><span><span class="author">D. Atkinson</span> (Brunel Univ., UK)</span><span><span class="author">P. Orzechowski</span> (Heriot-Watt Univ., UK)</span><span><span class="author">B. Petreca</span> (Brunel Univ., UK)</span><span><span class="author">N. Bianchi-Berthouze</span> (Univ. College London, UK)</span><span><span class="author">P. Watkins</span> (Brunel Univ., UK)</span><span><span class="author">S. Baurley</span> (Brunel Univ., UK)</span><span><span class="author">S. Padilla</span> (Heriot-Watt Univ., UK)</span><span><span class="author">M. Chantler</span> (Heriot-Watt Univ., UK)</span></div>
<p><span class="cbStatement">This paper contributes a methodology to explore the real-life gestures used to understand tactile qualities of deformable materials and re-create their visual and proprioceptive experience in multi-gesture interactive video. </span><span class="abstract">Current interactive media presentations of textiles provide an impoverished communication of their ‘textile hand’, that is their weight, drape, how they feel to touch. These are complex properties experienced through the visual, tactile, auditory and proprioceptive senses and are currently lost when textile materials are presented in interactive video. This paper offers a new perspective from which the production of multi-touch interactive video representations of the tactile qualities of materials is considered. Through an understanding of hand properties of textiles and how people inherently touch and handle them, we are able to develop methods to animate and bring these properties alive using design methods. Observational studies were conducted, noting gestures consumers used to evaluate textile hand. Replicating the appropriate textile deformations for these gestures in interactive video was explored as a design problem. The resulting digital textile swatches and their interactive behavior were then evaluated for their ability to communicate tactile qualities similar to those of the real textiles.</span></li>
<li id="PRD"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PRD"><span class="letterCode" style="float:right">PRD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PRD">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470734">Métamorphe: Augmenting  Hotkey Usage with Actuated Keys</a></span><br />
<span class="authors">G. Bailly (Telekom Innovation Laboratories, TU Berlin, DE), T. Pietrzak, J. Deber, D. Wigdor</span>
<div class="authorList"><span><span class="author">G. Bailly</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span><span><span class="author">T. Pietrzak</span> (Univ. de Lille 1, FR)</span><span><span class="author">J. Deber</span> (Univ. of Toronto, CA)</span><span><span class="author">D. Wigdor</span> (Univ. of Toronto, CA)</span></div>
<p><span class="cbStatement">Demonstrate the advantages of shape-changing keyboards for command selection. The Metamorphe keyboard offers a novel height-changing mechanism that provides haptic feedback and enables new key gestures.</span><span class="abstract">Hotkeys are an efficient method of selecting commands on a keyboard. However, these shortcuts are often underused by users. We present Métamorphe, a novel keyboard with keys that can be individually raised and lowered to promote hotkeys usage. Métamorphe augments the output of traditional keyboards with haptic and visual feedback, and offers a novel design space for user input on raised keys (e.g., gestures such as squeezing or pushing the sides of a key). We detail the implementation of Métamorphe and discuss design factors. We also report two user studies. The first is a user-defined interface study that shows that the new input vocabulary is usable and useful, and provides insights into the mental models that users associate with raised keys. The second user study shows improved eyes-free selection performance for raised keys as well as the surrounding unraised keys.</span></li>
<li id="PSM"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PSM"><span class="letterCode" style="float:right">PSM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PSM">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470665">Augmented Endurance: Controlling Fatigue while Handling Objects by Affecting Weight Perception using Augmented Reality</a></span><br />
<span class="authors">Y. Ban (The Univ. of Tokyo, JP), T. Narumi, T. Fujii, S. Sakurai, J. Imura, T. Tanikawa, M. Hirose</span>
<div class="authorList"><span><span class="author">Y. Ban</span> (The Univ. of Tokyo, JP)</span><span><span class="author">T. Narumi</span> (The Univ. of Tokyo, JP)</span><span><span class="author">T. Fujii</span> (The Univ. of Tokyo, JP)</span><span><span class="author">S. Sakurai</span> (The Univ. of Tokyo, JP)</span><span><span class="author">J. Imura</span> (The Univ. of Tokyo, JP)</span><span><span class="author">T. Tanikawa</span> (The Univ. of Tokyo, JP)</span><span><span class="author">M. Hirose</span> (The Univ. of Tokyo, JP)</span></div>
<p><span class="cbStatement">&#8220;Augmented Endurance&#8221; reveals the implicit effect of augmented reality on our perception of weight and realizes a method to utilize it for human interfaces.</span><span class="abstract">The main contribution of this paper is to develop a method for alleviating fatigue during handling medium-weight objects and augmenting our endurance by affecting our weight perception with augmented reality technology.   To assist people to lift medium-weight objects without a complex structure or various costs, we focus on the phenomenon that our weight perception during handling objects is affected by visual properties.   Our hypothesis is that this illusionary effect in weight perception can be applied to reduce fatigue while handling medium-weight objects without mechatronics-based physical assistance.    In this paper, we propose an augmented reality system that changes the brightness value of an object in order to reduce fatigue while handling the object.   We conducted two fundamental experiments to investigate the effectiveness of the proposed system.   Our results suggested that the system eliminates the need to use excess energy for handling objects and reduces fatigue during the handling task.</span></li>
<li id="PJP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PJP"><span class="letterCode" style="float:right">PJP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJP">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466181">The Effect of Time-based Cost of Error in Target-directed Pointing Tasks</a></span><br />
<span class="authors">N. Banovic (Carnegie Mellon Univ., USA), T. Grossman, G. Fitzmaurice</span>
<div class="authorList"><span><span class="author">N. Banovic</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">T. Grossman</span> (Autodesk Research, CA)</span><span><span class="author">G. Fitzmaurice</span> (Autodesk Research, CA)</span></div>
<p><span class="cbStatement">This paper present a model based on Fitts’ law that predicts the impact of the error cost on the user’s task completion time for target-directed pointing tasks.</span><span class="abstract">One of the fundamental operations in today’s user interfaces is pointing to targets, such as menus, buttons, and text. Making an error when selecting those targets in real-life user interfaces often results in some cost to the user. However, the existing target-directed pointing models do not consider the cost of error when predicting task completion time. In this paper, we present a model based on expected value theory that predicts the impact of the error cost on the user’s completion time for target-directed pointing tasks. We then present a target-directed pointing user study, which results show that time-based costs of error significantly impact the user’s performance. Our results also show that users perform according to an expected completion time utility function and that optimal performance computed using our model gives good prediction of the observed task completion times.</span></li>
<li id="PTH"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PTH"><span class="letterCode" style="float:right">PTH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PTH">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481364">Designing Mobile Health Technology for Bipolar Disorder: A Field Trial of the MONARCA System</a></span><br />
<span class="authors">J. Bardram (IT Univ. of Copenhagen, DK), M. Frost, K. Szántó, M. Faurholt-Jepsen, M. Vinberg, L. Kessing</span>
<div class="authorList"><span><span class="author">J. Bardram</span> (IT Univ. of Copenhagen, DK)</span><span><span class="author">M. Frost</span> (IT Univ. of Copenhagen, DK)</span><span><span class="author">K. Szántó</span> (IT Univ. of Copenhagen, DK)</span><span><span class="author">M. Faurholt-Jepsen</span> (Univ. Hospital of Copenhagen, DK)</span><span><span class="author">M. Vinberg</span> (Univ. Hospital of Copenhagen, DK)</span><span><span class="author">L. Kessing</span> (Univ. Hospital of Copenhagen, DK)</span></div>
<p><span class="cbStatement">We conducted a 14 week field trial of the MONARCA system with 12 patients, reporting on their experiences. Furthermore, the paper discusses three questions regarding design of personal health technologies.</span><span class="abstract">An increasing number of pervasive healthcare systems are being designed, that allow people to monitor and get feedback on their health and wellness. To address the challenges of self-management of mental illnesses, we have developed the MONARCA system – a personal monitoring system for bipolar patients. We conducted a 14 week field trial in which 12 patients used the system, and we report findings focusing on their experiences. The results were positive; compared to using paper-based forms, the adherence to self-assessment improved; the system was considered very easy to use; and the perceived usefulness of the system was high. Based on this study, the paper discusses three HCI questions related to the design of personal health technologies; how to design for disease awareness and self-treatment, how to ensure adherence to personal health technologies, and the roles of different types of technology platforms.</span></li>
<li id="PHQ"class="presentation design arts"><a href="http://chi2013.acm.org/previews/paper.html#PHQ"><span class="letterCode" style="float:right">PHQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PHQ">Thu. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466451">What is &#8220;Critical&#8221; About Critical Design?</a></span><br />
<span class="authors">J. Bardzell (Indiana Univ. Bloomington, USA), S. Bardzell</span>
<div class="authorList"><span><span class="author">J. Bardzell</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">S. Bardzell</span> (Indiana Univ. Bloomington, USA)</span></div>
<p><span class="cbStatement">We provide a critique of Critical Design and propose a broader, more practical reframing, based on humanistic scholarship on critical theory and criticism.</span><span class="abstract">Critical design is a research through design methodology that foregrounds the ethics of design practice, reveals potentially hidden agendas and values, and explores alternative design values. While it seems to be a timely fit for today’s socially, aesthetically, and ethically oriented approaches to HCI, its adoption seems surprisingly limited. We argue that its central concepts and methods are unclear and difficult to adopt. Rather than merely attempting to decode the intentions of its originators, Dunne and Raby, we instead turn to traditions of critical thought in the past 150 years to explore a range of critical ideas and their practical uses. We then suggest ways that these ideas and uses can be leveraged as practical resources for HCI researchers interested in critical design. We also offer readings of two designs, which are not billed as critical designs, but which we argue are critical using a broader formulation of the concept than the one found in the current literature. </span></li>
<li id="NHJ"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NHJ"><span class="letterCode" style="float:right">NHJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NHJ">Tue. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466258">DesignLibs: A Scenario-Based Design Method for Ideation</a></span><br />
<span class="authors">J. Bauer (Univ. of Washington, USA), J. Kientz</span>
<div class="authorList"><span><span class="author">J. Bauer</span> (Univ. of Washington, USA)</span><span><span class="author">J. Kientz</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">This note provides a study of a new design method we developed called “DeisgnLibs”. DesignLibs is an ideation technique with potential users inspired by the children’s game Mad Libs.</span><span class="abstract">Generating potential design ideas through ideation often benefits from the spontaneity of random ideas. Having po-tential users participate in this process can be beneficial, but is often difficult to implement. We present a new method for generating design ideas with potential users. The meth-od uses scenarios with missing words, which potential users fill in to generate ideas for features and attributes of new technology designs, similar to the children’s game of Mad Libs. We developed three different formats of DesignLibs, including 1) “Mad Libs-style:” blanks presented before seeing the scenario, 2) “Fill-in-the-Blanks:” blanks present-ed within the context of the scenario, and 3) “Q&#038;A:” blanks presented as questions and answers. We found that Design-Libs generated a number of new ideas, with the Fill-in-the-Blanks method providing the highest ratings for usefulness, feasibility, and diversity of answers. All three formats pro-vided equal ratings for creativity.</span></li>
<li id="PJJ"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PJJ"><span class="letterCode" style="float:right">PJJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PJJ">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466446">Limiting, Leaving, and (re)Lapsing: An Exploration of Facebook Non-Use Practices and Experiences</a></span><br />
<span class="authors">E. Baumer (Cornell Univ., USA), P. Adams, V. Khovanskaya, T. Liao, M. Smith, V. Schwanda Sosik, K. Williams</span>
<div class="authorList"><span><span class="author">E. Baumer</span> (Cornell Univ., USA)</span><span><span class="author">P. Adams</span> (Cornell Univ., USA)</span><span><span class="author">V. Khovanskaya</span> (Cornell Univ., USA)</span><span><span class="author">T. Liao</span> (Cornell Univ., USA)</span><span><span class="author">M. Smith</span> (Northwestern Univ., USA)</span><span><span class="author">V. Schwanda Sosik</span> (Cornell Univ., USA)</span><span><span class="author">K. Williams</span> (Cornell Univ., USA)</span></div>
<p><span class="cbStatement">This paper reports on a survey about non-use of Facebook. Results show the prevalence of non-use, the variety of types of non-use, and motivations and justifications given for non-use.</span><span class="abstract">Despite the abundance of research on social networking sites, relatively little research has studied those who choose not to use such sites. This paper presents results from a questionnaire of over 400 Internet users, focusing specifically on Facebook and those users who have left the service. Results show the lack of a clear, binary distinction between use and non-use, that various practices enable diverse ways and degrees of engagement with and disengagement from Facebook. Furthermore, qualitative analysis reveals numerous complex and interrelated motivations and justifications, both for leaving and for maintaining some type of connection. These motivations include: privacy, data misuse, productivity, banality, addiction, and external pressures. These results not only contribute to our understanding of online sociality by examining this under-explored area, but they also build on previous work to help advance how we conceptually account for the sociological processes of non-use.</span></li>
<li id="NJF"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NJF"><span class="letterCode" style="float:right">NJF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NJF">Wed. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481419">Pirates of the Search Results Page</a></span><br />
<span class="authors">K. Baxter (Google, Inc., USA), L. Malahy, J. Lubin</span>
<div class="authorList"><span><span class="author">K. Baxter</span> (Google, Inc., USA)</span><span><span class="author">L. Malahy</span> (Univ. of Washington, USA)</span><span><span class="author">J. Lubin</span> (Capriza, USA)</span></div>
<p><span class="cbStatement">Usability evaluation and interview findings provide insight into users’ experiences, behaviors, and self-blame in response to search malware; suggests domain familiarity is not enough to recognize a malware-impaired experience.</span><span class="abstract">Search malware redirects nearly 100% of infected users’ clicks on web search results to unintended websites. Most published research details how web-based malware works and technological interventions to stop it before users ever see it; however, the constant evolution of obfuscation techniques makes it difficult to prevent infection altogether. User interventions in the form of toolbars, dialogs, and user education have seen limited success. Previous research has focused on a prototypical type of malware; a sophisticated program that conceals itself (e.g., surreptitious download onto a host computer) or tries to fool the user by mimicking known, trusted websites (e.g., phishing attacks). The goal of our research is to understand users’ experience, understanding of and response to search malware. The present research shows that even when confronted with blatantly unusual search behavior, people are unlikely to attribute blame to malware or to engage in behavior that may remedy the situation.</span></li>
<li id="NJX"class="presentation design ux health"><a href="http://chi2013.acm.org/previews/paper.html#NJX"><span class="letterCode" style="float:right">NJX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NJX">Tue. 9am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466140">The Power of Mobile Notifications to Increase Wellbeing Logging Behavior</a></span><br />
<span class="authors">F. Bentley (Motorola Mobility Inc., USA), K. Tollmar</span>
<div class="authorList"><span><span class="author">F. Bentley</span> (Motorola Mobility Inc., USA)</span><span><span class="author">K. Tollmar</span> (KTH, SE)</span></div>
<p><span class="cbStatement">We demonstrate the power of passive mobile notifications to increase logging of wellbeing data, particularly food intake, in a mobile health service by 5x.</span><span class="abstract">Self-logging is a critical component to many wellbeing systems. However, self-logging often is difficult to sustain at regular intervals over many weeks. We demonstrate the power of passive mobile notifications to increase logging of wellbeing data, particularly food intake, in a mobile health service. Adding notifications increased the frequency of logging from 12% in a one-month, ten-user pilot study without reminders to 63% in the full 60-user study with reminders included. We will discuss the benefits of passive notifications over existing interruptive methods.</span></li>
<li id="PDH"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PDH"><span class="letterCode" style="float:right">PDH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PDH">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470658">Quantifying the Invisible Audience in Social Networks</a></span><br />
<span class="authors">M. Bernstein (Stanford Univ., USA), E. Bakshy, M. Burke, B. Karrer</span>
<div class="authorList"><span><span class="author">M. Bernstein</span> (Stanford Univ., USA)</span><span><span class="author">E. Bakshy</span> (Facebook, Inc., USA)</span><span><span class="author">M. Burke</span> (Facebook, Inc., USA)</span><span><span class="author">B. Karrer</span> (Facebook, Inc., USA)</span></div>
<p><span class="cbStatement">When you share content in a social network, who is listening? We combine survey and log data to examine how well users&#8217; audience perceptions match their true audience on Facebook.</span><span class="abstract">When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users&#8217; perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000 Facebook users&#8217; posts over the course of one month and find that publicly visible signals &#8212; friend count, likes, and comments &#8212; vary widely and do not strongly indicate the audience of a single post. Despite the variation, users typically reach 61% of their friends each month. Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.</span></li>
<li id="PTD"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PTD"><span class="letterCode" style="float:right">PTD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTD">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466228">Squaring the Circle: How Framing Influences User Behavior around a Seamless Cylindrical Display</a></span><br />
<span class="authors">G. Beyer (Univ. of Munich (LMU), DE), F. Köttner, M. Schiewe, I. Haulsen, A. Butz</span>
<div class="authorList"><span><span class="author">G. Beyer</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">F. Köttner</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">M. Schiewe</span> (Fraunhofer FOKUS, DE)</span><span><span class="author">I. Haulsen</span> (Fraunhofer FOKUS, DE)</span><span><span class="author">A. Butz</span> (Univ. of Munich (LMU), DE)</span></div>
<p><span class="cbStatement">Analyzes user behavior around a cylindrical and seamless interactive column display in the wild. Helps to better understand how framing influences user positions around more complex non-planar display shapes.</span><span class="abstract">Recent research has presented large public displays in novel non-flat shapes such as spheres, curved planes and cylinders, and looked at the influence of the form factor on user behavior. Yet, the basic shape cannot be considered in isolation when interpreting the behavior of passers-by around such displays. In this paper we investigate two further display factors, framedness and seamlessness, that have to be considered in conjunction with the form factor to understand user behavior in front of large non-flat displays. We present the findings from a field study with an interactive column display and take a closer look at how these factors influence actor and bystander behavior. Our results show that rectangular frames act as a sort of funnel for user position and can easily override effects of the non-flat shape on user position and interaction, even though the users didn’t recall the presence of these frames.</span></li>
<li id="PNB"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PNB"><span class="letterCode" style="float:right">PNB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNB">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466180">FFitts Law: Modeling Finger Touch with Fitts’ Law</a></span><br />
<span class="authors">X. Bi (Google, Inc., USA), Y. Li, S. Zhai</span>
<div class="authorList"><span><span class="author">X. Bi</span> (Google, Inc., USA)</span><span><span class="author">Y. Li</span> (Google Research, USA)</span><span><span class="author">S. Zhai</span> (Google, Inc., USA)</span></div>
<p><span class="cbStatement">Proposed and validated a dual Gaussian distribution hypothesis, from which we derived FFitts law, a novel expansion of Fitts’ law to more reliably model touchscreen target acquisition with finger.</span><span class="abstract">Fitts’ law has proven to be a strong predictor of pointing performance under a wide range of conditions. However, it has been insufficient in modeling small-target acquisition with finger-touch based input on screens. We propose a dual-distribution hypothesis to interpret the distribution of the endpoints in finger touch input. We hypothesize the movement endpoint distribution as a sum of two independent normal distributions. One distribution reflects the relative precision governed by the speed-accuracy tradeoff rule in the human motor system, and the other captures the absolute precision of finger touch independent of the speed-accuracy tradeoff effect. Based on this hypothesis, we derived the FFitts model—an expansion of Fitts’ law for finger touch input. We present three experiments in 1D target acquisition, 2D target acquisition and touchscreen keyboard typing tasks respectively. The results showed that FFitts law is more accurate than Fitts’ law in modeling finger input on touchscreens. At 0.91 or a greater R2 value, FFitts’ index of difficulty is able to account for significantly more variance than conventional Fitts’ index of difficulty based on either a nominal target width or an effective target width in all the three experiments. </span></li>
<li id="PLN"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PLN"><span class="letterCode" style="float:right">PLN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PLN">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470732">Octopus: Evaluating Touchscreen Keyboard Correction and Recognition Algorithms via “Remulation”</a></span><br />
<span class="authors">X. Bi (Google, Inc., USA), S. Azenkot, K. Partridge, S. Zhai</span>
<div class="authorList"><span><span class="author">X. Bi</span> (Google, Inc., USA)</span><span><span class="author">S. Azenkot</span> (Univ. of Washington, USA)</span><span><span class="author">K. Partridge</span> (Google, Inc., USA)</span><span><span class="author">S. Zhai</span> (Google, Inc., USA)</span></div>
<p><span class="cbStatement">Proposed and tested remulation, an efficient method for evaluating touchscreen keyboards by replicating prior user study data in real-time, on-device simulation. Implemented Octopus, a remulation-based evaluation tool.</span><span class="abstract">The time and labor demanded by a typical laboratory-based keyboard evaluation are limiting resources for algorithmic adjustment and optimization. We propose Remulation, a complementary method for evaluating touchscreen keyboard correction and recognition algorithms. It replicates prior user study data through real-time, on-device simulation. We have developed Octopus, a Remulation-based evaluation tool that enables keyboard developers to efficiently measure and inspect the impact of algorithmic changes without conducting resource-intensive user studies. It can also be used to evaluate third-party keyboards in a “black box” fashion, without access to their algorithms or source code. Octopus can evaluate both touch keyboards and word-gesture keyboards. Two empirical examples show that Remulation can efficiently and effectively measure many aspects of touch screen keyboards at both macro and micro levels. Additionally, we contribute two new metrics to measure keyboard accuracy at the word level: the Ratio of Error Reduction (RER) and the Word Score. </span></li>
<li id="PAL"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PAL"><span class="letterCode" style="float:right">PAL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PAL">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466198">A Matter of Life and Death: Practical and Ethical Constraints in the Development of a Mobile Verbal Autopsy Tool</a></span><br />
<span class="authors">J. Bird (Univ. College London, UK), P. Byass, K. Kahn, P. Mee, E. Fottrell</span>
<div class="authorList"><span><span class="author">J. Bird</span> (Univ. College London, UK)</span><span><span class="author">P. Byass</span> (Umeå Univ., SE)</span><span><span class="author">K. Kahn</span> (Univ. of the Witwatersrand, ZA)</span><span><span class="author">P. Mee</span> (Univ. of the Witwatersrand, ZA)</span><span><span class="author">E. Fottrell</span> (Univ. College London, UK)</span></div>
<p><span class="cbStatement">We describe the ethical issues raised by the field study of a mobile verbal autopsy device that identifies the probable cause of death from interviewing relatives of the deceased. </span><span class="abstract">Verbal autopsy (VA) involves interviewing relatives of the deceased to identify the probable cause of death and is typically used in settings where there is no official system for recording deaths or their causes. Following the interview, physician assessment to determine probable cause can take several years to complete.  The World Health Organization (WHO) recognizes that there is a pressing need for a mobile device that combines direct data capture and analysis if this technique is to become part of routine health surveillance. We conducted a field test in rural South Africa to evaluate a mobile system that we designed to meet WHO requirements (namely, simplicity, feasibility, adaptability to local contexts, cost-effectiveness and program relevance). If desired, this system can provide immediate feedback to respondents about the probable cause of death at the end of a VA interview. We assessed the ethical implications of this technological development by interviewing all the stakeholders in the VA process (respondents, fieldworkers, physicians, population scientists, data managers and community engagement managers) and highlight the issues that this community needs to debate and resolve.</span></li>
<li id="PGK"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGK"><span class="letterCode" style="float:right">PGK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PGK">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470752">Control Your Game-Self: Effects of Controller Type on Enjoyment, Motivation, and Personality in Game</a></span><br />
<span class="authors">M. Birk (Univ. of Saskatchewan, CA), R. Mandryk</span>
<div class="authorList"><span><span class="author">M. Birk</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">R. Mandryk</span> (Univ. of Saskatchewan, CA)</span></div>
<p><span class="cbStatement">We show that controller choice affects a player’s enjoyment and motivation of a game, but also affects a player’s perception of themselves during play as measured by their in-game personality.</span><span class="abstract">Whether they are made to entertain you, or to educate you, good video games engage you. Significant research has tried to understand engagement in games by measuring player experience (PX). Traditionally, PX evaluation has focused on the enjoyment of game, or the motivation of players; these factors no doubt contribute to engagement, but do decisions regarding play environment (e.g., the choice of game controller) affect the player more deeply than that? We apply self-determination theory (specifically satisfaction of needs and self-discrepancy represented using the five factors model of personality) to explain PX in an experiment with controller type as the manipulation. Our study shows that there are a number of effects of controller on PX and in-game player personality. These findings provide both a lens with which to view controller effects in games and a guide for controller choice in the design of new games. Our research demonstrates that including self-characteristics assessment in the PX evaluation toolbox is valuable and useful for understanding player experience.</span></li>
<li id="PCE"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PCE"><span class="letterCode" style="float:right">PCE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCE">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481404">Using Behavioral Data to Identify Interviewer Fabrication in Surveys</a></span><br />
<span class="authors">B. Birnbaum (Univ. of Washington, USA), G. Borriello, A. Flaxman, B. DeRenzi, A. Karlin</span>
<div class="authorList"><span><span class="author">B. Birnbaum</span> (Univ. of Washington, USA)</span><span><span class="author">G. Borriello</span> (Univ. of Washington, USA)</span><span><span class="author">A. Flaxman</span> (Univ. of Washington, USA)</span><span><span class="author">B. DeRenzi</span> (Univ. of Washington, USA)</span><span><span class="author">A. Karlin</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">We show that by instrumenting electronic data-collection software to record logs of behavioral data, and by using supervised classification on this data, we can accurately detect interviewer fabrication in surveys.</span><span class="abstract">Surveys conducted by human interviewers are one of the principal means of gathering data from all over the world, but the quality of this data can be threatened by interviewer fabrication. In this paper, we investigate a new approach to detecting interviewer fabrication automatically. We instrument electronic data collection software to record logs of low-level behavioral data and show that supervised classification, when applied to features extracted from these logs, can identify interviewer fabrication with an accuracy of up to 96%.  We show that even when interviewers know that our approach is being used, have some knowledge of how it works, and are incentivized to avoid detection, it can still achieve an accuracy of 86%. We also demonstrate the robustness of our approach to a moderate amount of label noise and provide practical recommendations, based on empirical evidence, on how much data is needed for our approach to be effective.</span></li>
<li id="PNV"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PNV"><span class="letterCode" style="float:right">PNV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNV">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466123">Write Here, Write Now!: An Experimental Study of Group Maintenance in Collaborative Writing</a></span><br />
<span class="authors">J. Birnholtz (Northwestern Univ., USA), S. Steinhardt, A. Pavese</span>
<div class="authorList"><span><span class="author">J. Birnholtz</span> (Northwestern Univ., USA)</span><span><span class="author">S. Steinhardt</span> (Cornell Univ., USA)</span><span><span class="author">A. Pavese</span> (Google, Inc., USA)</span></div>
<p><span class="cbStatement">We present a laboratory study of dyads writing together. Results suggest that communication via comments and chat is positively related to social outcomes in synchronous, but not asynchronous, writing.</span><span class="abstract">Writing documents together using collaborative editing tools has become extremely common with the widespread availability of tools such as Google Docs. The design of such tools, rooted in early CSCW research, has historically been focused on providing awareness of the presence and activities of one’s collaborators. Evidence from a recent qualitative study, however, suggests that people are also concerned about how their behaviors – and they themselves – will be perceived by others; and take steps to mitigate possible negative perceptions. We present an experimental study of dyads composing documents together, focusing in particular on group maintenance, impression management and relationship-focused behavior. Results suggest that communication is positively related to social relations, but only for synchronous writing in a shared space; the reverse can be true in asynchronous commenting and editing. </span></li>
<li id="NSN"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NSN"><span class="letterCode" style="float:right">NSN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NSN">Mon. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470767">Tweeting for Class: Co-Construction as a Means for Engaging Students in Lectures</a></span><br />
<span class="authors">J. Birnholtz (Northwestern Univ., USA), J. Hancock, D. Retelny</span>
<div class="authorList"><span><span class="author">J. Birnholtz</span> (Northwestern Univ., USA)</span><span><span class="author">J. Hancock</span> (Cornell Univ., USA)</span><span><span class="author">D. Retelny</span> (Stanford Univ., USA)</span></div>
<p><span class="cbStatement">We present a case study of students in a lecture course using Twitter to contribute instructional content. Results show that students enjoyed this and primarily contributed examples and asked questions.</span><span class="abstract">Motivating students to be active learners is a perennial problem in education, and is particularly challenging in lectures where instructors typically prepare content in ad-vance with little direct student participation. We describe our experience using Twitter as a tool for student “co-construction” of lecture materials. Students were required to post a tweet prior to each lecture related to that day’s topic, and these tweets – consisting of questions, examples and reflections – were incorporated into the lecture slides and notes.  Students reported that they found lectures including their tweets in the class slides to be engaging, interactive and relevant, and nearly 90% of them recommended we use our co-construction approach again.</span></li>
<li id="PHC"class="presentation design ux arts"><a href="http://chi2013.acm.org/previews/paper.html#PHC"><span class="letterCode" style="float:right">PHC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PHC">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470674">Unlimited Editions: Three Approaches to the Dissemination and Display of Digital Art</a></span><br />
<span class="authors">M. Blythe (Northumbria Univ., UK), J. Briggs, J. Hook, P. Wright, P. Olivier</span>
<div class="authorList"><span><span class="author">M. Blythe</span> (Northumbria Univ., UK)</span><span><span class="author">J. Briggs</span> (Northumbria Univ., UK)</span><span><span class="author">J. Hook</span> (Newcastle Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">Three approaches to digital art are explored: in “s[editon]” a limited digital editions website, the iPad “Brushes” Gallery and a field study using digital frames and an immersive projection room.</span><span class="abstract">The paper reflects on three approaches to the dissemination and display of digital art. “s[edition]” is a novel, web-based service that offers limited editions of “digital prints”. Analysis of user comments suggests that the metaphor of a “limited digital edition” raises issues and to some extent is resisted. The second approach is the Flickr Brushes Gallery, where digital painters post images and comment on one another’s work. Analysis of comment boards indicates that the shared art and comments are a form of gift exchange. Finally, the paper discusses a field study in which artists exhibited their work as it develops over time in digital frames and also in an immersive digital projection room. Analysis of field notes and interviews indicate that the digital frame approach was unsuccessful because of aesthetic and environmental concerns. The immersive projection suggested that more experiential approaches may be more interesting. It is argued that there is an inherent resistance in digital media to previous models of art commoditization. None of the approaches discussed here resolve the dilemma but rather indicate the scope and complexity of the issues.</span></li>
<li id="NPP"class="presentation design health games"><a href="http://chi2013.acm.org/previews/paper.html#NPP"><span class="letterCode" style="float:right">NPP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NPP">Tue. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466160">Stroke Rehabilitation with a Sensing Surface</a></span><br />
<span class="authors">C. Boulanger (Microsoft Applied Sciences Group, USA), A. Boulanger, L. de Greef, A. Kearney, K. Sobel, R. Transue, Z. Sweedyk, P. Dietz, S. Bathiche</span>
<div class="authorList"><span><span class="author">C. Boulanger</span> (Microsoft Applied Sciences Group, USA)</span><span><span class="author">A. Boulanger</span> (Hear for Yourself, USA)</span><span><span class="author">L. de Greef</span> (Harvey Mudd College, USA)</span><span><span class="author">A. Kearney</span> (Harvey Mudd College, USA)</span><span><span class="author">K. Sobel</span> (Harvey Mudd College, USA)</span><span><span class="author">R. Transue</span> (Harvey Mudd College, USA)</span><span><span class="author">Z. Sweedyk</span> (Harvey Mudd College, USA)</span><span><span class="author">P. Dietz</span> (Microsoft, USA)</span><span><span class="author">S. Bathiche</span> (Microsoft, USA)</span></div>
<p><span class="cbStatement">We propose a multisensory environment that tracks movements on a sensing platform for patients with a spectrum of cognitive and physical ability. Our study elaborates an interaction model that motivates patients in continued therapeutic engagement.  </span><span class="abstract">This paper presents a new sensing and interaction environment for post-stroke and upper extremity limb rehabilitation.  The device is a combination of camera-based multitouch sensing and a supporting therapeutic software application that advances the treatment, provides feedback, and records a user’s progress. The image-based analysis of hand position provided by a Microsoft Surface is used as an input into a tabletop game environment. Tailored image analysis algorithms assess rehabilitative hand movements. Visual feedback is provided in a game context. Experiments were conducted in a sub-acute rehabilitation center. Preliminary user studies with a stroke-afflicted population determined essential design criteria.  Hand and wrist sensing, as well as the goals of the supporting game environment, engage therapeutic flexion and extension as defined by consulted physicians.  Participants valued personalization of the activity, novelty, reward and the ability to work at their own pace in an otherwise repetitive therapeutic task.  A “character” – game element personifying the participant’s movement – was uniquely motivating relative to the media available in the typical therapeutic routine.</span></li>
<li id="PKL"class="presentation design games"><a href="http://chi2013.acm.org/previews/paper.html#PKL"><span class="letterCode" style="float:right">PKL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PKL">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466202">Prototyping in PLACE: A Scalable Approach to Developing Location-Based Apps and Games</a></span><br />
<span class="authors">A. Bowser (Univ. of Maryland, USA), D. Hansen, J. Raphael, M. Reid, R. Gamett, Y. He, D. Rotman, J. Preece</span>
<div class="authorList"><span><span class="author">A. Bowser</span> (Univ. of Maryland, USA)</span><span><span class="author">D. Hansen</span> (Brigham Young Univ., USA)</span><span><span class="author">J. Raphael</span> (Brigham Young Univ., USA)</span><span><span class="author">M. Reid</span> (Brigham Young Univ., USA)</span><span><span class="author">R. Gamett</span> (Brigham Young Univ., USA)</span><span><span class="author">Y. He</span> (Univ. of Maryland, USA)</span><span><span class="author">D. Rotman</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Preece</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">PLACE is a framework for prototyping location-based apps and games that considers location, activities, and collective experience over time.  PLACE is evaluated with Floracaching, a Geocaching game for citizen science.  </span><span class="abstract">The rising popularity of location-based applications and games (LBAGs) that break spatial, temporal, and social boundaries creates new challenges for designers. This paper introduces PLACE, an iterative, mixed-fidelity approach to Prototyping Location, Activities, Collective experience, and Experience over time in LBAGs. PLACE consists of 6 design principles: start small and scale up the fidelity, treat participants as co-designers, test in a representative space, focus on activities more than interfaces, respect authentic social experience, and represent time authentically. The effectiveness of PLACE was evaluated by prototyping   Floracaching, a geocaching game for citizen science. This revealed the types of insights that PLACE provides, best practices for implementing PLACE, and how PLACE com-pares to other prototyping methods.</span></li>
<li id="PHX"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHX"><span class="letterCode" style="float:right">PHX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PHX">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481291">Visual Challenges in the Everyday Lives of Blind People</a></span><br />
<span class="authors">E. Brady (Univ. of Rochester, USA), M. Morris, Y. Zhong, S. White, J. Bigham</span>
<div class="authorList"><span><span class="author">E. Brady</span> (Univ. of Rochester, USA)</span><span><span class="author">M. Morris</span> (Microsoft Research, USA)</span><span><span class="author">Y. Zhong</span> (Univ. of Rochester, USA)</span><span><span class="author">S. White</span> (Univ. of Rochester, USA)</span><span><span class="author">J. Bigham</span> (Univ. of Rochester, USA)</span></div>
<p><span class="cbStatement">Our results improve the understanding of the visual problems blind people face everyday by examining a sample of the 40,000 questions asked by blind VizWiz Social users.</span><span class="abstract">The challenges faced by blind people in their everyday lives are not well understood. In this paper, we report on the findings of a large-scale study of the visual questions that blind people would like to have answered. As part of this year-long study, 5,329 blind users asked 40,748 questions about photographs that they took from their iPhones using an application called VizWiz Social. We present a taxonomy of the types of questions asked, report on a number of features of the questions and accompanying photographs, and discuss how individuals changed how they used VizWiz Social over time. These results improve our understanding of the problems blind people face, and may help motivate new projects more accurately targeted to help blind people live more independently in their everyday lives.</span></li>
<li id="PEU"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PEU"><span class="letterCode" style="float:right">PEU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PEU">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466208">MultiNet: Reducing Interaction Overhead in Domestic Wireless Networks</a></span><br />
<span class="authors">A. Brown (The Univ. of Nottingham, UK), R. Mortier, T. Rodden</span>
<div class="authorList"><span><span class="author">A. Brown</span> (The Univ. of Nottingham, UK)</span><span><span class="author">R. Mortier</span> (The Univ. of Nottingham, UK)</span><span><span class="author">T. Rodden</span> (The Univ. of Nottingham, UK)</span></div>
<p><span class="cbStatement">A novel method for securely associating devices with domestic wireless networks. Where the interaction is lightweight and consistent across all devices; improving usability, decreasing interaction overhead and enabling access revocation.</span><span class="abstract">We present MultiNet, a novel method for securely associating devices with a domestic wireless network. We show that MultiNet has usability benefits over currently deployed commercial solutions while being backwards compatible with existing devices. MultiNet reduces the interaction overhead of secure association by focusing on users&#8217; interactions rather than the network&#8217;s requirements. This leads to a novel architectural arrangement of the home network infrastructure: the network is dynamically re-configured to accept each pre-configured device, rather than the current norm where each device is configured to be acceptable to the pre-configured network. Assuming devices are pre-configured for a unique, device-specific network name and passphrase, MultiNet constructs an out-of-band visual channel via an intermediary network controller device to convey the device&#8217;s configuration to the network. This makes the interaction to join a device to the wireless network lightweight and identical across all devices, considerably reducing the interaction overheads for users.</span></li>
<li id="PFZ"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PFZ"><span class="letterCode" style="float:right">PFZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PFZ">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466132">iPhone In Vivo: Video Analysis of Mobile Device Use</a></span><br />
<span class="authors">B. Brown (Mobile Life @ Stockholm Univ., SE), M. McGregor, E. Laurier</span>
<div class="authorList"><span><span class="author">B. Brown</span> (Mobile Life @ Stockholm Univ., SE)</span><span><span class="author">M. McGregor</span> (City Univ. London, UK)</span><span><span class="author">E. Laurier</span> (Univ. of Edinburgh, UK.University of Edinburgh)</span></div>
<p><span class="cbStatement">This paper uses video data to gain new insight into the use of mobile computing devices. Our new method combines screen-capture of iPhone use with video recordings from wearable cameras. </span><span class="abstract">Despite the widespread use of mobile devices, details of mobile technology use ‘in the wild’ have proven difficult to collect. This paper uses video data to gain new insight into the use of mobile computing devices. Our new method combines screen-capture of iPhone use with video recordings from wearable cameras. We use this data to analyse how mobile device use is threaded into other co-present activities, focusing on the use of maps and internet searches. Close analysis reveals novel aspects of gestures on touch screens, how they serve ‘double duty” &#8211; both as interface gestures but as as resources for ongoing joint action. We go on to describe how users ‘walk the blue dot’ to orientate themselves, and how searches are occasioned by the local environment. In conclusion, we argue that mobile devices &#8211; rather than pushing us away from the world around us &#8211; are instead just another thread in the complex tapestry of everyday interaction.  </span></li>
<li id="PJK"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PJK"><span class="letterCode" style="float:right">PJK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PJK">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470757">GravitySpace: Tracking Users and Their Poses in a Smart Room Using a Pressure-Sensing Floor</a></span><br />
<span class="authors">A. Bränzel (Hasso Plattner Institute, DE), C. Holz, D. Hoffmann, D. Schmidt, M. Knaust, P. Lühne, R. Meusel, S. Richter, P. Baudisch</span>
<div class="authorList"><span><span class="author">A. Bränzel</span> (Hasso Plattner Institute, DE)</span><span><span class="author">C. Holz</span> (Hasso Plattner Institute, DE)</span><span><span class="author">D. Hoffmann</span> (Hasso Plattner Institute, DE)</span><span><span class="author">D. Schmidt</span> (Hasso Plattner Institute, DE)</span><span><span class="author">M. Knaust</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Lühne</span> (Hasso Plattner Institute, DE)</span><span><span class="author">R. Meusel</span> (Hasso Plattner Institute, DE)</span><span><span class="author">S. Richter</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Baudisch</span> (Hasso Plattner Institute, DE)</span></div>
<p><span class="cbStatement">Introduces new approach to tracking people and objects in smart rooms based on a high-resolution pressure-sensitive floor. Provides consistent wall-to-wall coverage, is less susceptible and less privacy-critical than camera-based systems.</span><span class="abstract">We explore how to track people and furniture based on a high-resolution pressure-sensitive floor. Gravity pushes people and objects against the floor, causing them to leave imprints of pressure distributions across the surface. While the sensor is limited to sensing direct contact with the surface, we can sometimes conclude what takes place above the surface, such as users’ poses or collisions with virtual objects. We demonstrate how to extend the range of this approach by sensing through passive furniture that propagates pressure to the floor. To explore our approach, we have created an 8 m2 back-projected floor prototype, termed GravitySpace, a set of passive touch-sensitive furniture, as well as algorithms for identifying users, furniture, and poses. Pressure-based sensing on the floor offers four potential benefits over camera-based solutions: (1) it provides consistent coverage of rooms wall-to-wall, (2) is less susceptible to occlusion between users, (3) allows for the use of simpler recognition algorithms, and (4) intrudes less on users’ privacy.</span></li>
<li id="NAR"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NAR"><span class="letterCode" style="float:right">NAR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NAR">Mon. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470697">EyeContext: Recognition of High-level Contextual Cues from Human Visual Behaviour</a></span><br />
<span class="authors">A. Bulling (Max Planck Institute for Informatics, DE), C. Weichel, H. Gellersen</span>
<div class="authorList"><span><span class="author">A. Bulling</span> (Max Planck Institute for Informatics, DE)</span><span><span class="author">C. Weichel</span> (Lancaster Univ., UK)</span><span><span class="author">H. Gellersen</span> (Lancaster Univ., UK)</span></div>
<p><span class="cbStatement">We present EyeContext, a system to automatically infer high-level contextual cues from visual behaviour. We demonstrate the large information content available in long-term visual behaviour that&#8217;s potentially useful for eye-based behavioural monitoring or life logging.</span><span class="abstract">In this work we present EyeContext, a system to infer high-level contextual cues from human visual behaviour. We conducted a user study to record eye movements of four participants over a full day of their daily life, totalling 42.5 hours of eye movement data. Participants were asked to self-annotate four non-mutually exclusive cues: social (interacting with somebody vs. no interaction), cognitive (concentrated work vs. leisure), physical (physically active vs. not active), and spatial (inside vs. outside a building). We evaluate a proof-of-concept EyeContext system that combines encoding of eye movements into strings and a spectrum string kernel support vector machine (SVM) classifier. Our results demonstrate the large information content available in long-term human visual behaviour and opens up new venues for research on eye-based behavioural monitoring and life logging.</span></li>
<li id="PSJ"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PSJ"><span class="letterCode" style="float:right">PSJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PSJ">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481294">A Study on Icon Arrangement by Smartphone Users</a></span><br />
<span class="authors">M. Böhmer (German Research Center for Artificial Intelligence (DFKI), DE), A. Krüger</span>
<div class="authorList"><span><span class="author">M. Böhmer</span> (German Research Center for Artificial Intelligence (DFKI), DE)</span><span><span class="author">A. Krüger</span> (German Research Center for Artificial Intelligence (DFKI), DE)</span></div>
<p><span class="cbStatement">This paper studies peoples&#8217; arrangements of icons in smartphone menus. From 1,400+ menu screenshots we distill five fundamental concepts for arranging icons. Implications are useful for designing mobile launcher menus.</span><span class="abstract">The number of available mobile applications is steadily increasing. People have rapidly adopted application stores as means to customize their devices with various functionalities that go beyond communication. Understanding the principles of mobile application usage is crucial for supporting users within this new ecosystem. In this paper, we investigate how people organize applications they have installed on their devices. We asked more than 130 participants for their habits for icon arrangement and collected more than 1,400 screenshots of their devices&#8217; menus to further ground our findings. Based on this data we can distinguish five different concepts for arranging icons on smartphone menus, e.g. based on application usage frequency and applications&#8217; functional relatedness. Additionally, we investigated how these concepts emerge in relation to frequency of application installations, removals and icon rearrangements, as well as users&#8217; experience levels. Finally we discuss implications for the design of smartphone launchers, and highlight differences to icon arrangement on stationary computers.</span></li>
<li id="PSQ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PSQ"><span class="letterCode" style="float:right">PSQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PSQ">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466252">I See You There! Developing Identity-Preserving Embodied Interaction for Museum Exhibits</a></span><br />
<span class="authors">F. Cafaro (Univ. of Illinois at Chicago, USA), A. Panella, L. Lyons, J. Roberts, J. Radinsky</span>
<div class="authorList"><span><span class="author">F. Cafaro</span> (Univ. of Illinois at Chicago, USA)</span><span><span class="author">A. Panella</span> (Univ. of Illinois at Chicago, USA)</span><span><span class="author">L. Lyons</span> (Univ. of Illinois at Chicago, USA)</span><span><span class="author">J. Roberts</span> (Univ. of Illinois at Chicago, USA)</span><span><span class="author">J. Radinsky</span> (Univ. of Illinois at Chicago, USA)</span></div>
<p><span class="cbStatement">Describes a system that merges input from RFID and Kinect using a probabilistic model: combines fine-grained tracking with identity preservation, supporting the design of personalized embodied interaction for museum exhibits</span><span class="abstract">Museums are increasingly embracing technologies that provide highly-individualized and highly-interactive experiences to visitors. With embodied interaction experiences, increased localization accuracy supports greater nuance in interaction design, but there is usually a tradeoff between fast, accurate tracking and the ability to preserve the identity of users. Customization of experience relies on the ability to detect the identity of visitors, however. We present a method that combines fine-grained indoor tracking with robust preservation of the unique identities of multiple users. Our model merges input from an RFID reader with input from a commercial camera-based tracking system. We developed a probabilistic Bayesian model to infer at run-time the correct identification of the subjects in the camera’s field of view. This method, tested in a lab and at a local museum, requires minimal modification to the exhibition space, while addressing several identity-preservation problems for which many indoor tracking systems do not have robust solutions. </span></li>
<li id="NKN"class="presentation games cci"><a href="http://chi2013.acm.org/previews/paper.html#NKN"><span class="letterCode" style="float:right">NKN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NKN">Wed. 9am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481315">Using an Open Card Sort with Children to Categorize Games in a Mobile Phone Application Store</a></span><br />
<span class="authors">B. Cassidy (Univ. of Central Lancashire, UK), D. Antani, J. Read</span>
<div class="authorList"><span><span class="author">B. Cassidy</span> (Univ. of Central Lancashire, UK)</span><span><span class="author">D. Antani</span> (Univ. of Central Lancashire, UK)</span><span><span class="author">J. Read</span> (Univ. of Central Lancashire, UK)</span></div>
<p><span class="cbStatement">The paper found that when compared with existing categories, children chose categories more aligned to a games goals/aims rather than the more abstract categories currently found in app stores.</span><span class="abstract">This paper presents a study aimed at better understanding how children categorize different games. The paper reports the results of an open card sort where participants were asked to categorize games from the Google Play Store (formerly the ‘Android Marketplace’). The key contribution of the paper is that when compared with existing categories in the Google Play Store, children used categorization criteria much more aligned to the goals of the game rather than more abstract categories currently found in mobile phone application stores. The paper provides examples of existing categories that are not generally used by children and provides new examples of categorization criteria that are used by children to categorize existing games.</span></li>
<li id="NSY"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#NSY"><span class="letterCode" style="float:right">NSY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NSY">Wed. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481356">uTouch: Sensing Touch Gestures on Unmodified LCDs</a></span><br />
<span class="authors">K. Chen (Univ. of Washington, USA), G. Cohn, S. Gupta, S. Patel</span>
<div class="authorList"><span><span class="author">K. Chen</span> (Univ. of Washington, USA)</span><span><span class="author">G. Cohn</span> (Univ. of Washington, USA)</span><span><span class="author">S. Gupta</span> (Univ. of Washington, USA)</span><span><span class="author">S. Patel</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">We developed a system that allows any LCD or LED monitors to be converted into a touch sensitive surface without instrunmenting the user or installing the sensors on the monitor.</span><span class="abstract">Current solutions for enabling touch interaction on existing non-touch LCD screens require adding additional sensors to the interaction surface. We present uTouch, a system that detects and classifies touches and hovers without any modification to the display, and without adding any sensors to the user. Our approach utilizes existing signals in an LCD that are amplified when a user brings their hand near or touches the LCD’s front panel. These signals are coupled onto the power lines, where they appear as electromagnetic interference (EMI) which can be sensed using a single device connected elsewhere on the power line infrastructure. We validate our approach with an 11 user, 8 LCD study, and demonstrate a real-time system.</span></li>
<li id="PNH"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PNH"><span class="letterCode" style="float:right">PNH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNH">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466237">Graduate Student Use of a Multi-Slate Reading System</a></span><br />
<span class="authors">N. Chen (Microsoft Research, UK), F. Guimbretière, A. Sellen</span>
<div class="authorList"><span><span class="author">N. Chen</span> (Microsoft Research, UK)</span><span><span class="author">F. Guimbretière</span> (Cornell Univ., USA)</span><span><span class="author">A. Sellen</span> (Microsoft Research, UK)</span></div>
<p><span class="cbStatement">We conducted month-long deployments of a multi-slate active reading system with graduate students in the humanities. Results confirm the importance of added display space, mobility, and support for writing.</span><span class="abstract">In laboratory studies, multi-surface slate-based reading systems have shown great promise as platforms for active reading. However, the true utility of such a system can only be ascertained through the rigors of real world use. We conducted month-long deployments of a multi-slate reading system to support the active reading activities of graduate students in the humanities. During these deployments we documented how the added display area and increased micro-mobility of multiple devices enhanced navigation and reading comfort. We also noted the essential role of writing and annotation. Finally, we observed how electronic affordances like synchronization across devices helped provide functionality that would not have been possible with paper documents. This paper contributes new information about how electronic reading solutions fit into real world reading workflows.</span></li>
<li id="NLX"class="presentation engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#NLX"><span class="letterCode" style="float:right">NLX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NLX">Wed. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481424">iRotateGrasp: Automatic Screen Rotation based on Grasp of Mobile Devices</a></span><br />
<span class="authors">L. Cheng (National Taiwan Univ., TW), M. Lee, C. Wu, F. Hsiao, Y. Liu, H. Liang, Y. Chiu, M. Lee, M. Chen</span>
<div class="authorList"><span><span class="author">L. Cheng</span> (National Taiwan Univ., TW)</span><span><span class="author">M. Lee</span></span><span><span class="author">C. Wu</span> (National Taiwan Univ., TW)</span><span><span class="author">F. Hsiao</span> (National Taiwan Univ., TW)</span><span><span class="author">Y. Liu</span> (National Taiwan Univ., TW)</span><span><span class="author">H. Liang</span> (National Taiwan Univ., TW)</span><span><span class="author">Y. Chiu</span> (National Taiwan Univ., TW)</span><span><span class="author">M. Lee</span> (National Taiwan Univ., TW)</span><span><span class="author">M. Chen</span> (National Taiwan Univ., TW)</span></div>
<p><span class="cbStatement">Our paper shows that grasps can be used to rotate screens to more accurately match users’ view orientation in both upright and horizontal postures by implementing and evaluating a real-time grasp sensing and recognition prototype.</span><span class="abstract">Automatic screen rotation improves viewing experience and usability of mobile devices, but current gravity-based approaches do not support postures such as lying on one side, and manual rotation switches require explicit user input. iRotateGrasp automatically rotates screens of mobile devices to match users’ viewing orientations based on how users are grasping the devices. Our insight is that users’ grasps are consistent for each orientation, but significantly differ between different orientations. Our prototype used a total of 44 capacitive sensors along the four sides and the back of an iPod Touch, and uses support vector machine (SVM) to recognize grasps at 25Hz. We collected 6-users’ usage under 108 different combinations of posture, orienta-tion, touchscreen operation, and left/right/both hands. Our offline analysis showed that our grasp-based approach is promising, with 80.9% accuracy when training and testing on different users, and up to 96.7% if users are willing to train the system. Our user study (N=16) showed that iRo-tateGrasp had an accuracy of 78.8% and was 31.3% more accurate than gravity-based rotation. </span></li>
<li id="PPZ"class="presentation engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PPZ"><span class="letterCode" style="float:right">PPZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PPZ">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481422">iGrasp: Grasp-based Adaptive Keyboard for Mobile Devices</a></span><br />
<span class="authors">L. Cheng (National Taiwan Univ., TW), H. Liang, C. Wu, M. Chen</span>
<div class="authorList"><span><span class="author">L. Cheng</span> (National Taiwan Univ., TW)</span><span><span class="author">H. Liang</span> (National Taiwan Univ., TW)</span><span><span class="author">C. Wu</span> (National Taiwan Univ., TW)</span><span><span class="author">M. Chen</span> (National Taiwan Univ., TW)</span></div>
<p><span class="cbStatement">We propose iGrasp, a novel approach that uses implicit grasps of a tablet device to automatically adapt the virtual keyboard’s layout and position to match users’ preferences and help users type earlier.</span><span class="abstract">Multitouch tablets, such as iPad and Android tablets, support virtual keyboards for text entry. Our 64-user study shows that 98% of the users preferred different keyboard layouts and positions depending on how they were holding these devices. However, current tablets either do not allow keyboard adjustment or require users to manually adjust the keyboards. We present iGrasp, which automatically adapts the layout and position of virtual keyboards based on how and where users are grasping the devices without requiring explicit user input. Our prototype uses 46 capacitive sensors positioned along the sides of an iPad to sense users’ grasps, and supports two types of grasp-based automatic adaptation: layout switching and continuous positioning. Our two 18-user studies show that participants were able to begin typing 42% earlier using iGrasp’s adaptive keyboard compared to the manually adjustable keyboard. Participants also rated iGrasp much easier to use than the manually adjustable keyboard (4.2 vs 2.9 on five-point Likert scale.)</span></li>
<li id="PRF"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PRF"><span class="letterCode" style="float:right">PRF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PRF">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470685">A Multi-Site Field Study of Crowdsourced Contextual Help: Usage and Perspectives of End Users and Software Teams</a></span><br />
<span class="authors">P. Chilana (Univ. of Washington, USA), A. Ko, J. Wobbrock, T. Grossman</span>
<div class="authorList"><span><span class="author">P. Chilana</span> (Univ. of Washington, USA)</span><span><span class="author">A. Ko</span> (Univ. of Washington, USA)</span><span><span class="author">J. Wobbrock</span> (Univ. of Washington, USA)</span><span><span class="author">T. Grossman</span> (Autodesk Research, CA)</span></div>
<p><span class="cbStatement">We present a field study of a crowdsourced contextual help system deployed on 4 large web sites. Data was collected over several weeks through usage logs, surveys, and interviews. </span><span class="abstract">We present a multi-site field study to evaluate LemonAid, a crowdsourced contextual help approach that allows users to retrieve relevant questions and answers by making selections within the interface. We deployed LemonAid on 4 different web sites used by thousands of users and collected data over several weeks, gathering over 1,200 usage logs, 168 exit surveys, and 36 one-on-one interviews. Our results indicate that over 70% of users found LemonAid to be helpful, intuitive, and desirable for reuse. Software teams found LemonAid easy to integrate with their sites and found the analytics data aggregated by LemonAid a novel way of learning about users’ popular questions. Our work provides the first holistic picture of the adoption and use of a crowdsourced contextual help system and offers several insights into the social and organizational dimensions of implementing such help systems for real-world applications.</span></li>
<li id="PGF"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGF"><span class="letterCode" style="float:right">PGF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGF">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466265">Cascade: Crowdsourcing Taxonomy Creation</a></span><br />
<span class="authors">L. Chilton (Univ. of Washington, USA), G. Little, D. Edge, D. Weld, J. Landay</span>
<div class="authorList"><span><span class="author">L. Chilton</span> (Univ. of Washington, USA)</span><span><span class="author">G. Little</span> (oDesk, USA)</span><span><span class="author">D. Edge</span> (Microsoft Research Asia, CN)</span><span><span class="author">D. Weld</span> (Univ. of Washington, USA)</span><span><span class="author">J. Landay</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">Cascade is a novel crowd algorithm that produces a global understanding of large datasets.  Cascade is an online algorithm.  The tasks given to workers are quick and parallelizable.    </span><span class="abstract">Taxonomies are a useful and ubiquitous way of organizing information. However, creating organizational hierarchies is difficult because the process requires a global understanding of the objects to be categorized. Usually one is created by an individual or a small group of people working together for hours or even days. Unfortunately, this centralized approach does not work well for the large, quickly changing datasets found on the web. Cascade is an automated workflow that allows crowd workers to spend as little at 20 seconds each while collectively making a taxonomy. We evaluate Cascade and show that on three datasets its quality is 80-90% of that of experts. Cascade has a competitive cost to expert information architects, despite taking six times more human labor. Fortunately, this labor can be parallelized such that Cascade will run in as fast as four minutes instead of hours or days.</span></li>
<li id="PSV"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PSV"><span class="letterCode" style="float:right">PSV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PSV">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466207">How Groups of Users Associate Wireless Devices</a></span><br />
<span class="authors">M. Chong (Lancaster Univ., UK), H. Gellersen</span>
<div class="authorList"><span><span class="author">M. Chong</span> (Lancaster Univ., UK)</span><span><span class="author">H. Gellersen</span> (Lancaster Univ., UK)</span></div>
<p><span class="cbStatement">Presents a guessability study of eliciting device association techniques from groups of non-technical users. Can inform designers of how people conceptualise device association in group scenarios.</span><span class="abstract">Group association, the process of connecting a group of devices, opens up new opportunities for users to spontaneously share resources. Research has shown numerous techniques and protocols for group association; however, what people intuitively do to associate a group of devices remains an open question. We contribute a study of eliciting device association techniques from groups of non-technical people. In all, we collected and analysed 496 techniques from 61 participants. Our results show that mobility and physicality of devices influence how people perceive groups association. We present a complete set of user-defined techniques with subjective ratings and popularity scores. We examined people&#8217;s rationale and the effects of different device form factors. We analysed the techniques based on the roles that users assume with respect to device association. Our findings draw out insights from the perspective of users for design of group association.</span></li>
<li id="PRK"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PRK"><span class="letterCode" style="float:right">PRK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PRK">Wed. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481348">Digital Portraits: Photo-sharing After Domestic Violence</a></span><br />
<span class="authors">R. Clarke (Newcastle Univ., UK), P. Wright, M. Balaam, J. McCarthy</span>
<div class="authorList"><span><span class="author">R. Clarke</span> (Newcastle Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">M. Balaam</span> (Newcastle Univ., UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span></div>
<p><span class="cbStatement">Taking a feminist arts action research approach, we detail an account of engaging women in photo-sharing who have had experiences of domestic violence, in the early stages of longitudinal participatory research.</span><span class="abstract">This paper explores the potential role of photography in re-building of lives after domestic violence. We worked in the context of a women’s centre where women are accessing support after leaving abusive relationships. The paper contributes a feminist participatory arts action research approach to studying photo-sharing practices and helps to frame an understanding of the ongoing tensions in the construction of self with others that the women experience. We argue that the affirmation of new bonds, control in sharing the process of ‘moving on’, and supporting discursive negotiations of privacy are important considerations for design focused on interpersonal social processes around the use of digital technology.</span></li>
<li id="PNK"class="presentation sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PNK"><span class="letterCode" style="float:right">PNK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PNK">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481339">Domestic Food and Sustainable Design:  A Study of University Student Cooking and its Impacts</a></span><br />
<span class="authors">A. Clear (Lancaster Univ., UK), M. Hazas, J. Morley, A. Friday, O. Bates</span>
<div class="authorList"><span><span class="author">A. Clear</span> (Lancaster Univ., UK)</span><span><span class="author">M. Hazas</span> (Lancaster Univ., UK)</span><span><span class="author">J. Morley</span> (Lancaster Univ., UK)</span><span><span class="author">A. Friday</span> (Lancaster Univ., UK)</span><span><span class="author">O. Bates</span> (Lancaster Univ., UK)</span></div>
<p><span class="cbStatement">523 meals over 21 days:  705 kg carbon, 325 kWh of electricity.  Interviews, cameras and power meters reveal food&#8217;s impacts, situated within everyday life.  Come ponder the sustainable design challenges.</span><span class="abstract">In four university student kitchens over twenty-one days, we captured participants&#8217; food preparation activity, quantified the greenhouse gas emissions and direct energy connected to the food and cooking, and talked to participants about their food practices.  Grounded in this uniquely detailed micro-account, our findings inform sustainable design for cooking and eating at home and quantify the potential impacts.  We outline the relation of the impacts to our participants&#8217; approaches to everyday food preparation, the organisation of their time, and the role of social meals.  Our technique allows evaluation of opportunities for sustainable intervention design: at the appliance, in the digitally-mediated organisation of meals and inventory management, and more broadly in reflecting upon and reshaping diet.</span></li>
<li id="PAS"class="presentation design health"><a href="http://chi2013.acm.org/previews/paper.html#PAS"><span class="letterCode" style="float:right">PAS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAS">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481340">Food Practices as Situated Action: Exploring and designing for everyday food practices with households</a></span><br />
<span class="authors">R. Comber (Newcastle Univ., UK), J. Hoonhout, A. van Halteren, P. Moynihan, P. Olivier</span>
<div class="authorList"><span><span class="author">R. Comber</span> (Newcastle Univ., UK)</span><span><span class="author">J. Hoonhout</span> (Philips Research, NL)</span><span><span class="author">A. van Halteren</span> (Philips Research, NL)</span><span><span class="author">P. Moynihan</span> (Newcastle Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">This paper describes everyday practices of food shopping, preparation and consumption. The paper contributes design recommendations and rich descriptions of the configuration of food practices.</span><span class="abstract">Household food practices are complex. Many people are unable to effectively respond to challenges in their food environment to maintain diets considered to be in line with national and international standards for healthy eating. We argue that recognizing food practices as situated action affords opportunities to identify and design for practiced, local and achievable solutions to such food problems. Interviews and shop-a-longs were carried as part of a contextual inquiry with ten households. From this, we identify food practices, such as fitting food, stocking up, food value transitions, and having fun with others and how these practices are enacted in different ways with varied outcomes. We explore how HCI might respond to these practices through issues of social fooding, the presence of others, conceptions about food practices and food routines. </span></li>
<li id="PPR"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PPR"><span class="letterCode" style="float:right">PPR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PPR">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481373">Quantity Estimation in Visualizations of Tagged Text</a></span><br />
<span class="authors">M. Correll (Univ. of Wisconsin, Madison, USA), E. Alexander, M. Gleicher</span>
<div class="authorList"><span><span class="author">M. Correll</span> (Univ. of Wisconsin, Madison, USA)</span><span><span class="author">E. Alexander</span> (Univ. of Wisconsin, Madison, USA)</span><span><span class="author">M. Gleicher</span> (Univ. of Wisconsin, Madison, USA)</span></div>
<p><span class="cbStatement">We present results in the relatively unexplored  domain of text annotation. We  present empirical validation of performance  at estimation tasks for tagged text, and  further validate design choices that improve this ability.</span><span class="abstract">A valuable task in text visualization is to have viewers make judgments about text that has been annotated (either by hand or by some algorithm such as text clustering or entity extraction). In this work we look at the ability of viewers to make judgments about the relative quantities of tags in annotated text (specifically text tagged with one of a set of qualitatively distinct colors), and examine design choices that can improve performance at extracting statistical information from these texts.    We find that viewers can efficiently and accurately estimate the proportions of tag levels over a range of situations; however accuracy can be improved through color choice and area adjustments.</span></li>
<li id="NES"class="presentation design sustainability"><a href="http://chi2013.acm.org/previews/paper.html#NES"><span class="letterCode" style="float:right">NES</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NES">Tue. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466268">Virtual Birding: Extending an Environmental Pastime into the Virtual World for Citizen Science</a></span><br />
<span class="authors">M. Cottman-Fields (Queensland Univ. of Technology, AU), M. Brereton, P. Roe</span>
<div class="authorList"><span><span class="author">M. Cottman-Fields</span> (Queensland Univ. of Technology, AU)</span><span><span class="author">M. Brereton</span> (Queensland Univ. of Technology, AU)</span><span><span class="author">P. Roe</span> (Queensland Univ. of Technology, AU)</span></div>
<p><span class="cbStatement">This paper investigates how to engage the experienced birder with local knowledge to extend their hobby online. We explore interaction designs for identifying bird vocalisations in large recorded audio datasets gathered through environmental acoustic monitoring.</span><span class="abstract">This paper investigates engaging experienced birders, as volunteer citizen scientists, to analyze large recorded audio datasets gathered through environmental acoustic monitoring. Although audio data is straightforward to gather, automated analysis remains a challenging task; the existing expertise, local knowledge and motivation of the birder community can complement computational approaches and provide distinct benefits. We explored both the culture and practice of birders, and paradigms for interacting with recorded audio data. A variety of candidate design elements were tested with birders.    This study contributes an understanding of how virtual interactions and practices can be developed to complement existing practices of experienced birders in the physical world. In so doing this study contributes a new approach to engagement in e-science. Whereas most citizen science projects task lay participants with discrete real world or artificial activities, sometimes using extrinsic motivators, this approach builds on existing intrinsically satisfying practices.</span></li>
<li id="PBP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PBP"><span class="letterCode" style="float:right">PBP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBP">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466127">Building Open Bridges: Collaborative Remixing and Reuse of Open Educational Resources across Organisations</a></span><br />
<span class="authors">T. Coughlan (The Univ. of Nottingham, UK), R. Pitt, P. McAndrew</span>
<div class="authorList"><span><span class="author">T. Coughlan</span> (The Univ. of Nottingham, UK)</span><span><span class="author">R. Pitt</span> (The Open Univ., UK)</span><span><span class="author">P. McAndrew</span> (The Open Univ., UK)</span></div>
<p><span class="cbStatement">We broaden understanding of open collaborations through analysing a cross-organisational initiative to remix and reuse Open Educational Resources. We define emerging practices and issues as openness evolves in different domains.</span><span class="abstract">In this paper we analyse the remixing and reuse of online learning materials offered as Open Educational Resources (OER). We explore the practices that developed as a set of course materials were released as OER from the UK, remixed for a US context by a cross-organisational, cross-cultural team, and then reused in a broad range of educational settings. We analyse the approaches taken during these remixing and reuse activities as novel forms of creative collaboration. As a basis for comparison, we explore similarities and differences with openness in other domains. We identify how openness provoked novel inter-organisational collaboration and forms of ownership; define forms of open practice that need support, and present issues that should be considered in devising and supporting open projects in education and beyond.</span></li>
<li id="NFK"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#NFK"><span class="letterCode" style="float:right">NFK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NFK">Mon. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470766">TypeRighting: Combining the Benefits of Handwriting and Typeface in Online Educational Videos</a></span><br />
<span class="authors">A. Cross (Microsoft Research India, IN), M. Bayyapunedi, E. Cutrell, A. Agarwal, W. Thies</span>
<div class="authorList"><span><span class="author">A. Cross</span> (Microsoft Research India, IN)</span><span><span class="author">M. Bayyapunedi</span> (Microsoft Research India, IN)</span><span><span class="author">E. Cutrell</span> (Microsoft Research India, IN)</span><span><span class="author">A. Agarwal</span> (edX, USA)</span><span><span class="author">W. Thies</span> (Microsoft Research India, IN)</span></div>
<p><span class="cbStatement">Examines viewers’ preferences of presentation styles for online educational videos and presents a novel way to combine the benefits of handwriting and typeface called TypeRighting.</span><span class="abstract">Recent years have seen enormous growth of online educational videos, spanning K-12 tutorials to university lectures. As this content has grown, so too has grown the number of presentation styles.  Some educators have strong allegiance to handwritten recordings (using pen and tablet), while others use only typed (PowerPoint) presentations. In this paper, we present the first systematic comparison of these two presentation styles and how they are perceived by viewers. Surveys on edX and Mechanical Turk suggest that users enjoy handwriting because it is personal and engaging, yet they also enjoy typeface because it is clear and legible. Based on these observations, we propose a new presentation style, TypeRighting, that combines the benefits of handwriting and typeface. Each phrase is written by hand, but fades into typeface soon after it appears. Our surveys suggest that about 80% of respondents prefer TypeRighting over handwriting. The same fraction of respondents prefer TypeRighting over typeface, for videos in which the handwriting is sufficiently legible.</span></li>
<li id="PAJ"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PAJ"><span class="letterCode" style="float:right">PAJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAJ">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481392">VideoKheti: Making Video Content Accessible to Low-Literate and Novice Users</a></span><br />
<span class="authors">S. Cuendet (EPFL, CH), I. Medhi, K. Bali, E. Cutrell</span>
<div class="authorList"><span><span class="author">S. Cuendet</span> (EPFL, CH)</span><span><span class="author">I. Medhi</span> (Microsoft Research India, IN)</span><span><span class="author">K. Bali</span> (Microsoft Research India, IN)</span><span><span class="author">E. Cutrell</span> (Microsoft Research India, IN)</span></div>
<p><span class="cbStatement">Reports on the design of a speech and graphics smartphone application for low-literate Indian farmers to help them browse video content. Discusses results found from a user study.</span><span class="abstract">Designing ICT systems for rural users in the developing world is difficult for a variety of reasons ranging from problems with infrastructure to wide differences in user contexts and capabilities. Developing regions may include huge variability in spoken languages, and users are often low- or non-literate, with very little experience interacting with digital technologies. Researchers have explored the use of text-free graphical interfaces as well as speech-based applications to overcome some of the issues related to language and literacy. While there are benefits and drawbacks to each of these approaches, they can be complementary when used together. In this work, we present VideoKheti, a mobile system using speech, graphics, and touch interaction for low-literate farmers in rural India. VideoKheti helps farmers to find and watch agricultural extension videos in their own language and dialect. In this paper, we detail the design and development of VideoKheti and report on a field study with 20 farmers in rural India who were asked to find videos based on a scenario. The results show that farmers could use VideoKheti, but their success still greatly depended on their education level. While participants were enthusiastic about using the system, the multimodal interface did not overcome many obstacles for low-literate users.</span></li>
<li id="PBV"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/paper.html#PBV"><span class="letterCode" style="float:right">PBV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBV">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466125">Front-Camera Video Recordings as Emotion Responses to Mobile Photos Shared Within Close-Knit Groups</a></span><br />
<span class="authors">Y. Cui (Nokia Research Center, FI), J. Kangas, J. Holm, G. Grassel</span>
<div class="authorList"><span><span class="author">Y. Cui</span> (Nokia Research Center, FI)</span><span><span class="author">J. Kangas</span> (Nokia Research Center, FI)</span><span><span class="author">J. Holm</span> (Nokia Research Center, FI)</span><span><span class="author">G. Grassel</span> (Nokia Research Center, FI)</span></div>
<p><span class="cbStatement">Using the front camera of a cell phone in social photography services: capturing video clips and sharing them as emotion responses to the individual photo viewed</span><span class="abstract">People use social-photography services to tell stories about themselves and to solicit responses from viewers. State of the-art services concentrate on textual comments, “Like” buttons, or similar means for viewers to give explicit feedback, but they overlook other, non-textual means. This paper investigates how emotion responses—as video clips captured by the front camera of a cell phone and used as tags for the individual photo viewed—can enhance photo-sharing experiences for close-knit groups. Our exploration was carried out with a mobile social-photography service called Social Camera. Four user groups (N=19) used the application for two to four weeks. The study’s results support the value of using front-camera video recordings to glean emotion response. It supports lightweight phatic social interactions not possible with comments and “Like” buttons. Most users kept sharing emotion responses throughout the study. They typically shared the responses right after they saw a just taken photo received from a remote partner. They used the responses to share their current contexts with others just as much as to convey nuanced feelings about a photo. We discuss the implications for future design and research. </span></li>
<li id="PGM"class="presentation design engineering ux health"><a href="http://chi2013.acm.org/previews/paper.html#PGM"><span class="letterCode" style="float:right">PGM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGM">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466231">HeartLink: Open Broadcast of Live Biometric Data to Social Networks</a></span><br />
<span class="authors">F. Curmi (Lancaster Univ., UK), M. Ferrario, J. Southern, J. Whittle</span>
<div class="authorList"><span><span class="author">F. Curmi</span> (Lancaster Univ., UK)</span><span><span class="author">M. Ferrario</span> (Lancaster Univ., UK)</span><span><span class="author">J. Southern</span> (Lancaster Univ., UK)</span><span><span class="author">J. Whittle</span> (Lancaster Univ., UK)</span></div>
<p><span class="cbStatement">The key novelty of HeartLink is the analysis of changes in social connectedness through bio data sharing and the proposed two-way communication between the runner and the viewer. </span><span class="abstract">A number of studies in the literature have looked into the use of real-time biometric data to improve one’s own physiological performance and wellbeing. However, there is limited research that looks into the effects that sharing biometric data with others could have on one’s social network. Following a period of research on existing mobile applications and prototype testing, we developed a system, HeartLink, which collects real-time personal biometric data such as heart rate and broadcasts this data online. Insights gained on designing systems to broadcast real-time biometric data are presented. In this paper we also report emerging results from testing HeartLink in a pilot study and a user study that were conducted during sport events. The results showed that sharing heart rate data does influence the relationship of the persons involved and that the degree of influence seems related to the tie strength prior to visualizing the data.</span></li>
<li id="PRG"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PRG"><span class="letterCode" style="float:right">PRG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PRG">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470713">Large-Scale Participation: A Case Study of a Participatory Approach to Developing a New Public Library</a></span><br />
<span class="authors">P. Dalsgaard (Aarhus Univ., DK), E. Eriksson</span>
<div class="authorList"><span><span class="author">P. Dalsgaard</span> (Aarhus Univ., DK)</span><span><span class="author">E. Eriksson</span> (Chalmers Univ. of Technology, SE)</span></div>
<p><span class="cbStatement">A case study of a participatory large-scale project in the development of a new public library, with a range of activities and the main lessons from the project.</span><span class="abstract">In this paper, we present a case study of a participatory project that focuses on interaction in large-scale design, namely, the development of the new Urban Mediaspace Aarhus. This project, which has been under way for ten years, embodies a series of issues that arise when participatory design approaches are applied to large-scale, IT-oriented projects. At the same time, it highlights the issues public knowledge institutions face, when interactive technologies challenge their fundamental roles and practices; by extension, this case offers examples of how these challenges may be explored and addressed through IT-based participatory initiatives. We present a range of such activities carried out during the past ten years, and present the main lessons from the project, based on interviews with three key stakeholders. These lessons focus on how to make participation work in practice, how to align different paradigms of inquiry and practice in a project of this scale, and how to capture and anchor the insights from participatory events to inform the ongoing design process.</span></li>
<li id="PMG"class="presentation arts"><a href="http://chi2013.acm.org/previews/paper.html#PMG"><span class="letterCode" style="float:right">PMG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PMG">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470747">Creativity Support for Novice Digital Filmmaking</a></span><br />
<span class="authors">N. Davis (Georgia Institute of Technology , USA), A. Zook, B. O&#8217;Neill, A. Grosz, B. Headrick, M. Nitsche, M. Riedl</span>
<div class="authorList"><span><span class="author">N. Davis</span> (Georgia Institute of Technology , USA)</span><span><span class="author">A. Zook</span> (Georgia Institute of Technology, USA)</span><span><span class="author">B. O&#8217;Neill</span> (Georgia Institute of Technology, USA)</span><span><span class="author">A. Grosz</span> (Georgia Institute of Technology, USA)</span><span><span class="author">B. Headrick</span> (Georgia Institute of Technology, USA)</span><span><span class="author">M. Nitsche</span> (Georgia Institute of Technology, USA)</span><span><span class="author">M. Riedl</span> (Georgia Institute of Technology, USA)</span></div>
<p><span class="cbStatement">We show that novice digital filmmakers have difficulty adhering to certain cinematographic conventions. Our subsequent Wizard-of-Oz study showed that a rule-based cinematic critic can reduce the frequency of errors.</span><span class="abstract">Machinima is a new form of creative digital filmmaking that leverages the real time graphics rendering of computer game engines. Because of the low barrier to entry, machinima has become a popular creative medium for hobbyists and novices while still retaining borrowed conventions from professional filmmaking. Can novice machinima creators benefit from creativity support tools? A preliminary study shows novices generally have difficulty adhering to cinematographic conventions. We identify and document four cinematic conventions novices typically violate. We report on a Wizard-of-Oz study showing a rule-based intelligent system that can reduce the frequency of errors that novices make by providing information about rule violations without prescribing solutions. We discuss the role of error reduction in creativity support tools.</span></li>
<li id="PEN"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PEN"><span class="letterCode" style="float:right">PEN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PEN">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466447">Predicting Postpartum Changes in Emotion and Behavior via Social Media</a></span><br />
<span class="authors">M. De Choudhury (Microsoft Research, USA), S. Counts, E. Horvitz</span>
<div class="authorList"><span><span class="author">M. De Choudhury</span> (Microsoft Research, USA)</span><span><span class="author">S. Counts</span> (Microsoft Research, USA)</span><span><span class="author">E. Horvitz</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">We consider social media as a tool for behavioral health. We focus on how Twitter posts maybe used to build predictive models about the behavior of new mothers following childbirth.</span><span class="abstract">We consider social media as a promising tool for public health, focusing on the use of Twitter posts to build predictive models about the forthcoming influence of childbirth on the behavior and mood of new mothers. Using Twitter posts, we quantify postpartum changes in 376 mothers along dimensions of social engagement, emotion, social network, and linguistic style. We then construct statistical models from a training set of observations of these measures before and after the reported childbirth, to forecast significant postpartum changes in mothers. The predictive models can classify mothers who will change significantly following childbirth with an accuracy of 71%, using observations about their prenatal behavior, and as accurately as 80-83% when additionally leveraging the initial 2-3 weeks of postnatal data. The study is motivated by the opportunity to use social media to identify mothers at risk of postpartum depression, an underreported health concern among large populations, and to inform the design of low-cost, privacy-sensitive early-warning systems and intervention programs aimed at promoting wellness postpartum.</span></li>
<li id="PRV"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PRV"><span class="letterCode" style="float:right">PRV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PRV">Wed. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481330">Back-of-Device Authentication on Smartphones</a></span><br />
<span class="authors">A. De Luca (Univ. of Munich (LMU), DE), E. von Zezschwitz, N. Nguyen, M. Maurer, E. Rubegni, M. Scipioni, M. Langheinrich</span>
<div class="authorList"><span><span class="author">A. De Luca</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">E. von Zezschwitz</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">N. Nguyen</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">M. Maurer</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">E. Rubegni</span> (Univ. of Lugano, CH)</span><span><span class="author">M. Scipioni</span> (Univ. of Lugano, CH)</span><span><span class="author">M. Langheinrich</span> (Univ. of Lugano, CH)</span></div>
<p><span class="cbStatement">Presents a system that uses gestures on the back of a mobile device to authenticate. Shoulder surfing resistance is significantly improved while remaining reasonably fast and easy to use.</span><span class="abstract">This paper presents BoD Shapes, a novel authentication method for smartphones that uses the back of the device for input. We argue that this increases the resistance to shoulder surfing while remaining reasonably fast and easy-to-use. We performed a user study (n=24) comparing BoD Shapes to PIN authentication, Android grid unlock, and a front version of our system. Testing a front version allowed us to directly compare performance and security measures between front and back authentication. Our results show that BoD Shapes is significantly more secure than the three other approaches. While performance declined, our results show that BoD Shapes can be very fast (up to 1.5 seconds in the user study) and that learning effects have an influence on its performance. This indicates that speed improvements can be expected in long-term use.</span></li>
<li id="NRU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NRU"><span class="letterCode" style="float:right">NRU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NRU">Wed. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481331">Using Fake Cursors to Secure On-Screen Password Entry</a></span><br />
<span class="authors">A. De Luca (Univ. of Munich (LMU), DE), E. von Zezschwitz, L. Pichler, H. Hussmann</span>
<div class="authorList"><span><span class="author">A. De Luca</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">E. von Zezschwitz</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">L. Pichler</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">H. Hussmann</span> (Univ. of Munich (LMU), DE)</span></div>
<p><span class="cbStatement">Presents a system that uses fake cursors to secure password entry on on-screen keyboards. An evaluation of the system shows that shoulder surfing resistance is significantly improved.</span><span class="abstract">In this paper, we present a concept using fake cursors to disguise on-screen password entry. We performed two user studies with different amounts of dummy cursors and differently colored cursors. The results show that dummy cursors significantly improve security. At the same time, decrease in performance is kept within an acceptable range. Depending on the required degree of security, the studies favor 8 or 16 differently colored cursors as the best trade-off between security and usability.</span></li>
<li id="PPH"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PPH"><span class="letterCode" style="float:right">PPH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPH">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466251">Designing for Perceptual Crossing: Designing and Comparing Three Behaviors</a></span><br />
<span class="authors">E. Deckers (Eindhoven Univ. of Technology, NL), S. Wensveen, P. Levy, R. Ahn</span>
<div class="authorList"><span><span class="author">E. Deckers</span> (Eindhoven Univ. of Technology, NL)</span><span><span class="author">S. Wensveen</span> (Univ. of Southern Denmark, DK)</span><span><span class="author">P. Levy</span> (Eindhoven Univ. of Technology, NL)</span><span><span class="author">R. Ahn</span> (Eindhoven Univ. of Technology, NL)</span></div>
<p><span class="cbStatement">We show how to design for perceptual crossing between person and artifact. An experiment shows that person and artifact engage in this strong reciprocal interplay of perceiving and being perceived. </span><span class="abstract">Perceptual crossing is the reciprocal interplay of perceiving while being perceived. In this paper we discuss the last iteration of our ongoing research project on designing for perceptive qualities in systems of interactive products. We describe the design of explorative behavior in an artifact to enable the artifact and a person to engage in perceptual crossing. The explorative behavior is compared to the following and active behavior, the results of two earlier iterations. Through the iterations we formulated, applied and evaluated design relevant knowledge in the form of seven design notions. These notions inform design-researchers and design-practitioners on how to design for perceptive qualities in systems of interactive products. Here we specifically focus on how the artifact detects active perceptive behavior of a person, and how the artifact becomes aware of bygone perception and anticipates on future perception. An experiment shows how participants preferred the resulting explorative behavior that is closest to our theoretical framework based on phenomenology. </span></li>
<li id="PFN"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PFN"><span class="letterCode" style="float:right">PFN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PFN">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466477">Social Media and the Police—Tweeting Practices of British Police Forces during the August 2011 Riots</a></span><br />
<span class="authors">S. Denef (Fraunhofer Institute for Applied Information Technology (FIT), DE), P. Bayerl, N. Kaptein</span>
<div class="authorList"><span><span class="author">S. Denef</span> (Fraunhofer Institute for Applied Information Technology (FIT), DE)</span><span><span class="author">P. Bayerl</span> (Erasmus Univ. Rotterdam, NL)</span><span><span class="author">N. Kaptein</span> (COT Institute for Safety, Security and Crisis Management, NL)</span></div>
<p><span class="cbStatement">Analyzes the Twitter use by the London Metropolitan and the Greater Manchester Police during the riots in August 2011. Shows that the forces developed very different practices to appropriate Twitter.</span><span class="abstract">With this paper we take a first step to understand the appropriation of social media by the police. For this purpose we analyzed the Twitter communication by the London Metropolitan Police (MET) and the Greater Manchester Police (GMP) during the riots in August 2011. The systematic comparison of tweets demonstrates that the two forces developed very different practices for using Twitter. While MET followed an instrumental approach in their communication, in which the police aimed to remain in a controlled position and keep a distance to the general public, GMP developed an expressive approach, in which the police actively decreased the distance to the citizens. In workshops and interviews, we asked the police officers about their perspectives, which confirmed the identified practices. Our study discusses benefits and risks of the two approaches and the potential impact of social media on the evolution of the role of police in society.</span></li>
<li id="PFP"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PFP"><span class="letterCode" style="float:right">PFP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PFP">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470763">The Effect of Virtual Achievements on Student Engagement</a></span><br />
<span class="authors">P. Denny (The Univ. of Auckland, NZ)</span>
<div class="authorList"><span><span class="author">P. Denny</span> (The Univ. of Auckland, NZ)</span></div>
<p><span class="cbStatement">Do badge-based achievement systems actually engage users?  We present the first large-scale study providing empirical evidence of their impact within an online learning tool.  </span><span class="abstract">Badge-based achievement systems are being used increasingly to drive user participation and engagement across a variety of platforms and contexts.  Despite positive anecdotal reports, there is currently little empirical evidence to support their efficacy in particular domains.  With the recent rapid growth of tools for online learning, an interesting open question for educators is the extent to which badges can positively impact student participation.    In this paper, we report on a large-scale (n > 1000) randomized, controlled experiment measuring the impact of incorporating a badge-based achievement system within an online learning tool.  We discover a highly significant positive effect on the quantity of students&#8217; contributions, without a corresponding reduction in their quality, as well as on the period of time over which students engaged with the tool. Students enjoyed being able to earn badges, and indicated a strong preference for having them available in the user interface.</span></li>
<li id="PQP"class="presentation design ux arts"><a href="http://chi2013.acm.org/previews/paper.html#PQP"><span class="letterCode" style="float:right">PQP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQP">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466133">AnyType: Provoking Reflection and Exploration with Aesthetic Interaction</a></span><br />
<span class="authors">L. Devendorf (Univ. of California, Berkeley, USA), K. Ryokai</span>
<div class="authorList"><span><span class="author">L. Devendorf</span> (Univ. of California, Berkeley, USA)</span><span><span class="author">K. Ryokai</span> (Univ. of California, Berkeley, USA)</span></div>
<p><span class="cbStatement">AnyType generates unique typefaces from photographs of shapes people find in their environment. In keeping with the principles of aesthetic interaction, AnyType supports opportunities for surprise, storytelling, and expression.</span><span class="abstract">AnyType is a mobile application that generates unique typefaces from photographs of shapes that people find in their environment. In keeping with the principles of aesthetic interaction, the design of AnyType supports opportunities for surprise, storytelling, and expression. This paper presents data collected from two observational studies of AnyType. In both studies, we found that people appropriated the application to create highly personalized messages. They found inspiration in unexpected locations, created memories from nuanced details in their lives, and creatively explored the design space provided by the system. Drawing from our observations, we discuss possible roles mobile devices could play in people’s personal meaning making, creative process, and discovery, in interaction with elements of their physical environment.</span></li>
<li id="PGE"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGE"><span class="letterCode" style="float:right">PGE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGE">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466250">The Effects of Tactile Feedback and Movement Alteration on Interaction and Awareness with Digital Embodiments</a></span><br />
<span class="authors">A. Doucette (Univ. of Saskatchewan, CA), R. Mandryk, C. Gutwin, M. Nacenta, A. Pavlovych</span>
<div class="authorList"><span><span class="author">A. Doucette</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">R. Mandryk</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">M. Nacenta</span> (Univ. of St Andrews, UK)</span><span><span class="author">A. Pavlovych</span> (Univ. of Saskatchewan, CA)</span></div>
<p><span class="cbStatement">Presents and evaluates methods for affecting group behaviour in tabletop groupware by providing cues of physical boundaries in digital space.</span><span class="abstract">Collaborative tabletop systems can employ direct touch, where people’s real arms and hands manipulate objects, or indirect input, where people are represented on the table with digital embodiments. The input type and the resulting embodiment dramatically influence tabletop interaction: in particular, the touch avoidance that naturally governs people’s touching and crossing behavior with physical arms is lost with digital embodiments. One result of this loss is that people are less aware of each others’ arms, and less able to coordinate actions and protect personal territories. To determine whether there are strategies that can influence group interaction on shared digital tabletops, we studied augmented digital arm embodiments that provide tactile feedback or movement alterations when people touched or crossed arms. The study showed that both augmentation types changed people’s behavior (people crossed less than half as often) and also changed their perception (people felt more aware of the other person’s arm, and felt more awkward when touching). This work shows how groupware designers can influence people’s interaction, awareness, and coordination abilities when physical constraints are absent.</span></li>
<li id="PKK"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PKK"><span class="letterCode" style="float:right">PKK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PKK">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470686">A Pilot Study of Using Crowds in the Classroom</a></span><br />
<span class="authors">S. Dow (Carnegie Mellon Univ., USA), E. Gerber, A. Wong</span>
<div class="authorList"><span><span class="author">S. Dow</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">E. Gerber</span> (Northwestern Univ., USA)</span><span><span class="author">A. Wong</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We contribute early evidence and discuss implications for creating a socio-technical infrastructure to use online crowds to increase the authenticity of innovation education.</span><span class="abstract">Industry relies on higher education to prepare students for careers in innovation. Fulfilling this obligation is especially difficult in classroom settings, which often lack authentic interaction with the outside world. Online crowdsourcing has the potential to change this. Our research explores if and how online crowds can support student learning in the classroom. We explore how scalable, diverse, immediate (and often ambiguous and conflicting) input from online crowds affects student learning and motivation for project-based innovation work. In a pilot study with three classrooms, we explore interactions with the crowd at four key stages of the innovation process: needfinding, ideating, testing, and pitching. Students reported that online crowds helped them quickly and inexpensively identify needs and uncover issues with early-stage prototypes, although they favored face-to-face interactions for more contextual feed-back. We share early evidence and discuss implications for creating a socio-technical infrastructure to more effectively use crowdsourcing in education.</span></li>
<li id="PCX"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PCX"><span class="letterCode" style="float:right">PCX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCX">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481318">TouchViz: A Case Study Comparing Two Interfaces for Data Analytics on Tablets</a></span><br />
<span class="authors">S. Drucker (Microsoft Research, USA), D. Fisher, R. Sadana, J. Herron, m. schraefel</span>
<div class="authorList"><span><span class="author">S. Drucker</span> (Microsoft Research, USA)</span><span><span class="author">D. Fisher</span> (Microsoft Research, USA)</span><span><span class="author">R. Sadana</span> (Georgia Institute of Technology, USA)</span><span><span class="author">J. Herron</span> (Microsoft Research, USA)</span><span><span class="author">m. schraefel</span> (Univ. of Southampton, UK)</span></div>
<p><span class="cbStatement">Two different design approaches to touch based data analytics and an evaluation of relative advantages and benefits thereof.</span><span class="abstract">As more applications move from the desktop to touch devices like tablets, designers must wrestle with the costs of porting a design with as little revision of the UI as possible from one device to the other, or of optimizing the interaction per device. We consider the tradeoffs between two versions of a UI for working with data on a touch tablet. One interface is based on using the conventional desktop metaphor (WIMP) with a control panel, push buttons, and checkboxes – where the mouse click is effectively replaced by a finger tap. The other interface (which we call FLUID) eliminates the control panel and focuses touch actions on the data visualization itself. We describe our design process and evaluation of each interface. We discuss the significantly better task performance and preference for the FLUID interface, in particular how touch design may challenge certain assumptions about the performance benefits of WIMP interfaces that do not hold on touch devices, such as the superiority of gestural vs. control panel based interaction. </span></li>
<li id="PQY"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PQY"><span class="letterCode" style="float:right">PQY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PQY">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466444">Motif Simplification: Improving Network Visualization Readability with Fan, Connector, and Clique Glyphs</a></span><br />
<span class="authors">C. Dunne (Univ. of Maryland, USA), B. Shneiderman</span>
<div class="authorList"><span><span class="author">C. Dunne</span> (Univ. of Maryland, USA)</span><span><span class="author">B. Shneiderman</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">It is difficult to visualize large networks. Motif simplification reduces network complexity by replacing common, repeating patterns with representative glyphs. Our controlled study shows this is helpful for many tasks.</span><span class="abstract">Analyzing networks involves understanding the complex relationships between entities, as well as any attributes they may have. The widely used node-link diagrams excel at this task, but many are difficult to extract meaning from because of the inherent complexity of the relationships and limited screen space. To help address this problem we introduce a technique called motif simplification, in which common patterns of nodes and links are replaced with compact and meaningful glyphs. Well-designed glyphs have several benefits: they (1) require less screen space and layout effort, (2) are easier to understand in the context of the network, (3) can reveal otherwise hidden relationships, and (4) preserve as much underlying information as possible. We tackle three frequently occurring and high-payoff motifs: fans of nodes with a single neighbor, connectors that link a set of anchor nodes, and cliques of completely connected nodes. We contribute design guidelines for motif glyphs; example glyphs for the fan, connector, and clique motifs; algorithms for detecting these motifs; a free and open source reference implementation; and results from a controlled study of 36 participants that demonstrates the effectiveness of motif simplification.</span></li>
<li id="PRQ"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PRQ"><span class="letterCode" style="float:right">PRQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PRQ">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470749">HyperSlides: Dynamic Presentation Prototyping</a></span><br />
<span class="authors">D. Edge (Microsoft Research Asia, CN), J. Savage, K. Yatani</span>
<div class="authorList"><span><span class="author">D. Edge</span> (Microsoft Research Asia, CN)</span><span><span class="author">J. Savage</span> (Microsoft Research Asia, CN)</span><span><span class="author">K. Yatani</span> (Microsoft Research Asia, CN)</span></div>
<p><span class="cbStatement">Motivates and evaluates the design of the HyperSlides system for dynamic prototyping of PowerPoint presentations that are themselves dynamic in their ability to help presenters rehearse and deliver their story.</span><span class="abstract">Presentations are a crucial form of modern communication, yet there is a dissonance between everyday practices with presentation tools and best practices from the presentation literature. We conducted a grounded theory study to gain a better understanding of the activity of presenting, discovering the potential for a more dynamic, automated, and story-centered approach to prototyping slide presentations that are themselves dynamic in their ability to help presenters rehearse and deliver their story. Our prototype tool for dynamic presentation prototyping, which we call HyperSlides, uses a simple markup language for the creation of hierarchically structured scenes, which are algorithmically transformed into hyperlinked slides of a consistent and minimalist style. Our evaluation suggests that HyperSlides helps idea organization, saves authoring time, creates aesthetic layouts, and supports more flexible rehearsal and delivery than linear slides, at the expense of reduced layout control and increased navigation demands.</span></li>
<li id="NRS"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NRS"><span class="letterCode" style="float:right">NRS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NRS">Mon. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470721">SpatialEase: Learning Language through Body Motion</a></span><br />
<span class="authors">D. Edge (Microsoft Research Asia, CN), K. Cheng, M. Whitney</span>
<div class="authorList"><span><span class="author">D. Edge</span> (Microsoft Research Asia, CN)</span><span><span class="author">K. Cheng</span> (Microsoft Research Asia, CN)</span><span><span class="author">M. Whitney</span> (Microsoft Research Asia, CN)</span></div>
<p><span class="cbStatement">Motivates and evaluates the design of the SpatialEase system for the kinesthetic learning of second language constructions grounded in space and motion, leading to implications for mixed-modality learning games.</span><span class="abstract">Games that engage both mind and body by targeting users’ kinesthetic intelligence have the potential to transform the activity of learning across a wide variety of domains. To investigate this potential in the context of second language learning, we have developed SpatialEase: a Kinect game for the body-based learning of language that is grounded in space and motion. In this game, learners respond to audio commands in the second language by moving their bodies in space, while a game mechanic based on distributed cued-recall supports learning over time. Our comparison of SpatialEase with the popular Rosetta Stone software for learner of Mandarin Chinese showed similar learning gains over a single session and generated several key implications for the future design of mixed-modality learning systems.</span></li>
<li id="PEY"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PEY"><span class="letterCode" style="float:right">PEY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEY">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481328">My Profile Is My Password, Verify Me! The Privacy/Convenience Tradeoff of Facebook Connect</a></span><br />
<span class="authors">S. Egelman (Univ. of California, Berkeley, USA)</span>
<div class="authorList"><span><span class="author">S. Egelman</span> (Univ. of California, Berkeley, USA)</span></div>
<p><span class="cbStatement">We experimentally measure informed consent across users of Facebook Connect, the most widely-used single sign-on (SSO) implementation, to examine whether users understand they are trading privacy for convenience.</span><span class="abstract">We performed a laboratory experiment to study the privacy tradeoff offered by Facebook Connect: disclosing Facebook profile data to third-party websites for the convenience of logging in without creating separate accounts.  We controlled for trustworthiness and amount of information each website requested, as well as the consent dialog layout.  We discovered that these factors had no observable effects, likely because participants did not read the dialogs.  Yet, 15% still refused to use Facebook Connect, citing privacy concerns.  A likely explanation for subjects ignoring the dialogs while also understanding the privacy tradeoff&#8212;our exit survey indicated that 88% broadly understood what data would be collected&#8212;is that subjects were already familiar with the dialogs prior to the experiment.  We discuss how our results demonstrate informed consent, but also how habituation prevented subjects from understanding the nuances between individual websites&#8217; data collection policies.</span></li>
<li id="PDG"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PDG"><span class="letterCode" style="float:right">PDG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PDG">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481329">Does My Password Go up to Eleven? The Impact of Password Meters on Password Selection</a></span><br />
<span class="authors">S. Egelman (Univ. of California, Berkeley, USA), A. Sotirakopoulos, I. Muslukhov, K. Beznosov, C. Herley</span>
<div class="authorList"><span><span class="author">S. Egelman</span> (Univ. of California, Berkeley, USA)</span><span><span class="author">A. Sotirakopoulos</span> (Univ. of British Columbia, CA)</span><span><span class="author">I. Muslukhov</span></span><span><span class="author">K. Beznosov</span> (Univ. of British Columbia, CA)</span><span><span class="author">C. Herley</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">We show that password meters result in stronger passwords during changes to &#8220;important&#8221; accounts, whereas they do not have an observable effect when users create new passwords for &#8220;unimportant&#8221; accounts.</span><span class="abstract">Password meters tell users whether their passwords are &#8220;weak&#8221; or &#8220;strong.&#8221;  We performed a laboratory experiment to examine whether these meters influenced users&#8217; password selections when they were forced to change their real passwords, and when they were not told that their passwords were the subject of a study.  We observed that the presence of meters yielded significantly stronger passwords.  We performed a followup field experiment to test a different scenario: creating a password for an unimportant account.  In this scenario, we found that the meters made no observable difference: participants simply reused weak passwords that they used to protect similar low-risk accounts.  We conclude that meters result in stronger passwords when users are forced to change existing passwords on &#8220;important&#8221; accounts and that individual meter design decisions likely have a marginal impact.</span></li>
<li id="PKJ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PKJ"><span class="letterCode" style="float:right">PKJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PKJ">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481347">Protecting the Home: Exploring the Roles of Technology and Citizen Activism from a Burglar&#8217;s Perspective</a></span><br />
<span class="authors">S. Erete (Northwestern Univ., USA)</span>
<div class="authorList"><span><span class="author">S. Erete</span> (Northwestern Univ., USA)</span></div>
<p><span class="cbStatement">Examines how burglars perceive deterrents. Finds that alarms, cameras, etc. do not dissuade burglars. In-person citizen activism is the strongest deterrent. Presents implications for crime prevention technology and activist research.</span><span class="abstract">For decades, HCI scholars have designed technology for the domestic space. Many of these systems aim to protect the home and its residents by requesting help from local authorities during emergency situations. While the use of these systems have been examined, few studies attempt to understand the behavior of potential offenders who can create such emergency situations (e.g., by attempting a burglary). This paper analyzes three panel sessions with 15 people who have been convicted of burglarizing homes, cars, and/or businesses. Participants describe in detail what they looked for when deciding to burglarize a home and what deterred them. Technologies such as security systems, alarms, and cameras do not dissuade burglars. Instead, evidence of neighborhood cohesion was named the strongest deterrent. This paper presents implications for designing technologies that will effectively discourage burglary and support citizen activism.</span></li>
<li id="PGZ"class="presentation ux sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PGZ"><span class="letterCode" style="float:right">PGZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGZ">Tue. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466155">The Dubuque Electricity Portal: Evaluation of a City-Scale Residential Electricity Consumption Feedback System</a></span><br />
<span class="authors">T. Erickson (IBM T.J. Watson Research Center, USA), M. Li, Y. Kim, A. Deshpande, S. Sahu, T. Chao, P. Sukaviriya, M. Naphade</span>
<div class="authorList"><span><span class="author">T. Erickson</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">M. Li</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">Y. Kim</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">A. Deshpande</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">S. Sahu</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">T. Chao</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">P. Sukaviriya</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">M. Naphade</span> (IBM T.J. Watson Research Center, USA)</span></div>
<p><span class="cbStatement">Evaluation of an electricity portal deployed to 765 homes for 20 weeks that used feedback and social techniques to support decreased electricity consumption. Can assist designers of residential feedback  systems.  </span><span class="abstract">This paper describes the Dubuque Electricity Portal, a city-scale system aimed at supporting voluntary reductions of electricity consumption. The Portal provided each household with fine-grained feedback on its electricity use, as well as using incentives, comparisons, and goal setting to encourage conservation. Logs, a survey and interviews were used to evaluate the user experience of the Portal during a 20-week pilot with 765 volunteer households. Although the volunteers had already made a wide range of changes to conserve electricity prior to the pilot, those who used the Portal decreased their electricity use by about 3.7%. They also reported increased understanding of their usage, and reported taking an array of actions ¬ – both changing their behavior and their electricity infrastructure. The paper discusses the experience of the system’s users, and describes challenges for the design of ECF systems, including balancing accessibility and security, a preference for time-based visualizations, and the advisability of multiple modes of feedback, incentives and information presentation.</span></li>
<li id="PGC"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PGC"><span class="letterCode" style="float:right">PGC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PGC">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481370">The Secret Life of a Persona: When the Personal Becomes Private</a></span><br />
<span class="authors">E. Eriksson (KTH &#8211; Royal Institute of Technology, SE), H. Artman, A. Swartling</span>
<div class="authorList"><span><span class="author">E. Eriksson</span> (KTH &#8211; Royal Institute of Technology, SE)</span><span><span class="author">H. Artman</span> (Swedish Defence Research Agency (FOI), SE)</span><span><span class="author">A. Swartling</span> (Scania CV AB, SE)</span></div>
<p><span class="cbStatement">Two persona cases for a secretive organization are uncovered! Secrecy makes personas problematic. This paper examines how to turn the unspoken into a resource: “Not to tell is to tell”.</span><span class="abstract">Some organizations fail to involve users in systems development due to a widespread organization, high workload or secrecy issues. A remedy against this situation could be the persona method in which users and main stakeholders as represented as fictitious characters. Personas help eliciting user needs and requirements, facilitate design choices and are an overall communication aid where users cannot be present. An important part of the persona method, as portrayed in literature, is the personal details that make the personas trustworthy and alive. In this paper we present two cases in which personas have been developed and used, but where the personal is scarce or even non-existent because of a dispersed organisation, the organisational culture and secrecy issues. The paper describes how the personas were developed, used and received and how the method was altered in order to work in these special circumstances.</span></li>
<li id="PDX"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PDX"><span class="letterCode" style="float:right">PDX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PDX">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481353">Reality Jockey: Lifting the Barrier between Alternate Realities through Audio and Haptic Feedback</a></span><br />
<span class="authors">K. Fan (Keio Univ., JP), H. Izumi, Y. Sugiura, K. Minamizawa, S. Wakisaka, M. Inami, N. Fujii, S. Tachi</span>
<div class="authorList"><span><span class="author">K. Fan</span> (Keio Univ., JP)</span><span><span class="author">H. Izumi</span> (Keio Univ., JP)</span><span><span class="author">Y. Sugiura</span> (Keio Univ., JP)</span><span><span class="author">K. Minamizawa</span> (Keio Univ., JP)</span><span><span class="author">S. Wakisaka</span> (RIKEN, JP)</span><span><span class="author">M. Inami</span> (Keio Univ., JP)</span><span><span class="author">N. Fujii</span> (RIKEN, JP)</span><span><span class="author">S. Tachi</span> (Keio Univ., JP)</span></div>
<p><span class="cbStatement">This research works on the concept of how alternate realities from the past can be re-experienced with immersion through the cross-modality of audio and haptics.</span><span class="abstract">We present Reality Jockey, a system that confuses the participant’s perception of the reality by mixing in a recorded past-reality. The participant will be immersed in a spatialized 3D sound environment that is a mix of sounds from the reality and from the past. The sound environment from the past is augmented with haptic feedback in cross-modality. The haptic feedback is associated with certain sounds such as the vibration in the table when stuff is placed on the table to make the illusion of it happening in live. The seamless transition between live and past creates immersive experience of past events. The blending of live and past allows interactivity. To validate our system, we conducted user studies on 1) does blending live sensations improve such experiences, and 2) how beneficial is it to provide haptic feedbacks in recorded pasts. Potential applications are suggested to illustrate the significance of Reality Jockey.</span></li>
<li id="NFE"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/paper.html#NFE"><span class="letterCode" style="float:right">NFE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NFE">Tue. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466183">Can We Beat the Mouse with MAGIC?</a></span><br />
<span class="authors">R. Fares (Texas State Univ., USA), S. Fang, O. Komogortsev</span>
<div class="authorList"><span><span class="author">R. Fares</span> (Texas State Univ., USA)</span><span><span class="author">S. Fang</span> (Texas State Univ., USA)</span><span><span class="author">O. Komogortsev</span> (Texas State Univ., USA)</span></div>
<p><span class="cbStatement">Animated MAGIC is a novel interaction method that improves the throughput of the mouse by incorporating eye-tracking as a complementary input.</span><span class="abstract">MAGIC pointing techniques combine eye tracking with manual input. Since the mouse performs exceptionally well in a desktop setting, previous research on MAGIC pointing either resulted in minor improvements, or the techniques were applied to alternative devices or environments. We design Animated MAGIC, a novel, target-agnostic MAGIC pointing technique, for the specific goal of beating the mouse in a desktop setting. To improve the eye-tracking accuracy, we develop a dynamic local calibration method that uses each selection as a local calibration point. We compare Animated MAGIC to mouse-only and Conservative MAGIC, one of the two original MAGIC pointing methods, in a Fitts&#8217; Law experiment. We conduct a user questionnaire to evaluate the usability of the interaction methods. Results suggest that Dynamic Local Calibration improves eye-tracking accuracy and, consequently, MAGIC pointing performance. Powered with Dynamic Local Calibration, Animated MAGIC outperformed mouse-only by 8% in terms of throughput. Both MAGIC pointing methods reduced the amount of hand movement by more than half.</span></li>
<li id="PDJ"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PDJ"><span class="letterCode" style="float:right">PDJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PDJ">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470765">Wikipedia Classroom Experiment: Bidirectional Benefits of Students&#8217; Engagement in Online Production Communities</a></span><br />
<span class="authors">R. Farzan (Univ. of Pittsburgh, USA), R. Kraut</span>
<div class="authorList"><span><span class="author">R. Farzan</span> (Univ. of Pittsburgh, USA)</span><span><span class="author">R. Kraut</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">This paper provides details in the design of a program to encourage students’ contribution to Wikipedia and our quantitative and qualitative approaches to evaluating it. </span><span class="abstract">Over the last decade, a citizen science movement has tried to engage students, laymen and other non-scientists in the production of science. However, there has been less attention in citizen science projects to use the public to disseminate scientific knowledge. Wikipedia provides a platform to study engagement of citizen scientists in knowledge dissemination. College and university students are especially appropriate members of the public to write science articles, because of the course-work and mentorship they receive from faculty. This paper describes a project to support students&#8217; writing of scientific articles in Wikipedia. In collaboration with a scientific association, we involved 640 students from 36 courses in editing scientific articles on Wikipedia.  This paper provides details in the design of the program and our quantitative and qualitative approaches to evaluating it. Our results show that the Wikipedia classroom experiment benefits both the Wikipedia community and students.  Undergraduate and graduate students substantially improved the scientific content of over 800 articles, at a level of quality indistinguishable from content written by PhD experts.  Both students and faculty endorsed the motivational benefits of an authentic writing experience that would be read by thousands of people.</span></li>
<li id="PKU"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PKU"><span class="letterCode" style="float:right">PKU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PKU">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466177">Brainstorm, Chainstorm, Cheatstorm, Tweetstorm: New Ideation Strategies for Distributed HCI Design</a></span><br />
<span class="authors">H. Faste (Carnegie Mellon Univ., USA), N. Rachmel, R. Essary, E. Sheehan</span>
<div class="authorList"><span><span class="author">H. Faste</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">N. Rachmel</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">R. Essary</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">E. Sheehan</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">In this paper we describe the results of a design-driven study of “cheatstorming,” a new collaborative ideation technique, to demonstrate how ideation need not require the generation of new ideas.</span><span class="abstract">In this paper we describe the results of a design-driven study of collaborative ideation. Based on preliminary findings that identified a novel digital ideation paradigm we refer to as chainstorming, or online communication brainstorming, two exploratory studies were performed. First, we developed and tested a distributed method of ideation we call cheatstorming, in which previously generated brainstorm ideas are delivered to targeted local contexts in response to a prompt. We then performed a more rigorous case study to examine the cheatstorming method and consider its possible implementation in the context of a distributed online ideation tool. Based on observations from these studies, we conclude with the somewhat provocative suggestion that ideation need not require the generation of new ideas. Rather, we present a model of ideation suggesting that its value has less to do with the generation of novel ideas than the cultural influence exerted by unconventional ideas on the ideating team. Thus brainstorming is more than the pooling of “invented” ideas, it involves the sharing and interpretation of concepts in unintended and (ideally) unanticipated ways.</span></li>
<li id="PAX"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PAX"><span class="letterCode" style="float:right">PAX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAX">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481416">Supporting Orientation during Search Result Examination</a></span><br />
<span class="authors">H. Feild (Univ. of Massachusetts, USA), R. White, X. Fu</span>
<div class="authorList"><span><span class="author">H. Feild</span> (Univ. of Massachusetts, USA)</span><span><span class="author">R. White</span> (Microsoft Research, USA)</span><span><span class="author">X. Fu</span> (LinkedIn, USA)</span></div>
<p><span class="cbStatement">Describes and evaluates Clickable Snippets, a new method to help searchers transition from results to landing pages. Can help searchers orient themselves in landing-page content and find relevant information faster.</span><span class="abstract">Search engines help their users decide which results to visit using captions comprising titles, URLs, and snippets containing the query keywords and proximal text from landing pages (the search results linked from the result page). Although caption content can be a key factor in these decisions, snippets provide only basic support for orienting users with landing page content from the search-engine result page (SERP), and no support during the transition to landing pages or once users reach the page following a selection decision. As a result, many searchers must employ inefficient strategies such as skimming and scanning the content of the landing page. In this paper we propose a novel method, called clickable snippets, to address this shortcoming. Clickable snippets provide searchers with a direct and actionable link between SERP captions and landing-page content. We describe a user study comparing clickable snippets with extant methods of orientation support such as query-term highlighting on the landing page and thumbnail previews on the SERP. We show that clickable snippets are preferred by participants, and lead to more effective and efficient searching. Our findings have implications for the design of the user experience in search systems.</span></li>
<li id="PMJ"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PMJ"><span class="letterCode" style="float:right">PMJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PMJ">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466453">Beyond Digital and Physical Objects: The Intellectual Work as a Concept of Interest for HCI</a></span><br />
<span class="authors">M. Feinberg (The Univ. of Texas at Austin, USA)</span>
<div class="authorList"><span><span class="author">M. Feinberg</span> (The Univ. of Texas at Austin, USA)</span></div>
<p><span class="cbStatement">Demonstrates how the concept of the work can extend research on the perceived value of digital objects. Shows how a flexible definition of the work can reveal new aspects of a design situation. </span><span class="abstract">To understand activities of personal collecting and preservation, HCI researchers have investigated why people become attached to particular objects. These studies have examined ways that people relate to physical and digital objects, observing, for example, that people tend to cherish physical objects more than digital ones. This paper proposes that the value of digital objects may inhere less in an object’s identity as a particular item and more in the object’s ability to provide access to an intellectual work. The work, a familiar concept in information studies and textual studies, designates a general product of intellectual creation that may be instantiated in many versions. (For example, Shakespeare’s Hamlet exists in many editions and forms, which may differ in both content and carrier and yet still are all Hamlet.) The paper demonstrates how the concept of the work can extend research on the perceived value of digital objects. It also shows how a flexible definition of the work can reveal new aspects of a design situation.</span></li>
<li id="NDF"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NDF"><span class="letterCode" style="float:right">NDF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NDF">Mon. 2pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470703">Age-Related Differences in Performance with Touchscreens Compared to Traditional Mouse Input</a></span><br />
<span class="authors">L. Findlater (Univ. of Maryland, USA), J. Froehlich, K. Fattal, J. Wobbrock, T. Dastyar</span>
<div class="authorList"><span><span class="author">L. Findlater</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Froehlich</span> (Univ. of Maryland, USA)</span><span><span class="author">K. Fattal</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Wobbrock</span> (Univ. of Washington, USA)</span><span><span class="author">T. Dastyar</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">We compared performance of older and younger adults on a range of desktop and touchscreen tasks. The touchscreen reduced the performance gap between the two groups relative to the desktop. </span><span class="abstract">Despite the apparent popularity of touchscreens for older adults, little is known about the psychomotor performance of these devices. We compared performance between older adults and younger adults on four desktop and touchscreen tasks: pointing, dragging, crossing and steering. On the touchscreen, we also examined pinch-to-zoom. Our results show that while older adults were significantly slower than younger adults in general, the touchscreen reduced this performance gap relative to the desktop and mouse. Indeed, the touchscreen resulted in a significant movement time reduction of 35% over the mouse for older adults, compared to only 16% for younger adults. Error rates also decreased.</span></li>
<li id="PSF"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PSF"><span class="letterCode" style="float:right">PSF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PSF">Wed. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481323">Improving Navigation-Based File Retrieval</a></span><br />
<span class="authors">S. Fitchett (Univ. of Canterbury, NZ), A. Cockburn, C. Gutwin</span>
<div class="authorList"><span><span class="author">S. Fitchett</span> (Univ. of Canterbury, NZ)</span><span><span class="author">A. Cockburn</span> (Univ. of Canterbury, NZ)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span></div>
<p><span class="cbStatement">Introduces three interfaces to improve navigation-based file retrieval. Empirical studies show they are subjectively preferred and decrease retrieval times for both new and revisited items.</span><span class="abstract">Navigating through a file hierarchy is one of the most common methods for accessing files, yet it can be slow and repetitive. New algorithms that predict upcoming file accesses have the potential to improve navigation-based file retrieval, but it is unknown how best to present their  predictions to users. We present three design goals aiming to  improve navigation-based file retrieval interfaces: minimise the time spent at each hierarchical level en route to the target file; reduce the number of levels traversed by providing shortcuts; and promote rehearsal of the retrieval mechanics to facilitate expertise. We introduce three interfaces that augment  standard file browsers based on each of these goals: Icon Highlights give greater prominence to predicted items in the current folder; Hover Menus provide shortcuts to predicted folder content; and Search Directed Navigation uses predictive highlighting to guide users through the hierarchy in response to query terms. Results from a user evaluation show that all three interfaces improve file retrieval times, with Icon Highlights and Hover Menus best suited for frequently accessed items and Search Directed Navigation best suited for infrequent ones. We also show that the benefits are larger when folder content is spatially unstable. Finally, we discuss how the interfaces  could be combined and deployed in existing file browsers.</span></li>
<li id="PFU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PFU"><span class="letterCode" style="float:right">PFU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PFU">Wed. 9am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481283">SPRWeb: Preserving Subjective Responses to Website Colour Schemes through Automatic Recolouring</a></span><br />
<span class="authors">D. Flatla (Univ. of Saskatchewan, CA), K. Reinecke, C. Gutwin, K. Gajos</span>
<div class="authorList"><span><span class="author">D. Flatla</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">K. Reinecke</span> (Harvard Univ., USA)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">K. Gajos</span> (Harvard Univ., USA)</span></div>
<p><span class="cbStatement">SPRWeb equalizes website experience for people with colour vision deficiency by improving colour differentiation (like previous recolouring tools), but also maintains the original colour scheme&#8217;s subjective properties (&#8216;warmth&#8217;, &#8216;weight&#8217;, &#8216;activity&#8217;).</span><span class="abstract">Colours are an important part of user experiences on the Web. Colour schemes influence the aesthetics, first impressions and long-term engagement with websites. However, five percent of people perceive a subset of all colours because they have colour vision deficiency (CVD), resulting in an unequal and less-rich user experience on the Web. Traditionally, people with CVD have been supported by recolouring tools that improve colour differentiability, but do not consider the subjective properties of colour schemes while recolouring. To address this, we developed SPRWeb, a tool that recolours websites to preserve subjective responses and improve colour differentiability &#8211; thus enabling users with CVD to have similar online experiences. To develop SPRWeb, we extended existing models of non-CVD subjective responses to CVD, then used this extended model to steer the recolouring process. In a lab study, we found that SPRWeb did significantly better than a standard recolouring tool at preserving the temperature and naturalness of websites, while achieving similar weight and differentiability preservation. We also found that recolouring did not preserve activity, and hypothesize that visual complexity influences activity more than colour. SPRWeb is the first tool to automatically preserve the subjective and perceptual properties of website colour schemes thereby equalizing the colour-based web experience for people with CVD.</span></li>
<li id="PBY"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PBY"><span class="letterCode" style="float:right">PBY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PBY">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470675">‘See Me, Feel Me, Touch Me, Hear Me’: Trajectories and Interpretation in a Sculpture Garden</a></span><br />
<span class="authors">L. Fosh (The Univ. of Nottingham, UK), S. Benford, S. Reeves, B. Koleva, P. Brundell</span>
<div class="authorList"><span><span class="author">L. Fosh</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Benford</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Reeves</span> (The Univ. of Nottingham, UK)</span><span><span class="author">B. Koleva</span> (The Univ. of Nottingham, UK)</span><span><span class="author">P. Brundell</span> (The Univ. of Nottingham, UK)</span></div>
<p><span class="cbStatement">Describes the application of the trajectories framework to the design of a user experience in a sculpture garden. Can assist in designing experiences for engagement and interpretation.</span><span class="abstract">We apply the HCI concept of trajectories to the design of a sculpture trail. We crafted a trajectory through each sculpture, combining textual and audio instructions to drive directed viewing, movement and touching while listening to accompanying music. We designed key transitions along the way to oscillate between moments of social interaction and isolated personal engagement, and to deliver official interpretation only after visitors had been given the opportunity to make their own. We describe how visitors generally followed our trajectory, engaging with sculptures and making interpretations that sometimes challenged the received interpretation. We relate our findings to discussions of sense-making and design for multiple interpretations, concluding that curators and designers may benefit from considering ‘trajectories of interpretation’.</span></li>
<li id="PME"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/paper.html#PME"><span class="letterCode" style="float:right">PME</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PME">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470669">From Competition to Metacognition: Designing Diverse, Sustainable Educational Games</a></span><br />
<span class="authors">S. Foster (UC San Diego, USA), S. Esper, W. Griswold</span>
<div class="authorList"><span><span class="author">S. Foster</span> (UC San Diego, USA)</span><span><span class="author">S. Esper</span> (Univ. of California, San Diego, USA)</span><span><span class="author">W. Griswold</span> (UC San Diego, USA)</span></div>
<p><span class="cbStatement">Educational games are traditionally single-player games.  We evaluate commercial multiplayer games in order to inform the design of educational multiplayer games.</span><span class="abstract">We investigate the unique educational benefits of 1-on-1 competitive games, arguing that such games can be just as easy to design as single-player educational games, while yielding a more diverse and sustainable learning experience.  We present a study of chess and StarCraft II in order to inform the design of similar educational games and their communities.  We discuss a competitive game we designed to teach Java programming.  We evaluate the game by discussing its user study.    Our main contributions are 1) an argument that the use of 1-on-1 competition can solve two existing problems inherent to single-player games, 2) an analysis of the features that make competitive games effective learning environments, and 3) an early but encouraging description of the emergent learning environment one can expect from designing an educational game with these features.</span></li>
<li id="NSU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NSU"><span class="letterCode" style="float:right">NSU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NSU">Wed. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481408">Reifying Social Movement Trajectories</a></span><br />
<span class="authors">A. Fouse (Univ. of California, San Diego, USA), N. Weibel, C. Johnson, J. Hollan</span>
<div class="authorList"><span><span class="author">A. Fouse</span> (Univ. of California, San Diego, USA)</span><span><span class="author">N. Weibel</span> (Univ. of California, San Diego, USA)</span><span><span class="author">C. Johnson</span> (Univ. of California, San Diego, USA)</span><span><span class="author">J. Hollan</span> (Univ. of California, San Diego, USA)</span></div>
<p><span class="cbStatement">We describe the development of a novel paper-digital interface for recording movement trajectories, designed to assist ethnographers and ethologists in analysis of social  movement.</span><span class="abstract">In this paper we describe the development of a novel paper-digital  interface for recording movement trajectories, designed to  assist ethnographers and ethologists in analysis of social  movement. While we focus on development of a system to aid analysis of  elephant movement, the resulting interaction techniques and facilities  are quite general. The paper highlights how our design evolved to  balance the goals of researchers, their current practices, and the challenges of  integrating the relatively unconstrained world of pen and paper with  the relatively constrained world of digital systems.</span></li>
<li id="PGD"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PGD"><span class="letterCode" style="float:right">PGD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PGD">Wed. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481385">Gestures and Widgets: Performance in Text Editing on Multi-Touch Capable Mobile Devices</a></span><br />
<span class="authors">V. Fuccella (Univ. di Salerno, IT), P. Isokoski, B. Martin</span>
<div class="authorList"><span><span class="author">V. Fuccella</span> (Univ. di Salerno, IT)</span><span><span class="author">P. Isokoski</span> (Univ. of Tampere, FI)</span><span><span class="author">B. Martin</span> (Univ. de Lorraine, FR)</span></div>
<p><span class="cbStatement">We present the design and evaluation of a gestural text editing technique for touchscreens.   Gestures drawn on the soft keyboard are often faster than conventional editing techniques.</span><span class="abstract">We describe the design and evaluation of a gestural text editing technique for touchscreen devices. The gestures are drawn on top of the soft keyboard and interpreted as commands for moving the caret, performing selections, and controlling the clipboard. Our implementation is an Android service that can be used in any text editing task on Android-based devices. We conducted an experiment to compare the gestural editing technique against the widget-based technique available on a smartphone (Samsung Galaxy II with Android 2.3.5). The results show a performance benefit of 13-24% for the gestural technique depending on the font size. Subjective feedback from the participants was also positive. Because the two editing techniques use different input areas, they can co-exist on a device. This means that the gestural editing can be added on any soft keyboard without interfering with user experience for those users that choose not to use it.</span></li>
<li id="PSE"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PSE"><span class="letterCode" style="float:right">PSE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PSE">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466443">Evaluation of Alternative Glyph Designs for Time Series Data in a Small Multiple Setting</a></span><br />
<span class="authors">J. Fuchs (Univ., DE), F. Fischer, F. Mansmann, E. Bertini, P. Isenberg</span>
<div class="authorList"><span><span class="author">J. Fuchs</span> (Univ., DE)</span><span><span class="author">F. Fischer</span> (Univ., DE)</span><span><span class="author">F. Mansmann</span> (Univ., DE)</span><span><span class="author">E. Bertini</span> (Univ., USA)</span><span><span class="author">P. Isenberg</span> (INRIA, FR)</span></div>
<p><span class="cbStatement">1. Evaluation of alternative glyph designs for time series data.  2. Design considerations and guidelines for creating glyphs for time series data. </span><span class="abstract">We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting.  Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring. Several visualization techniques have, thus, been proposed in the literature.  Among these, iconic displays or glyphs are an appropriate choice   because of their expressiveness and effective use of screen space.  Through a controlled experiment, we compare the performance of four glyphs that use different combinations of visual variables to encode two properties of temporal data: a) the position of a data point in time and b) the quantitative value of this data point.   Our results show that depending on tasks and data density, the chosen glyphs performed differently. Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations. From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.</span></li>
<li id="PTB"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PTB"><span class="letterCode" style="float:right">PTB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PTB">Wed. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481395">Materials, Materiality, and Media</a></span><br />
<span class="authors">V. Fuchsberger (Univ. of Salzburg, AT), M. Murer, M. Tscheligi</span>
<div class="authorList"><span><span class="author">V. Fuchsberger</span> (Univ. of Salzburg, AT)</span><span><span class="author">M. Murer</span> (Univ. of Salzburg, AT)</span><span><span class="author">M. Tscheligi</span> (Univ. of Salzburg, AT)</span></div>
<p><span class="cbStatement">Reflects on Marshall McLuhan’s media analysis, as well as Bruno Latour’s Actor-Network Theory regarding materials in HCI interaction design. Presents transferred ideas and junctures for the materiality discourse. </span><span class="abstract">In HCI, and especially in interaction design, the material aspect of interactions is currently emphasized. Nevertheless, it is challenging to theoretically frame the variety of digital or immaterial, and physical materials. In order to contribute to this materiality discourse, we reflect on McLuhan’s work on media analysis and on Latour’s Actor-Network Theory in this paper. Both emphasize the active role of the material – be it media or any other kind of non-human actors – in the interplay with the human. Thus, we establish junctures between their findings and materials, as used in interaction design in HCI. We discuss McLuhan’s claim to focus on new sensory effects and ways of interaction brought forth by new media. Furthermore, we illustrate how describing the connections between materials, designers, and users in terms of Latour’s Actor-Networks can be beneficial for interaction design. Finally, we discuss the respective methodology and its relation to research through design.</span></li>
<li id="PLJ"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PLJ"><span class="letterCode" style="float:right">PLJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PLJ">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470719">Same Translation but Different Experience: The Effects of Highlighting on Machine-Translated Conversations</a></span><br />
<span class="authors">G. Gao (Cornell Univ., USA), H. Wang, D. Cosley, S. Fussell</span>
<div class="authorList"><span><span class="author">G. Gao</span> (Cornell Univ., USA)</span><span><span class="author">H. Wang</span> (National Tsing Hua Univ., TW)</span><span><span class="author">D. Cosley</span> (Cornell Univ., USA)</span><span><span class="author">S. Fussell</span> (Cornell Univ., USA)</span></div>
<p><span class="cbStatement">This study demonstrates that keyword highlighting is useful for improving the quality of MT-mediated communication. It informs the design of tools to support communication and collaboration across language boundaries.</span><span class="abstract">Machine translation (MT) has the potential to allow members of multilingual organizations to interact via their own native languages, but issues with the quality of MT output have made it difficult to realize this potential. We hypothesized that highlighting keywords in MT output might make it easier for people to overlook translation errors and focus on what was intended by the message. To test this hypothesis, we conducted a laboratory experiment in which native English speakers interacted with a Mandarin-speaking confederate using machine translation. Participants performed three brainstorming tasks, under each of three conditions: no highlighting, keyword highlighting, and random highlighting. Our results indicated that people consider the identical messages clearer and less distracting when the keywords in the message are highlighted. Keyword highlighting also improved subjective impressions of the partner and the quality of the collaboration. These findings inform the design of future communication tools to support multilingual communications. </span></li>
<li id="PMU"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PMU"><span class="letterCode" style="float:right">PMU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PMU">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466426">Adaptive Automation and Cue Invocation: The Effect of Cue Timing on Operator Error</a></span><br />
<span class="authors">D. Gartenberg (George Mason Univ., USA), L. Breslow, J. Park, M. McCurry, G. Trafton</span>
<div class="authorList"><span><span class="author">D. Gartenberg</span> (George Mason Univ., USA)</span><span><span class="author">L. Breslow</span> (Naval Research Laboratory, USA)</span><span><span class="author">J. Park</span> (George Mason Univ., USA)</span><span><span class="author">M. McCurry</span> (Naval Research Laboratory, USA)</span><span><span class="author">G. Trafton</span> (Naval Research Laboratory, USA)</span></div>
<p><span class="cbStatement">Hybrid adaptive automation, which uses critical-events and eye-movements, was compared with critical-event invocation.  Both systems reduced errors, but cue timing affected the types of errors made in a supervisory-control task.</span><span class="abstract">Adaptive automation (AA) can improve performance while addressing the problems associated with a fully automated system.  The best way to invoke AA is unclear, but two ways include critical events and the operator’s state. A hybrid model of AA invocation, the dynamic model of operator overload (DMOO), that takes into account critical events and the operator’s state was recently shown to improve performance.  The DMOO initiates AA using critical events and attention allocation, informed by eye movements.  We compared the DMOO with an inaccurate automation invocation system and a system that invoked AA based only on critical events. Fewer errors were made with DMOO than with the inaccurate system.  In the critical event condition, where automation was invoked at an earlier point in time, there were more memory and planning errors, while for the DMOO condition, which invocated automation at a later point in time, there were more perceptual errors.  These findings provide a framework for reducing specific types of errors through different automation invocation. </span></li>
<li id="PLG"class="presentation design ux sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PLG"><span class="letterCode" style="float:right">PLG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PLG">Thu. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466474">Indoor Weather Stations: Investigating a Ludic Approach to Environmental HCI Through Batch Prototyping</a></span><br />
<span class="authors">W. Gaver (Goldsmiths, Univ. of London, UK), J. Bowers, K. Boehner, A. Boucher, D. Cameron, M. Hauenstein, N. Jarvis, S. Pennington</span>
<div class="authorList"><span><span class="author">W. Gaver</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">J. Bowers</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">K. Boehner</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">A. Boucher</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">D. Cameron</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">M. Hauenstein</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">N. Jarvis</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">S. Pennington</span> (Goldsmiths, Univ. of London, UK)</span></div>
<p><span class="cbStatement">Three ‘weatherstations’, designed to take a ludic approach to environmental issues, were deployed to twenty households. The result is a distinctive example of environmental HCI, batch production, and ludic design.</span><span class="abstract">In this project, we investigated how a ludic approach might open new possibilities for environmental HCI by designing three related devices that encourage environmental awareness while eschewing utilitarian or persuasive agendas. In addition, we extended our methodological approach by batch-producing multiple copies of each device and deploying them to 20 households for several months, gathering a range of accounts about how people engaged and used them.  The devices, collectively called the ‘Indoor Weather Stations’, reveal the home’s microclimate by highlighting small gusts of wind, the colour of ambient light, and temperature differentials within the home. We found that participants initially tended to relate to the devices in line with two ‘orienting narratives’ of environmental tools or ludic designs, finding the devices disappointing from either perspective. Most of our participants showed lingering affection for the devices, however, for a variety of reasons. We discuss the implications of this ‘sporadic interaction’, and the more general lessons from the project, both for environmental HCI and ludic design. </span></li>
<li id="PKY"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PKY"><span class="letterCode" style="float:right">PKY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PKY">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470700">‘Digital Motherhood’: How does technology help new mothers?</a></span><br />
<span class="authors">L. Gibson (Univ. of Dundee, UK), V. Hanson</span>
<div class="authorList"><span><span class="author">L. Gibson</span> (Univ. of Dundee, UK)</span><span><span class="author">V. Hanson</span> (Univ. of Dundee, UK)</span></div>
<p><span class="cbStatement">This research identified two themes where technology supports mothers: improving confidence and being more than ‘just’ a mother. Findings have implications for digital engagement, digital identity and social networking.</span><span class="abstract">New mothers can experience social exclusion, particularly during the early weeks when infants are solely dependent on their mothers. We used ethnographic methods to investigate whether technology plays a role in supporting new mothers. Our research identified two core themes: (1) the need to improve confidence as a mother; and (2) the need to be more than ‘just’ a mother. We reflect on these findings both in terms of those interested in designing applications and services for motherhood and also the wider CHI community.</span></li>
<li id="PDM"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PDM"><span class="letterCode" style="float:right">PDM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PDM">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481336">&#8220;I Need to Try This!&#8221;: A Statistical Overview of Pinterest</a></span><br />
<span class="authors">E. Gilbert (Georgia Institute of Technology, USA), S. Bakhshi, S. Chang, L. Terveen</span>
<div class="authorList"><span><span class="author">E. Gilbert</span> (Georgia Institute of Technology, USA)</span><span><span class="author">S. Bakhshi</span> (Georgia Institute of Technology, USA)</span><span><span class="author">S. Chang</span> (Univ. of Minnesota, USA)</span><span><span class="author">L. Terveen</span> (Univ. of Minnesota, USA)</span></div>
<p><span class="cbStatement">We use a quantitative approach to study activity, gender and distinctiveness on Pinterest. This work serves as an early snapshot of Pinterest that later work can leverage.</span><span class="abstract">Over the past decade, social network sites have become ubiquitous places for people to maintain relationships, as well as loci of intense research interest. Recently, a new site has exploded into prominence: Pinterest became the fastest social network to reach 10M users, growing 4000% in 2011 alone. While many Pinterest articles have appeared in the popular press, there has been little scholarly work so far. In this paper, we use a quantitative approach to study three research questions about the site. What drives activity on Pinterest? What role does gender play in the site’s social connections? And finally, what distinguishes Pinterest from existing networks, in particular Twitter? In short, we find that being female means more repins, but fewer followers, and that four verbs set Pinterest apart from Twitter: use, look, want and need. This work serves as an early snapshot of Pinterest that later work can leverage.</span></li>
<li id="NJT"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NJT"><span class="letterCode" style="float:right">NJT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NJT">Wed. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481386">ContextType: Using Hand Posture Information to Improve Mobile Touch Screen Text Entry</a></span><br />
<span class="authors">M. Goel (Univ. of Washington, USA), A. Jansen, T. Mandel, S. Patel, J. Wobbrock</span>
<div class="authorList"><span><span class="author">M. Goel</span> (Univ. of Washington, USA)</span><span><span class="author">A. Jansen</span> (Univ. of Washington, USA)</span><span><span class="author">T. Mandel</span> (Univ. of Washington, USA)</span><span><span class="author">S. Patel</span> (Univ. of Washington, USA)</span><span><span class="author">J. Wobbrock</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">ContextType is an adaptive text entry system that leverages information about a user’s hand posture to improve mobile touch screen text entry by 20.6%.</span><span class="abstract">The challenge of mobile text entry is exacerbated as mobile devices are used in a number of situations and with a number of hand postures. We introduce ContextType, an adaptive text entry system that leverages information about a user’s hand posture (using two thumbs, the left thumb, the right thumb, or the index finger) to improve mobile touch screen text entry. ContextType switches between various keyboard models based on hand posture inference while typing. ContextType combines the user’s posture-specific touch pattern information with a language model to classify the user’s touch events as pressed keys. To create our models, we collected usage patterns from 16 participants in each of the four postures. In a subsequent study with the same 16 participants comparing ContextType to a control condition, ContextType reduced total text entry error rate by 20.6%. </span></li>
<li id="PBR"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PBR"><span class="letterCode" style="float:right">PBR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PBR">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470737">MorePhone: A Study of Actuated Shape Deformations for Flexible Thin-Film Smartphone Notifications</a></span><br />
<span class="authors">A. Gomes (Queen&#8217;s Univ., CA), A. Nesbitt, R. Vertegaal</span>
<div class="authorList"><span><span class="author">A. Gomes</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">A. Nesbitt</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">R. Vertegaal</span> (Queen&#8217;s Univ., CA)</span></div>
<p><span class="cbStatement">Presents a shape changing flexible smartphone that actuates its body for the purpose of providing notifications. Empirically evaluates mapping between shape actuations, urgency and notification type.</span><span class="abstract">We present MorePhone, an actuated flexible smartphone with a thin-film E Ink display. MorePhone uses shape memory alloys to actuate the entire surface of the display as well as individual corners. We conducted a participatory study to determine how users associate urgency and notification type with full screen, 1 corner, 2 corner and 3 corner actuations of the smartphone. Results suggest that with the current prototype, actuated shape notifications are useful for visual feedback. Urgent notifications such as alarms and voice calls were best matched with actuation of the entire display surface, while less urgent notifications, such as software notifications were best matched to individual corner bends. While different corner actuations resulted in significantly different matches between notification types, medium urgency notification types were treated as similar, and best matched to a single corner bend. A follow-up study suggested that users prefer to dedicate each corner to a specific type of notification. Users would like to personalize the assignment of corners to notification type. Animation of shape actuation significantly increased the perceived urgency of any of the presented shapes.</span></li>
<li id="PMH"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PMH"><span class="letterCode" style="float:right">PMH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PMH">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481405">Footprint Tracker: Supporting Diary Studies with Lifelogging</a></span><br />
<span class="authors">R. Gouveia (Madeira Interactive Technologies Institute, PT), E. Karapanos</span>
<div class="authorList"><span><span class="author">R. Gouveia</span> (Madeira Interactive Technologies Institute, PT)</span><span><span class="author">E. Karapanos</span> (Madeira Interactive Technologies Institute, PT)</span></div>
<p><span class="cbStatement">Study of how visual, location, temporal and social context life logs support recall and reflection over daily activities and experiences in the context of diary studies.</span><span class="abstract">As HCI shifts “to the wild”, in-situ methods such as Diary Methods and the Experience Sampling Method are gaining momentum. However, researchers have acknowledged the intrusiveness and lack of realism in these methods and have proposed solutions, notably through lightweight and rich media capture. In this paper we explore the concept of lifelogging as an alternative solution to these two challenges. We describe Footprint Tracker, a tool that allows the review of lifelogs with the aim to support recall and reflection over daily activities and experiences. In a field trial, we study how four different types of cues, namely visual, location, temporal and social context, trigger memories of recent events and associated emotions. We conclude with a number of implications for the design of lifelogging systems that support recall and reflection upon recent events as well as ones lying further in our past.</span></li>
<li id="NDU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NDU"><span class="letterCode" style="float:right">NDU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NDU">Wed. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481376">Effects of Visualization and Note-Taking  on Sensemaking and Analysis</a></span><br />
<span class="authors">N. Goyal (Cornell Univ., USA), G. Leshed, S. Fussell</span>
<div class="authorList"><span><span class="author">N. Goyal</span> (Cornell Univ., USA)</span><span><span class="author">G. Leshed</span> (Cornell Univ., USA)</span><span><span class="author">S. Fussell</span> (Cornell Univ., USA)</span></div>
<p><span class="cbStatement">The utility of intelligence analysis tools’ individual features is rarely tested. Through experiment, we tested the utility of visualization and notetaking. Our Results question potential constraints on their individual utility.</span><span class="abstract">Many sophisticated tools have been developed to help analysts detect patterns in large datasets, but the value of these tools’ individual features is rarely tested. In an experiment in which participants played detectives solving homicides, we tested the utility of a visualization of data links and a notepad for collecting and organizing annotations. The visualization significantly improved participants’ ability to solve the crime whereas the notepad did not. Having both features available provided no benefit over having just the visualization. The results raise questions about the potential constraints on the usefulness of intelligence analysis tools.</span></li>
<li id="PLF"class="presentation games"><a href="http://chi2013.acm.org/previews/paper.html#PLF"><span class="letterCode" style="float:right">PLF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PLF">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470754">Villains, Architects and Micro-Managers: What Tabula Rasa Teaches Us About Game Orchestration</a></span><br />
<span class="authors">T. Graham (Queen&#8217;s Univ., CA), I. Schumann, M. Patel, Q. Bellay, R. Dachselt</span>
<div class="authorList"><span><span class="author">T. Graham</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">I. Schumann</span> (Univ. of Magdeburg, DE)</span><span><span class="author">M. Patel</span> (Kingston Univ., CA)</span><span><span class="author">Q. Bellay</span> (Kingston Univ., CA)</span><span><span class="author">R. Dachselt</span> (Technische Univ. Dresden, DE)</span></div>
<p><span class="cbStatement">Describes how digital games can allow design like activities at play-time, and how players use them when playing games.</span><span class="abstract">Players of digital games are limited by the constraints of the game’s implementation. Players cannot fly a kite, plant a tree or make friends with a dragon if these activities were not coded within the game. Game orchestration relaxes these restrictions by allowing players to create game narratives and settings as the game is being played. This enables players to express their creativity beyond the strictures of the game’s implementation. We present Tabula Rasa, a novel game orchestration tool based on an efficient tabletop interface. Based on a study of 20 game orchestration sessions using Tabula Rasa, we identify five behavioural patterns adopted by orchestrators, and four styles of collaborative interaction between orchestrators and players. Finally, we present recommendations for designers of game orchestration systems.</span></li>
<li id="PCH"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PCH"><span class="letterCode" style="float:right">PCH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PCH">Mon. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470718">The Efficacy of Human Post-Editing for Language Translation</a></span><br />
<span class="authors">S. Green (Stanford Univ., USA), J. Heer, C. Manning</span>
<div class="authorList"><span><span class="author">S. Green</span> (Stanford Univ., USA)</span><span><span class="author">J. Heer</span> (Stanford Univ., USA)</span><span><span class="author">C. Manning</span> (Stanford Univ., USA)</span></div>
<p><span class="cbStatement">We analyzed human post-editing of machine translation output, a common feature in translator interfaces. We found that machine suggestions reduce human translation time and improved final quality.</span><span class="abstract">Language translation is slow and expensive, so various forms of machine assistance have been devised. Automatic machine translation systems process text quickly and cheaply, but with quality far below that of skilled human translators. To bridge this quality gap, the translation industry has investigated post-editing, or the manual correction of machine output. We present the first rigorous, controlled analysis of post-editing and find that post-editing leads to reduced time and, surprisingly, improved quality for three diverse language pairs (English to Arabic, French, and German). Our statistical models and visualizations of experimental data indicate that some simple predictors (like source text part of speech counts) predict translation time, and that post-editing results in very different interaction patterns. From these results we distill implications for the design of new language translation interfaces.</span></li>
<li id="NMZ"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#NMZ"><span class="letterCode" style="float:right">NMZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NMZ">Thu. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466421">Informal Cognitive Walkthroughs (ICW): Paring Down and Pairing Up for an Agile World</a></span><br />
<span class="authors">V. Grigoreanu (Microsoft Corporation, USA), M. Mohanna</span>
<div class="authorList"><span><span class="author">V. Grigoreanu</span> (Microsoft Corporation, USA)</span><span><span class="author">M. Mohanna</span> (Microsoft Corporation, USA)</span></div>
<p><span class="cbStatement">We present the Informal Cognitive Walkthrough (ICW): an agile user experience research methodology, developed and perfected over three years to meet the needs of a large agile software development team.</span><span class="abstract">Agile software teams’ frequent releases and fast iterations present a growing need for rigorous user experience research methods that are faster, lighter-weight, and more flexible. To this end, we developed the Informal Cognitive Walkthrough (ICW). This agile research methodology grew organically, over the course of three years, while working with a very large agile software development team. ICWs involve conducting one or more Simplified ‘Streamlined Cognitive Walkthroughs’ (SSCW), followed by one or more Simplified ‘Pluralistic Walkthroughs’ (SPW). In this paper, we present the ICW and provide a real-world example of its application. Preliminary experiences with the method revealed potential advantages over traditional lab studies, ranging from more quickly uncovering and fixing usability issues, to a stronger collaboration between the disciplines, and to acting as a forcing function in aligning diverse engineers to deliver on a common user goal.</span></li>
<li id="PLC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PLC"><span class="letterCode" style="float:right">PLC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLC">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466124">Machinima Production Tools:  A Vernacular History of a Creative Medium</a></span><br />
<span class="authors">S. Gross (Indiana Univ. Bloomington, USA), T. Pace, J. Bardzell, S. Bardzell</span>
<div class="authorList"><span><span class="author">S. Gross</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">T. Pace</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">J. Bardzell</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">S. Bardzell</span> (Indiana Univ. Bloomington, USA)</span></div>
<p><span class="cbStatement">In this study of massive scale community creativity, we provide a diachronic analysis of the co-emergence of community-developed creativity tools and the expressive visual language of their medium.</span><span class="abstract">In recent years, HCI has shown a rising interest in the creative practices associated with massive online communities, including crafters, hackers, DIY, and other expert amateurs. One strategy for researching creativity at this scale is through an analysis of a community’s outputs, including its creative works, custom created tools, and emergent practices. In this paper, we offer one such case study, a historical account of World of Warcraft (WoW) machinima (i.e., videos produced inside of video games), which shows how the aesthetic needs and requirements of video making community coevolved with the community-made creativity support tools in use at the time. We view this process as inhabiting different layers and practices of appropriation, and through an analysis of them, we trace the ways that support for emerging stylistic conventions become built into creativity support tools over time.</span></li>
<li id="PCY"class="presentation design ux sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PCY"><span class="letterCode" style="float:right">PCY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PCY">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466472">Slow Design for Meaningful Interactions</a></span><br />
<span class="authors">B. Grosse-Hering (Designit, DE), J. Mason, D. Aliakseyeu, C. Bakker, P. Desmet</span>
<div class="authorList"><span><span class="author">B. Grosse-Hering</span> (Designit, DE)</span><span><span class="author">J. Mason</span> (Philips Research, NL)</span><span><span class="author">D. Aliakseyeu</span> (Philips Research, NL)</span><span><span class="author">C. Bakker</span> (Delft Univ. of Technology, NL)</span><span><span class="author">P. Desmet</span> (Delft Univ. of Technology, NL)</span></div>
<p><span class="cbStatement">In this paper we report on an exploration of how to apply the theory of Slow Design to mass produced products to establish more mindful usage of products.</span><span class="abstract">In this paper we report on an exploration of how to apply the theory of Slow Design to mass produced products to establish more mindful usage of products; the intention behind this is to promote product attachment and the associated sustainable benefits of long term use. Slow Design is a design philosophy that focuses on promoting well-being for individuals, society, and the natural environment. It encourages people to do things at the right time and at the right speed which helps them to understand and reflect on their actions. Several authors have proposed Slow Design principles and cases have been reported in which these principles were applied in cultural design projects. These applications indicated that Slow Design can indeed have a positive impact on wellbeing. Although promising, this philosophy has not yet been used in the design of mass consumer products. In this paper we present a design case study in which we explored how the Slow Design principles can be applied in the design of an electric fruit juicer. Two studies are reported on where the conditions for implementing Slow Design are explored.  The results led to a revision of the principles for use by product designers. The main finding from the case study is that the Slow Design principles can be used to create more ‘mindful’ interactions that stimulate positive user involvement.  This is not from designing interactions that require more time per se, but by stimulating the user to use more time for those parts of the interaction that are meaningful and less for those that are not meaningful.</span></li>
<li id="PPE"class="presentation engineering ux games"><a href="http://chi2013.acm.org/previews/paper.html#PPE"><span class="letterCode" style="float:right">PPE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPE">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466186">Swiss-Cheese Extended: An Object Recognition Method for Ubiquitous Interfaces based on Capacitive Proximity Sensing</a></span><br />
<span class="authors">T. Grosse-Puppendahl (Fraunhofer IGD, DE), A. Braun, F. Kamieth, A. Kuijper</span>
<div class="authorList"><span><span class="author">T. Grosse-Puppendahl</span> (Fraunhofer IGD, DE)</span><span><span class="author">A. Braun</span> (Fraunhofer IGD, DE)</span><span><span class="author">F. Kamieth</span> (Fraunhofer IGD, DE)</span><span><span class="author">A. Kuijper</span> (Fraunhofer IGD, DE)</span></div>
<p><span class="cbStatement">Swiss-Cheese Extended proposes a novel real-time method for recognizing continuous object parameters with capacitive proximity sensors. The method is evaluated with a study of a multi-hand interaction device.</span><span class="abstract">Swiss-Cheese Extended proposes a novel real-time method for recognizing objects with capacitive proximity sensors. Applying this technique to ubiquitous user interfaces, it is possible to detect the 3D-position of multiple human hands in different configurations above a surface that is equipped with a small number of sensors. The retrieved object configurations can significantly improve a user&#8217;s interaction experience or an application&#8217;s execution context, for example by detecting multi-hand zoom and rotation gestures or recognizing a grasping hand. We emphasize the broad applicability of the proposed method with a study of a multi-hand gesture recognition device.</span></li>
<li id="PLE"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PLE"><span class="letterCode" style="float:right">PLE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLE">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466188">LongPad: A TouchPad Using the Entire Area below the Keyboard of a Laptop Computer</a></span><br />
<span class="authors">J. Gu (KAIST (Korea Advanced Institute of Science and Technology), KR), S. Heo, J. Han, S. Kim, G. Lee</span>
<div class="authorList"><span><span class="author">J. Gu</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">S. Heo</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">J. Han</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">S. Kim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">G. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span></div>
<p><span class="cbStatement">We implemented a proximity- and force-sensing touchpad and explored the feasibility and new possibilities of a long touchpad that utilizes the entire area below the keyboard on a laptop computer.</span><span class="abstract">In this paper, we explore the possibility of a long touchpad that utilizes the entire area below the keyboard of a laptop computer. An essential prerequisite for such a touchpad is a robust palm rejection method, which we satisfy using a proximity-sensing touchpad. We developed LongPad, a proximity-sensing optical touchpad that is as wide as a laptop keyboard, and implemented a palm rejection algorithm that utilizes proximity images from LongPad. In a user study conducted, we observed that LongPad rejected palm touches almost perfectly while participants were repeating typing and pointing tasks. We also summarize the new design space enabled by LongPad and demonstrate a few of the interaction techniques it facilitates.</span></li>
<li id="PAE"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PAE"><span class="letterCode" style="float:right">PAE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PAE">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466240">Digital Artifacts as Legacy: Exploring the Lifespan and Value of Digital Data</a></span><br />
<span class="authors">R. Gulotta (Carnegie Mellon Univ., USA), W. Odom, H. Faste, J. Forlizzi</span>
<div class="authorList"><span><span class="author">R. Gulotta</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">W. Odom</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">H. Faste</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Forlizzi</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We designed interactive systems to investigate how digital materials might be passed down. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. </span><span class="abstract">Legacy is the meaningful and complex way in which information, values, and possessions are passed on to others. As digital systems and information become meaningfully parts of people’s everyday and social relationships, it is essential to develop new insights about how technology intersects with legacy and inheritance practices. We designed three interactive systems to investigate how digital materials might be passed down in the future. We conducted in-home interviews with ten parents using the systems to provoke discussion about how technology might support or complicate their existing practices. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. Findings are interpreted to describe design considerations for future work in this emerging space.  </span></li>
<li id="PBJ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PBJ"><span class="letterCode" style="float:right">PBJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBJ">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466114">Understanding Palm-Based Imaginary Interfaces: The Role of Visual and Tactile Cues when Browsing</a></span><br />
<span class="authors">S. Gustafson (Hasso Plattner Institute, DE), B. Rabe, P. Baudisch</span>
<div class="authorList"><span><span class="author">S. Gustafson</span> (Hasso Plattner Institute, DE)</span><span><span class="author">B. Rabe</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Baudisch</span> (Hasso Plattner Institute, DE)</span></div>
<p><span class="cbStatement">The main contribution of this paper is an exploration into the inherent properties of palm-based imaginary interfaces and how the available visual and tactile cues are responsible for user performance.</span><span class="abstract">Imaginary Interfaces are screen-less ultra-mobile interfaces. Previously we showed that even though they offer no visual feedback they allow users to interact spatially, e.g., by pointing at a location on their non-dominant hand.    The primary goal of this paper is to provide a deeper understanding of palm-based imaginary interfaces, i.e., why they work. We perform our exploration using an interaction style inspired by interfaces for visually impaired users. We implemented a system that audibly announces target names as users scrub across their palm. Based on this interface, we conducted three studies. We found that (1) even though imaginary interfaces cannot display visual contents, users’ visual sense remains the main mechanism that allows users to control the interface, as they watch their hands interact. (2) When we remove the visual sense by blindfolding, the tactile cues of both hands feeling each other in part replace the lacking visual cues, keeping imaginary interfaces usable. (3) While we initially expected the cues sensed by the pointing finger to be most important, we found instead that it is the tactile cues sensed by the palm that allow users to orient themselves most effectively.     While these findings are primarily intended to deepen our understanding of Imaginary Interfaces, they also show that eyes-free interfaces located on skin outperform interfaces on physical devices. In particular, this suggests that palm-based imaginary interfaces may have benefits for visually impaired users, potentially outperforming the touchscreen-based devices they use today.  </span></li>
<li id="PRR"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PRR"><span class="letterCode" style="float:right">PRR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PRR">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466187">HACHIStack: Dual-Layer Photo Touch Sensing for Haptic and Auditory Tapping Interaction</a></span><br />
<span class="authors">T. Hachisu (Univ., JP), H. Kajimoto</span>
<div class="authorList"><span><span class="author">T. Hachisu</span> (Univ., JP)</span><span><span class="author">H. Kajimoto</span> (Univ., JP)</span></div>
<p><span class="cbStatement">Extends photo touch sensor architecture that can measure the approaching velocity and predict its contact time with the surface. Demonstrates its applications including no-delay haptic feedback for tapping interaction.</span><span class="abstract">We present a novel photo touch sensing architecture, HACHIStack. It can measure the approaching velocity of an object and predict its contact time with the touch screen using two optical sensing layers above the surface. The photo sensing layers form three unique capabilities: high-speed sampling, velocity acquisition, and contact time prediction. This work quantitatively examines these capabilities through two laboratory experiments, and confirms that the capabilities of HACHIStack are sufficient for multimodal interaction, in particular, touch-based interaction with haptic enhancement. We then present three applications with HACHIStack: 1) chromatic percussions (xylophone and glockenspiel) with haptic feedback; 2) no-delay haptic feedback with the sensation of tapping on various simulated materials (e.g., rubber, wood and aluminum); and 3) a virtual piano instrument that allows players to perform weak and strong strokes by changing the tapping velocity.</span></li>
<li id="PLK"class="presentation design games"><a href="http://chi2013.acm.org/previews/paper.html#PLK"><span class="letterCode" style="float:right">PLK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLK">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466203">Designing Reusable Alternate Reality Games</a></span><br />
<span class="authors">D. Hansen (Brigham Young Univ., USA), E. Bonsignore, M. Ruppel, A. Visconti, K. Kraus</span>
<div class="authorList"><span><span class="author">D. Hansen</span> (Brigham Young Univ., USA)</span><span><span class="author">E. Bonsignore</span> (Univ. of Maryland, USA)</span><span><span class="author">M. Ruppel</span> (National Endowment for the Humanities, USA)</span><span><span class="author">A. Visconti</span> (Univ. of Maryland, USA)</span><span><span class="author">K. Kraus</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">This paper presents a framework for making Alternate Reality Games reusable, including replayable, adaptable, and extensible, and presents design strategies for implementing them.</span><span class="abstract">Successful Alternate Reality Games (ARGs), such as The Lost Experience, I Love Bees and Urgent EVOKE have solicited thousands of active participants and, often, millions of spectators from around the world. ARGs require significant resources not only in terms of initial design, but also in implementation, since live, dynamic interplay between players and designers is an inherent aspect of their interactive storylines. This paper outlines a novel design framework for creating reusable ARGs that will help extend the lifespan of ARGs and allow them to permeate new domains such as education. The framework includes three key reusable design objectives (replayability, adaptability, extensibility), each of which can be enacted at different levels of depth. We also identify barriers to reusable ARGs and design strategies for overcoming those barriers, drawing upon ARG designer interviews and existing ARGs. </span></li>
<li id="PJC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PJC"><span class="letterCode" style="float:right">PJC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PJC">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470744">Combining Crowdsourcing and Google Street View to Identify Street-level Accessibility Problems</a></span><br />
<span class="authors">K. Hara (Univ. of Maryland, USA), V. Le, J. Froehlich</span>
<div class="authorList"><span><span class="author">K. Hara</span> (Univ. of Maryland, USA)</span><span><span class="author">V. Le</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Froehlich</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">In this paper, we investigate the feasibility of using untrained crowd workers from Amazon Mechanical Turk (turkers) to find, label, and assess sidewalk accessibility problems in Google Street View imagery</span><span class="abstract">Poorly maintained sidewalks, missing curb ramps, and other obstacles pose considerable accessibility challenges; however, there are currently few, if any, mechanisms to determine accessible areas of a city a priori. In this paper, we investigate the feasibility of using untrained crowd workers from Amazon Mechanical Turk (turkers) to find, label, and assess sidewalk accessibility problems in Google Street View imagery. We report on two studies: Study 1 examines the feasibility of this labeling task with six dedicated labelers including three wheelchair users; Study 2 investigates the comparative performance of turkers. In all, we collected 13,379 labels and 19,189 verification labels from a total of 402 turkers. We show that turkers are capable of determining the presence of an accessibility problem with 81% accuracy. With simple quality control methods, this number increases to 93%. Our work demonstrates a promising new, highly scalable method for acquiring knowledge about sidewalk accessibility.</span></li>
<li id="PHG"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PHG"><span class="letterCode" style="float:right">PHG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PHG">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481292">Accessible Photo Album: Enhancing the Photo Sharing Experience for People with Visual Impairment</a></span><br />
<span class="authors">S. Harada (IBM Research, JP), D. Sato, D. Adams, S. Kurniawan, H. Takagi, C. Asakawa</span>
<div class="authorList"><span><span class="author">S. Harada</span> (IBM Research, JP)</span><span><span class="author">D. Sato</span> (IBM Research, JP)</span><span><span class="author">D. Adams</span> (Univ. of California, Santa Cruz, Santa Cruz)</span><span><span class="author">S. Kurniawan</span> (Univ. of California, Santa Cruz, Santa Cruz)</span><span><span class="author">H. Takagi</span> (IBM Research, JP)</span><span><span class="author">C. Asakawa</span> (IBM Research, JP)</span></div>
<p><span class="cbStatement">Study of how to support people with visual impairments to partake in photo capturing and sharing activities. Results from online survey and user study evaluation of custom accessible iPhone app.</span><span class="abstract">While a photograph is a visual artifact, studies reveal that a number of people with visual impairments are also interested in being able to share their memories and experiences with their sighted counterparts in the form of a photograph. We conducted an online survey to better understand the challenges faced by people with visual impairments in sharing and organizing photos, and reviewed existing tools and their limitations. Based on our analysis, we developed an accessible mobile application that enables a visually impaired user to capture photos along with audio recordings for the ambient sound and memo description and to browse through them eyes-free. Five visually impaired participants took part in a study in which they used our app to take photographs in naturalistic settings and to share them later with a sighted viewer. The participants were able to use our app to identify each photograph on their own during the photo sharing session, and reported high satisfaction in having been able to take the initiative during the process.</span></li>
<li id="PKG"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PKG"><span class="letterCode" style="float:right">PKG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PKG">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466134">Stories of the Smartphone in Everyday Discourse: Conflict, Tension &#038; Instability</a></span><br />
<span class="authors">E. Harmon (Univ. of California, Irvine, USA), M. Mazmanian</span>
<div class="authorList"><span><span class="author">E. Harmon</span> (Univ. of California, Irvine, USA)</span><span><span class="author">M. Mazmanian</span> (Univ. of California, Irvine, USA)</span></div>
<p><span class="cbStatement">This analysis of popular stories about the smartphone highlights three areas of conflict, tension and instability relevant to the relationships among values, mobile ICTs, user experience, and everyday practice.</span><span class="abstract">As the smartphone proliferates in American society, so too do stories about its value and impact. In this paper we draw on advertisements and news articles to analyze cultural discourse about the smartphone. We highlight two common tropes: one calling for increased technological integration, the other urging individuals to dis-integrate the smartphone from daily life. We examine the idealized subject positions of these two stories and show how both simplistic tropes call on the same overarching values to compel individuals to take opposing actions. We then reflect on the conflicts individuals experience in trying to align and account for their actions in relation to multiple contradictory narratives. Finally, we call for CHI researchers to tell and provoke more complicated stories of technologies and their relationships with values in conversations, publications, and future designs.</span></li>
<li id="PLP"class="presentation games cci"><a href="http://chi2013.acm.org/previews/paper.html#PLP"><span class="letterCode" style="float:right">PLP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PLP">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470667">In Search of Learning: Facilitating Data Analysis in Educational Games</a></span><br />
<span class="authors">E. Harpstead (Carnegie Mellon Univ., USA), B. Myers, V. Aleven</span>
<div class="authorList"><span><span class="author">E. Harpstead</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">B. Myers</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">V. Aleven</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We present a toolkit and methodology for recording and analyzing player log data in educational games, that allows game designers and researches multiple ways to explore student learning.</span><span class="abstract">The field of Educational Games has seen many calls for added rigor. One avenue for improving the rigor of the field is developing more generalizable methods for measuring student learning within games. Throughout the process of development, what is relevant to measure and assess may change as a game evolves into a finished product. The field needs an approach for game developers and researchers to be able to prototype and experiment with different measures that can stand up to rigorous scrutiny, as well as provide insight into possible new directions for development. We demonstrate a toolkit and analysis tools that capture and analyze students’ performance within open educational games. The system records relevant events during play, which can be used for analysis of player learning by designers. The tools support replaying student sessions within the original game’s environment, which allows researchers and developers to explore possible explanations for student behavior. Using this system, we were able to facilitate a number of analyses of student learning in an open educational game developed by a team of our collaborators as well as gain greater insight into student learning with the game and where to focus as we iterate.</span></li>
<li id="PND"class="presentation design management"><a href="http://chi2013.acm.org/previews/paper.html#PND"><span class="letterCode" style="float:right">PND</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PND">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481410">Influencing Visual Judgment through Affective Priming</a></span><br />
<span class="authors">L. Harrison (Univ. of North Carolina at Charlotte, USA), D. Skau, S. Franconeri, A. Lu, R. Chang</span>
<div class="authorList"><span><span class="author">L. Harrison</span> (Univ. of North Carolina at Charlotte, USA)</span><span><span class="author">D. Skau</span> (Univ. of North Carolina at Charlotte, USA)</span><span><span class="author">S. Franconeri</span> (Northwestern Univ., USA)</span><span><span class="author">A. Lu</span> (Univ. of North Carolina at Charlotte, USA)</span><span><span class="author">R. Chang</span> (Tufts Univ., USA)</span></div>
<p><span class="cbStatement">Affective priming (positive and negative emotion) is shown to significantly influence accuracy in visual judgment tasks for several common chart types.</span><span class="abstract">Recent research suggests that individual personality differences can influence performance with visualizations.  In addition to stable personality traits, research in psychology has found that temporary changes in affect (emotion) can also significantly impact performance during cognitive tasks.  In this paper, we show that affective priming also influences user performance on visual judgment tasks through an experiment that combines affective priming with longstanding graphical perception experiments.  Our results suggest that affective priming can influence accuracy in common graphical perception tasks.  We discuss possible explanations for these findings, and describe how these findings can be applied to design visualizations that are less (or more) susceptible to error in common visualization contexts. </span></li>
<li id="PQR"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PQR"><span class="letterCode" style="float:right">PQR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PQR">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481282">Love it or Hate it!  Interactivity and User Types</a></span><br />
<span class="authors">J. Hart (The Univ. of Manchester, UK), A. Sutcliffe, A. De Angeli</span>
<div class="authorList"><span><span class="author">J. Hart</span> (The Univ. of Manchester, UK)</span><span><span class="author">A. Sutcliffe</span> (The Univ. of Manchester, UK)</span><span><span class="author">A. De Angeli</span> (Univ. of Trento, IT)</span></div>
<p><span class="cbStatement">Demonstrates a mixed methods approach that identifies the importance of interactivity and repeated exposure in positively influencing UX and shows that different levels of UX can be explained through use types</span><span class="abstract">This paper investigates general and individual evaluations of User Experience (UX) with interactive web sites. A series of studies investigate user judgment on web sites with different interactivity levels over repeated exposures. The more interactive websites produced more positive affect, had better design quality ratings, which improved with exposure, and were preferred. Differences between the more interactive sites indicated overall UX was influenced by users’ preferences for interactive styles, with both sites having enthusiast, potential adopter, and non-adopter users. The implications for models and frameworks of UX are discussed.  </span></li>
<li id="PLM"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PLM"><span class="letterCode" style="float:right">PLM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLM">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466115">AD-Binning: Leveraging Around Device Space for Storing, Browsing and Retrieving Mobile Device Content</a></span><br />
<span class="authors">K. Hasan (Univ. of Manitoba, CA), D. Ahlström, P. Irani</span>
<div class="authorList"><span><span class="author">K. Hasan</span> (Univ. of Manitoba, CA)</span><span><span class="author">D. Ahlström</span> (Alpen-Adria-Univ. Klagenfurt, AT)</span><span><span class="author">P. Irani</span> (Univ. of Manitoba, CA)</span></div>
<p><span class="cbStatement">Presents AD-Binning, a novel interface for future small-screen mobile devices equipped with around-device sensing capabilities, with which screen content can be off-loaded in around-device-space to improve browsing and interaction efficiency.</span><span class="abstract">Exploring information content on mobile devices can be tedious and time consuming. We present Around-Device Binning, or AD-Binning, a novel mobile user interface that allows users to off-load mobile content in the space around the device. We informed our implementation of AD-Binning by exploring various design factors, such as the minimum around-device target size, suitable item selection methods, and techniques for placing content in off-screen space. In a task requiring exploration, we find that AD-Binning improves browsing efficiency by avoiding the minute selection and flicking mechanisms needed for on-screen interaction. We conclude with design guidelines for off screen content storage and browsing. </span></li>
<li id="NDV"class="presentation design engineering games arts"><a href="http://chi2013.acm.org/previews/paper.html#NDV"><span class="letterCode" style="float:right">NDV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NDV">Mon. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470739">LightCloth: Senseable Illuminating Optical Fiber Cloth for Creating Interactive Surfaces</a></span><br />
<span class="authors">S. Hashimoto (JST ERATO Igarashi Design Interface Project, JP), R. Suzuki, Y. Kamiyama, M. Inami, T. Igarashi</span>
<div class="authorList"><span><span class="author">S. Hashimoto</span> (JST ERATO Igarashi Design Interface Project, JP)</span><span><span class="author">R. Suzuki</span> (The Univ. of Tokyo, JP)</span><span><span class="author">Y. Kamiyama</span> (JST ERATO Igarashi Design Interface Project, JP)</span><span><span class="author">M. Inami</span> (Keio Univ., JP)</span><span><span class="author">T. Igarashi</span> (The Univ. of Tokyo, JP)</span></div>
<p><span class="cbStatement">LightCloth is a fabric interface that enables illumination, light communication, and position sensing. We added a sensory function to diffusive optical fibers, and widened the possibilities for new fabric interactions.</span><span class="abstract">This paper introduces an input and output device that enables illumination, bi-directional data communication, and position sensing on a soft cloth. This “LightCloth” is woven from diffusive optical fibers. Since the fibers are arranged in parallel, the cloth has one-dimensional position information. Sensor-emitter pairs attached to bundles of contiguous fibers enable bundle-specific light input and output. We developed a prototype system that allows full-color illumination and 8-bit data input by infrared signals. We present as an application a chair with a LightCloth cover whose illumination pattern is specified using an infrared light pen. Here we describe the implementation details of the device and discuss possible interactions using the device.</span></li>
<li id="PAG"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PAG"><span class="letterCode" style="float:right">PAG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAG">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481286">Extracting Usability and User Experience Information from Online User Reviews</a></span><br />
<span class="authors">S. Hedegaard (Univ. of Copenhagen, DK), J. Simonsen</span>
<div class="authorList"><span><span class="author">S. Hedegaard</span> (Univ. of Copenhagen, DK)</span><span><span class="author">J. Simonsen</span> (Univ. of Copenhagen, DK)</span></div>
<p><span class="cbStatement">We chart the occurrences of usability and user experience dimensions and their associated vocabulary found in online reviews of software and video games.    </span><span class="abstract">Internet review sites allow consumers to write detailed reviews  of products potentially containing information related  to user experience (UX) and usability. Using 5198 sentences  from 3492 online reviews of software and video games, we  investigate the content of online reviews with the aims of (i)  charting the distribution of information in reviews among different  dimensions of usability and UX, and (ii) extracting an  associated vocabulary for each dimension using techniques  from natural language processing and machine learning.     We (a) find that 13%–49% of sentences in our online reviews pool  contain usability or UX information; (b) chart the distribution  of four sets of dimensions of usability and UX across  reviews from two product categories; (c) extract a catalogue  of important word stems for a number of dimensions.     Our results suggest that a greater understanding of users’ preoccupation  with different dimensions of usability and UX may be  inferred from the large volume of self-reported experiences  online, and that research focused on identifying pertinent dimensions  of usability and UX may benefit further from empirical  studies of user-generated experience reports.</span></li>
<li id="PGX"class="presentation design health sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PGX"><span class="letterCode" style="float:right">PGX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PGX">Thu. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466452">Mind the Theoretical Gap: Interpreting, Using, and Developing Behavioral Theory in HCI Research</a></span><br />
<span class="authors">E. Hekler (Arizona State Univ., USA), P. Klasnja, J. Froehlich, M. Buman</span>
<div class="authorList"><span><span class="author">E. Hekler</span> (Arizona State Univ., USA)</span><span><span class="author">P. Klasnja</span> (Univ. of Michigan, USA)</span><span><span class="author">J. Froehlich</span> (Univ. of Maryland, USA)</span><span><span class="author">M. Buman</span> (Arizona State Univ., USA)</span></div>
<p><span class="cbStatement">Are you trying to use behavioral theory in your work?  Our paper will help by providing a context and organizing framework for interpreting, using, and developing behavioral theory. </span><span class="abstract">Researchers in HCI and behavioral science are increasingly exploring the use of technology to support behavior change in domains such as health and sustainability. This work, however, remain largely siloed within the two communities. We begin to address this silo problem by attempting to build a bridge between the two disciplines at the level of behavioral theory. Specifically, we define core theoretical terms to create shared understanding about what theory is, discuss ways in which behavioral theory can be used to inform research on behavior change technologies, identify shortcomings in current behavioral theories, and outline ways in which HCI researchers can not only interpret and utilize behavioral science theories but also contribute to improving them.</span></li>
<li id="NJG"class="presentation design engineering"><a href="http://chi2013.acm.org/previews/paper.html#NJG"><span class="letterCode" style="float:right">NJG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NJG">Mon. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470693">Indirect Shear Force Estimation for Multi-Point Shear Force Operations</a></span><br />
<span class="authors">S. Heo (KAIST (Korea Advanced Institute of Science and Technology), KR), G. Lee</span>
<div class="authorList"><span><span class="author">S. Heo</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">G. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span></div>
<p><span class="cbStatement">We designed a novel method to indirectly estimate shear forces at multiple points. We show the feasibility by implementing a prototype and a demo application.</span><span class="abstract">The possibility of using shear forces is being explored recently as a method to enrich touch screen interaction. However, most of the related studies are restricted to the case of single-point shear forces, possibly owing to the difficulty of independently sensing shear forces at multiple touch points. In this paper, we propose indirect methods to estimate shear forces using the movement of contact areas. These methods enable multi-point shear force estimation, where the estimation is done for each finger independently. We show the feasibility of these methods through an informal user study with a demo application utilizing these methods.</span></li>
<li id="PBD"class="presentation games cci"><a href="http://chi2013.acm.org/previews/paper.html#PBD"><span class="letterCode" style="float:right">PBD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBD">Tue. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466164">Designing Action-based Exergames for Children with Cerebral Palsy</a></span><br />
<span class="authors">H. Hernandez (Queen&#8217;s Univ., CA), Z. Ye, T. Graham, D. Fehlings, L. Switzer</span>
<div class="authorList"><span><span class="author">H. Hernandez</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">Z. Ye</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">T. Graham</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">D. Fehlings</span> (Holland Bloorview Kids Rehabilitation Hospital, CA)</span><span><span class="author">L. Switzer</span> (Holland Bloorview Kids Rehabilitation Hospital, CA)</span></div>
<p><span class="cbStatement">We present guidelines for the design of action-oriented exergames for people with motor disabilities. These preserve the core message of traditional guidelines, while mitigating their push to slow-paced gameplay.</span><span class="abstract">Children with cerebral palsy (CP) want to play fast-paced action-oriented videogames similar to those played by their peers without motor disabilities. This is particularly true of exergames, whose physically-active gameplay matches the fast pace of action games. But disabilities resulting from CP can make it difficult to play action games. Guidelines for developing games for people with motor disabilities steer away from high-paced action, including recommendations to avoid the need for time-sensitive actions and to keep game pace slow. Through a year-long participatory design process with children with CP, we have discovered that it is in fact possible to develop action-oriented exergames for children with CP at level III on the Gross Motor Function Classification Scale. We followed up the design process with an eight-week home trial, in which we found the games to be playable and enjoyable. In this paper, we discuss the design of these games, and present a set of design recommendations for how to achieve both action-orientation and playability.</span></li>
<li id="PEP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PEP"><span class="letterCode" style="float:right">PEP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEP">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481335">&#8220;Shared Joy is Double Joy&#8221;: The Social Practices of User Networks Within Group Shopping Sites</a></span><br />
<span class="authors">S. Hillman (Simon Fraser Univ., CA), C. Neustaedter, C. Pang, E. Oduor</span>
<div class="authorList"><span><span class="author">S. Hillman</span> (Simon Fraser Univ., CA)</span><span><span class="author">C. Neustaedter</span> (Simon Fraser Univ., CA)</span><span><span class="author">C. Pang</span> (Simon Fraser Univ., CA)</span><span><span class="author">E. Oduor</span> (Simon Fraser Univ., CA)</span></div>
<p><span class="cbStatement">eCommerce has transformed with the emergence of social, apps and mobile. One emerging area is group shopping sites. We investigate these users&#8217; routines, sharing networks, purpose and chosen mediums.</span><span class="abstract">Group shopping sites are beginning to rise in popularity amongst eCommerce users. Yet we do not know how or why people are using such sites, and whether or not the design of group shopping sites map to the real shopping needs of end users.  To address this, we describe an interview study that investigates the friendship networks of people who participate in group shopping sites  (e.g., Groupon) with the goal of understanding how to best design for these experiences. Our results show that group shopping sites are predominently used to support social activities; that is, users do not use them first and foremost to find ‘deals.’  Instead, group shopping sites are used for planning group activities, extending and building friendships, and constructing one’s social identity. Based on these findings, we suggest improved social network integration and impression management tools to improve user experience within group shopping sites.</span></li>
<li id="NCU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NCU"><span class="letterCode" style="float:right">NCU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NCU">Thu. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466463">CrashAlert: Enhancing Peripheral Alertness for Eyes-Busy Mobile Interaction while Walking</a></span><br />
<span class="authors">J. Hincapié-Ramos (Univ. of Manitoba, CA), P. Irani</span>
<div class="authorList"><span><span class="author">J. Hincapié-Ramos</span> (Univ. of Manitoba, CA)</span><span><span class="author">P. Irani</span> (Univ. of Manitoba, CA)</span></div>
<p><span class="cbStatement">CrashAlert improves safety when walking and texting with smartphones. CrashAlert uses a depth camera to create ambient visualizations of the obstacles ahead of the user. Results show safer walking behaviors without compromising performance.</span><span class="abstract">Mobile device use while walking, or eyes-busy mobile in-teraction, is a leading cause of life-threatening pedestrian collisions. We introduce CrashAlert, a system that aug-ments mobile devices with a depth camera, to provide dis-tance and location visual cues of obstacles on the user’s path. In a realistic environment outside the lab, CrashAlert users improve their handling of potential collisions, dodg-ing and slowing down for simple ones while lifting their head in more complex situations. Qualitative results outline the value of extending users’ peripheral alertness in eyes-busy mobile interaction through non-intrusive depth cues, as used in CrashAlert. We present the design features of our system and lessons learned from our evaluation.</span></li>
<li id="NKP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NKP"><span class="letterCode" style="float:right">NKP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NKP">Wed. 9am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481304">8D: Interacting with a Relightable Glasses-Free 3D Display</a></span><br />
<span class="authors">M. Hirsch (Massachusetts Institute of Technology, USA), S. Izadi, H. Holtzman, R. Raskar</span>
<div class="authorList"><span><span class="author">M. Hirsch</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">S. Izadi</span> (Microsoft Research, UK)</span><span><span class="author">H. Holtzman</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">R. Raskar</span> (Massachusetts Institute of Technology, USA)</span></div>
<p><span class="cbStatement">We contribute a real-time, relightable, glasses-free 3D display with horizontal and vertical parallax, two interaction scenarios: relightable objects and virtual x-ray, and propose an architecture for future light field interaction devices.</span><span class="abstract">Imagine a display that behaves like a window. Glancing through it, viewers perceive a virtual 3D scene with correct parallax, without the need to wear glasses or track the user. Light that passes through the display correctly illuminates both virtual objects on the display and physical objects in the environment. While researchers have considered such displays, or prototyped subsets of these capabilities, we contribute a relightable, interactive display which simultaneously captures a 4D light field and displays a 4D light field. This 8-dimensional display attains a new degree of realism by reacting to incident environmental and user controlled light sources. We demonstrate two interaction techniques enabled by our lens-array-based hardware prototype, and real-time GPU-accelerated software pipeline. Additionally, we present a path to deploying such displays in commodity hardware, using current Sensor-in-Pixel (SIP) LCD panels, which physically collocate sensing and display elements.</span></li>
<li id="NFX"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NFX"><span class="letterCode" style="float:right">NFX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NFX">Wed. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481423">Multi-Touch Rotation Gestures: Performance and Ergonomics</a></span><br />
<span class="authors">E. Hoggan (Helsinki Institute for Information Technology, FI), J. Williamson, A. Oulasvirta, M. Nacenta, P. Kristensson, A. Lehtiö</span>
<div class="authorList"><span><span class="author">E. Hoggan</span> (Helsinki Institute for Information Technology, FI)</span><span><span class="author">J. Williamson</span> (Univ. of Glasgow, UK)</span><span><span class="author">A. Oulasvirta</span> (Max Planck Institute for Informatics, DE)</span><span><span class="author">M. Nacenta</span> (Univ. of St Andrews, UK)</span><span><span class="author">P. Kristensson</span> (Univ. of St Andrews, UK)</span><span><span class="author">A. Lehtiö</span></span></div>
<p><span class="cbStatement">Studies performance and ergonomics characteristics of multi-touch rotations. Presents findings concerning the effects of angle, diameter, diameter, and position.  </span><span class="abstract">Rotations performed with the index finger and thumb involve some of the most complex motor action among common multi-touch gestures, yet little is known about the factors affecting performance and ergonomics. This note presents results from a study where the angle, direction, diameter, and position of rotations were systematically manipulated. Subjects were asked to perform the rotations as quickly as possible without losing contact with the display, and were allowed to skip rotations that were too uncomfortable. The data show surprising interaction effects among the variables, and help us identify whole categories of rotations that are slow and cumbersome for users.</span></li>
<li id="NLT"class="presentation design cci"><a href="http://chi2013.acm.org/previews/paper.html#NLT"><span class="letterCode" style="float:right">NLT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NLT">Wed. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481401">Three Tensions in Participatory Design for Inclusion</a></span><br />
<span class="authors">H. Holone (Østfold Univ. College, NO), J. Herstad</span>
<div class="authorList"><span><span class="author">H. Holone</span> (Østfold Univ. College, NO)</span><span><span class="author">J. Herstad</span> (Univ. of Oslo, NO)</span></div>
<p><span class="cbStatement">In this paper we identify three tensions between the ideals of Participatory Design (PD) and the application of PD approaches in projects including children with severe disabilities.</span><span class="abstract">One ideal of Participatory Design (PD) is active involvement by all  stakeholders as co-designers.  However, when PD is applied to real  projects, certain compromises are unavoidable, no matter what  stakeholders are involved.  With this paper we want to shed light on  some of the challenges in implementing &#8220;true&#8221; PD in the case of  designing with children, in particular children with severe  disabilities.  We do this work to better understand challenges in an  ongoing project, RHYME, and by doing so we hope to provide insight and  inspiration for others.  </span></li>
<li id="PGL"class="presentation design ux health"><a href="http://chi2013.acm.org/previews/paper.html#PGL"><span class="letterCode" style="float:right">PGL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PGL">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466439">Investigating the Use of Circles in Social Networks to Support Independence of Individuals with Autism</a></span><br />
<span class="authors">H. Hong (Georgia Institute of Technology, USA), S. Yarosh, J. Kim, G. Abowd, R. Arriaga</span>
<div class="authorList"><span><span class="author">H. Hong</span> (Georgia Institute of Technology, USA)</span><span><span class="author">S. Yarosh</span> (AT&#038;T Research Labs, USA)</span><span><span class="author">J. Kim</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">G. Abowd</span> (Georgia Institute of Technology, USA)</span><span><span class="author">R. Arriaga</span> (Georgia Institute of Technology, USA)</span></div>
<p><span class="cbStatement">Explores using communication circle on a social network site for young adults with autism. Provides implications for social intervention and technical design to support independence of the special needs population.</span><span class="abstract">Building social support networks is crucial both for less-independent individuals with autism and for their primary caregivers. In this paper, we describe a four-week exploratory study of a social network service (SNS) that allows young adults with autism to garner support from their family and friends. We explore the unique benefits and challenges of using SNSs to mediate requests for help or advice. In particular, we examine the extent to which specialized features of an SNS can engage users in communicating with their network members to get advice in varied situations. Our findings indicate that technology-supported communication particularly strengthened the relationship between the individual and extended network members, mitigating concerns about over-reliance on primary caregivers. Our work identifies implications for the design of social networking services tailored to meet the needs of this special needs population. </span></li>
<li id="PCT"class="presentation design arts"><a href="http://chi2013.acm.org/previews/paper.html#PCT"><span class="letterCode" style="float:right">PCT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCT">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481412">Waves: Exploring Idiographic Design for Live Performance</a></span><br />
<span class="authors">J. Hook (Newcastle Univ., UK), J. McCarthy, P. Wright, P. Olivier</span>
<div class="authorList"><span><span class="author">J. Hook</span> (Newcastle Univ., UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">We explore whether idiographic design, an approach that focuses on personal accounts of individuals’ experiences, can support designers in responding to the subtle and complex issues that affect live performance.</span><span class="abstract">We explore whether idiographic design, a category of interaction design that focuses upon responding to detailed personal accounts of individuals’ practices, can be used to support interaction designers in responding to the complex and multifaceted design space posed by live performance. We describe and reflect upon the application of an idiographic approach during the design of Waves, an interface for live VJ performance. This approach involved a close and dialogical engagement with the practices and experiences of an individual live performer, during a series of semi-structured interviews and then the discussion and iteration of an evolving prototypical design. Reflection on the experience of applying this approach highlights idiographic design as a practical means to support interaction designers in proposing innovative designs that respond sensitively to the kinds of subtle and complex issues that underpin people’s lived and felt experiences of live performance and, potentially, many other domains.</span></li>
<li id="PQD"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PQD"><span class="letterCode" style="float:right">PQD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PQD">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481312">Activity-Centric Support for Ad Hoc Knowledge Work &#8211; A Case Study of co-Activity Manager</a></span><br />
<span class="authors">S. Houben (IT Univ. of Copenhagen, DK), J. Bardram, J. Vermeulen, K. Luyten, K. Coninx</span>
<div class="authorList"><span><span class="author">S. Houben</span> (IT Univ. of Copenhagen, DK)</span><span><span class="author">J. Bardram</span> (IT Univ. of Copenhagen, DK)</span><span><span class="author">J. Vermeulen</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span><span><span class="author">K. Luyten</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span><span><span class="author">K. Coninx</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span></div>
<p><span class="cbStatement">The core contribution of this paper is the design of a desktop manager that supports personal and collaborative activity-centric workflows with integrated activity-centric collaboration and interruption management tools.</span><span class="abstract">Modern knowledge work consists of both individual and highly collaborative activities that are typically composed of a  number of configuration, coordination and articulation processes. The desktop interface today, however, provides very little support for these processes and rather forces knowledge workers to adapt to the technology. We introduce co-Activity Manager,  an activity-centric desktop system that (i) provides tools for ad hoc dynamic configuration of a desktop working context, (ii) supports both explicit and implicit articulation of ongoing work through a built-in collaboration manager and (iii) provides the means to coordinate and share working context with other users and devices.  In this paper, we discuss the activity theory informed design of co-Activity Manager and report on a 14 day field deployment in a multi-disciplinary software development team.   The study showed that the activity-centric workspace supports different individual and collaborative work configuration practices and that activity-centric collaboration is a two-phase process consisting of an activity sharing and per-activity coordination phase.</span></li>
<li id="PSH"class="presentation cci"><a href="http://chi2013.acm.org/previews/paper.html#PSH"><span class="letterCode" style="float:right">PSH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PSH">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466438">Evaluation of Tablet Apps to Encourage Social Interaction in Children with Autism Spectrum Disorders</a></span><br />
<span class="authors">J. Hourcade (Univ. of Iowa, USA), S. Williams, E. Miller, K. Huebner, L. Liang</span>
<div class="authorList"><span><span class="author">J. Hourcade</span> (Univ. of Iowa, USA)</span><span><span class="author">S. Williams</span> (Univ. of Iowa, USA)</span><span><span class="author">E. Miller</span> (Univ. of Iowa, USA)</span><span><span class="author">K. Huebner</span> (Univ. of Iowa, USA)</span><span><span class="author">L. Liang</span> (Univ. of Iowa, USA)</span></div>
<p><span class="cbStatement">Comparison of app-based and paper-based activities by children with autism spectrum disorders. Using the apps was associated with increased verbal communication, physical interaction, and supportive comments.</span><span class="abstract">The increasing rates of diagnosis for Autism Spectrum Disorders (ASDs) have brought unprecedented attention to these conditions. Interventions during childhood can increase the likelihood of independent living later in life, but most adults with ASDs who benefited from early intervention do not live independently. There is a need for novel therapies and interventions that can help children with ASDs develop the social skills necessary to live independently. Since the launch of the iPad, there has been a great deal of excitement in the autism community about multitouch tablets and their possible use in interventions. There are hundreds of apps listed as possibly helping children with ASDs, yet there is little empirical evidence that any of them have positive effects. In this paper we present a study on the use of a set of apps from Open Autism Software at an afterschool program for children with ASDs. The apps are designed to naturally encourage positive social interactions through creative, expressive, and collaborative activities. The study compared activities conducted with the apps to similar activities conducted without the apps. We video recorded the activities, and coded children’s behavior. We found that during the study children spoke more sentences, had more verbal interactions, and were more physically engaged with the activities when using the apps. We also found that children made more supportive comments during activities conducted with two of the apps. The results suggest the approach to using apps evaluated in this paper can increase positive social interactions in children with ASDs.</span></li>
<li id="NNC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NNC"><span class="letterCode" style="float:right">NNC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NNC">Wed. 9am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481314">Factors Impacting Community Response in an Interest-Sharing Network</a></span><br />
<span class="authors">I. Howley (Carnegie Mellon Univ., USA), T. Newman</span>
<div class="authorList"><span><span class="author">I. Howley</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">T. Newman</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">This study looks at archival data from a new interest-sharing network, So.cl, in order to better understand what user-shared content receives most interaction from others in the community. </span><span class="abstract">The arrival of a new interest-sharing network, So.cl, provides for a new opportunity to explore human behavior as it relates to constructing public contributions and receiving community response. This study looks at archival data in order to better understand how types of shared content receive interaction from others. The results suggest that a So.cl user should include more photos and less links on their post to increase the quantity of likes and comments the community gives to the post, among other discoveries.</span></li>
<li id="PEM"class="presentation engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PEM"><span class="letterCode" style="float:right">PEM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PEM">Thu. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466478">Whoo.ly: Facilitating Information Seeking For Hyperlocal Communities Using Social Media</a></span><br />
<span class="authors">Y. Hu (Arizona State Univ., USA), S. Farnham, A. Monroy-Hernández</span>
<div class="authorList"><span><span class="author">Y. Hu</span> (Arizona State Univ., USA)</span><span><span class="author">S. Farnham</span> (Microsoft Research, USA)</span><span><span class="author">A. Monroy-Hernández</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">We present Whoo.ly, an extraction service for hyperlocal information: events, topics, people and places; from neighborhood-specific tweets. We demonstrate that users prefer its use for neighborhood exploration over competing approaches.  </span><span class="abstract">Social media systems promise powerful opportunities for people to connect to timely, relevant information at the hyper local level. Yet, finding the meaningful signal in noisy social media streams can be quite daunting to users. In this paper, we present and evaluate Whoo.ly, a web service that provides neighborhood-specific information based on Twitter posts that were automatically inferred to be hyperlocal. Whoo.ly automatically extracts and summarizes hyperlocal information about events, topics, people, and places from these Twitter posts. We provide an overview of our design goals with Whoo.ly and describe the system including the user interface and our unique event detection and summarization algorithms. We tested the usefulness of the system as a tool for finding neighborhood information through a comprehensive user study. The outcome demonstrated that most participants found Whoo.ly easier to use than Twitter and they would prefer it as a tool for exploring their neighborhoods.</span></li>
<li id="PDS"class="presentation games"><a href="http://chi2013.acm.org/previews/paper.html#PDS"><span class="letterCode" style="float:right">PDS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PDS">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470753">Mastering the Art of War: How Patterns of Gameplay Influence Skill in Halo</a></span><br />
<span class="authors">J. Huang (Univ. of Washington, USA), T. Zimmermann, N. Nagapan, C. Harrison, B. Phillips</span>
<div class="authorList"><span><span class="author">J. Huang</span> (Univ. of Washington, USA)</span><span><span class="author">T. Zimmermann</span> (Microsoft Research, USA)</span><span><span class="author">N. Nagapan</span> (Microsoft Research, USA)</span><span><span class="author">C. Harrison</span> (Microsoft, USA)</span><span><span class="author">B. Phillips</span> (Microsoft, USA)</span></div>
<p><span class="cbStatement">We look at patterns of skill through large-scale gameplay analysis and player surveys to identify how different factors (play intensity, skill change over time, demographics, breaks, and prior games played) affect players&#8217; skill in Halo.</span><span class="abstract">How do video game skills develop, and what sets the top players apart? We study this question of skill through a rating generated from repeated multiplayer matches called TrueSkill. Using these ratings from 7 months of games from over 3 million players, we look at how play intensity, breaks in play, skill change over time, and other games affect skill. These analyzed factors are then combined to model future skill and games played; the results show that skill change in early matches is a useful metric for modeling future skill, while play intensity explains eventual games played. The best players in the 7-month period, who we call &#8220;Master Blasters&#8221;, have varied skill patterns that often run counter to the trends we see for typical players. The data analysis is supplemented with a 70 person survey to explore how players&#8217; self-perceptions compare to the gameplay data; most survey responses align well with the data and provide insight into player beliefs and motivation. Finally, we wrap up with a discussion about hiding skill information from players, and implications for game designers.</span></li>
<li id="PBH"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PBH"><span class="letterCode" style="float:right">PBH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PBH">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470743">Don&#8217;t Hide in the Crowd! Increasing Social Transparency Between Peer Workers Improves Crowdsourcing Outcomes</a></span><br />
<span class="authors">S. Huang (Univ. of Illinois at Urbana-Champaign, USA), W. Fu</span>
<div class="authorList"><span><span class="author">S. Huang</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">W. Fu</span> (Univ. of Illinois at Urbana-Champaign, USA)</span></div>
<p><span class="cbStatement">Our study suggests that a careful combination of methods that increase social transparency and different peer-dependent reward schemes can significantly improve crowdsourcing outcomes.</span><span class="abstract">This paper studied how social transparency and different peer-dependent reward schemes (i.e., individual, teamwork, and competition) affect the outcomes of crowdsourcing. The results showed that when social transparency was increased by asking otherwise anonymous workers to share their demographic information (e.g., name, nationality) to the paired worker, they performed significantly better. A more detailed analysis showed that in a teamwork reward scheme, in which the reward of the paired workers depended only on the collective outcomes, increasing social transparency could offset effects of social loafing by making them more accountable to their teammates. In a competition reward scheme, in which workers competed against each other and the reward depended on how much they outperformed their opponent, increasing social transparency could augment effects of social facilitation by providing more incentives for them to outperform their opponent. The results suggested that a careful combination of methods that increase social transparency and different reward schemes can significantly improve crowdsourcing outcomes.</span></li>
<li id="PEX"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PEX"><span class="letterCode" style="float:right">PEX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PEX">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470706">LEMtool &#8211; Measuring Emotions in Visual Interfaces</a></span><br />
<span class="authors">G. Huisman (Univ. of Twente, NL), M. Van Hout, E. van Dijk, T. Van der Geest, D. Heylen</span>
<div class="authorList"><span><span class="author">G. Huisman</span> (Univ. of Twente, NL)</span><span><span class="author">M. Van Hout</span> (SusaGroup, NL)</span><span><span class="author">E. van Dijk</span> (Univ. of Twente, NL)</span><span><span class="author">T. Van der Geest</span> (Univ. of Twente, NL)</span><span><span class="author">D. Heylen</span> (Univ. of Twente, NL)</span></div>
<p><span class="cbStatement">The paper describes the development and validation of the LEMtool: a non-verbal self-report method for indicating emotions during interaction with a visual interface.</span><span class="abstract">In this paper the development process and validation of the LEMtool (Layered Emotion Measurement tool) are described. The LEMtool consists of eight images that display a cartoon figure expressing four positive and four negative emotions using facial expressions and body postures. The instrument can be used during interaction with a visual interface, such as a website, and allows participants to select elements of the interface that elicit a certain emotion. The images  of the cartoon figure were submitted to a validation study, in which participants rated the recognizability of the images as specific emotions. All images were found to be recognizable above chance level. In another study, the LEMtool was used to assess visual appeal judgements of a number of web pages. The LEMtool ratings were supported by visual appeal ratings of web pages both for very brief (50 milliseconds) and for long (free-viewing) stimulus exposures. Furthermore, the instrument provided insight into the elements of the web pages that elicited the emotional responses.</span></li>
<li id="PGH"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGH"><span class="letterCode" style="float:right">PGH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PGH">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481374">Contextifier: Automatic Generation of Annotated Stock Visualizations</a></span><br />
<span class="authors">J. Hullman (Univ. of Michigan, USA), N. Diakopoulos, E. Adar</span>
<div class="authorList"><span><span class="author">J. Hullman</span> (Univ. of Michigan, USA)</span><span><span class="author">N. Diakopoulos</span> (Interaction Foundry, USA)</span><span><span class="author">E. Adar</span> (Univ. of Michigan, USA)</span></div>
<p><span class="cbStatement">We present the Contextifier system for automatic annotated stock visualizations from company news. Contextifier’s algorithms, informed by news professional visualizations, account for visual salience, contextual relevance, and notable company events.</span><span class="abstract">Online news tools—for aggregation, summarization and automatic generation—are an area of fruitful development as reading news online becomes increasingly commonplace. While textual tools have dominated these developments, annotated information visualizations are a promising way to complement articles based on their ability to add context. But the manual effort required for professional designers to create thoughtful annotations for contextualizing news visualizations is difficult to scale. We describe the design of Contextifier, a novel system that automatically produces custom, annotated visualizations of stock behavior given a news article about a company. Contextifier’s algorithms for choosing annotations is informed by a study of professionally created visualizations and takes into account visual salience, contextual relevance, and a detection of key events in the company’s history. In evaluating our system we find that Contextifier better balances graphical salience and relevance than the baseline.</span></li>
<li id="PJQ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PJQ"><span class="letterCode" style="float:right">PJQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PJQ">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470771">A Longitudinal Study of Follow Predictors on Twitter</a></span><br />
<span class="authors">C. Hutto (Georgia Institute of Technology, USA), E. Gilbert, S. Schoenebeck</span>
<div class="authorList"><span><span class="author">C. Hutto</span> (Georgia Institute of Technology, USA)</span><span><span class="author">E. Gilbert</span> (Georgia Institute of Technology, USA)</span><span><span class="author">S. Schoenebeck</span> (Univ. of Michigan, USA)</span></div>
<p><span class="cbStatement">Comparing across many variables related to message content, social behavior, and network structure allows us to interpret their relative effect on follower growth from different theoretical perspectives.</span><span class="abstract">Follower count is important to Twitter users: it can indicate popularity and prestige. Yet, holistically, little is understood about what factors – like social behavior, message content, and network structure – lead to more followers. Such information could help technologists design and build tools that help users grow their audiences. In this paper, we study 507 Twitter users and a half-million of their tweets over 15 months. Marrying a longitudinal approach with a negative binomial auto-regression model, we find that variables for message content, social behavior, and network structure should be given equal consideration when predicting link formations on Twitter.  To our knowledge, this is the first longitudinal study of follow predictors, and the first to show that the relative contributions of social behavior and message content are just as impactful as factors related to social network structure for predicting growth of online social networks. We conclude with practical and theoretical implications for designing social media technologies. </span></li>
<li id="PHZ"class="presentation sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PHZ"><span class="letterCode" style="float:right">PHZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PHZ">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481378">Beyond Being Green: Simple Living Families and ICT</a></span><br />
<span class="authors">M. Håkansson (Cornell Univ., USA), P. Sengers</span>
<div class="authorList"><span><span class="author">M. Håkansson</span> (Cornell Univ., USA)</span><span><span class="author">P. Sengers</span> (Cornell Univ., USA)</span></div>
<p><span class="cbStatement">Presents a qualitative study of simple living families&#8217; practices and use of ICT. Demonstrates how a holistic perspective on sustainability broadens opportunities for &#8220;green&#8221; design in HCI.</span><span class="abstract">Motivated by a need in sustainable HCI for studies of everyday practices, and a belief that a holistic view on sustainability is crucial to deeper understanding of how to design ICT to support sustainability, we here present a qualitative study of 11 simple living families in the US. Simple living refers to a lifestyle which is voluntarily simple out of concern for both the environment and quality of life. Our goal was to learn about a holistic view on sustainability and the role of ICT in helping and hindering families to live simply. The study contributes new insights about how holistic sustainability could be a valuable lens for HCI, revealing that sustainability is important to a wider range of areas in HCI than previously discussed. We conclude with implications for HCI for how to support sustainable practices beyond being “about” being green.</span></li>
<li id="PFT"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PFT"><span class="letterCode" style="float:right">PFT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PFT">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481413">Effects of the Display Angle in Museums on User&#8217;s Cognition, Behavior, and Subjective Responses</a></span><br />
<span class="authors">J. Ichino (Univ. of Electro-Communications, JP), K. Isoda, A. Hanai, T. Ueda</span>
<div class="authorList"><span><span class="author">J. Ichino</span> (Univ. of Electro-Communications, JP)</span><span><span class="author">K. Isoda</span> (Dai Nippon Printing Co., Ltd., JP)</span><span><span class="author">A. Hanai</span> (Dai Nippon Printing Co., Ltd., JP)</span><span><span class="author">T. Ueda</span> (Dai Nippon Printing Co., Ltd., JP)</span></div>
<p><span class="cbStatement">This paper described a user study in effects of using horizontal, vertical and tilted flat displays on people visiting in a museum.</span><span class="abstract">In order to achieve the intended level of communication with visitors in museums where large displays are installed, it is essential to understand how various display factors affect visitors. We explore the effects of the display angle on individual users. In our experiment, we set up three types of flat displays—vertical, horizontal, and tilted—and comprehensively tested users&#8217; cognitive, behavioral, and subjective aspects. The results showed that a significant difference could be discerned in regards to cognitive and subjective aspects. Test results for the cognitive aspect showed that the display angle on which the displayed content was easy to understand and remember differed depending on age. Test results for the subjective aspect showed that irrespective of age, users rated tilted displays as being quicker to attract attention and easier to peruse, to understand and remember the content, and to interact with, and such displays were the most preferred.</span></li>
<li id="PGJ"class="presentation design engineering"><a href="http://chi2013.acm.org/previews/paper.html#PGJ"><span class="letterCode" style="float:right">PGJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PGJ">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466431">Canyon: Providing Location Awareness of Multiple Moving Objects in a Detail View on Large Displays</a></span><br />
<span class="authors">A. Ion (Univ. of Applied Sciences Upper Austria, AT), Y. Chang, M. Haller, M. Hancock, S. Scott</span>
<div class="authorList"><span><span class="author">A. Ion</span> (Univ. of Applied Sciences Upper Austria, AT)</span><span><span class="author">Y. Chang</span> (Univ. of Waterloo, CA)</span><span><span class="author">M. Haller</span> (Univ. of Applied Sciences Upper Austria, AT)</span><span><span class="author">M. Hancock</span> (Univ. of Waterloo, CA)</span><span><span class="author">S. Scott</span> (Univ. of Waterloo, CA)</span></div>
<p><span class="cbStatement">A novel interaction technique, Canyon, was implemented and evaluated addressing the problem of data exiting a person&#8217;s field of view on large displays. Results indicate higher accuracy and comparable speed.</span><span class="abstract">Overview+Detail interfaces can be used to examine the details of complex data while retaining the data&#8217;s overall context. Dynamic data introduce challenges for these interfaces, however, as moving objects may exit the detail view, as well as a person’s field of view if they are working at a large interactive surface. To address this &#8220;off-view&#8221; problem, we propose a new information visualization technique, called Canyon. This technique attaches a small view of an off-view object, including some surrounding context, to the external boundary of the detail view. The area between the detail view and the region containing the off-view object is virtually &#8220;folded&#8221; to conserve space. A comparison study was conducted contrasting the benefits and limitations of Canyon to an established technique, called Wedge. Canyon was more accurate across a number of tasks, especially more complex tasks, and was comparably efficient.</span></li>
<li id="PML"class="presentation design HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PML"><span class="letterCode" style="float:right">PML</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PML">Mon. 4pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470742">Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk</a></span><br />
<span class="authors">L. Irani (Univ. of California, Irvine, USA), M. Silberman</span>
<div class="authorList"><span><span class="author">L. Irani</span> (Univ. of California, Irvine, USA)</span><span><span class="author">M. Silberman</span> (Bureau of Economic Interpretation, USA)</span></div>
<p><span class="cbStatement">With Turkopticon, we contribute an example of a long-term systems building project that reworks employer-worker relations in Amazon Mechanical Turk.  We analyze the system in feminist, infrastrastructural, and political terms.  </span><span class="abstract">As HCI researchers have explored the possibilities of human computation, they have paid less attention to ethics and values of crowdwork. This paper offers an analysis of Amazon Mechanical Turk, a popular human computation system, as a site of technically mediated worker-employer relations. We argue that human computation currently relies on worker invisibility. We then present Turkopticon, an activist system that allows workers to publicize and evaluate their relationships with employers. As a common infrastructure, Turkopticon also enables workers to engage one another in mutual aid. We conclude by discussing the potentials and challenges of sustaining activist technologies that intervene in large, existing socio-technical systems. </span></li>
<li id="PST"class="presentation design engineering ux health"><a href="http://chi2013.acm.org/previews/paper.html#PST"><span class="letterCode" style="float:right">PST</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PST">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466137">Echoes From the Past: How Technology Mediated Reflection Improves Well-Being</a></span><br />
<span class="authors">E. Isaacs (Palo Alto Research Center (PARC), USA), A. Konrad, A. Walendowski, T. Lennig, V. Hollis, S. Whittaker</span>
<div class="authorList"><span><span class="author">E. Isaacs</span> (Palo Alto Research Center (PARC), USA)</span><span><span class="author">A. Konrad</span> (Univ. of California, Santa Cruz, Santa Cruz)</span><span><span class="author">A. Walendowski</span> (Samsung Research America, USA)</span><span><span class="author">T. Lennig</span> (Univ. of California at Santa Cruz , USA)</span><span><span class="author">V. Hollis</span> (Univ. of California at Santa Cruz , USA)</span><span><span class="author">S. Whittaker</span> (Univ. of California at Santa Cruz, USA)</span></div>
<p><span class="cbStatement">We explored technology mediated reminiscence (TMR) by building Echo, a novel smartphone application for recording and reflecting on everyday experiences. Three deployments with 44 users show TMR improves well-being.</span><span class="abstract">As people document more of their lives online, some recent systems are encouraging people to later revisit those recordings, a practice we’re calling technology-mediated reflection (TMR). Since we know that unmediated reflection benefits psychological well-being, we explored whether and how TMR affects well-being. We built Echo, a smartphone application for recording everyday experiences and reflecting on them later. We conducted three system deployments with 44 users who generated over 12,000 recordings and reflections. We found that TMR improves well-being as assessed by four psychological metrics. By analyzing the content of these entries we discovered two mechanisms that explain this improvement. We also report benefits of very long-term TMR.</span></li>
<li id="PMV"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PMV"><span class="letterCode" style="float:right">PMV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PMV">Wed. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481397">Infrastructure and Vocation: Field, Calling, and Computation in Ecology</a></span><br />
<span class="authors">S. Jackson (Cornell Univ., USA), S. Barbrow</span>
<div class="authorList"><span><span class="author">S. Jackson</span> (Cornell Univ., USA)</span><span><span class="author">S. Barbrow</span> (Univ. of Michigan, USA)</span></div>
<p><span class="cbStatement">Ethnographic study exploring relationship between computational change and ecology as a vocation. Argues that new computational development remediates ecology&#8217;s crucial field relations, with implications for design and engagement.</span><span class="abstract">HCI studies of computational change in the sciences have made important design and analytic contributions, to other fields of science and to HCI itself. But some of the longer-term effects and complexities of infrastructural change in the sciences aren’t easily captured under short-term, design- or artifact-centered accounts. Drawing on extended ethnographic study of computational development in ecology, this paper explores the relationship between new computational infrastructure and the nature of ecology as a vocation: roughly, the deeply held sense of what it means to ‘be’ an ecologist, and to ‘do’ ecology. We analyze in particular the nature of the field and field work as a central site of ecological practice and identity; how new computational developments are remediating this crucial relation; and the emergent vocational values that new and more computationally-intensive forms of ecology may give rise to.</span></li>
<li id="PLR"class="presentation design cci arts"><a href="http://chi2013.acm.org/previews/paper.html#PLR"><span class="letterCode" style="float:right">PLR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLR">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466211">Codeable Objects: Computational Design and Digital Fabrication for Novice Programmers</a></span><br />
<span class="authors">J. Jacobs (Massachusetts Institute of Technology, USA), L. Buechley</span>
<div class="authorList"><span><span class="author">J. Jacobs</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">L. Buechley</span> (Massachusetts Institute of Technology, USA)</span></div>
<p><span class="cbStatement">The combination of programing and digital fabrication offers compelling new opportunities for creative expression. Codeable Objects is a computational-design tool to support novice programmers in production of personal, physical artifacts.</span><span class="abstract">The combination of computational design and digital fabrication offers many exciting possibilities for art, design, and creative expression. We seek to make computational design accessible by developing tools that allow novices to use programming and digital fabrication to produce personal and functional objects. In this paper, we describe our development of Codeable Objects, a preliminary computational-design programing tool developed to work in conjunction with digital-fabrication machines. We also present our evaluation of the tool based on a set of user studies in which people built computationally generated crafts, clothing, and accessories. These studies illuminated the viability (and challenges) of engaging novice programmers through design and digital fabrication, and provide a platform for future work in developing programming tools to support personal expression.</span></li>
<li id="PJB"class="presentation sustainability arts"><a href="http://chi2013.acm.org/previews/paper.html#PJB"><span class="letterCode" style="float:right">PJB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PJB">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470673">A Conversation Between Trees: What Data Feels Like In The Forest</a></span><br />
<span class="authors">R. Jacobs (The Univ. of Nottingham, UK), S. Benford, M. Selby, M. Golembewski, D. Price, G. Giannachi</span>
<div class="authorList"><span><span class="author">R. Jacobs</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Benford</span> (The Univ. of Nottingham, UK)</span><span><span class="author">M. Selby</span> (The Univ. of Nottingham, UK)</span><span><span class="author">M. Golembewski</span> (The Univ. of Nottingham, UK)</span><span><span class="author">D. Price</span> (The Univ. of Nottingham, UK)</span><span><span class="author">G. Giannachi</span> (The Univ. of Exeter, UK)</span></div>
<p><span class="cbStatement">Study of an environmentally engaged artwork reveals how artists’ strategies of embodying, performing and juxtaposing different views of climate data fostered emotional engagement and interpretation among visitors.</span><span class="abstract">A study of an interactive artwork shows how artists engaged the public with scientific climate change data. The artwork visualised live environmental data collected from remote trees, alongside both historical and forecast global CO2 data. Visitors also took part in a mobile sensing experience in a nearby forest. Our study draws on the perspectives of the artists, visitors and a climate scientist to reveal how the work was designed and experienced. We show that the artists adopted a distinct approach that fostered an emotional engagement with data rather than an informative or persuasive one. We chart the performative strategies they used to achieve this including sensory engagement with data, a temporal structure that balanced liveness with slowness, and the juxtaposition of different treatments of the data to enable interpretation and dialogue.</span></li>
<li id="PBQ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PBQ"><span class="letterCode" style="float:right">PBQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PBQ">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481359">Evaluating the Efficiency of Physical Visualizations</a></span><br />
<span class="authors">Y. Jansen (Univ. Paris-Sud, FR), P. Dragicevic, J. Fekete</span>
<div class="authorList"><span><span class="author">Y. Jansen</span> (Univ. Paris-Sud, FR)</span><span><span class="author">P. Dragicevic</span> (INRIA, FR)</span><span><span class="author">J. Fekete</span> (INRIA, FR)</span></div>
<p><span class="cbStatement">Presents an infovis study comparing physical to on-screen visualizations. Identifies and evaluates inherent properties of physical interfaces.</span><span class="abstract">Data sculptures are an increasingly popular form of physical visualization whose purposes are essentially artistic, communicative or educational. But can physical visualizations help carry out actual information visualization tasks? We present the first infovis study comparing physical to on-screen visualizations. We focus on 3D visualizations, as these are common among physical visualizations but known to be problematic on computers. Taking 3D bar charts as an example, we show that moving visualizations to the physical world can improve users&#8217; efficiency at information retrieval tasks. In contrast, augmenting on-screen visualizations with stereoscopic rendering alone or with prop-based manipulation was of limited help. The efficiency of physical visualizations seems to stem from features that are unique to physical objects, such as their ability to be touched and their perfect visual realism. These findings provide empirical motivation for current research on fast digital fabrication and self-reconfiguring interfaces.</span></li>
<li id="PPF"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PPF"><span class="letterCode" style="float:right">PPF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PPF">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466459">A Comparative Evaluation of Touch-Based Methods to Bind Mobile Devices for Collaborative Interactions</a></span><br />
<span class="authors">T. Jokela (Nokia Research Center, FI), A. Lucero</span>
<div class="authorList"><span><span class="author">T. Jokela</span> (Nokia Research Center, FI)</span><span><span class="author">A. Lucero</span> (Nokia Research Center, FI)</span></div>
<p><span class="cbStatement">Reports a comparative evaluation of three different methods that allow collocated users to bind their mobile devices together. Crucial for enabling collaborative experiences such as sharing photos or playing games.</span><span class="abstract">We present a comparative evaluation of two touch-based group-binding methods, a leader-driven method and a peer-based method, against a more conventional group-binding method based on scanning and passwords. The results indicate that the participants strongly preferred the touch-based methods in both pragmatic and hedonic qualities as well as in the overall attractiveness. While the leader-driven method allowed better control over the group and required only one participant to be able to form a group, the peer-based method helped to create a greater sense of community and scaled better for larger group sizes and distances. As the optimal group-binding method depends on the social situation and physical environment, the binding methods should be flexible, allowing the users to adapt them to different contexts of use. For determining the order of the devices, manual arrangement was preferred over defining the order by touching.</span></li>
<li id="PCJ"class="presentation design engineering games"><a href="http://chi2013.acm.org/previews/paper.html#PCJ"><span class="letterCode" style="float:right">PCJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PCJ">Tue. 9am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466112">IllumiRoom: Peripheral Projected Illusions for Interactive Experiences</a></span><br />
<span class="authors">B. Jones (Univ. of Illinois at Urbana-Champaign, USA), H. Benko, E. Ofek, A. Wilson</span>
<div class="authorList"><span><span class="author">B. Jones</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">H. Benko</span> (Microsoft Research, USA)</span><span><span class="author">E. Ofek</span> (Microsoft Research, USA)</span><span><span class="author">A. Wilson</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. </span><span class="abstract">IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions.</span></li>
<li id="PCS"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PCS"><span class="letterCode" style="float:right">PCS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCS">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481317">How Fast is Fast Enough? A Study of the Effects of Latency in Direct-Touch Pointing Tasks</a></span><br />
<span class="authors">R. Jota (Univ. of Toronto, CA), A. Ng, P. Dietz, D. Wigdor</span>
<div class="authorList"><span><span class="author">R. Jota</span> (Univ. of Toronto, CA)</span><span><span class="author">A. Ng</span> (Microsoft Applied Sciences Group, USA)</span><span><span class="author">P. Dietz</span> (Microsoft Applied Sciences Group, USA)</span><span><span class="author">D. Wigdor</span> (Univ. of Toronto, CA)</span></div>
<p><span class="cbStatement">Further explores the issue of the effects of latency on input performance. We find that, for pointing on direct-touch, even extremely low latencies reduce performance.</span><span class="abstract">Although advances in touchscreen technology have provided us with more precise devices, touchscreens are still laden with latency issues. Common commercial devices present with latency up to 125ms. Although these levels have been shown to impact users’ perception of the responsiveness of the system [16], relatively little is known about the impact of latency on the performance of tasks common to direct-touch interfaces, such as direct physical manipulation.    In this paper, we study the effect of latency of a directtouch pointing device on dragging tasks. Our tests show that user performance decreases as latency increases. We also find that user performance is more severely affected by latency when targets are smaller or farther away. We present a detailed analysis of users’ coping mechanisms for latency, and present the results of a follow-up study demonstrating user perception of latency in the land-on phase of the dragging task.</span></li>
<li id="PBK"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PBK"><span class="letterCode" style="float:right">PBK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBK">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466118">On the Relation of Ordinary Gestures to TV Screens: General Lessons for the Design of Collaborative Interactive Techniques</a></span><br />
<span class="authors">O. Juhlin (Mobile Life @ Stockholm Univ., SE), E. Onnevall</span>
<div class="authorList"><span><span class="author">O. Juhlin</span> (Mobile Life @ Stockholm Univ., SE)</span><span><span class="author">E. Onnevall</span> (Mobile Life @ Stockholm Univ., SE)</span></div>
<p><span class="cbStatement">If natural and social gesturing in front of TV screens are on-goingly and collaboratively shaped, then viewers might need to adapt such behaviour to emerging gesture tracking technology.</span><span class="abstract">We present an interaction analysis based on ethnographic fieldwork of how physical movements, including gestures, are produced by viewers in front of television screens in a sports bar. Understanding ordinary life and specifically television watching in social situations will benefit the dis-cussion of the potential of gesture techniques for controlling interactive televisions in various locations. Challenges for system design include body movement recognition, since movements can have many different purposes and are di¬rected simultaneously at the screen and co-viewers. More¬over, gestures as elements of conversation are sometimes negotiated and overlapping. Since these ordinary move¬ments are hard to automatically track and analyse, sug¬gested systems might lead to demands on viewers to re¬strain their accustomed movements and adapt them in ways that might be considered awkward. We also reveal new design opportunities that draw upon the ways viewers’ gestures are influenced by ongoing broadcast. </span></li>
<li id="PRM"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PRM"><span class="letterCode" style="float:right">PRM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PRM">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466178">Shape Switching Mobile Devices-  Explorations in Outfit-Centric Design</a></span><br />
<span class="authors">O. Juhlin (Mobile Life @ Stockholm Univ., SE), Y. Zhang, C. Sundbom, Y. Fernaeus</span>
<div class="authorList"><span><span class="author">O. Juhlin</span> (Mobile Life @ Stockholm Univ., SE)</span><span><span class="author">Y. Zhang</span> (Stockholm Univ., SE)</span><span><span class="author">C. Sundbom</span> (KTH &#8211; Royal Institute of Technology, SE)</span><span><span class="author">Y. Fernaeus</span> (Stockholm Univ., SE)</span></div>
<p><span class="cbStatement">Fashionable people will adore their mobile phones much more, when the devices organically change to a shape and colors that relate  their chosen dressed ensemble for the day. </span><span class="abstract">We present a design exercise illustrating how fashion practices and the fashion design process can be used to create new opportunities both in the mobile domain and in product design, as well as in wearable computing. We investigate the concept of outfit-centric design by extending the support for social and visual interaction with digital devices beyond the currently available shells and stickers, and drawing on the ways in which people vary their dress ensembles. We designed a set of mock-up samples in a local fashion style, as a first step in understanding possible applications of the emerging technology of organic interfaces. Initial user feedback shows how fashion-conscious participants creatively experimented with the set’s variations of shape and color in outfits created from their personal wardrobes, which revealed the importance of the objects’ size and location on the body. It also points out that a lack of integration with the fashion system’s processes reduces the attractiveness of the samples.</span></li>
<li id="PPY"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PPY"><span class="letterCode" style="float:right">PPY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPY">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466168">Make It Move: A Movement Design Method of Simple Standing Products Based on Systematic Mapping of Torso Movements &#038; Product Messages</a></span><br />
<span class="authors">J. Jung (KAIST (Korea Advanced Institute of Science and Technology), KR), S. Bae, J. Lee, M. Kim</span>
<div class="authorList"><span><span class="author">J. Jung</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">S. Bae</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">J. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">M. Kim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span></div>
<p><span class="cbStatement">For affective movement design of daily products, this paper brought human movement expertise and product design expertise together through a step-by-step research procedure by using mediated prototyping, the robotic torso</span><span class="abstract">Human communication significantly relies on the expressivity of their body movements. Based on these body language experiences, humans tend to extract meanings even from movements of objects. This paper begins with the above human tendencies to create a design method that can help product designers make their products move to communicate. As a research vehicle, we created a robotic torso prototype and utilized it to collaborate with movement experts, and listed up possible expressive movement components. We then built a mapping matrix that links these movements to general product messages. A method which utilizes this mapping matrix was developed to help designers determine a set of effective movements that can communicate specific product messages. Lastly, a design workshop was conducted to identify the usefulness of the proposed method. We expect the procedures and findings of this study to help researchers and designers approach affective user experience through product movement design.</span></li>
<li id="PHN"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHN"><span class="letterCode" style="float:right">PHN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PHN">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470657">Favors from Facebook Friends: Unpacking Dimensions of Social Capital</a></span><br />
<span class="authors">Y. Jung (Michigan State Univeristy, USA), R. Gray, C. Lampe, N. Ellison</span>
<div class="authorList"><span><span class="author">Y. Jung</span> (Michigan State Univeristy, USA)</span><span><span class="author">R. Gray</span> (Michigan State Univeristy, USA)</span><span><span class="author">C. Lampe</span> (Univ. of Michigan, USA)</span><span><span class="author">N. Ellison</span> (Univ. of Michigan, USA)</span></div>
<p><span class="cbStatement">This paper provides an innovative way of using Williams’ (2006) social capital measures which are the most widely-used social capital measures in social media studies.</span><span class="abstract">Past research has demonstrated a link between perceptions of social capital and use of the popular social network site, Facebook. Williams’ Internet Social Capital Scales, based on Putnam’s formulation, tap into sub-dimensions of social capital that have not been broadly used yet may enlighten our understanding of the different ways in which connecting with others online can facilitate access to resources embedded within our social relationships. In this study, we segment Williams’ Internet Social Capital Scales into various sub-dimensions using factor analysis and explicate the distinct facets of social capital through a lab experiment in which Facebook users (N=98) request a small favor from their Facebook network. We find that some sub-dimensions play a significant role in getting favors from Facebook friends while bonding and bridging social capital do not significantly predict responses to favor requests.</span></li>
<li id="NLH"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NLH"><span class="letterCode" style="float:right">NLH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NLH">Mon. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470704">Access Lens: A Gesture-Based Screen Reader for Real-World Documents</a></span><br />
<span class="authors">S. Kane (Univ. of Maryland, Baltimore County, USA), B. Frey, J. Wobbrock</span>
<div class="authorList"><span><span class="author">S. Kane</span> (Univ. of Maryland, Baltimore County, USA)</span><span><span class="author">B. Frey</span> (Univ. of Maryland, Baltimore County, USA)</span><span><span class="author">J. Wobbrock</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">Introduces Access Lens, a computer vision-based system that comboines gesture tracking and optical character recognition to enable blind people to explore physical documents using accessible gestures.</span><span class="abstract">Gesture-based touch screen user interfaces, when designed to be accessible to blind users, can be an effective mode of interaction for those users. However, current accessible touch screen interaction techniques suffer from one serious limitation: they are only usable on devices that have been explicitly designed to support them. Access Lens is a new interaction method that uses computer vision-based gesture tracking to enable blind people to use accessible gestures on paper documents and other physical objects, such as product packages, device screens, and home appliances. This paper describes the development of Access Lens hardware and software, the iterative design of Access Lens in collaboration with blind computer users, and opportunities for future development.</span></li>
<li id="PCC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PCC"><span class="letterCode" style="float:right">PCC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCC">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481368">Why Do People Seek Anonymity on the Internet?  Informing Policy and Design</a></span><br />
<span class="authors">R. Kang (Carnegie Mellon Univ., USA), S. Brown, S. Kiesler</span>
<div class="authorList"><span><span class="author">R. Kang</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">S. Brown</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">S. Kiesler</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We conducted 44 interviews with people from America, Asia, Europe and Africa, and found a large variation in their motivation and strategies for achieving anonymity on the Internet.</span><span class="abstract">In this research we set out to discover why and how people seek anonymity in their online interactions. Our goal is to inform policy and the design of future Internet architecture and applications. We interviewed 44 people from America, Asia, Europe, and Africa who had sought anonymity and asked them about their experiences. A key finding of our research is the very large variation in interviewees’ past experiences and life situations leading them to seek anonymity, and how they tried to achieve it. Our results suggest implications for the design of online communities, challenges for policy, and ways to improve anonymity tools and educate users about the different routes and threats to anonymity on the Internet.</span></li>
<li id="NTQ"class="presentation design engineering games"><a href="http://chi2013.acm.org/previews/paper.html#NTQ"><span class="letterCode" style="float:right">NTQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NTQ">Thu. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466422">Picode: Inline Photos Representing Posture Data in Source Code</a></span><br />
<span class="authors">J. Kato (The Univ. of Tokyo, JP), D. Sakamoto, T. Igarashi</span>
<div class="authorList"><span><span class="author">J. Kato</span> (The Univ. of Tokyo, JP)</span><span><span class="author">D. Sakamoto</span> (The Univ. of Tokyo, JP)</span><span><span class="author">T. Igarashi</span> (The Univ. of Tokyo, JP)</span></div>
<p><span class="cbStatement">Picode is a text-based development environment augmented with inline photos of human and robots. They contain richer context information than mere posture data, and enhance the programming experience.</span><span class="abstract">Current programming environments use textual or symbolic representations. While these representations are appropriate for describing logical processes, they are not appropriate for representing raw values such as human and robot posture data, which are necessary for handling gesture input and controlling robots. To address this issue, we propose Picode, a text-based development environment integrated with visual representations: photos of human and robots. With Picode, the user first takes a photo to bind it to posture data. S/he then drag-and-drops the photo into the code editor, where it is displayed as an inline image. A preliminary in-house user study implied positive effects of taking photos on the programming experience.</span></li>
<li id="NTC"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NTC"><span class="letterCode" style="float:right">NTC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NTC">Thu. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466434">Studying Spatial Memory and Map Navigation Performance on Projector Phones with Peephole Interaction</a></span><br />
<span class="authors">B. Kaufmann (Alpen-Adria Univ. Klagenfurt, AT), D. Ahlström</span>
<div class="authorList"><span><span class="author">B. Kaufmann</span> (Alpen-Adria Univ. Klagenfurt, AT)</span><span><span class="author">D. Ahlström</span> (Alpen-Adria Univ. Klagenfurt, AT)</span></div>
<p><span class="cbStatement">Uses a map navigation task and compares users’ navigation performance with touch screen interaction to peephole interaction, users’ location recall performance, and observers’ location recall performance.</span><span class="abstract">Smartphones are useful personal assistants and omnipresent communication devices. However, collaboration is not among their strengths. With the advent of embedded projectors this might change. We conducted a study with 56 participants to find out if map navigation and spatial memory performance among users and observers can be improved by using a projector phone with a peephole interface instead of a smartphone with its touchscreen interface. Our results show that users performed map navigation equally well on both interfaces. Spatial memory performance, however, was 41% better for projector phone users. Moreover, observers of the map navigation on the projector phone were 25% more accurate when asked to recall locations of points of interest after they watched a user performing map navigation.</span></li>
<li id="PMK"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PMK"><span class="letterCode" style="float:right">PMK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PMK">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466466">Privacy as Part of the App Decision-Making Process</a></span><br />
<span class="authors">P. Kelley (Univ. of New Mexico, USA), L. Cranor, N. Sadeh</span>
<div class="authorList"><span><span class="author">P. Kelley</span> (Univ. of New Mexico, USA)</span><span><span class="author">L. Cranor</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">N. Sadeh</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We found that presenting privacy information to users more clearly and at the time they were making decisions made them more likely to choose Android applications that requested fewer permissions.</span><span class="abstract">Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short &#8220;Privacy Facts&#8221; display, which we  tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.</span></li>
<li id="PFG"class="presentation design games"><a href="http://chi2013.acm.org/previews/paper.html#PFG"><span class="letterCode" style="float:right">PFG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PFG">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466201">Design Metaphors for Procedural Content Generation in Games</a></span><br />
<span class="authors">R. Khaled (Univ. of Malta, MT), M. Nelson, P. Barr</span>
<div class="authorList"><span><span class="author">R. Khaled</span> (Univ. of Malta, MT)</span><span><span class="author">M. Nelson</span> (IT Univ. of Copenhagen, DK)</span><span><span class="author">P. Barr</span> (Univ. of Malta, MT)</span></div>
<p><span class="cbStatement">We present procedural content generation (PCG) design metaphors that help designers understand and appropriate PCG, and advance research by highlighting assumptions implicit in existing systems and discourse.</span><span class="abstract">Procedural content generation (PCG), the algorithmic creation of game content with limited or indirect user input, has much to offer to game design. In recent years, it has become a mainstay of game AI, with significant research being put towards the investigation of new PCG systems, algorithms, and techniques. But for PCG to be absorbed into the practice of game design, it must be contextualised within design-centric as opposed to AI or engineering perspectives. We therefore provide a set of design metaphors for understanding potential relationships between a designer and PCG. These metaphors are:  tool, material, designer, and domain expert. By examining PCG through these metaphors, we gain the ability to articulate qualities, consequences, affordances, and limitations of existing PCG approaches in relation to design. These metaphors are intended both to aid designers in understanding and appropriating PCG for their own contexts, and to advance PCG research by highlighting the assumptions implicit in existing systems and discourse.</span></li>
<li id="PNT"class="presentation cci"><a href="http://chi2013.acm.org/previews/paper.html#PNT"><span class="letterCode" style="float:right">PNT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNT">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466130">Tables in the Wild: Lessons Learned from a Large-Scale Multi-Tabletop Deployment</a></span><br />
<span class="authors">A. Kharrufa (Newcastle Univ., UK), M. Balaam, P. Heslop, D. Leat, P. Dolan, P. Olivier</span>
<div class="authorList"><span><span class="author">A. Kharrufa</span> (Newcastle Univ., UK)</span><span><span class="author">M. Balaam</span> (Newcastle Univ., UK)</span><span><span class="author">P. Heslop</span> (Newcastle Univ., UK)</span><span><span class="author">D. Leat</span> (Newcastle Univ., UK)</span><span><span class="author">P. Dolan</span> (Northumbria Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">The paper presents the analysis of our observations and design recommendations for multi-tabletop applications designed for and deployed within a realistic classroom setting.</span><span class="abstract">This paper presents the results and experiences of a six-week deployment of multiple digital tabletops in a school. Dillenbourg’s orchestration framework was used both to guide the design and analysis of the study. Four themes, which directly relate to the design of the technology for the classroom, out of the 15 orchestration factors are considered. For each theme, we present our design choices, the relevant observations, feedback from teachers and students, and we conclude with a number of lessons learned in the form of design recommendations. The distinguishing factors of our study are its scale (in terms of duration, number of classes, subjects, and teachers), and its ‘in-the-wild’ character, with the entire study being conducted in a school, led by the teachers, and using teacher-prepared, curriculum-based tasks. Our primary contributions are the analysis of our observations and design recommendations for future multi-tabletop applications designed for and deployed within the classroom. Our analyses and recommendations meaningfully extend HCI’s current design understandings of such settings. </span></li>
<li id="PQG"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PQG"><span class="letterCode" style="float:right">PQG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PQG">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466467">&#8220;Everybody Knows What You’re Doing&#8221;: A Critical Design Approach to Personal Informatics</a></span><br />
<span class="authors">V. Khovanskaya (Cornell Univ., USA), E. Baumer, D. Cosley, S. Voida, G. Gay</span>
<div class="authorList"><span><span class="author">V. Khovanskaya</span> (Cornell Univ., USA)</span><span><span class="author">E. Baumer</span> (Cornell Univ., USA)</span><span><span class="author">D. Cosley</span> (Cornell Univ., USA)</span><span><span class="author">S. Voida</span> (Cornell Univ., USA)</span><span><span class="author">G. Gay</span> (Cornell Univ., USA)</span></div>
<p><span class="cbStatement">The paper introduces critical design strategies to the area of personal informatics in order to encourage users to reflect on the data that is gathered about their online activity.</span><span class="abstract">We present an alternative approach to the design of personal informatics systems: instead of motivating people to examine their own behaviors, this approach promotes awareness of and reflection on the infrastructures behind personal informatics and the modes of engagement that they promote. Specifically, this paper presents an interface that displays personal web browsing data. The interface aims to reveal underlying infrastructure using several methods: drawing attention to the scope of mined data by displaying deliberately selected sensitive data, using purposeful malfunction as a way to encourage reverse engineering, and challenging normative expectations around data mining by displaying information in unconventional ways. Qualitative results from a two-week deployment show that these strategies can raise people’s awareness about data mining, promote efficacy and control over personal data, and inspire reflection on the goals and assumptions embedded in infrastructures for personal data analytics.</span></li>
<li id="PLY"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PLY"><span class="letterCode" style="float:right">PLY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PLY">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470691">EventHurdle: Supporting Designers’ Exploratory Interaction Prototyping with Gesture-Based Sensors</a></span><br />
<span class="authors">J. Kim (KAIST (Korea Advanced Institute of Science and Technology), KR), T. Nam</span>
<div class="authorList"><span><span class="author">J. Kim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">T. Nam</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span></div>
<p><span class="cbStatement">This paper presents EventHurdle, a visual gesture authoring tool for designers that supports connecting gesture-based sensors, visually intuitive gesture definitions, and easy prototyping without programming expertise.</span><span class="abstract">Prototyping of gestural interactions in the early phase of design is one of the most challenging tasks for designers without advanced programming skills. Relating users’ input from gesture-based sensor values requires a great deal of effort on the designer’s part and disturbs their reflective and creative thinking. To deal with this problem, we present EventHurdle, a visual gesture-authoring tool to support designers’ explorative prototyping. It supports remote gestures from a camera, handheld gestures with physical sensors, and touch gestures by utilizing touch screens. EventHurdle allows designers to visually define and modify gestures through interaction workspace and graphical markup language with hurdles. Because the created gestures can be integrated into a prototype as programming code and automatically recognized, designers do not need to pay attention in sensor-related implementation. Two user studies and a recognition test are reported to discuss the acceptance and implications of explorative prototyping tools for designers. </span></li>
<li id="PHY"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PHY"><span class="letterCode" style="float:right">PHY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PHY">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470733">TapBoard: Making a Touch Screen Keyboard More Touchable</a></span><br />
<span class="authors">S. Kim (KAIST (Korea Advanced Institute of Science and Technology), KR), J. Son, G. Lee, H. Kim, W. Lee</span>
<div class="authorList"><span><span class="author">S. Kim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">J. Son</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">G. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">H. Kim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">W. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span></div>
<p><span class="cbStatement">TapBoard is a touch screen software keyboard that regards tapping actions as keystrokes and enables other touches for more useful operations; such as resting, feeling surface textures, and making gestures.</span><span class="abstract">A physical keyboard key has three states, whereas a touch screen usually has only two. Due to this difference, the state corresponding to the touched state of a physical key is missing in a touch screen keyboard. This touched state is an important factor in the usability of a keyboard. In order to recover the role of a touched state in a touch screen, we propose the TapBoard, a touch screen software keyboard that regards tapping actions as keystrokes and other touches as the touched state. In a series of user studies, we validate the effectiveness of the TapBoard concept. First, we show that tapping to type is in fact compatible with the existing typing skill of most touch screen keyboard users. Second, users quickly adapt to the TapBoard and learn to rest their fingers in the touched state. Finally, we confirm by a controlled experiment that there is no difference in text-entry performance between the TapBoard and a traditional touch screen software keyboard. In addition to these experimental results, we demonstrate a few new interaction techniques that will be made possible by the TapBoard.</span></li>
<li id="PKD"class="presentation design health sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PKD"><span class="letterCode" style="float:right">PKD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PKD">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481380">inAir: A Longitudinal study of Indoor Air Quality Measurements and Visualizations</a></span><br />
<span class="authors">S. Kim (Carnegie Mellon Univ., USA), E. Paulos, J. Mankoff</span>
<div class="authorList"><span><span class="author">S. Kim</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">E. Paulos</span> (Univ. of California, Berkeley, USA)</span><span><span class="author">J. Mankoff</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">This work aims at understanding the indoor air quality dynamics with respect to indoor activities and analyzing behavioral and quantitative changes towards improving air quality from a longitudinal deployment study. </span><span class="abstract">Indoor air quality (IAQ) is important for health as people spend the majority of time indoors, and it is particularly interesting over outdoor air because it strongly ties to indoor activities. Some activities easily exacerbate IAQ, resulting in serious pollution. However, people may not notice such changes because many pollutants are colorless and odorless, while many activities are inconspicuous and routine. We implemented inAir, a system that measures and visualizes IAQ that households appropriate and integrate into everyday life. The research goals of this work include understanding the IAQ dynamics with respect to habitual behaviors and analyzing behavioral and quantitative changes towards improving IAQ by the use of inAir. From our longitudinal study for four months, we found that inAir successfully elicited the reflection upon, and the modification of habitual behaviors for healthy domestic environments, which resulted in the significant improvement of IAQ.</span></li>
<li id="PMP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PMP"><span class="letterCode" style="float:right">PMP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PMP">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481415">Costs and Benefits of Structured Information Foraging</a></span><br />
<span class="authors">A. Kittur (Carnegie Mellon Univ., USA), A. Peters, A. Diriye, T. Telang, M. Bove</span>
<div class="authorList"><span><span class="author">A. Kittur</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Peters</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Diriye</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">T. Telang</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">M. Bove</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We introduce a novel interface for capturing online information in a structured but lightweight way and use it to experimentally characterize the costs and benefits of structured sensemaking.</span><span class="abstract">People spend an enormous amount of time searching for and saving information online. Existing tools capture only a small portion of the cognitive processing a user engages in while making sense of a new domain. In this paper we introduce a novel interface for capturing online infor-mation in a structured but lightweight way. We use this in-terface as a platform to experimentally characterize the costs and benefits of structuring information during the sensemaking process. Our results contribute empirical knowledge relevant to theories of information seeking and sensemaking, and practical implications for the develop-ment of tools to capture and share online information.</span></li>
<li id="PJE"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PJE"><span class="letterCode" style="float:right">PJE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PJE">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481369">Preference-based Location Sharing: Are More Privacy Options Really Better?</a></span><br />
<span class="authors">B. Knijnenburg (Univ. of California, Irvine, USA), A. Kobsa, H. Jin</span>
<div class="authorList"><span><span class="author">B. Knijnenburg</span> (Univ. of California, Irvine, USA)</span><span><span class="author">A. Kobsa</span> (Univ. of California, Irvine, USA)</span><span><span class="author">H. Jin</span> (Samsung R&#038;D Research Center, USA)</span></div>
<p><span class="cbStatement">Users of a location-sharing service opt for more or less granular disclosure when one granularity level is omitted, depending on the subjective distance between the omitted and remaining options.</span><span class="abstract">We examine the effect of coarse-grained vs. fine-grained location sharing options on users’ disclosure decisions when configuring a sharing profile in a location-sharing service. Our results from an online user experiment (N=291) indicate that users who would otherwise select one of the finer-grained options will employ a compensatory decision strategy when this option is removed. This means that they switch either in the direction of more privacy and less benefit, or less privacy and more benefit, depending on the subjective distance between the omitted option and the remaining options. This explanation of users’ disclosure behavior is in line with fundamental decision theories, as well as the well-established notion of “privacy calculus”. Two alternative hypotheses that we tested were not supported by our experimental data.</span></li>
<li id="PMF"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PMF"><span class="letterCode" style="float:right">PMF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PMF">Mon. 11am</a></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470684">Crowdsourcing Performance Evaluations of User Interfaces</a></span><br />
<span class="authors">S. Komarov (Harvard Univ., USA), K. Reinecke, K. Gajos</span>
<div class="authorList"><span><span class="author">S. Komarov</span> (Harvard Univ., USA)</span><span><span class="author">K. Reinecke</span> (Harvard Univ., USA)</span><span><span class="author">K. Gajos</span> (Harvard Univ., USA)</span></div>
<p><span class="cbStatement">We explored the feasibility of using Amazon Mechanical Turk for user interface evaluation by replicating three well-known UI experiments both in lab and online. </span><span class="abstract">Online labor markets, such as Amazon&#8217;s Mechanical Turk (MTurk), provide an attractive platform for conducting human subjects experiments because the relative ease of recruitment, low cost, and a diverse pool of potential participants enable larger-scale experimentation and faster experimental revision cycle compared to lab-based settings.  However, because the experimenter gives up the direct control over the participants&#8217; environments and behavior, concerns about the quality of the data collected in online settings are pervasive.  In this paper, we investigate the feasibility of conducting online performance evaluations of user interfaces with anonymous, unsupervised, paid participants recruited via MTurk. We implemented three performance experiments to re-evaluate three previously well-studied user interface designs. We conducted each experiment both in lab and online with participants recruited via MTurk.  The analysis of our results did not yield any evidence of significant or substantial differences in the data collected in the two settings: All statistically significant differences detected in lab were also present on MTurk and the effect sizes were similar. In addition, there were no significant differences between the two settings in the raw task completion times, error rates, consistency, or the rates of utilization of the novel interaction mechanisms introduced in the experiments.  These results suggest that MTurk may be a productive setting for conducting performance evaluations of user interfaces providing a complementary approach to existing methodologies.</span></li>
<li id="PAU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PAU"><span class="letterCode" style="float:right">PAU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PAU">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466419">How Tools in IDEs Shape Developers&#8217; Navigation Behavior</a></span><br />
<span class="authors">J. Krämer (RWTH Aachen Univ., DE), T. Karrer, J. Kurz, M. Wittenhagen, J. Borchers</span>
<div class="authorList"><span><span class="author">J. Krämer</span> (RWTH Aachen Univ., DE)</span><span><span class="author">T. Karrer</span> (RWTH Aachen Univ., DE)</span><span><span class="author">J. Kurz</span> (RWTH Aachen Univ., DE)</span><span><span class="author">M. Wittenhagen</span> (RWTH Aachen Univ., DE)</span><span><span class="author">J. Borchers</span> (RWTH Aachen Univ., DE)</span></div>
<p><span class="cbStatement">Introduces a model to describe the code navigation behavior of programmers; this model can be used to analyze the influence of different call graph navigation tools on navigation strategies.</span><span class="abstract">Understanding source code is crucial for successful software maintenance, and navigating the call graph is especially helpful to understand source code. We compared maintenance performance across four different development environments: an IDE without any call graph exploration tool, a Call Hierarchy tool as found in Eclipse, and the tools Stacksplorer and Blaze. Using any of the call graph exploration tools more developers could solve certain maintenance tasks correctly. Only Stacksplorer and Blaze, however, were also able to decrease task completion times, although the Call Hierarchy offers access to a larger part of the call graph. To investigate if this result was caused by a change in navigation behavior between the tools, we used a set of predictive models to create formally comparable descriptions of programmer navigation. The results suggest that the decrease in task completion times has been caused by Stacksplorer and Blaze promoting call graph navigation more than the Call Hierarchy tool.</span></li>
<li id="PFQ"class="presentation design management ux"><a href="http://chi2013.acm.org/previews/paper.html#PFQ"><span class="letterCode" style="float:right">PFQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PFQ">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466135">Emotions, Experiences and Usability in Real-Life Mobile Phone Use</a></span><br />
<span class="authors">S. Kujala (Aalto Univ., FI), T. Miron-Shatz</span>
<div class="authorList"><span><span class="author">S. Kujala</span> (Aalto Univ., FI)</span><span><span class="author">T. Miron-Shatz</span> (Ono Academic College, IL)</span></div>
<p><span class="cbStatement">Longitudinal study investigating emotions over a five-month period of product use. Clarifies the role of emotions in usability, user experience and product success and helps in designing for user experience.</span><span class="abstract">Positive emotional experiences with an interactive product are assumed to lead to good user experience and, ultimately, to product success. However, the path from emotional experiences to product evaluation may not be direct, as emotions fluctuate over time, and some experiences are easier to recall than others. In this study, we examined emotions and experience episodes during real-life mobile phone use over a five-month period. The goal is to understand how emotions and memories are related to overall evaluation of a product: usability, user experience and behavioral intentions. The results show that both emotions and how people remember them had strong unique roles in the overall evaluation of the product. Positive emotions were mostly related to good user experience and negative emotions to low usability. In the early stages of use, users overestimated their positive emotions and seemed to focus on user experience, the importance of usability increased over time.</span></li>
<li id="PKE"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PKE"><span class="letterCode" style="float:right">PKE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PKE">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466225">What Makes You Click: Exploring Visual Signals to Entice Interaction on Public Displays</a></span><br />
<span class="authors">H. Kukka (Univ. of Oulu, FI), H. Oja, V. Kostakos, J. Gonçalves, T. Ojala</span>
<div class="authorList"><span><span class="author">H. Kukka</span> (Univ. of Oulu, FI)</span><span><span class="author">H. Oja</span> (Univ. of Oulu, FI)</span><span><span class="author">V. Kostakos</span> (Univ. of Oulu, FI)</span><span><span class="author">J. Gonçalves</span> (Univ. of Oulu, FI)</span><span><span class="author">T. Ojala</span> (Univ. of Oulu, FI)</span></div>
<p><span class="cbStatement">We investigate mechanisms for enticing interaction on public displays. Eight visual signals were developed and deployed on a university campus to study which visual elements work best at enticing interaction.</span><span class="abstract">Most studies take for granted the critical first steps that prelude interaction with a public display: awareness of the interactive affordances of the display, and enticement to interact. In this paper we investigate mechanisms for enticing interaction on public displays, and study the effectiveness of visual signals in overcoming the ‘first click’ problem. We combined 3 atomic visual elements (color/greyscale, animation/static, and icon/text) to form 8 visual signals that were deployed on 8 interactive public displays on a university campus for 8 days. Our findings show that text is more effective in enticing interaction than icons, color more than greyscale, and static signals are more effective than animated. Further, we identify gender differences in the effectiveness of these signals. Finally, we identify a behavior termed “display avoidance” that people exhibit with interactive public displays. </span></li>
<li id="PJR"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PJR"><span class="letterCode" style="float:right">PJR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJR">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466129">Challenges and Opportunities for Technology in Foreign Language Classrooms</a></span><br />
<span class="authors">K. Kuksenok (Univ. of Washington, USA), M. Brooks, Q. Wang, C. Lee</span>
<div class="authorList"><span><span class="author">K. Kuksenok</span> (Univ. of Washington, USA)</span><span><span class="author">M. Brooks</span> (Univ. of Washington, USA)</span><span><span class="author">Q. Wang</span> (Univ. of Washington, USA)</span><span><span class="author">C. Lee</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">The roles of artifacts in language learning, based on ethnographic study of introductory Russian classrooms, informing design for this stressful, yet creative, cooperative environment.</span><span class="abstract">We present the results of a two-month ethnographic study of three introductory Russian classrooms. Through observation and interviews, we identify several distinct roles played by physical artifacts in the classrooms, such as providing a reference to necessary foreign-language material and serving as props in creative role-play. The range of roles taken on by artifacts and the attitudes students have toward them provide a basis for our discussion about how technology might be more effectively introduced into the socially negotiated environment of the introductory foreign-language classroom. We identify the need to balance between collaborative and personal technology in a stressful, but social, context. Our findings inform a range of roles that technology can undertake in replacing or augmenting existing classroom artifacts.</span></li>
<li id="PQS"class="presentation ux health"><a href="http://chi2013.acm.org/previews/paper.html#PQS"><span class="letterCode" style="float:right">PQS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PQS">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470664">Accessible Online Content Creation By End Users</a></span><br />
<span class="authors">K. Kuksenok (Univ. of Washington, USA), M. Brooks, J. Mankoff</span>
<div class="authorList"><span><span class="author">K. Kuksenok</span> (Univ. of Washington, USA)</span><span><span class="author">M. Brooks</span> (Univ. of Washington, USA)</span><span><span class="author">J. Mankoff</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">End-user generated content is common, yet often not accessibility. Our case studies of online communities that create accessible content, shows the importance of negotiated and community-defined notions of accessibility.</span><span class="abstract">Like most online content, user-generated content (UGC) poses accessibility barriers to users with disabilities. However, the accessibility difficulties pervasive in UGC warrant discussion and analysis distinct from other kinds of online content. Content authors, community culture, and the authoring tool itself all affect UGC accessibility. The choices, resources available, and strategies in use to ensure accessibility are different than for other types of online content. We contribute case studies of two UGC communities with accessible content: Wikipedia, where authors focus on access to visual materials and navigation, and an online health support forum where users moderate the cognitive accessibility of posts. Our data demonstrate real world moderation strategies and illuminate factors affecting success, such as community culture. We conclude with recommended strategies for creating a culture of accessibility around UGC.</span></li>
<li id="PMN"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PMN"><span class="letterCode" style="float:right">PMN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PMN">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481334">All the News that’s Fit to Read: A Study of Social Annotations for News Reading</a></span><br />
<span class="authors">C. Kulkarni (Stanford Univ., USA), E. Chi</span>
<div class="authorList"><span><span class="author">C. Kulkarni</span> (Stanford Univ., USA)</span><span><span class="author">E. Chi</span> (Google, Inc., USA)</span></div>
<p><span class="cbStatement">Compares annotations for news in logged-in and logged-out contexts. When logged-out, annotations by companies are persuasive, but by strangers aren&#8217;t. When logged-in, friend annotations are persuasive and improve satisfaction.</span><span class="abstract">As news reading becomes more social, how do different types of  annotations affect people&#8217;s selection of news articles?  This paper  reports on results from two experiments looking at social annotations  in two different news reading contexts.  The first experiment  simulates a logged-out experience with annotations from strangers, a  computer agent, and a branded company.  Results indicate that, perhaps  unsurprisingly, annotations by strangers have no persuasive  effects. However, surprisingly, unknown branded companies still had a  persuasive effect.  The second experiment simulates a logged-in  experience with annotations from friends, finding that friend  annotations are both persuasive and improve user satisfaction over  their article selections.  In post-experiment interviews, we found  that this increased satisfaction is due partly because of the context  that annotations add. That is, friend annotations both help people  decide what to read, and provide social context that improves  engagement.  Interviews also suggest subtle expertise effects. We  discuss implications for design of social annotation systems and  suggestions for future research.  </span></li>
<li id="PEH"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PEH"><span class="letterCode" style="float:right">PEH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PEH">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466263">The Mobile Media Actor-Network in Urban India</a></span><br />
<span class="authors">N. Kumar (Univ. of California, Berkeley, USA), N. Rangaswamy</span>
<div class="authorList"><span><span class="author">N. Kumar</span> (Univ. of California, Berkeley, USA)</span><span><span class="author">N. Rangaswamy</span> (Microsoft Research India, IN)</span></div>
<p><span class="cbStatement">This paper describes the vast, growing mobile media consumption culture in urban India, which relies on the ubiquity of informal socioeconomic practices for reproducing, sharing, and distributing pirated digital media. </span><span class="abstract">Building on a growing body of human-computer interaction (HCI) literature on information and communication technology (ICT) use in the developing world, this paper describes the vast, growing mobile media consumption culture in India, which relies on the ubiquity of informal socioeconomic practices for reproducing, sharing, and distributing pirated digital media. Using an Actor-Network Theory (ANT) based approach, we show how piracy not only fuels media consumption, but also drives further technology adoption and promotes digital literacy. To do this, we first uncover the role of piracy as a legitimate actor that brings ICT capability to underserved communities and reveal the heterogeneous character of the pirated mobile media distribution and consumption infrastructure in India. We then emphasize the benefits of an ANT-based theory-driven analysis to HCI’s efforts in this arena. In particular, ANT enables us to one, draw attention to the ties in the pirate media network that facilitate the increased decentralization of piracy in India; two, highlight the progressive transition from the outsourcing to the self-sourcing of users’ media needs as this network evolves; and three, recognize the agency of human and non-human entities in this inherently sociotechnical ecosystem.  </span></li>
<li id="PMM"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PMM"><span class="letterCode" style="float:right">PMM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PMM">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481396">Mobiles, Music, and Materiality</a></span><br />
<span class="authors">N. Kumar (Univ. of California, Berkeley, USA), T. Parikh</span>
<div class="authorList"><span><span class="author">N. Kumar</span> (Univ. of California, Berkeley, USA)</span><span><span class="author">T. Parikh</span> (Univ. of California, Berkeley, USA)</span></div>
<p><span class="cbStatement">Building on recent research that highlights the materiality of digital information, we examine the materiality of digital media in mobile music production, reproduction, and reception practices of small town India. </span><span class="abstract">Building on recent HCI contributions that assert the materiality of digital information, we examine the material nature of digital media and information technology in the context of mobile music production, reproduction, and reception in rural and semi-urban India. We use ethnographic methods to study the recent adoption and use of mobile technology and discuss our findings in relation to the evolving materiality of music. We also investigate the sociotechnical configurations that emerge as a consequence of this materiality. Thus we contribute to HCI research by showing how the material representations of digital media affect the interactions of humans with technology.</span></li>
<li id="PLB"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PLB"><span class="letterCode" style="float:right">PLB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PLB">Thu. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466420">Webzeitgeist: Design Mining the Web</a></span><br />
<span class="authors">R. Kumar (Stanford Univ., USA), A. Satyanarayan, C. Torres, M. Lim, S. Ahmad, S. Klemmer, J. Talton</span>
<div class="authorList"><span><span class="author">R. Kumar</span> (Stanford Univ., USA)</span><span><span class="author">A. Satyanarayan</span> (Stanford Univ., USA)</span><span><span class="author">C. Torres</span> (Stanford Univ., USA)</span><span><span class="author">M. Lim</span> (Stanford Univ., USA)</span><span><span class="author">S. Ahmad</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">S. Klemmer</span> (Stanford Univ., USA)</span><span><span class="author">J. Talton</span> (Intel Corporation, USA)</span></div>
<p><span class="cbStatement">This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools.</span><span class="abstract">Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes.  This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools.  This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables.</span></li>
<li id="NDP"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NDP"><span class="letterCode" style="float:right">NDP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NDP">Mon. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470710">Scenario-Based Interactive UI Design</a></span><br />
<span class="authors">K. Kusano (NTT Service Evolution Laboratories, JP), M. Nakatani, T. Ohno</span>
<div class="authorList"><span><span class="author">K. Kusano</span> (NTT Service Evolution Laboratories, JP)</span><span><span class="author">M. Nakatani</span> (NTT Service Evolution Laboratories, JP)</span><span><span class="author">T. Ohno</span> (NTT Service Evolution Laboratories, JP)</span></div>
<p><span class="cbStatement">Our proposal is a novel tool that enhances the designer’s skill in writing scenarios and designing UIs smoothly and easily.</span><span class="abstract">Clearly picturing user behavior is one of the key requirements when designing successful interactive software. However, covering all possible user behaviors with one UI is a complex challenge. The Scenario-based Interactive UI Design tool is designed to support the characterization of user behavior based on scenarios and then using the information in UI design. Scenarios make it easy to understand and share user behavior even if we have little design knowledge. However, they have two big weaknesses; 1) integrating several scenarios in one UI is difficult, even if we can create appropriate scenarios, 2) maintaining the links between scenarios and the UI is a heavy task in iterative design. Our tool solves the above problems through its hierarchical scenario structure and visualized overview of scenarios. It enhances the designer’s skill in writing scenarios and designing UIs smoothly and easily.</span></li>
<li id="PPU"class="presentation engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PPU"><span class="letterCode" style="float:right">PPU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPU">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466213">Debugging Support for End User Mashup Programming</a></span><br />
<span class="authors">S. Kuttal (Univ. of Nebraska-Lincoln , USA), A. Sarma, G. Rothermel</span>
<div class="authorList"><span><span class="author">S. Kuttal</span> (Univ. of Nebraska-Lincoln , USA)</span><span><span class="author">A. Sarma</span> (Univ. of Nebraska, Lincoln, USA)</span><span><span class="author">G. Rothermel</span> (Univ. of Nebraska, Lincoln, USA)</span></div>
<p><span class="cbStatement">Debugging mashups is difficult and error-prone. We identify classes of faults in Yahoo! Pipes, present a prototype for automated fault localization, and illustrate its effectiveness via a user study. </span><span class="abstract">Programming for the web can be an intimidating task,particularly for non-professional (“end-user”) programmers. Mashup programming environments attempt to remedy this by providing support for such programming. It is well known, however, that mashup programmers create applications that contain bugs. Furthermore, mashup programmers learn from examples and reuse other mashups, which causes bugs to propagate to other mashups. In this paper we classify the bugs that occur in a large corpus of Yahoo! Pipes mashups. We describe support we have implemented in the Yahoo! Pipes environment to provide automatic error detection techniques that help mashup programmers localize and correct these  bugs. We present the results of a think-aloud study comparing the experiences of end-user mashup programmers using and not using our support. Our results show that our debugging enhancements do help these programmers localize and  correct bugs more effectively and efficiently.</span></li>
<li id="PJU"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PJU"><span class="letterCode" style="float:right">PJU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJU">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466235">Community Enhanced Tutorials: Improving Tutorials with Multiple Demonstrations</a></span><br />
<span class="authors">B. Lafreniere (Univ. of Waterloo, CA), T. Grossman, G. Fitzmaurice</span>
<div class="authorList"><span><span class="author">B. Lafreniere</span> (Univ. of Waterloo, CA)</span><span><span class="author">T. Grossman</span> (Autodesk Research, CA)</span><span><span class="author">G. Fitzmaurice</span> (Autodesk Research, CA)</span></div>
<p><span class="cbStatement">We propose a novel web-based tutorial system that gathers video demonstrations from its users. An initial study shows the presence of multiple demonstrations can help users when following a tutorial.</span><span class="abstract">Web-based tutorials are a popular help resource for learning how to perform unfamiliar tasks in complex software. However, in their current form, web tutorials are isolated from the applications that they support. In this paper we present FollowUs, a web-tutorial system that integrates a fully-featured application into a web-based tutorial. This novel architecture enables community enhanced tutorials, which continuously improve as more users work with them. FollowUs captures video demonstrations of users as they perform a tutorial. Subsequent users can use the original tutorial, or choose from a library of captured community demonstrations of each tutorial step. We conducted a user study to test the benefits of making multiple demonstrations available to users, and found that users perform significantly better using our system with a library of multiple demonstrations in comparison to its equivalent baseline system with only the original authored content.</span></li>
<li id="PQK"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PQK"><span class="letterCode" style="float:right">PQK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PQK">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481309">Ownership and Control of Point of View in Remote Assistance</a></span><br />
<span class="authors">J. Lanir (Univ. of Haifa, IL), R. Stone, B. Cohen, P. Gurevich</span>
<div class="authorList"><span><span class="author">J. Lanir</span> (Univ. of Haifa, IL)</span><span><span class="author">R. Stone</span> (IBM Research, IL)</span><span><span class="author">B. Cohen</span> (IBM Research, IL)</span><span><span class="author">P. Gurevich</span> (IBM Research, IL)</span></div>
<p><span class="cbStatement">This work investigates user performance and behavior related to the issue of who controls the point of view of a gesturing device in a remote assistance scenario</span><span class="abstract">In this paper we investigate user performance and user behavior, related to the issue of who controls the point of view in a remote assistance scenario. We describe an experiment that examined users completing two different tasks with the aid of a remote gesturing device under two conditions: when control of the camera and gesturing point of view was in the hands of the remote helper, and when it was in the hands of the worker. Results indicate that in general, when most of the knowledge is with the helper, it is preferable to leave control in the hands of the helper. However, these results may depend on the situation and task at hand.</span></li>
<li id="PQU"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PQU"><span class="letterCode" style="float:right">PQU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PQU">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481301">PixelTone: A Multimodal Interface for Image Editing</a></span><br />
<span class="authors">G. Laput (Univ. of Michigan, USA), M. Dontcheva, G. Wilensky, W. Chang, A. Agarwala, J. Linder, E. Adar</span>
<div class="authorList"><span><span class="author">G. Laput</span> (Univ. of Michigan, USA)</span><span><span class="author">M. Dontcheva</span> (Adobe Research, USA)</span><span><span class="author">G. Wilensky</span> (Adobe Research, USA)</span><span><span class="author">W. Chang</span> (Adobe Research, USA)</span><span><span class="author">A. Agarwala</span> (Adobe Research, USA)</span><span><span class="author">J. Linder</span> (Adobe Research, USA)</span><span><span class="author">E. Adar</span> (Univ. of Michigan, USA)</span></div>
<p><span class="cbStatement">PixelTone is a multimodal photo editing interface that combines speech and direct manipulation.</span><span class="abstract">Photo editing can be a challenging task, and it becomes even more difficult on the small, portable screens of mobile devices that are now frequently used to capture and edit images. To address this problem we present PixelTone, a multimodal photo editing interface that combines speech and direct manipulation. We observe existing image editing practices and derive a set of principles that guide our design. In particular, we use natural language for expressing desired changes to an image, and sketching to localize these changes to specific regions. To support the language commonly used in photo-editing we develop a customized natural language interpreter that maps user phrases to specific image processing operations. Finally, we perform a user study that evaluates and demonstrates the effectiveness of our interface.</span></li>
<li id="NFD"class="presentation design engineering management"><a href="http://chi2013.acm.org/previews/paper.html#NFD"><span class="letterCode" style="float:right">NFD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NFD">Tue. 4pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466269">Warping Time for More Effective Real-Time Crowdsourcing</a></span><br />
<span class="authors">W. Lasecki (Univ. of Rochester, USA), C. Miller, J. Bigham</span>
<div class="authorList"><span><span class="author">W. Lasecki</span> (Univ. of Rochester, USA)</span><span><span class="author">C. Miller</span> (Univ. of Rochester, USA)</span><span><span class="author">J. Bigham</span> (Univ. of Rochester, USA)</span></div>
<p><span class="cbStatement">We present TimeWarp, a crowdsourcing approach that allows workers to individually complete continuous tasks that involve streaming media at reduced speeds, while the crowd can collectively keep up with real-time.</span><span class="abstract">  In this paper, we introduce the idea of &#8221;warping time&#8221; to improve    crowd performance on the difficult task of captioning speech in    real-time.  Prior work has shown that the crowd can collectively    caption speech in real-time by merging the partial results of    multiple workers.  Because non-expert workers cannot keep up with    natural speaking rates, the task is frustrating and prone to errors    as workers buffer what they hear to type later.  The TimeWarp    approach automatically increases and decreases the speed of speech    playback systematically across individual workers who caption only    the periods played at reduced speed. Studies with 139 remote crowd    workers and 24 local participants show that this approach improves    median coverage (14.8%), precision (11.2%), and per-word latency    (19.1%). Warping time may also help crowds outperform individuals on    other difficult real-time performance tasks.</span></li>
<li id="PAY"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PAY"><span class="letterCode" style="float:right">PAY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PAY">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470702">The Presentation of Health-Related Search Results and Its Impact on Negative Emotional Outcomes</a></span><br />
<span class="authors">C. Lauckner (Michigan State Univeristy, USA), G. Hsieh</span>
<div class="authorList"><span><span class="author">C. Lauckner</span> (Michigan State Univeristy, USA)</span><span><span class="author">G. Hsieh</span> (Michigan State Univeristy, USA)</span></div>
<p><span class="cbStatement">This experiment demonstrates features of health symptom search results that can influence negative emotional outcomes, with results suggesting strategies for web developers and users to help avoid such effects.</span><span class="abstract">Searching for health information online has become increasingly common, yet few studies have examined potential negative emotional effects of online health information search. We present results from an experiment manipulating the presentation of search results for common symptoms, which shows that the frequency and placement of serious illness mentions within results can influence perceptions of symptom severity and susceptibility of having the serious illness, respectively. The increase in severity and susceptibility can then lead to higher levels of negative emotional outcomes experienced–including feeling overwhelmed and frightened. Interestingly, health literacy can help reduce perceived symptom severity, and high online health experience actually increases the likelihood that individuals use a frequency-based heuristic. Technological implications and directions for future research are discussed. </span></li>
<li id="PLD"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PLD"><span class="letterCode" style="float:right">PLD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PLD">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481345">Validating a Mobile Phone Application for the Everyday, Unobtrusive, Objective Measurement of Sleep</a></span><br />
<span class="authors">S. Lawson (Univ. of Lincoln, UK), S. Jamison-Powell, A. Garbett, C. Linehan, E. Kucharczyk, S. Verbaan, D. Rowland, K. Morgan</span>
<div class="authorList"><span><span class="author">S. Lawson</span> (Univ. of Lincoln, UK)</span><span><span class="author">S. Jamison-Powell</span> (Univ. of Leicester, UK)</span><span><span class="author">A. Garbett</span> (Newcastle Univ., UK)</span><span><span class="author">C. Linehan</span> (Univ. of Lincoln, UK)</span><span><span class="author">E. Kucharczyk</span> (Loughborough Univ., UK)</span><span><span class="author">S. Verbaan</span> (The Hague Univ. of Applied Sciences, NL)</span><span><span class="author">D. Rowland</span> (Univ. of Lincoln, UK)</span><span><span class="author">K. Morgan</span> (Loughborough Univ., UK)</span></div>
<p><span class="cbStatement">This paper describes the validation, using long standing methods from the sleep research community, of an Android phone app that can be used to record sleep and measure sleep efficiency.</span><span class="abstract">There is an identified need for objective, reliable, and scalable methods of measuring and recording sleep. Such methods must be designed for easy integration into people’s lives in order to support both sleep therapy and everyday personal informatics. This paper describes the design and evaluation of a mobile phone application to record sleep, the design of which has substantive foundation in clinical sleep research. Two user studies were carried out which demonstrate that the application produces valid measurements of sleep quality and high levels of usability, whilst not seriously disturbing sleep or the sleep environment. These findings suggest that the app is suitable for both everyday sleep monitoring in a personal informatics context, and for integration into sleep interventions.</span></li>
<li id="NFM"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NFM"><span class="letterCode" style="float:right">NFM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NFM">Thu. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466455">How Categories Come to Matter</a></span><br />
<span class="authors">L. Leahu (Mobile Life @ SICS, SE), M. Cohn, W. March</span>
<div class="authorList"><span><span class="author">L. Leahu</span> (Mobile Life @ SICS, SE)</span><span><span class="author">M. Cohn</span> (Univ. of California, Irvine, USA)</span><span><span class="author">W. March</span> (Intel Labs, USA)</span></div>
<p><span class="cbStatement">We present and discuss interviews with Siri users as a means to understand the role categories play in the design of user studies and of technologies. </span><span class="abstract">In a study of users&#8217; interactions with Siri, the iPhone personal assistant application, we noticed the emergence of overlaps and blurrings between explanatory categories such as “human” and “machine.” We found that users work to purify these categories, thus resolving the tensions related to the overlaps. This &#8220;purification work&#8221; demonstrates how such categories are always in flux and are redrawn even as they are kept separate. Drawing on STS analytic techniques, we demonstrate the mechanisms of such &#8220;purification work.&#8221; We also describe how such category work remained invisible to us during initial data analysis, due to our own forms of latent purification, and outline the particular analytic techniques that helped lead to this discovery. We thus provide an illustrative case of how categories come to matter in HCI research and design.</span></li>
<li id="PGQ"class="presentation engineering games"><a href="http://chi2013.acm.org/previews/paper.html#PGQ"><span class="letterCode" style="float:right">PGQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PGQ">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481354">Real-Time Perception-Level Translation from Audio Signals to Vibrotactile Effects</a></span><br />
<span class="authors">J. Lee (Pohang Univ. of Science and Technology (POSTECH), KR), S. Choi</span>
<div class="authorList"><span><span class="author">J. Lee</span> (Pohang Univ. of Science and Technology (POSTECH), KR)</span><span><span class="author">S. Choi</span> (Pohang Univ. of Science and Technology (POSTECH), KR)</span></div>
<p><span class="cbStatement">This paper presents an automatic translation framework that creates vibrotactile effects from audio content with explicit understandings of the perceptual consequences, for easy production of tactile effects for multimedia content.</span><span class="abstract">In this paper, we propose a real-time perception-level audio-to-vibrotactile translation algorithm. Unlike previous signal-level conversion methods, our algorithm considers only perceptual characteristics, such as loudness and roughness, of audio and tactile stimuli. This perception-level approach allows for designing intuitive and explicit conversion models with clear understandings of their perceptual consequences. Our current implementation is tailored to accurate detection of special sound effects to provide well-synchronized audio-tactile feedback in immersive applications. We also assessed the performance of our translation algorithm in terms of the detection rate of special sound effects, computational performance, and user preference. All the experimental results supported that our algorithm works well as intended with better performance than the signal-level conversion methods, especially for games. Our algorithm can be easily realized in current products, including mobile devices, gaming devices, and 4D home theater systems, for richer user experience.</span></li>
<li id="NNG"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#NNG"><span class="letterCode" style="float:right">NNG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NNG">Mon. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470680">SpaceTop: Integrating 2D and Spatial 3D Interactions  in a See-through Desktop Environment</a></span><br />
<span class="authors">J. Lee (Media Lab, USA), A. Olwal, H. Ishii, C. Boulanger</span>
<div class="authorList"><span><span class="author">J. Lee</span> (Media Lab, USA)</span><span><span class="author">A. Olwal</span> (Media Lab, USA)</span><span><span class="author">H. Ishii</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">C. Boulanger</span> (Microsoft Applied Sciences Group, USA)</span></div>
<p><span class="cbStatement">SpaceTop is a concept that integrates 2D and 3D spatial interactions in a desktop workspace. It extends the desktop interface with interaction technology and visualization techniques that enable seamless transitions between 2D and 3D manipulations.</span><span class="abstract">SpaceTop is a concept that fuses spatial 2D and 3D interactions in a single workspace. It extends the traditional desktop interface with interaction technology and visualization techniques that enable seamless transitions between 2D and 3D manipulations. SpaceTop allows users to type, click, draw in 2D, and directly manipulate interface elements that float in the 3D space above the keyboard. It makes it possible to easily switch from one modality to another, or to simultaneously use two modalities with different hands. We introduce hardware and software configurations for co-locating these various interaction modalities in a unified workspace using depth cameras and a transparent display. We describe new interaction and visualization techniques that allow users to interact with 2D elements floating in 3D space. We present the results from a preliminary user study that indicates the benefit of such hybrid workspaces. </span></li>
<li id="NHH"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NHH"><span class="letterCode" style="float:right">NHH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NHH">Thu. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466433">Binocular Cursor: Enabling Selection on Transparent Displays Troubled by Binocular Parallax</a></span><br />
<span class="authors">J. Lee (KAIST (Korea Advanced Institute of Science and Technology), KR), S. Bae</span>
<div class="authorList"><span><span class="author">J. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">S. Bae</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span></div>
<p><span class="cbStatement">Transparent displays are about to be commercialized, yet it is troubled by binocular parallax. We propose a measure to quantify the usability degradation caused by binocular parallax, and an interaction strategy.</span><span class="abstract">Binocular parallax is a problem for any interaction system that has a transparent display and objects behind it, as users will see duplicated and overlapped images. In this note, we propose a quantitative measure called Binocular Selectability Discriminant (BSD) to predict the ability of the user to perform selection task in such a setup. In addition, we propose a technique called Binocular Cursor (BC) which takes advantage of this duplicating and overlapping phenomenon, rather than being hampered by it, to resolve binocular selection ambiguity by visualizing the correct selection point. An experiment shows that selection with BC is not slower than monocular selection, and that it can be significantly more precise, depending on the design of BC.</span></li>
<li id="NEK"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NEK"><span class="letterCode" style="float:right">NEK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NEK">Mon. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470698">A Preliminary Investigation of Human Adaptations for Various Virtual Eyes in Video See-Through HMDs</a></span><br />
<span class="authors">J. Lee (Korea Institute of Science and Technology (KIST), KR), S. Kim, H. Yoon, B. Huh, J. Park</span>
<div class="authorList"><span><span class="author">J. Lee</span> (Korea Institute of Science and Technology (KIST), KR)</span><span><span class="author">S. Kim</span> (Korea Institute of Science and Technology (KIST), KR)</span><span><span class="author">H. Yoon</span> (Korea Institute of Science and Technology (KIST), KR)</span><span><span class="author">B. Huh</span> (KIST(Korea Institute of Science and Technology), KR)</span><span><span class="author">J. Park</span> (Korea Institute of Science and Technology (KIST), KR)</span></div>
<p><span class="cbStatement">We investigated whether any differences in visuomotor and adaptation trends exist across 16 distinct VD conditions. The performance tasks studied were of two types: foot placement and finger touch.</span><span class="abstract">A video see-through head mounted display (HMD) has a different viewing point than does the real eye, resulting in visual displacement (VD). VD deteriorates visuomotor performance due to sensory conflict. Previous work has investigated this deterioration and human adaptation by comparing fixed VD and real eye conditions. In this study we go a step further to investigate whether any differences in visuomotor and adaptation trends exist across 16 distinct VD conditions. The performance tasks studied were of two types: foot placement and finger touch. In contrast to our initial prediction, the results showed equal task performance levels and adaptation within about 5 minutes regardless of VD conditions. We found that human adaptation covered a variety of VDs — up to 55 mm in the X, Y direction; up to 125mm in the Z direction; and up to 140mm of interocular distance (IOD). In addition, we found that partial adaptation gave participants the interesting experience of a sense of body structure distortion for a few minutes.</span></li>
<li id="PJN"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PJN"><span class="letterCode" style="float:right">PJN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PJN">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470730">Analyzing Crowd Workers in Mobile Pay-for-Answer Q&#038;A</a></span><br />
<span class="authors">U. Lee (KAIST (Korea Advanced Institute of Science and Technology), KR), J. Kim, E. Yi, J. Sung, M. Gerla</span>
<div class="authorList"><span><span class="author">U. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">J. Kim</span> (Univ. of California, Los Angeles, USA)</span><span><span class="author">E. Yi</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">J. Sung</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">M. Gerla</span> (Univ. of California, Los Angeles, USA)</span></div>
<p><span class="cbStatement">We studied one of the largest mobile pay-for-answer Q&#038;A services called Jisiklog to understand behaviors of crowdworkers: key motivators of participation, working strategies of experienced users, and longitudinal interaction dynamics.</span><span class="abstract">Despite the popularity of mobile pay-for-answer Q&#038;A services, little is known about the people who answer questions on these services. In this paper we examine 18.8 million question and answer pairs from Jisiklog, the largest mobile pay-foranswer Q&#038;A service in Korea, and the results of a complementary survey study of 245 Jisiklog workers. The data are used to investigate key motivators of participation, working strategies of experienced users, and longitudinal interaction dynamics. We find that answerers are rarely motivated by social factors but are motivated by financial incentives and intrinsic motives. Additionally, although answers are provided quickly, an answerer&#8217;s topic selection tends to be broad, with experienced workers employing unique strategies to answer questions and judge relevance. Finally, analysis of longitudinal working patterns and community dynamics demonstrate the robustness of mobile pay-for-answer Q&#038;A. These findings have significant implications on the design of mobile pay-for-answer Q&#038;A.</span></li>
<li id="PQX"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PQX"><span class="letterCode" style="float:right">PQX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PQX">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470770">Does Slacktivism Hurt Activism?: The Effects of Moral Balancing and Consistency in Online Activism</a></span><br />
<span class="authors">Y. Lee (Michigan State Univeristy, USA), G. Hsieh</span>
<div class="authorList"><span><span class="author">Y. Lee</span> (Michigan State Univeristy, USA)</span><span><span class="author">G. Hsieh</span> (Michigan State Univeristy, USA)</span></div>
<p><span class="cbStatement">We examine how simple online activism influence people&#8217;s likelihood and efforts in a subsequent civic action. The findings have implications for online campaign design.</span><span class="abstract">In this paper we explore how the decision of partaking in low-cost, low-risk online activism—slacktivism—may affect subsequent civic action. Based on moral balancing and consistency effects, we designed an online experiment to test if signing or not signing an online petition increased or decreased subsequent contribution to a charity. We found that participants who signed the online petition were significantly more likely to donate money to a related charity, demonstrating a consistency effect. We also found that participants who did not sign the petition donated significantly more money to an unrelated charity, demonstrating a moral balancing effect. The results suggest that exposure to an online activism influences individual decision on subsequent civic actions. </span></li>
<li id="PER"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PER"><span class="letterCode" style="float:right">PER</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PER">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466191">Sublimate: State-Changing Virtual and Physical Rendering to Augment Interaction with Shape Displays</a></span><br />
<span class="authors">D. Leithinger (Massachusetts Institute of Technology, USA), S. Follmer, A. Olwal, S. Luescher, A. Hogge, J. Lee, H. Ishii</span>
<div class="authorList"><span><span class="author">D. Leithinger</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">S. Follmer</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">A. Olwal</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">S. Luescher</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">A. Hogge</span></span><span><span class="author">J. Lee</span> (Media Lab, USA)</span><span><span class="author">H. Ishii</span> (Massachusetts Institute of Technology, USA)</span></div>
<p><span class="cbStatement">Sublimate co-locates spatial 3D visuals with actuated shape displays. We introduce interfaces and applications that combine virtual graphics and physical form, and explores the transitions between those states.</span><span class="abstract">Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and vaporization, as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video see-through AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how free- hand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.</span></li>
<li id="PSB"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PSB"><span class="letterCode" style="float:right">PSB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PSB">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466236">Kolibri – Tiny and Fast Gestures for Large Pen-based Surfaces</a></span><br />
<span class="authors">J. Leitner (Univ. of Applied Sciences Upper Austria, AT), F. Perteneder, C. Liu, C. Rendl, M. Haller</span>
<div class="authorList"><span><span class="author">J. Leitner</span> (Univ. of Applied Sciences Upper Austria, AT)</span><span><span class="author">F. Perteneder</span> (Univ. of Applied Sciences Upper Austria, AT)</span><span><span class="author">C. Liu</span> (Univ. of Applied Sciences Upper Austria, AT)</span><span><span class="author">C. Rendl</span> (Univ. of Applied Sciences Upper Austria, AT)</span><span><span class="author">M. Haller</span> (Univ. of Applied Sciences Upper Austria, AT)</span></div>
<p><span class="cbStatement">We introduce Kolibri &#8211; a pen-based gesture system that brings shortcuts to interactive white-boards. Users can draw tiny gestures anywhere on the surface without interfering with normal inking.</span><span class="abstract">Triggering commands on large interactive surfaces is less efficient than on desktop PCs. It requires either large physical movements to reach an interaction area (e.g., buttons) or additional operations to call context menus (e.g., dwell). There is a lack of efficient ways to trigger shortcuts. We introduce Kolibri &#8211; a pen-based gesture system that allows fast access of commands on interactive whiteboards. Users can draw tiny gestures (approx. 3 mm) anywhere on the surface to trigger commands without interfering with normal inking. This approach does neither require entering a gesture mode, nor dedicated gesture areas. The implementation relies on off-the-shelf hardware only. We tested the feasibility and explored the properties of this technique with several studies. The results from a controlled experiment show significant benefits of Kolibri comparing to an existing approach.</span></li>
<li id="PNE"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PNE"><span class="letterCode" style="float:right">PNE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNE">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466122">Revisiting Social Practices Surrounding Music</a></span><br />
<span class="authors">T. Leong (Univ. of Technology, Sydney, AU), P. Wright</span>
<div class="authorList"><span><span class="author">T. Leong</span> (Univ. of Technology, Sydney, AU)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">This paper extends and contributes to our understanding of social practices and sociality surrounding music in light of recent key technological developments.</span><span class="abstract">Music shapes our social lives. While previous research has provided a foundational understanding of the social affordances surrounding people’s interactions with music, there is a need to update this understanding in light of recent key developments in our digital technological landscape. This paper describes a qualitative study of people’s social activities and practices around music in households. It extends previous research by revealing the impact key technologies have on how, where, when, and with who people’s interactions surrounding music occur. It also reveals people’s creative attempts to design their musical experiences with others through reconfiguring and connecting to various digital technologies and digital platforms in order to pursue more opportunities for communicating, sharing, bonding, and celebrating lives with others.</span></li>
<li id="PCL"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PCL"><span class="letterCode" style="float:right">PCL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCL">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481300">Flights in my Hands: Coherence Concerns in Designing Strip’TIC, a Tangible Space for Air Traffic Controllers</a></span><br />
<span class="authors">C. Letondal (ENAC, FR), C. Hurter, R. Lesbordes, J. Vinot, S. Conversy</span>
<div class="authorList"><span><span class="author">C. Letondal</span> (ENAC, FR)</span><span><span class="author">C. Hurter</span> (ENAC, FR)</span><span><span class="author">R. Lesbordes</span> (DGAC DSNA, FR)</span><span><span class="author">J. Vinot</span> (ENAC, FR)</span><span><span class="author">S. Conversy</span> (ENAC, FR)</span></div>
<p><span class="cbStatement">We reflect upon the design of a paper-based tangible space to support air traffic control. We propose a new account of coherence for mixed interaction that integrates cognitive externalization mechanisms.</span><span class="abstract">We reflect upon the design of a paper-based tangible interactive space to support air traffic control. We have observed, studied, prototyped and discussed with controllers a new mixed interaction system based on Anoto, video projection, and tracking. Starting from the understanding of the benefits of tangible paper strips, our goal is to study how mixed physical and virtual augmented data can support the controllers’ mental work. The context of the activity led us to depart from models that are proposed in tangible interfaces research where coherence is based on how physical objects are representative of virtual objects. We propose a new account of coherence in a mixed interaction system that integrates externalization mechanisms. We found that physical objects play two roles: they act both as representation of mental objects and as tangible artifacts for interacting with augmented features. We observed that virtual objects represent physical ones, and not the reverse, and, being virtual representations of physical objects, should seamlessly converge with the cognitive role of the physical object. Finally, we show how coherence is achieved by providing a seamless interactive space.</span></li>
<li id="NKR"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NKR"><span class="letterCode" style="float:right">NKR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NKR">Wed. 9am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481287">UMUX-LITE – When There’s No Time for the SUS</a></span><br />
<span class="authors">J. Lewis (IBM Software Group, USA), B. Utesch, D. Maher</span>
<div class="authorList"><span><span class="author">J. Lewis</span> (IBM Software Group, USA)</span><span><span class="author">B. Utesch</span> (IBM Software Group, USA)</span><span><span class="author">D. Maher</span> (IBM Software Group, USA)</span></div>
<p><span class="cbStatement">The UMUX-LITE is a concise (two-item) usability satisfaction questionnaire.  Psychometric evaluation indicates its potential usefulness when it is critical to quickly obtain a SUS-like measurement.</span><span class="abstract">In this paper we present the UMUX-LITE, a two-item questionnaire based on the Usability Metric for User Experience (UMUX) [6].  The UMUX-LITE items are “This system’s capabilities meet my requirements” and “This system is easy to use.”  Data from two independent surveys demonstrated adequate psychometric quality of the questionnaire.  Estimates of reliability were .82 and .83 – excellent for a two-item instrument.  Concurrent validity was also high, with significant correlation with the SUS (.81, .81) and with likelihood-to-recommend (LTR) scores (.74, .73).  The scores were sensitive to respondents’ frequency-of-use.  UMUX-LITE score means were slightly lower than those for the SUS, but easily adjusted using linear regression to match the SUS scores.  Due to its parsimony (two items), reliability, validity, structural basis (usefulness and usability) and, after applying the corrective regression formula, its correspondence to SUS scores, the UMUX-LITE appears to be a promising alternative to the SUS when it is not desirable to use a 10-item instrument.</span></li>
<li id="PFH"class="presentation design engineering"><a href="http://chi2013.acm.org/previews/paper.html#PFH"><span class="letterCode" style="float:right">PFH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PFH">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466185">GaussBits: Magnetic Tangible Bits for Portable and Occlusion-Free Near-Surface Interactions</a></span><br />
<span class="authors">R. Liang (National Taiwan Univ., TW), K. Cheng, L. Chan, C. Peng, M. Chen, R. Liang, D. Yang, B. Chen</span>
<div class="authorList"><span><span class="author">R. Liang</span> (National Taiwan Univ., TW)</span><span><span class="author">K. Cheng</span> (National Taiwan Univ., TW)</span><span><span class="author">L. Chan</span> (Academia Sinica, TW)</span><span><span class="author">C. Peng</span> (National Taiwan Univ. of Science and Technology, TW)</span><span><span class="author">M. Chen</span> (National Taiwan Univ., TW)</span><span><span class="author">R. Liang</span> (National Taiwan Univ. of Science and Technology, TW)</span><span><span class="author">D. Yang</span> (Academia Sinica, TW)</span><span><span class="author">B. Chen</span> (National Taiwan Univ., TW)</span></div>
<p><span class="cbStatement">This work presents a system of the passive magnetic tangible designs that enables occlusion-free tangible interactions in the near-surface space of portable displays.</span><span class="abstract">We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user&#8217;s hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.</span></li>
<li id="PCB"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PCB"><span class="letterCode" style="float:right">PCB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCB">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481326">Beyond the Filter Bubble: Interactive Effects of Perceived Threat and Topic Involvement on Selective Exposure to Information</a></span><br />
<span class="authors">Q. Liao (Univ. of Illinois at Urbana-Champaign, USA), W. Fu</span>
<div class="authorList"><span><span class="author">Q. Liao</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">W. Fu</span> (Univ. of Illinois at Urbana-Champaign, USA)</span></div>
<p><span class="cbStatement">Investigated whether information bubble can emerge from people&#8217;s preferential selection between attitude reinforcing versus attitude challenging information in an online environment, and the roles situational factors and personal factors play.</span><span class="abstract">We investigated participants’ preferential selection of information and their attitude moderation in an online environment. Results showed that even when opposing views were presented side-to-side, people would still preferentially select information that reinforced their existing attitudes. Preferential selection of information was, however, influenced by both situational (e.g., perceived threat) and personal (e.g., topic involvement) factors. Specifically, perceived threat induced selective exposure to attitude consistent information for topics that participants had low involvement. Participants had a higher tendency to select peer user opinions in topics that they had low than high involvement, but only when there was no perception of threat. Overall, participants’ attitudes were moderated after being exposed to diverse views, although high topic involvement led to higher resistance to such moderation. Perceived threat also weakened attitude moderation, especially for low involvement topics. Results have important implication to the potential effects of “information bubble” – selective exposure can be induced by situational and personal factors even when competing views are presented side-by-side.</span></li>
<li id="PDC"class="presentation design engineering arts"><a href="http://chi2013.acm.org/previews/paper.html#PDC"><span class="letterCode" style="float:right">PDC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PDC">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466424">Modeling How People Extract Color Themes from Images</a></span><br />
<span class="authors">S. Lin (Stanford Univ., USA), P. Hanrahan</span>
<div class="authorList"><span><span class="author">S. Lin</span> (Stanford Univ., USA)</span><span><span class="author">P. Hanrahan</span> (Stanford Univ., USA)</span></div>
<p><span class="cbStatement">We present a method for extracting color themes from images, using a regression model trained on themes people extract. Model-extracted themes match the source image more closely than previous approaches.</span><span class="abstract">Color choice plays an important role in works of graphic art and design. However, it can be difficult to choose a compelling set of colors, or emph{color theme}, from scratch. In this work, we present a method for extracting color themes from images using a regression model trained on themes created by people. We collect 1600 themes from Mechanical Turk as well as from artists. We find that themes extracted by Turk participants were similar to ones extracted by artists. In addition, people tended to select diverse colors and focus on colors in salient image regions. We show that our model can match human-extracted themes more closely compared to previous work. Themes extracted by our model were also rated higher as representing the image than previous approaches in a Mechanical Turk study.</span></li>
<li id="PRC"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PRC"><span class="letterCode" style="float:right">PRC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PRC">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470663">Health Vlogger-Viewer Interaction in Chronic Illness Management</a></span><br />
<span class="authors">L. Liu (Univ. of Washington, USA), J. Huh, T. Neogi, K. Inkpen, W. Pratt</span>
<div class="authorList"><span><span class="author">L. Liu</span> (Univ. of Washington, USA)</span><span><span class="author">J. Huh</span> (Univ. of Washington, USA)</span><span><span class="author">T. Neogi</span> (Univ. of Washington, USA)</span><span><span class="author">K. Inkpen</span> (Microsoft Research, USA)</span><span><span class="author">W. Pratt</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">Health vlogs allow individuals with chronic illnesses to share experiences. We examined methods that vloggers use to connect with viewers. We present design implications that facilitate sustainable communities for vloggers.</span><span class="abstract">Health video blogs (vlogs) allow individuals with chronic illnesses to share their stories, experiences, and knowledge with the general public. Furthermore, health vlogs help in creating a connection between the vlogger and the viewers. In this work, we present a qualitative study examining the various methods that health vloggers use to establish a connection with their viewers. We found that vloggers used genres to express specific messages to their viewers while using the uniqueness of video to establish a deeper connection with their viewers. Health vloggers also explicitly sought interaction with their viewers. Based on these results, we present design implications to help facilitate and build sustainable communities for vloggers. </span></li>
<li id="NTY"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NTY"><span class="letterCode" style="float:right">NTY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NTY">Mon. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470750">SidePoint: A Peripheral Knowledge Panel for Presentation Slide Authoring</a></span><br />
<span class="authors">Y. Liu (Waseda Univ., JP), D. Edge, K. Yatani</span>
<div class="authorList"><span><span class="author">Y. Liu</span> (Waseda Univ., JP)</span><span><span class="author">D. Edge</span> (Microsoft Research Asia, CN)</span><span><span class="author">K. Yatani</span> (Microsoft Research Asia, CN)</span></div>
<p><span class="cbStatement">Implements an implicit search and peripheral panel system for presentation authoring by showing concise knowledge items relevant to the slide content, and investigates the benefits and issues of such peripheral knowledge panels.</span><span class="abstract">Presentation authoring is an important activity, but often requires the secondary task of collecting the information and media necessary for both slides and speech. Integration of implicit search and peripheral displays into presentation authoring tools may reduce the effort to satisfy not just active needs the author is aware of, but also latent needs that she is not aware of until she encounters content of perceived value. We develop SidePoint, a peripheral panel that supports presentation authoring by showing concise knowledge items relevant to the slide content. We study SidePoint as a technology probe to examine the benefits and issues associated with peripheral knowledge panels for presentation authoring. Our results show that peripheral knowledge panels have the potential to satisfy both types of needs in ways that transform presentation authoring for the better. </span></li>
<li id="PLL"class="presentation design games cci"><a href="http://chi2013.acm.org/previews/paper.html#PLL"><span class="letterCode" style="float:right">PLL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PLL">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470668">Optimizing Challenge in an Educational Game Using Large-Scale Design Experiments</a></span><br />
<span class="authors">D. Lomas (Carnegie Mellon Univ., USA), K. Patel, J. Forlizzi, K. Koedinger</span>
<div class="authorList"><span><span class="author">D. Lomas</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">K. Patel</span> (DA-IICT, IN)</span><span><span class="author">J. Forlizzi</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">K. Koedinger</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">Online experiments (>80,000 game players in >14,400 conditions) optimized challenge to maximize engagement and learning in an educational game. Alas, what was optimal for engagement was not optimal for learning.</span><span class="abstract">Online games can serve as research instruments to explore the effects of game design elements on motivation and learning. In our research, we manipulated the design of an online math game to investigate the effect of challenge on player motivation and learning. To test the “Inverted-U Hypothesis”, which predicts that maximum game engagement will occur with moderate challenge, we produced two large-scale (10K and 70K subjects), multi-factor (2&#215;3 and 2x9x8x4x25) online experiments. We found that, in almost all cases, subjects were more engaged and played longer when the game was easier, which seems to contradict the generality of the Inverted-U Hypothesis. Troublingly, we also found that the most engaging design conditions produced the slowest rates of learning. Based on our findings, we describe several design implications that may increase challenge-seeking in games, such as providing feedforward about the anticipated degree of challenge. </span></li>
<li id="PMR"class="presentation games sustainability cci HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PMR"><span class="letterCode" style="float:right">PMR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PMR">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481379">The Power of Play: Design Lessons for Increasing the Lifespan of Outdated Computers</a></span><br />
<span class="authors">D. Lomas (Carnegie Mellon Univ., USA), K. Patel, D. Ching, M. Lakshmanan, M. Kam, A. Kumar, J. Forlizzi</span>
<div class="authorList"><span><span class="author">D. Lomas</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">K. Patel</span> (DA-IICT, IN)</span><span><span class="author">D. Ching</span> (NYU, USA)</span><span><span class="author">M. Lakshmanan</span> (Not presently affiliated, IN)</span><span><span class="author">M. Kam</span> (American Institutes for Research, USA)</span><span><span class="author">A. Kumar</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Forlizzi</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">Why is Visicalc obsolete, but not Super Mario Bros? The continued success of 8-bit computers in developing countries shows how hedonic utility (aka fun) can dramatically extend computer lifespans.</span><span class="abstract">One consequence of rapid advances in computer technology is the obsolescence of hundreds of millions of computers each year. This paper explores strategies for increasing the reuse of outdated computers through an investigation of an 8-bit home computer that is still popular in developing countries. We observed the use of the computers in 16 households in Ahmedabad and Bangalore, India in order to gain insight into the contextual factors that support the continued popularity of the device. While most computers become obsolete in less than a decade, this 30-year-old computer technology remains useful because it provides exciting, multi-user family entertainment. While having minimal processing power and virtually no connectivity, the 8-bit computer supports input and output channels that are especially suited for co-located social game play. In contrast, PCs are primarily designed for individual use. Therefore, we offer low-cost design recommendations that would enable outdated PCs to support greater shared use and increased utility within the constrained material context of low-income households. These simple interventions, if adopted by computer refurbishment industries, have the potential to significantly extend the useful lifespan of PCs.</span></li>
<li id="NAF"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#NAF"><span class="letterCode" style="float:right">NAF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NAF">Wed. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481355">Muscle-Propelled Force Feedback: Bringing Force Feedback to Mobile Devices</a></span><br />
<span class="authors">P. Lopes (Hasso Plattner Institute, DE), P. Baudisch</span>
<div class="authorList"><span><span class="author">P. Lopes</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Baudisch</span> (Hasso Plattner Institute, DE)</span></div>
<p><span class="cbStatement">We propose mobile force feedback devices by eliminating motors and instead actuating the user’s muscles using electrical stimulation. Without the motors, we obtain substantially smaller and more energy-efficient devices. </span><span class="abstract">Force feedback devices resist miniaturization, because they require physical motors and mechanics. We propose mobile force feedback by eliminating motors and instead actuating the user’s muscles using electrical stimulation. Without the motors, we obtain substantially smaller and more energy-efficient devices. We present a prototype that fits on the back of a mobile phone. It actuates users’ forearm muscles via four electrodes, which causes users’ muscles to contract involuntarily, so that they tilt the device sideways. As users resist this motion using their other arm, they perceive force feedback. We demonstrate the interaction at the example of an interactive videogame in which users steer an airplane through winds rendered using force feedback. In a first user study, we found our device to cause users to produce up to 18.7N of force, when used to actuate their palm flexors. In a second study, participants played the video game de-scribed above; all ten participants reported to prefer the experience of muscle-propelled force feedback to vibrotactile feedback.</span></li>
<li id="PRN"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PRN"><span class="letterCode" style="float:right">PRN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PRN">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481371">Consent for All: Revealing the Hidden Complexity of Terms and Conditions</a></span><br />
<span class="authors">E. Luger (The Univ. of Nottingham, UK), S. Moran, T. Rodden</span>
<div class="authorList"><span><span class="author">E. Luger</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Moran</span> (The Univ. of Nottingham, UK)</span><span><span class="author">T. Rodden</span></span></div>
<p><span class="cbStatement">Stimulus paper and plug-in surfacing the readability of web-based terms and conditions. Highlights the role of documents in the online consent process and calls for better readability and design practice.</span><span class="abstract">Terms and conditions are central in acquiring user consent by service providers. Such documents are frequently highly complex and unreadable, placing doubts on the validity of so called ‘informed consent’. While readability and web accessibility have been major themes for some time in HCI, the core principles have yet to be applied beyond webpage content and are absent from the underpinning terms and conditions. Our concern is that accessible web pages will encourage consent, masking the complexities of the terms of usage.     Using the SMOG readability formula and UK Energy services as a case study, we observed that a series of supplier terms and conditions were far beyond what a functionally literate adult could be expected to understand. We also present a browser based plug-in which compares SMOG readability scores to popular books. The intention is to use this plug-in to assist in surfacing the hidden complexities underpinning online consent.   </span></li>
<li id="PHB"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PHB"><span class="letterCode" style="float:right">PHB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PHB">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466217">Toying with Time: Considering Temporal Themes in Interactive Artifacts</a></span><br />
<span class="authors">S. Lundgren (Chalmers Univ. of Technology, SE)</span>
<div class="authorList"><span><span class="author">S. Lundgren</span> (Chalmers Univ. of Technology, SE)</span></div>
<p><span class="cbStatement">This paper proposes:  1) A framework describing use of time in interactive artifacts, and 2) An ideation method for deliberately and systematically exploring potential temporal behaviors of an interactive artifact. </span><span class="abstract">This paper argues that there is a value in deliberately and systematically exploring potential temporal behaviors of an interactive artifact, either as a means to add new functions, or to change the interaction with it. An improved version of Temporal Themes – a vocabulary describing how software can “use” time or sequences of events – will be presented, alongside a series of design cases. These exemplify how adding or changing temporal themes in existing applications can enhance functionality and/or interaction. Moreover, the cases also serve as a basis for a discussion of the issues coupled to temporality, control and interaction strategies. Finally, a design approach with focus on temporal aspects is outlined. As a result, the paper opens up for a more conscious use of time and temporality in interaction design.    </span></li>
<li id="PMS"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PMS"><span class="letterCode" style="float:right">PMS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PMS">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470690">Gesture Studio: Authoring Multi-Touch Interactions through Demonstration and Declaration</a></span><br />
<span class="authors">H. Lü (Univ. of Washington, USA), Y. Li</span>
<div class="authorList"><span><span class="author">H. Lü</span> (Univ. of Washington, USA)</span><span><span class="author">Y. Li</span> (Google Research, USA)</span></div>
<p><span class="cbStatement">We present Gesture Studio, a tool for creating multi-touch interactions. It combines the strengths of both programming by demonstration and declaration in an intuitive UI based on video-editing metaphor.</span><span class="abstract">The prevalence of multi-touch devices opens the space for rich interactions. However, the complexity for creating multi-touch interactions hinders this potential. In this paper, we present Gesture Studio, a tool for creating multi-touch interaction behaviors by combining the strength of two distinct but complementary approaches: programming by demonstration and declaration. We employ an intuitive video-authoring metaphor for developers to demonstrate touch gestures, compose complicated behaviors, test these behaviors in the tool and export them as source code that can be integrated into the developers’ project.</span></li>
<li id="PQN"class="presentation health games cci"><a href="http://chi2013.acm.org/previews/paper.html#PQN"><span class="letterCode" style="float:right">PQN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQN">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466163">Understanding Exergame Users’ Physical Activity, Motivation and Behavior Over Time</a></span><br />
<span class="authors">A. Macvean (Heriot-Watt Univ., UK), J. Robertson</span>
<div class="authorList"><span><span class="author">A. Macvean</span> (Heriot-Watt Univ., UK)</span><span><span class="author">J. Robertson</span> (Heriot-Watt Univ., UK)</span></div>
<p><span class="cbStatement">A school based exergame intervention analysed through the lens of self-efficacy in order to understand in-game behavior, and provide guidance for affective exergame interventions</span><span class="abstract">Effective exergames should increase the proportion of time users regularly spend in moderate to vigorous physical activity. There are currently few studies of exergame systems which evaluate the impact on physical activity over time. Those which do, show increases in light intensity exercise which although valuable, do not increase the proportion of moderate to vigorous activity required for optimal health benefits. Furthermore, longitudinal studies to date have encountered a plateau effect in physical activity as the novelty of the game wears off. This paper suggests how exergame designs based on deeper understandings of player motivations could address these problems.    We report on longitudinal patterns of users’ physical activity, motivations and behaviour when using exergames, based on case studies from a seven week long school based field trial. These new insights, interpreted through Bandura’s theory of self efficacy, are of value to designers in the HCI community who wish to motivate users with a range of attitudes towards exercise to undertake regular moderate to vigorous physical activity.  </span></li>
<li id="PKC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PKC"><span class="letterCode" style="float:right">PKC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PKC">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470735">Promoting Hotkey Use through Rehearsal with ExposeHK</a></span><br />
<span class="authors">S. Malacria (Univ. of Canterbury, NZ), G. Bailly, J. Harrison, A. Cockburn, C. Gutwin</span>
<div class="authorList"><span><span class="author">S. Malacria</span> (Univ. of Canterbury, NZ)</span><span><span class="author">G. Bailly</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span><span><span class="author">J. Harrison</span> (Univ. of Canterbury, NZ)</span><span><span class="author">A. Cockburn</span> (Univ. of Canterbury, NZ)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span></div>
<p><span class="cbStatement">Introduces ExposeHK, a new interface that promotes hotkey selection. Presents results of three studies showing that ExposeHK increases hotkey use, improves performance and was strongly prefered.</span><span class="abstract">Keyboard shortcuts allow fast interaction, but they are known to be infrequently used, with most users relying heavily on traditional pointer-based selection for most commands. We describe the goals, design, and evaluation of ExposeHK, a new interface mechanism that aims to increase hotkey use. ExposeHK’s four key design goals are: 1) enable users to browse hotkeys; 2) allow non-expert users to issue hotkey commands as a physical rehearsal of expert performance; 3) exploit spatial memory to assist non-expert users in identifying hotkeys; and 4) maximise expert performance by using consistent shortcuts in a flat command hierarchy. ExposeHK supports these objectives by displaying hotkeys overlaid on their associated commands when a modifier key is pressed. We evaluated ExposeHK in three empirical studies using toolbars, menus, and a tabbed ‘ribbon’ toolbar. Results show that participants used more hotkeys, and used them more often, with ExposeHK than with other techniques; they were faster with ExposeHK than with either pointing or other hotkey methods; and they strongly preferred ExposeHK. Our research shows that ExposeHK can substantially improve the user’s transition from a ‘beginner mode’ of interaction to a higher level of expertise.</span></li>
<li id="PQJ"class="presentation design sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PQJ"><span class="letterCode" style="float:right">PQJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQJ">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466216">Looking Past Yesterday’s Tomorrow: Using Futures Studies Methods to Extend the Research Horizon</a></span><br />
<span class="authors">J. Mankoff (Carnegie Mellon Univ., USA), H. Faste, J. Rode</span>
<div class="authorList"><span><span class="author">J. Mankoff</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">H. Faste</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Rode</span> (Drexel Univ., USA)</span></div>
<p><span class="cbStatement">A review of futures studies methods used to forecast and think  critically about alternative futures and their relevance for HCI  research.</span><span class="abstract">Doing research is, in part, an act of foresight. Even though it is not  explicit in many projects, we especially value research that is still  relevant five, ten or more years after it is completed. However,  published research in the field of interactive computing (and  technology research in general) often lacks evidence of systematic  thinking about the long-term impacts of current trends.  For example,  trends on an exponential curve change much more rapidly than intuition  predicts. As a result, research may accidentally emphasize near-term  thinking. When thinking about the future is approached systematically,  we can critically examine multiple potential futures, expand the set  of externalities under consideration, and address both negative and  positive forecasts of the future. The field of Futures Studies  provides methods that can support analysis of long-term trends,  support the identification of new research areas and guide design and  evaluation. We survey methods for futuristic thinking and discuss  their relationship to Human Computer Interaction. Using the  sustainability domain an example, we present a case study of a Futures  Studies approach&#8211;the Delphi Method. We show how Futures Studies can  be incorporated into Human Computer Interaction and highlight future  work such as rethinking the role of externalities in the validation  process.</span></li>
<li id="PKV"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PKV"><span class="letterCode" style="float:right">PKV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PKV">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466436">Why Do They Still Use Paper? Understanding Data Collection and Use in Autism Education</a></span><br />
<span class="authors">G. Marcu (Carnegie Mellon Univ., USA), K. Tassini, Q. Carlson, J. Goodwyn, G. Rivkin, K. Schaefer, A. Dey, S. Kiesler</span>
<div class="authorList"><span><span class="author">G. Marcu</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">K. Tassini</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">Q. Carlson</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Goodwyn</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">G. Rivkin</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">K. Schaefer</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Dey</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">S. Kiesler</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We conducted fieldwork to understand data collection and use in the domain of autism education to explain why current technology had not met staff needs.</span><span class="abstract">Autism education programs for children collect and use large amounts of behavioral data on each student. Staff use paper almost exclusively to collect these data, despite significant problems they face in tracking student data in situ, filling out data sheets and graphs on a daily basis, and using the sheets in collaborative decision making. We conducted fieldwork to understand data collection and use in the domain of autism education to explain why current technology had not met staff needs. We found that data needs are complex and unstandardized, immediate demands of the job interfere with staff ability to collect in situ data, and existing technology for data collection is inadequate. We also identified opportunities for technology to improve sharing and use of data. We found that data sheets are idiosyncratic and not useful without human mediation; improved communication with parents could benefit children’s development; and staff are willing, and even eager, to incorporate technology. These factors explain the continued dependence on paper for data collection in this environment, and reveal opportunities for technology to support data collection and improve use of collected data. </span></li>
<li id="PAV"class="presentation sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PAV"><span class="letterCode" style="float:right">PAV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PAV">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470708">Using Crowdsourcing to Support Pro-Environmental Community Activism</a></span><br />
<span class="authors">E. Massung (Univ. of Bristol, UK), D. Coyle, K. Cater, M. Jay, C. Preist</span>
<div class="authorList"><span><span class="author">E. Massung</span> (Univ. of Bristol, UK)</span><span><span class="author">D. Coyle</span> (Univ. of Bristol, UK)</span><span><span class="author">K. Cater</span> (Univ. of Bristol, UK)</span><span><span class="author">M. Jay</span> (Univ. of Bristol, UK)</span><span><span class="author">C. Preist</span> (Univ. of Bristol, UK)</span></div>
<p><span class="cbStatement">We developed mobile applications and investigated motivational techniques to support crowdsourcing and pro-environmental community activism. The paper offers new insights and recommendations for environmental technologies targeting communities, rather than individuals.</span><span class="abstract">Community activist groups typically rely on core groups of highly motivated members. In this paper we consider how crowdsourcing strategies can be used to supplement the activities of pro-environmental community activists, thus increasing the scalability of their campaigns. We focus on mobile data collection applications and strategies that can be used to engage casual participants in pro-environmental data collection. We report the results of a study that used both quantitative and qualitative methods to investigate the impact of different motivational factors and strategies, including both intrinsic and extrinsic motivators. The study compared and provides empirical evidence for the effectiveness of two extrinsic motivation strategies, pointification – a subset of gamification – and financial incentives. Prior environmental interest is also assessed as an intrinsic motivation factor. In contrast to previous HCI research on pro-environmental technology, much of which has focused on individual behavior change, this paper offers new insights and recommendations on the design of systems that target groups and communities.</span></li>
<li id="PLV"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PLV"><span class="letterCode" style="float:right">PLV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLV">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466149">Swifter: Improved Online Video Scrubbing</a></span><br />
<span class="authors">J. Matejka (Autodesk Research, CA), T. Grossman, G. Fitzmaurice</span>
<div class="authorList"><span><span class="author">J. Matejka</span> (Autodesk Research, CA)</span><span><span class="author">T. Grossman</span> (Autodesk Research, CA)</span><span><span class="author">G. Fitzmaurice</span> (Autodesk Research, CA)</span></div>
<p><span class="cbStatement">Swifter is a new technique for navigating streaming videos which presents a grid of thumbnail images during scrubbing operations, and allows the user to directly select the desired playback location.</span><span class="abstract">Online streaming video systems have become extremely popular, yet navigating to target scenes of interest can be a challenge. While recent techniques have been introduced to enable real-time seeking, they break down for large videos, where scrubbing the timeline causes video frames to skip and flash too quickly to be comprehendible. We present Swifter, a new video scrubbing technique that displays a grid of pre-cached thumbnails during scrubbing actions. In a series of studies, we first investigate possible design variations of the Swifter technique, and the impact of those variations on its performance. Guided by these results we compare an implementation of Swifter to the previously published Swift technique, in addition to the approaches utilized by YouTube and Netfilx. Our results show that Swifter significantly outperforms each of these techniques in a scene locating task, by a factor of up to 48%.</span></li>
<li id="PDB"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PDB"><span class="letterCode" style="float:right">PDB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PDB">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466442">Patina: Dynamic Heatmaps for Visualizing Application Usage</a></span><br />
<span class="authors">J. Matejka (Autodesk Research, CA), T. Grossman, G. Fitzmaurice</span>
<div class="authorList"><span><span class="author">J. Matejka</span> (Autodesk Research, CA)</span><span><span class="author">T. Grossman</span> (Autodesk Research, CA)</span><span><span class="author">G. Fitzmaurice</span> (Autodesk Research, CA)</span></div>
<p><span class="cbStatement">Patina is an application independent system which uses accessibility APIs to collect and visualize software application usage data. The primary visualization is a dynamic heatmap overlaid on the application.</span><span class="abstract">We present Patina, an application independent system for collecting and visualizing software application usage data.  Patina requires no instrumentation of the target application, all data is collected through standard window metrics and accessibility APIs. The primary visualization is a dynamic heatmap overlay which adapts to match the content, location, and shape of the user interface controls visible in the active application. We discuss a set of design guidelines for the Patina system, describe our implementation of the system, and report on an initial evaluation based on a short-term deployment of the system. </span></li>
<li id="PHV"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHV"><span class="letterCode" style="float:right">PHV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PHV">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470728">Community Insights: Helping Community Leaders Enhance the Value of Enterprise Online Communities</a></span><br />
<span class="authors">T. Matthews (IBM Research, USA), S. Whittaker, H. Badenes, B. Smith, M. Muller, K. Ehrlich, M. Zhou, T. Lau</span>
<div class="authorList"><span><span class="author">T. Matthews</span> (IBM Research, USA)</span><span><span class="author">S. Whittaker</span> (Univ. of California at Santa Cruz, USA)</span><span><span class="author">H. Badenes</span> (IBM, AR)</span><span><span class="author">B. Smith</span> (IBM Research, USA)</span><span><span class="author">M. Muller</span> (IBM, USA)</span><span><span class="author">K. Ehrlich</span> (IBM, USA)</span><span><span class="author">M. Zhou</span> (IBM Research, USA)</span><span><span class="author">T. Lau</span> (Willow Garage, USA)</span></div>
<p><span class="cbStatement">Evidence-based design and evaluation of a novel tool that provides community leaders with useful, actionable, and contextualized analytics. Benefits designers of and practitioners using analytic tools to foster successful communities.</span><span class="abstract">Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member- rather than leader-centric. We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.</span></li>
<li id="NHL"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NHL"><span class="letterCode" style="float:right">NHL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NHL">Wed. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481407">The Effect of Global Instructions on Think-aloud Testing</a></span><br />
<span class="authors">S. McDonald (Univ. of Sunderland, UK), H. Petrie</span>
<div class="authorList"><span><span class="author">S. McDonald</span> (Univ. of Sunderland, UK)</span><span><span class="author">H. Petrie</span> (Univ. of York, UK)</span></div>
<p><span class="cbStatement">This study investigates whether deviating from the classic concurrent think-aloud instructions during usability testing induces reactivity: a change in participants’ cognitive processing, which affects task performance measures.</span><span class="abstract">Verbal protocols are the primary tool for understanding users’ task-solving behaviors during usability testing. We investigated whether the classic think-aloud and a think-aloud with an explicit instruction leads to different task-solving performance compared to silent working.   The results suggest that the classic method had no impact on task performance whereas the explicit instruction led to an increase in within-page and between-page navigation and scrolling activity.  The classic method was linked to an increase in mental workload in terms of effort and frustration. The explicit think-aloud led to an increase in mental demand, performance, effort and frustration.</span></li>
<li id="PJL"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PJL"><span class="letterCode" style="float:right">PJL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJL">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466245">Categorised Ethical Guidelines for Large Scale Mobile HCI</a></span><br />
<span class="authors">D. McMillan (Mobile Life @ Stockholm Univ., SE), A. Morrison, M. Chalmers</span>
<div class="authorList"><span><span class="author">D. McMillan</span> (Mobile Life @ Stockholm Univ., SE)</span><span><span class="author">A. Morrison</span> (Univ. of Glasgow, UK)</span><span><span class="author">M. Chalmers</span> (Univ. of Glasgow, UK)</span></div>
<p><span class="cbStatement">A discussion of ethical challenges in large scale mobile HCI trials. We identify anonymisation and user expectation as key factors and present proportional guidelines that reflect risks in these areas.</span><span class="abstract">The recent rise in large scale trials of mobile software using `app stores&#8217; has moved current researcher practice beyond available ethical guidelines. By surveying this recent and growing body of literature, as well as established professional principles adopted in psychology, we propose a set of ethical guidelines for large scale HCI user trials. These guidelines come in two parts: a set of general principles and a framework into which individual app store-based trials can be assessed and ethical concerns exposed. We categorise existing literature using our scheme, and explain how researchers could use our framework to classify their future user trials to determine ethical responsibility, and the steps required to meet these obligations. </span></li>
<li id="PMY"class="presentation design engineering ux arts"><a href="http://chi2013.acm.org/previews/paper.html#PMY"><span class="letterCode" style="float:right">PMY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PMY">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481302">The Space Between the Notes: Adding Expressive Pitch Control to the Piano Keyboard</a></span><br />
<span class="authors">A. McPherson (Queen Mary, Univ. of London, UK), A. Gierakowski, A. Stark</span>
<div class="authorList"><span><span class="author">A. McPherson</span> (Queen Mary, Univ. of London, UK)</span><span><span class="author">A. Gierakowski</span> (Queen Mary, Univ. of London, UK)</span><span><span class="author">A. Stark</span> (Queen Mary, Univ. of London, UK)</span></div>
<p><span class="cbStatement">This paper presents an extended keyboard interface that engages with pianists&#8217; existing training and expertise. Touch sensors add expressive vibrato and pitch bend capabilities without interfering with traditional technique.</span><span class="abstract">This paper addresses the question of how to extend the capabilities of a well-established interface in a way that respects users&#8217; existing expertise. The piano-style keyboard is among the most widely used and versatile of digital musical interfaces. However, it lacks the ability to alter the pitch of a note after it has been played, a limitation which prevents the performer from executing common expressive techniques including vibrato and pitch bending. We present a system for controlling pitch from the keyboard surface using capacitive touch sensors to measure the locations of the player&#8217;s fingers on the keys. The large community of trained pianists makes the keyboard a compelling target for augmentation, but it also poses a challenge: how can a musical interface be extended while making use of the existing techniques performers have spent thousands of hours learning? In this paper, user studies with conservatory pianists explore the constraints of traditional keyboard technique and evaluate the usability of the continuous pitch control system. The paper also discusses implications for the extension of other established interfaces in musical and non-musical contexts.</span></li>
<li id="PEB"class="presentation design ux HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PEB"><span class="letterCode" style="float:right">PEB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEB">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481390">Some Evidence for the Impact of Limited Education on Hierarchical User Interface Navigation</a></span><br />
<span class="authors">I. Medhi (Indian Institute of Technology, IN), M. Lakshmanan, K. Toyama, E. Cutrell</span>
<div class="authorList"><span><span class="author">I. Medhi</span> (Indian Institute of Technology, IN)</span><span><span class="author">M. Lakshmanan</span> (temp, IN)</span><span><span class="author">K. Toyama</span> (Univ. of California, Berkeley, USA)</span><span><span class="author">E. Cutrell</span> (Microsoft Research India, IN)</span></div>
<p><span class="cbStatement">Experimental study shows limited education impacting the ability to navigate a hierarchical UI, even when text-free. Can benefit designers interested in recommendations for UI hierarchies for people with limited education.</span><span class="abstract">One of the greatest challenges in designing applications for economically poor communities is that potential users may have little or no education. We investigated how limited education appears to impact the ability to navigate a hierarchical UI, even when it has no text. We scored 60 participants from low-income communities in India using tests of textual literacy and Raven’s Progressive Matrices. These were used as proxies for educational level and a subset of cognitive abilities. We then evaluated participants’ performance on a UI task involving hierarchical navigation. First, our results confirm that textual literacy is correlated with scores on the Raven’s test. In addition, we found that performance on both instruments are predictive of performance in navigating UI hierarchies, even when the UI is text-free. This provides statistically significant confirmation of previous anecdotal hypotheses. We conclude with design recommendations for UI hierarchies for people with limited education.</span></li>
<li id="PCM"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PCM"><span class="letterCode" style="float:right">PCM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PCM">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466119">From Codes to Patterns:  Designing Interactive Decoration for Tableware</a></span><br />
<span class="authors">R. Meese (The Univ. of Nottingham, UK), S. Ali, E. Thorne, S. Benford, A. Quinn, R. Mortier, B. Koleva, T. Pridmore, S. Baurley</span>
<div class="authorList"><span><span class="author">R. Meese</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Ali</span> (The Univ. of Nottingham, UK)</span><span><span class="author">E. Thorne</span> (Central Saint Martins College of Art and Design, UK)</span><span><span class="author">S. Benford</span> (The Univ. of Nottingham, UK)</span><span><span class="author">A. Quinn</span> (Central Saint Martins College of Art and Design, UK)</span><span><span class="author">R. Mortier</span> (The Univ. of Nottingham, UK)</span><span><span class="author">B. Koleva</span> (The Univ. of Nottingham, UK)</span><span><span class="author">T. Pridmore</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Baurley</span> (Brunel Univ., UK)</span></div>
<p><span class="cbStatement">A collaboration between ceramic designers, technologists and a restaurant reveals strategies for creating aesthetic decorative pattern for plates and other tableware that contain multiple embedded visual codes hidden within them.</span><span class="abstract">We explore the idea of making aesthetic decorative patterns that contain multiple visual codes. We chart an iterative collaboration with ceramic designers and a restaurant to refine a recognition technology to work reliably on ceramics, produce a pattern book of designs, and prototype sets of tableware and a mobile app to enhance a dining experience. We document how the designers learned to work with and creatively exploit the technology, enriching their patterns with embellishments and backgrounds and developing strategies for embedding codes into complex designs. We discuss the potential and challenges of interacting with such patterns. We argue for a transition from designing ‘codes to patterns’ that reflects the skills of designers alongside the development of new technologies.</span></li>
<li id="PTT"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PTT"><span class="letterCode" style="float:right">PTT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PTT">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466462">Seeing Movement Qualities</a></span><br />
<span class="authors">H. Mentis (Microsoft Research, UK), C. Johansson</span>
<div class="authorList"><span><span class="author">H. Mentis</span> (Microsoft Research, UK)</span><span><span class="author">C. Johansson</span> (Mobile Life @ Stockholm Univ., SE)</span></div>
<p><span class="cbStatement">Presents fieldwork on mechanisms of user perceptions of movement qualities. Lends to implications for further efforts in designing interactive movement-based systems that strive to capitalize on movement qualities.</span><span class="abstract">With the increased availability of movement based interactive devices there is a growing interest in exploring the potential design space for engaging movement-based interactions. This has led to the exploration of different ways to sense and model movement such as Laban Movement Analysis’ Effort qualities. However, little is understood in how movement qualities are perceived and experienced by users.  We explored this in an interactive improvisational dance performance setting.  From video analysis with a Laban Movement expert and post-performance interviews with audience members, we discuss the differences in how a movement quality was perceived.  From these findings, we discuss implications for further efforts in designing interactive movement-based systems that strive to capitalize on movement qualities.</span></li>
<li id="PTS"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PTS"><span class="letterCode" style="float:right">PTS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTS">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466197">Imaging the Body: Embodied Vision in Minimally Invasive Surgery</a></span><br />
<span class="authors">H. Mentis (Microsoft Research, UK), A. Taylor</span>
<div class="authorList"><span><span class="author">H. Mentis</span> (Microsoft Research, UK)</span><span><span class="author">A. Taylor</span> (Microsoft Research, UK)</span></div>
<p><span class="cbStatement">Presents findings concerning the constructed and embodied use of images during neurosurgery. Lends itself to a discussion of the directions for new imaging interaction technologies. </span><span class="abstract">Recent years have seen the possibilities of new imaging and interaction technologies for minimally invasive surgery such as touchless interaction and high definition renderings of three-dimensional anatomy. With this paper we take a step back to review the historical introduction and assimilation of imaging technologies in the surgical theatre in parallel with the productive and cross-referential nature of surgical practice and image use. We present findings from a field study of image use during neurosurgery where we see that the work to see medical images is highly constructed and embodied with the action of manipulating the body. This perspective lends itself to a discussion of the directions for new imaging interaction technologies.</span></li>
<li id="PMC"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/paper.html#PMC"><span class="letterCode" style="float:right">PMC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PMC">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466200">How Does It Play Better? Exploring User Testing and Biometric Storyboards in Games User Research</a></span><br />
<span class="authors">P. Mirza-Babaei (Univ. of Sussex, Brighton, East Sussex, UK), L. Nacke, J. Gregory, N. Collins, G. Fitzpatrick</span>
<div class="authorList"><span><span class="author">P. Mirza-Babaei</span> (Univ. of Sussex, Brighton, East Sussex, UK)</span><span><span class="author">L. Nacke</span> (Univ. of Ontario Institute of Technology, CA)</span><span><span class="author">J. Gregory</span> (Univ. of Ontario Institute of Technology, CA)</span><span><span class="author">N. Collins</span> (Univ. of Sussex, UK)</span><span><span class="author">G. Fitzpatrick</span> (Vienna Univ. of Technology, AT)</span></div>
<p><span class="cbStatement">Our paper is the first study of its kind presented at CHI to report on the value of game user testing and physiological evaluation in providing formative feedback for game development.  </span><span class="abstract">Improving game design is a hard task. Few methods are available in games user research (GUR) to test formally how game designs work for players. In particular, the usefulness of user tests (UTs) for game designers has not been fully studied in the CHI community. We propose a novel GUR method called Biometric Storyboards (BioSt) and present a study demonstrating how a Classic UT and a BioSt UT both help designers create a better gameplay experience. In addition, we show that BioSt can help designers deliver significantly better visuals, more fun, and higher gameplay quality than designing without UTs and that classic UTs do not provide this significant advantage. Our interviews support the idea that BioSt provides more nuanced game design improvement. The design implication is that a game designed with the BioSt method will result in high gameplay quality.</span></li>
<li id="PRT"class="presentation design ux health HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PRT"><span class="letterCode" style="float:right">PRT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PRT">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466248">The Emotional Wellbeing of Researchers: Considerations for Practice</a></span><br />
<span class="authors">W. Moncur (Univ. of Dundee, UK)</span>
<div class="authorList"><span><span class="author">W. Moncur</span> (Univ. of Dundee, UK)</span></div>
<p><span class="cbStatement">We consider the impact which research in sensitive contexts can have on researchers’ emotional wellbeing and on research validity, and ways to incorporate consideration for researchers’ wellbeing into research plans.</span><span class="abstract">As technology progressively pervades all aspects of our lives, members of the HCI community are engaging with increasingly sensitive contexts in their research – for example, end of life, genocide, computer-mediated communication under oppressive regimes. The considerations generated by research in such contexts can go well beyond those addressed by generic ethical approval processes and institutional practice. Whilst it is standard to ensure that the wellbeing of participants is taken into account in research design and the ethical approval process, it is much less common for the researcher’s own emotional wellbeing to be considered explicitly. This paper describes the role that a researcher’s emotions may play in research, and the impact which research in sensitive contexts can have on researchers’ emotional wellbeing and on research validity. A qualitative survey is described which investigated the support mechanisms which HCI researchers have in place in case they are distressed/ troubled as a result of their research. The results of the survey are used, in combination with insights into how other disciplines address the topic, to synthesize suggestions for ways in which the HCI community can proactively incorporate consideration for the emotional wellbeing of the researcher into the research process.</span></li>
<li id="PBX"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PBX"><span class="letterCode" style="float:right">PBX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PBX">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481325">The Challenges of Specifying Intervals and Absences in Temporal Queries: A Graphical Language Approach</a></span><br />
<span class="authors">M. Monroe (Univ. of Maryland, USA), R. Lan, J. Morales del Olmo, B. Shneiderman, C. Plaisant, J. Millstein</span>
<div class="authorList"><span><span class="author">M. Monroe</span> (Univ. of Maryland, USA)</span><span><span class="author">R. Lan</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Morales del Olmo</span> (Universidad Politécnica de Madrid, ES)</span><span><span class="author">B. Shneiderman</span> (Univ. of Maryland, USA)</span><span><span class="author">C. Plaisant</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Millstein</span> (Oracle Corporation, USA)</span></div>
<p><span class="cbStatement">Our contributions incude an assessment of the primary user difficulties in specifying queries involving intervals and absences, and two novel temporal query interfaces, designed to offer intuitive access to a wide range of temporal relationships.</span><span class="abstract">In our burgeoning world of ubiquitous sensors and affordable data storage, records of timestamped events are being produced across nearly every domain of personal and professional computing.  The resulting data surge has created an overarching need to search these records for meaningful patterns of events.  This paper reports on a two-part user study, as well as a series of early tests and interviews with clinical researchers, that informed the development of two temporal query interfaces: a basic, menu-based interface and an advanced, graphic-based interface. While the scope of temporal query is very broad, this work focuses on two particularly complex and critical facets of temporal event sequences: intervals (events with both a start time and an end time), and the absence of an event. We describe how users encounter a common set of difficulties when specifying such queries, and propose solutions to help overcome them.  Finally, we report on two case studies with epidemiologists at the US Army Pharmacovigilance Center, illustrating how both query interfaces were used to study patterns of drug use. </span></li>
<li id="PNP"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PNP"><span class="letterCode" style="float:right">PNP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNP">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466147">NoteVideo: Facilitating Navigation of Blackboard-style Lecture Videos</a></span><br />
<span class="authors">T. Monserrat (National Univ. of Singapore, SG), S. Zhao, K. McGee, A. Pandey</span>
<div class="authorList"><span><span class="author">T. Monserrat</span> (National Univ. of Singapore, SG)</span><span><span class="author">S. Zhao</span> (National Univ. of Singapore, SG)</span><span><span class="author">K. McGee</span> (National Univ. of Singapore, SG)</span><span><span class="author">A. Pandey</span> (National Univ. of Singapore, SG)</span></div>
<p><span class="cbStatement">We create a summarized image of the video and using it as an in-scene navigation interface that allows users to directly jump to the video frame of choice.</span><span class="abstract">Khan Academy&#8217;s pre-recorded blackboard-style lecture videos attract millions of online users every month. However, current video navigation tools do not adequately support the kinds of goals that students typically have, like quickly finding a particular concept in a blackboard-style lecture video. This paper reports on the development and evaluation of the new NoteVideo and its improved version, NoteVideo+, systems for identifying the conceptual ‘objects’ of a blackboard-based video – and then creating a summarized image of the video and using it as an in-scene navigation interface that allows users to directly jump to the video frame where that object first appeared instead of navigating it linearly through time. The research consisted of iteratively implementing the system and then having users perform four different navigation tasks using three different interfaces: Scrubbing, Transcript, and NoteVideo. Results of the study show that participants perform significantly better on all four tasks while using the NoteVideo and its improved version &#8211; NoteVideo+ &#8211; as compared to others.</span></li>
<li id="PFL"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PFL"><span class="letterCode" style="float:right">PFL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PFL">Wed. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481358">LaserOrigami: Laser-Cutting 3D Objects</a></span><br />
<span class="authors">S. Mueller (Hasso Plattner Institute, DE), B. Kruck, P. Baudisch</span>
<div class="authorList"><span><span class="author">S. Mueller</span> (Hasso Plattner Institute, DE)</span><span><span class="author">B. Kruck</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Baudisch</span> (Hasso Plattner Institute, DE)</span></div>
<p><span class="cbStatement">LaserOrigami is a rapid prototyping system that produces 3D objects using a laser cutter. LaserOrigami is substantially faster than 3D-printing and unlike traditional laser cutting it requires no manual assembly.</span><span class="abstract">We present LaserOrigami, a rapid prototyping system that produces 3D objects using a laser cutter. Laser¬Origami is substantially faster than traditional 3D fabrication techniques such as 3D printing and unlike traditional laser cutting the resulting 3D objects require no manual assembly. The key idea behind LaserOrigami is that it achieves three-dimensionality by folding and stretching the workpiece, rather than by placing joints, thereby eliminating the need for manual assembly. Laser¬Origami achieves this by heating up selected regions of the workpiece until they become compliant and bend down under the force of gravity. LaserOrigami administers the heat by defocusing the laser, which distributes the laser’s power across a larger surface. LaserOrigami implements cutting and bending in a single integrated process by automatically moving the cutting table up and down—when users take out the workpiece, it is already fully assembled. We present the three main design elements of Laser¬Origami: the bend, the suspender, and the stretch, and demonstrate how to use them to fabricate a range of physical objects. Finally, we demonstrate an interactive fabrication version of Laser¬Origami, a process in which user interaction and fabrication alternate step-by-step.</span></li>
<li id="PRE"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PRE"><span class="letterCode" style="float:right">PRE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PRE">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470727">Crowdfunding inside the Enterprise: Employee-Initiatives for Innovation and Collaboration</a></span><br />
<span class="authors">M. Muller (IBM, USA), W. Geyer, T. Soule, S. Daniels, L. Cheng</span>
<div class="authorList"><span><span class="author">M. Muller</span> (IBM, USA)</span><span><span class="author">W. Geyer</span> (IBM Research, USA)</span><span><span class="author">T. Soule</span> (IBM Research, USA)</span><span><span class="author">S. Daniels</span> (IBM T.J. Watson Research, USA)</span><span><span class="author">L. Cheng</span> (IBM Research, USA)</span></div>
<p><span class="cbStatement">Crowdfunding behind a company firewall showed diverse projects, inter-organizational collaborations, and collaborative motivations. Potential interest for HCI researchers, organizational practitioners, and consultants.</span><span class="abstract">We describe a first experiment in enterprise crowdfunding – i.e., employees allocating money for employee-initiated proposals at an Intranet site, including a trial of this system with 511 employees in IBM Research.  Major outcomes include: employee proposals that addressed diverse indivi-dual and organizational needs; high participation rates; ex-tensive inter-departmental collaboration, including the dis-covery of large numbers of previously unknown collabora-tors; and the development of goals and motivations based on collective concerns at multiple levels of project groups, communities of practice, and the organization as a whole.  We recommend further, comparative research into crowd-funding and other forms of employee-initiated innovations.</span></li>
<li id="PKZ"class="presentation design management"><a href="http://chi2013.acm.org/previews/paper.html#PKZ"><span class="letterCode" style="float:right">PKZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PKZ">Mon. 4pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470745">Labor Dynamics in a Mobile Micro-Task Market</a></span><br />
<span class="authors">M. Musthag (Univ. of Massachusetts, USA), D. Ganesan</span>
<div class="authorList"><span><span class="author">M. Musthag</span> (Univ. of Massachusetts, USA)</span><span><span class="author">D. Ganesan</span> (Univ. of Massachusetts, USA)</span></div>
<p><span class="cbStatement">This paper provides an in-depth exploration of labor dynamics in mobile task markets which require spatial mobility based on a year-long dataset from a leading mobile crowdsourcing platform.  </span><span class="abstract">The ubiquity of smartphones has led to the emergence of mobile crowdsourcing markets, where smartphone users participate to perform tasks in the physical world. Mobile crowdsourcing markets are uniquely different from their online counterparts in that they require spatial mobility, and are therefore impacted by geographic factors and constraints that are not present in the online case. Despite the emergence and importance of such mobile marketplaces, little to none is known about the labor dynamics and mobility patterns of agents.    This paper provides an in-depth exploration of labor dynamics in mobile task markets based on a year-long dataset from a leading mobile crowdsourcing platform.  We find that a small core group of workers (< 10%) account for a disproportionately large proportion of activity (> 80%) generated in the market. We find that these super agents are more efficient than other agents across several dimensions: a) they are willing to move longer distances to perform tasks, yet they amortize travel across more tasks, b) they work and search for tasks more efficiently, c) they have higher data quality in terms of accepted submissions, and d) they improve in almost all of these efficiency measures over time. We find that super agent efficiency stems from two simple optimizations &#8212; they are 3x more likely than other agents to chain tasks and they pick fewer lower priced tasks than other agents. We compare mobile and online micro-task markets, and discuss differences in demographics, data quality, and time of use, as well as similarities in super agent behavior. We conclude with a discussion of how a mobile micro-task market might leverage some of our results to improve performance.</span></li>
<li id="PJH"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/paper.html#PJH"><span class="letterCode" style="float:right">PJH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PJH">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466461">The Design Space of Body Games: Technological, Physical, and Social Design.</a></span><br />
<span class="authors">E. Márquez Segura (Mobile Life @ SICS Swedish ICT AB, SE), A. Waern, C. Johansson, J. Moen</span>
<div class="authorList"><span><span class="author">E. Márquez Segura</span> (Mobile Life @ SICS Swedish ICT AB, SE)</span><span><span class="author">A. Waern</span> (Mobile Life @ Stockholm Univ., SE)</span><span><span class="author">C. Johansson</span> (Mobile Life @ Stockholm Univ., SE)</span><span><span class="author">J. Moen</span> (Movinto Fun AB, SE)</span></div>
<p><span class="cbStatement">Movement-based games are in the limelight today. We argue that for these games, the physical and social settings become just as important design resources as the technology.</span><span class="abstract">The past decade has seen an increased focus on body movement in computer games. We take a step further to look at body games: games in which the main source of enjoyment comes from bodily engagement. We argue that for these games, the physical and social settings become just as important design resources as the technology. Although all body games benefit from an integrated design approach, the social and physical setting become particularly useful as design resources when the technology has limited sensing capabilities. We develop our understanding of body games through a literature study and a concrete design experiment with designing multiplayer games for the BodyBug, a mobile device with limited sensing capabilities. Although the device was designed for free and natural movements, previous games fell short in realizing this design ideal. By designing the technology function together with its physical and social context, we were able to overcome device limitations. One of the games was subsequently incorporated in its commercial release.</span></li>
<li id="PGY"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGY"><span class="letterCode" style="float:right">PGY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PGY">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481406">Investigating Self-Reporting Behavior In Long-Term Studies</a></span><br />
<span class="authors">A. Möller (Technische Univ. München, DE), M. Kranz, B. Schmid, L. Roalter, S. Diewald</span>
<div class="authorList"><span><span class="author">A. Möller</span> (Technische Univ. München, DE)</span><span><span class="author">M. Kranz</span> (Univ. Passau, DE)</span><span><span class="author">B. Schmid</span> (Technische Univ. München, DE)</span><span><span class="author">L. Roalter</span> (Technische Univ. München, DE)</span><span><span class="author">S. Diewald</span> (Technische Univ. München, DE)</span></div>
<p><span class="cbStatement">We provide empirical quantitative long-term data on the reliability of self-reported data collected with mobile devices. We give recommendations for maximizing the reliability of results when conducting long-term app usage studies.</span><span class="abstract">Self-reporting techniques, such as data logging or a diary, are frequently used in long-term studies, but prone to subjects&#8217; forgetfulness and other sources of inaccuracy.  We conducted a six-week self-reporting study on smartphone usage in order to investigate the accuracy of self-reported information, and used logged data as ground truth to compare the subjects&#8217; reports against.  Subjects never recorded more than 70% and, depending on the requested reporting interval, down to less than 40% of actual app usages. They significantly overestimated how long they used apps.  While subjects forgot self-reports when no automatic reminders were sent, a high reporting frequency was perceived as uncomfortable and burdensome. Most significantly, self-reporting even changed the actual app usage of users and hence can lead to deceptive measures if a study relies on no other data sources.    With this contribution, we provide empirical quantitative long-term data on the reliability of self-reported data collected with mobile devices. We aim to make researchers aware of the caveats of self-reporting and give recommendations for maximizing the reliability of results when conducting large-scale, long-term app usage studies. </span></li>
<li id="NRP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NRP"><span class="letterCode" style="float:right">NRP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NRP">Mon. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470760">Improving Touch Accuracy on Large Tabletops Using Predecessor and Successor</a></span><br />
<span class="authors">M. Möllers (RWTH Aachen Univ., DE), N. Dumont, S. Ladwig, J. Borchers</span>
<div class="authorList"><span><span class="author">M. Möllers</span> (RWTH Aachen Univ., DE)</span><span><span class="author">N. Dumont</span> (RWTH Aachen Univ., DE)</span><span><span class="author">S. Ladwig</span> (RWTH Aachen Univ., DE)</span><span><span class="author">J. Borchers</span> (RWTH Aachen Univ., DE)</span></div>
<p><span class="cbStatement">We explore how  one touch affects the location and orientation of its successor. We show how this can be used to increase touch accuracy on tabletops.</span><span class="abstract">Touch interfaces provide great flexibility in designing an UI. However, the actual experience is often frustrating due to bad touch recognition. On small systems, we can analyze yaw, roll, and pitch of the finger to increase touch accuracy for a single touch. On larger systems, we need to take additional factors into account as users have more flexibility for their limb posture and need to aim over larger distances. Thus, we investigated how people perform touch sequences on those large touch surfaces. We show that the relative location of the predecessor of a touch has a significant impact on the orientation and position of the touch ellipsis.    We exploited this effect on an off-the-shelf touch display and showed that with only minimal preparation the touch accuracy of standard hardware can be improved by at least 7%, allowing better recognition rates or more UI components on the same screen.</span></li>
<li id="PHK"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHK"><span class="letterCode" style="float:right">PHK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PHK">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466142">Memorability of Pre-designed and User-defined Gesture Sets</a></span><br />
<span class="authors">M. Nacenta (Univ. of St Andrews, UK), Y. Kamber, Y. Qiang, P. Kristensson</span>
<div class="authorList"><span><span class="author">M. Nacenta</span> (Univ. of St Andrews, UK)</span><span><span class="author">Y. Kamber</span> (Univ. of St Andrews, UK)</span><span><span class="author">Y. Qiang</span> (Univ. of St Andrews, UK)</span><span><span class="author">P. Kristensson</span> (Univ. of St Andrews, UK)</span></div>
<p><span class="cbStatement">We analyze memorability aspects of gesture sets, comparing gesture sets created by users, gesture sets created by designers, and stock gesture sets. We present evidence from three studies.</span><span class="abstract">We studied the memorability of free-form gesture sets for invoking actions. We compared three types of gesture sets: user-defined gesture sets, gesture sets designed by the authors, and random gesture sets in three studies with 33 participants in total. We found that user-defined gestures are easier to remember, both immediately after creation and on the next day (up to a 24% difference in recall rate compared to pre-designed gestures). We also discovered that the differences between gesture sets are mostly due to association errors (rather than gesture form errors), that participants prefer user-defined sets, and that they think user-defined gestures take less time to learn. Finally, we contribute a qualitative analysis of the tradeoffs involved in gesture type selection and share our data and a video corpus of 66 gestures for replicability and further analysis.</span></li>
<li id="PBZ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PBZ"><span class="letterCode" style="float:right">PBZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PBZ">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470773">High-Precision Pointing on Large Wall Displays using Small Handheld Devices</a></span><br />
<span class="authors">M. Nancel (Univ Paris-Sud, FR), O. Chapuis, E. Pietriga, X. Yang, P. Irani, M. Beaudouin-Lafon</span>
<div class="authorList"><span><span class="author">M. Nancel</span> (Univ Paris-Sud, FR)</span><span><span class="author">O. Chapuis</span> (Univ Paris-Sud, FR)</span><span><span class="author">E. Pietriga</span> (INRIA, Orsay, France &#038; INRIA Chile, FR)</span><span><span class="author">X. Yang</span> (Univ. of Alberta, CA)</span><span><span class="author">P. Irani</span> (Univ. of Manitoba, CA)</span><span><span class="author">M. Beaudouin-Lafon</span> (Univ Paris-Sud, FR)</span></div>
<p><span class="cbStatement">Reports on the design and evaluation of pointing techniques, some of which use head orientation, so the handheld device can also be used for other interactions.</span><span class="abstract">Rich interaction with high-resolution wall displays is not limited to remotely pointing at targets. Other relevant types of interaction include virtual navigation, text entry, and direct manipulation of control widgets. However, most techniques for remotely acquiring targets with high precision have studied remote pointing in isolation, focusing on pointing efficiency and ignoring the need to support these other types of interaction.  We investigate high-precision pointing techniques capable of acquiring targets as small as 4 millimeters on a 5.5 meters wide display while leaving up to 93 % of a typical tablet device&#8217;s screen space available for task-specific widgets. We compare these techniques to state-of-the-art distant pointing techniques and show that two of our techniques, a purely relative one and one that uses head orientation, perform as well or better than the best pointing-only input techniques while using a fraction of the interaction resources.</span></li>
<li id="PRL"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#PRL"><span class="letterCode" style="float:right">PRL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PRL">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481319">W3Touch: Metrics-based Web Page Adaptation for Touch</a></span><br />
<span class="authors">M. Nebeling (ETH Zurich, CH), M. Speicher, M. Norrie</span>
<div class="authorList"><span><span class="author">M. Nebeling</span> (ETH Zurich, CH)</span><span><span class="author">M. Speicher</span> (ETH Zurich, CH)</span><span><span class="author">M. Norrie</span> (ETH Zurich, CH)</span></div>
<p><span class="cbStatement">W3Touch contributes a new method of adapting user interfaces for touch interaction, supporting automation based on usability metrics and the evidence of interaction problems on different forms of touch devices.</span><span class="abstract">Web designers currently face the increased proliferation and diversity of new touch devices which pose major challenges to the design task. This paper presents W3Touch&#8211;an interface instrumentation toolkit for web designers to collect user performance data for different device characteristics in order to help them identify potential design problems for touch interaction. Web designers can visualise the data aggregated by W3Touch and use simple metrics to automate the adaptation process for many different viewing and interaction contexts. In a series of experiments with web designers and users, we show that W3Touch is able to detect interaction problems that are hard to find using conventional methods and demonstrate how the tool was successfully used to automate the desktop-to-mobile migration of Wikipedia as an example.</span></li>
<li id="PQQ"class="presentation design sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PQQ"><span class="letterCode" style="float:right">PQQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQQ">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466153">Everyday Activities and Energy Consumption: How Families Understand the Relationship</a></span><br />
<span class="authors">C. Neustaedter (Simon Fraser Univ., CA), L. Bartram, A. Mah</span>
<div class="authorList"><span><span class="author">C. Neustaedter</span> (Simon Fraser Univ., CA)</span><span><span class="author">L. Bartram</span> (Simon Fraser Univ., CA)</span><span><span class="author">A. Mah</span> (Simon Fraser Univ., CA)</span></div>
<p><span class="cbStatement">Describes a study of how families tie their everyday routines to their understanding of energy consumption.  Outlines how designs can leverage calendars and increase shared knowledge of consumption between family members.</span><span class="abstract">Energy consumption is a growing concern and it is important to inform families of their consumption and how they might reduce it. We conducted an interview study that focuses on the existing routines of families and how they currently understand their power and gas consumption based on standard utility bills.  We also investigated how this understanding ties to their everyday activities as might be recorded on their calendars.  This allowed us to assess calendars as an artifact for energy consumption awareness. Our results show that many people relate changes in energy consumption to high-level effects such as weather and temperature and not necessarily their own everyday activities.  Events on calendars may aid this understanding but people do not currently record enough information on their calendars to make a strong tie.  This suggests that if calendars are to be used as artifacts to aid energy consumption understanding, digital calendars need to provide support to include more energy-related information, including both activities and patterns of consumption.</span></li>
<li id="NNM"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#NNM"><span class="letterCode" style="float:right">NNM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NNM">Tue. 9am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466150">Direct Manipulation Video Navigation in 3D</a></span><br />
<span class="authors">C. Nguyen (Portland State Univ., USA), Y. Niu, F. Liu</span>
<div class="authorList"><span><span class="author">C. Nguyen</span> (Portland State Univ., USA)</span><span><span class="author">Y. Niu</span> (Portland State Univ., USA)</span><span><span class="author">F. Liu</span> (Portland State Univ., USA)</span></div>
<p><span class="cbStatement">This paper presents a 3D DMVN system that visualizes the video frame and motion in 3D, resolves temporal ambiguities, and allows a user to manipulate an object along its trajectory.  </span><span class="abstract">Direct Manipulation Video Navigation (DMVN) systems allow a user to navigate a video by dragging an object along its motion trajectory. These systems have been shown effective for space-centric video browsing. Their performance, however, is often limited by temporal ambiguities in a video with complex motion, such as recurring motion, self-intersecting motion, and pauses. The ambiguities come from reducing the 3D spatial-temporal motion (x, y, t) to the 2D spatial motion (x, y) in visualizing the motion and dragging the object. In this paper, we present a 3D DMVN system that maps the spatial-temporal motion (x, y, t) to 3D space (x, y, z) by mapping time t to depth z, visualizes the motion and video frame in 3D, and allows to navigate the video by spatial-temporally manipulating the object in 3D. We show that since our 3D DMVN system preserves all the motion information, it resolves the temporal ambiguities and supports intuitive navigation on challenging videos with complex motion.</span></li>
<li id="PTP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PTP"><span class="letterCode" style="float:right">PTP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PTP">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470701">Age-Related Performance Issues for PIN and Face-Based Authentication Systems</a></span><br />
<span class="authors">J. Nicholson (Northumbria Univ., UK), L. Coventry, P. Briggs</span>
<div class="authorList"><span><span class="author">J. Nicholson</span> (Northumbria Univ., UK)</span><span><span class="author">L. Coventry</span> (Northumbria Univ., UK)</span><span><span class="author">P. Briggs</span> (Northumbria Univ., UK)</span></div>
<p><span class="cbStatement">A PIN system and a face-based graphical system were evaluated with younger and older adults. Old benefitted from own-age faces most while young performed well with faces overall.</span><span class="abstract">Graphical authentication systems typically claim to be more usable than PIN or password-based systems, but these claims often follow limited, single-stage paradigm testing on a young, student population.  We present a more demanding test paradigm in which multiple codes are learned and tested over a three-week period.  We use this paradigm with two user populations, comparing the performance of younger and older adults.  We first establish baseline performance in a study in which populations of younger and older adults learn PIN codes and we follow this with a second study in which younger and older adults use two face-based graphical authentication systems employing young faces vs. old faces as code components.    As expected, older adults show relatively poor performance when compared to younger adults, irrespective of the authentication material, but this age-related deficit can be markedly reduced by the introduction of age-appropriate faces. We conclude firstly that this paradigm provides a good basis for the future evaluation of memory-based authentication systems and secondly that age-appropriate face-based authentication is viable in the security marketplace.</span></li>
<li id="PBC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PBC"><span class="letterCode" style="float:right">PBC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBC">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466174">Putting Things in Focus: Establishing Co-Orientation Through Video in Context</a></span><br />
<span class="authors">J. Norris (The Univ. of Nottingham, UK), H. Schnädelbach, P. Luff</span>
<div class="authorList"><span><span class="author">J. Norris</span> (The Univ. of Nottingham, UK)</span><span><span class="author">H. Schnädelbach</span> (The Univ. of Nottingham, UK)</span><span><span class="author">P. Luff</span> (King&#8217;s College, London, UK)</span></div>
<p><span class="cbStatement">The CamBlend video collaboration system is used to assess how participants co-orientate around objects, both local or remote, virtual or physical, as well as around people, showing new interactional fractures.</span><span class="abstract">In collaborative video communication systems, establishing co-orientation around physical objects, virtual objects and people is a critical requirement. This is problematic as the technical limitations of video fractures the display of conduct in the connected environments. We present the results of a study of one collaborative system, CamBlend, which aims to alleviate some of these problems by using screen based pointing tools to both physical spaces and virtual resources. We report on how participants achieved co-orientation when using this system. We relate these findings to previous research into the fractured ecologies of collaborative spaces, describing how the form and nature of fractures in CamBlend differ from earlier reported work.</span></li>
<li id="PKS"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PKS"><span class="letterCode" style="float:right">PKS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PKS">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470707">Exploring Personality-Targeted UI Design in Online Social Participation Systems</a></span><br />
<span class="authors">O. Nov (Polytechnic Institute of New York Univ., USA), O. Arazy, C. López, P. Brusilovsky</span>
<div class="authorList"><span><span class="author">O. Nov</span> (Polytechnic Institute of New York Univ., USA)</span><span><span class="author">O. Arazy</span> (Univ. of Alberta, CA)</span><span><span class="author">C. López</span> (Univ. of Pittsburgh, USA)</span><span><span class="author">P. Brusilovsky</span> (Univ. of Pittsburgh, USA)</span></div>
<p><span class="cbStatement">We show how personality-targeted UI design can be more effective than design applied to entire populations – much like a medical treatment applied to a person based on his genetic profile.</span><span class="abstract">We present a theoretical foundation and empirical findings demonstrating the effectiveness of personality-targeted design. Much like a medical treatment applied to a person based on his specific genetic profile, we argue that theory-driven, personality-targeted UI design can be more effective than design applied to the entire population. The empirical exploration focused on two settings, two populations and two personality traits: Study 1 shows that users’ extraversion level moderates the relationship between the UI cue of audience size and users’ contribution. Study 2 demonstrates that the effectiveness of social anchors in encouraging online contributions depends on users’ level of emotional stability. Taken together, the findings demonstrate the potential and robustness of the interactionist approach to UI design. The findings contribute to the HCI community, and in particular to designers of social systems, by providing guidelines to targeted design that can increase online participation. </span></li>
<li id="NPJ"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#NPJ"><span class="letterCode" style="float:right">NPJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NPJ">Mon. 4pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470761">Touchbugs: Actuated Tangibles on Multi-Touch Tables</a></span><br />
<span class="authors">D. Nowacka (Newcastle Univ., UK), K. Ladha, N. Hammerla, D. Jackson, C. Ladha, E. Rukzio, P. Olivier</span>
<div class="authorList"><span><span class="author">D. Nowacka</span> (Newcastle Univ., UK)</span><span><span class="author">K. Ladha</span> (Newcastle Univ., UK)</span><span><span class="author">N. Hammerla</span> (Newcastle Univ., UK)</span><span><span class="author">D. Jackson</span> (Newcastle Univ., UK)</span><span><span class="author">C. Ladha</span> (Newcastle Univ., UK)</span><span><span class="author">E. Rukzio</span> (Ulm Univ., DE)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">We present a novel approach to graspable interfaces using Touchbugs, small tangibles that are able to move across surfaces by employing vibrating motors and to communicate with interactive surfaces by using infrared LEDs.</span><span class="abstract">We present a novel approach to graspable interfaces using Touchbugs, actuated physical objects for interacting with interactive surface computing applications. Touchbugs are active tangibles that are able to move across surfaces by employing vibrating motors and can communicate with camera based multi-touch surfaces using infrared LEDs. Touchbug’s embedded inertial sensors and computational capabilities open a new interaction space by providing autonomous capabilities for tangibles that allow goal directed behavior.</span></li>
<li id="PBU"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PBU"><span class="letterCode" style="float:right">PBU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBU">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466256">Q-Methodology as a Research and Design Tool for HCI</a></span><br />
<span class="authors">K. O&#8217;Leary (Univ. of Washington, USA), J. Wobbrock, E. Riskin</span>
<div class="authorList"><span><span class="author">K. O&#8217;Leary</span> (Univ. of Washington, USA)</span><span><span class="author">J. Wobbrock</span> (Univ. of Washington, USA)</span><span><span class="author">E. Riskin</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">HCI-Q provides statistically valid and qualitatively rich perspectives of the personal significance of designs. HCI-Q provides design constraints by leveraging statistical methods to reveal consensus and conflict among those perspectives. </span><span class="abstract">A “discount” version of Q-methodology for HCI, called “HCI-Q,” can be used in iterative design cycles to explore, from the point of view of users and other stakeholders, what makes technologies personally significant. Initially, designers critically reflect on their own assumptions about how a design may affect social and individual behavior. Then, designers use these assumptions as stimuli to elicit other people’s points of view. This process of critical self-reflection and evaluation helps the designer to assess the fit between a design and its intended social context of use. To demonstrate the utility of HCI-Q for research and design, we use HCI-Q to explore stakeholders’ responses to a prototype Alternative and Augmentative Communication (AAC) application called Vid2Speech. We show that our adaptation of Q-methodology is useful for revealing the structure of consensus and conflict among stakeholder perspectives, helping to situate design within the context of relevant value tensions and norms.</span></li>
<li id="PFC"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PFC"><span class="letterCode" style="float:right">PFC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PFC">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470683">Form Digitization in BPO: From Outsourcing to Crowdsourcing?</a></span><br />
<span class="authors">J. O&#8217;Neill (Xerox Research Centre Europe, FR), S. Roy, A. Grasso, D. Martin</span>
<div class="authorList"><span><span class="author">J. O&#8217;Neill</span> (Xerox Research Centre Europe, FR)</span><span><span class="author">S. Roy</span> (Xerox Research Centre India, IN)</span><span><span class="author">A. Grasso</span> (Xerox Innovation Group, FR)</span><span><span class="author">D. Martin</span> (Xerox Research Center Europe, FR)</span></div>
<p><span class="cbStatement">This work describes findings from an ethnographic study of an outsourced business process for “form digitization”. It is a first step to how crowdsourcing might be applied to business processes.</span><span class="abstract">This paper describes an ethnographic study of an outsourced business process – the digitization of healthcare forms. The aim of the study was to understand how the work is currently organized, with an eye to uncovering the research challenges which need to be addressed if that work is to be crowdsourced. The findings are organised under four emergent themes: Workplace Ecology, Data Entry Skills and Knowledge, Achieving Targets and Collaborative Working. For each theme a description of how the work is undertaken in the outsourcer’s Indian office locations is given, followed by the implications for crowdsourcing that work. This research is a first step in understanding how crowdsourcing might be applied to BPO activities. The paper examines features specific to form digitization – extreme distribution and form decomposition – and lightly touches on the crowdsourcing of BPO work more generally.</span></li>
<li id="PFF"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PFF"><span class="letterCode" style="float:right">PFF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PFF">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466220">Talking about Tactile Experiences</a></span><br />
<span class="authors">M. Obrist (Newcastle Univ., UK), S. Seah, S. Subramanian</span>
<div class="authorList"><span><span class="author">M. Obrist</span> (Newcastle Univ., UK)</span><span><span class="author">S. Seah</span> (Univ. of Bristol, UK)</span><span><span class="author">S. Subramanian</span> (Univ. of Bristol, UK)</span></div>
<p><span class="cbStatement">A common problem with designing applications with tactile interfaces is the lack of a vocabulary that allows one to communicate about haptics. We present a human-experiential vocabulary for tactile experiences.</span><span class="abstract">A common problem with designing and developing applications with tactile interfaces is the lack of a vocabulary that allows one to describe or communicate about haptics. Here we present the findings from a study exploring participants’ verbalizations of their tactile experiences across two modulated tactile stimuli (16Hz and 250Hz) related to two important mechanoreceptors in the human hand. The study, with 14 participants, applied the explicitation interview technique to capture detailed descriptions of the diachronic and synchronic structure of tactile experiences. We propose 14 categories for a human-experiential vocabulary based on the categorization of the findings and tie them back to neurophysiological and psychophysical data on the human hand. We finally discuss design opportunities created through this experiential understanding in relation to the two mechanoreceptors.</span></li>
<li id="PSK"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PSK"><span class="letterCode" style="float:right">PSK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PSK">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466242">Fragmentation and Transition: Understanding Perceptions of Virtual Possessions among Young Adults in Spain, South Korea and the United States</a></span><br />
<span class="authors">W. Odom (Carnegie Mellon Univ., USA), J. Zimmerman, J. Forlizzi, A. López Higuera, M. Marchitto, J. Cañas, Y. Lim, T. Nam, D. Kim, M. Lee, Y. Lee, Y. Row, J. Seok, B. Sohn, H. Moore</span>
<div class="authorList"><span><span class="author">W. Odom</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Zimmerman</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Forlizzi</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. López Higuera</span> (Univ. of Granada, ES)</span><span><span class="author">M. Marchitto</span> (Univ. of Granada, ES)</span><span><span class="author">J. Cañas</span> (Univ. of Granada, ES)</span><span><span class="author">Y. Lim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">T. Nam</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">D. Kim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">M. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">Y. Lee</span> (Department of Industrial Design, KAIST, KR)</span><span><span class="author">Y. Row</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">J. Seok</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">B. Sohn</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">H. Moore</span> (Vodafone Group Services, DE)</span></div>
<p><span class="cbStatement">Contributes an investigation of young adults&#8217; value construction practices with their virtual possessions in South Korea, Spain and the United States and proposes design opportunities in this emerging design space.</span><span class="abstract">People worldwide are increasingly acquiring collections of virtual possessions. While virtual possessions have become ubiquitous, little work exists on how people value and form attachments to these things. To investigate, we conducted a study with 48 young adults from South Korea, Spain and the United States. The study probed on participants’ perceived value of their virtual possessions as compared to their material things, and the comparative similarities and differences across cultures. Findings show that young adults live in unfinished spaces and that they often experience a sense of fragmentation when trying to integrate their virtual possessions into their lives. These findings point to several design opportunities, such as tools for life story-oriented archiving, and insights on better forms of Cloud storage.</span></li>
<li id="PNU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PNU"><span class="letterCode" style="float:right">PNU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PNU">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466425">Reducing Disruption from Subtle Information Delivery during a Conversation: Mode and Bandwidth Investigation</a></span><br />
<span class="authors">E. Ofek (Microsoft Research, USA), S. Iqbal, K. Strauss</span>
<div class="authorList"><span><span class="author">E. Ofek</span> (Microsoft Research, USA)</span><span><span class="author">S. Iqbal</span> (Microsoft Research, USA)</span><span><span class="author">K. Strauss</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">We study how much information and via what mode people can receive and process information in the background while not disrupting a face-to-face conversation they are engaged in. </span><span class="abstract">With proliferation of mobile devices that provide ubiqui-tous access to information, the question arises of how dis-tracting processing information in social settings can be, especially during face-to-face conversations. However, relevant information presented at opportune moments may help enhance conversation quality. In this paper, we study how much information users can consume during a conversation and what information delivery mode, via audio or visual aids, helps them effectively conceal the fact that they are receiving information. We observe that users can internalize more information while still disguising this fact the best when information is delivered visually in batches (multiple pieces of information at a time) and perform better on both dimensions if information is delivered while they are not speaking. Interestingly, participants qualitatively did not prefer this mode as being the easiest to use, preferring modes that displayed one piece of information at a time.  </span></li>
<li id="NSD"class="presentation engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#NSD"><span class="letterCode" style="float:right">NSD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NSD">Wed. 9am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481320">FlashTouch: Data Communication through Touchscreens</a></span><br />
<span class="authors">M. Ogata (Keio Univ., JP), Y. Sugiura, H. Osawa, M. Imai</span>
<div class="authorList"><span><span class="author">M. Ogata</span> (Keio Univ., JP)</span><span><span class="author">Y. Sugiura</span> (Keio Univ., JP)</span><span><span class="author">H. Osawa</span> (Keio Univ., JP)</span><span><span class="author">M. Imai</span> (Keio Univ., JP)</span></div>
<p><span class="cbStatement">FlashTouch is a new technology that enables data communication between touchscreen-based mobile devices and digital peripheral devices using visible light and capacitive touch.</span><span class="abstract">FlashTouch is a new technology that enables data communication between touchscreen-based mobile devices and digital peripheral devices. Touchscreen can be used as communication media using visible light and capacitive touch. In this paper, we designed a stylus prototype to describe the concept of FlashTouch. With this prototype, users can easily transfer data from one mobile device to another. It eliminates the complexity associated with data sharing among mobile users, which is currently achieved by online data sharing services or wireless connections for data sharing that need a pairing operation to establish connections between devices. Therefore, it can prove to be of particular significance to people who are not adept at current software services and hardware functions. Finally, we demonstrate the valuable applications in online settlements via mobile device, and data communication for mobile robots.</span></li>
<li id="PRY"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PRY"><span class="letterCode" style="float:right">PRY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PRY">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466205">Designing for the Living Room: Long-Term User Involvement in a Living Lab</a></span><br />
<span class="authors">C. Ogonowski (Univ. of Siegen, DE), B. Ley, J. Hess, L. Wan, V. Wulf</span>
<div class="authorList"><span><span class="author">C. Ogonowski</span> (Univ. of Siegen, DE)</span><span><span class="author">B. Ley</span> (Univ. of Siegen, DE)</span><span><span class="author">J. Hess</span> (Univ. of Siegen, DE)</span><span><span class="author">L. Wan</span> (Univ. of Siegen, DE)</span><span><span class="author">V. Wulf</span> (Univ. of Siegen, DE)</span></div>
<p><span class="cbStatement">We present lessons learned from a 2.5 year period of a Living Lab project and discuss aspects that need to be considered when setting up such a research framework.</span><span class="abstract">Living Labs provide a research infrastructure for long-term user involvement in Participatory Design processes. Users take part in software co-creation during context analysis, for concept development, reflecting on early-stage prototypes and evaluations in the field. In this paper we describe lessons learned from our Living Lab in the area of home entertainment, with 27 participants from 16 households, over a 2.5 year period. We show that this kind of long-term participation of users involves various challenges over the lifetime of the project. We highlight several aspects that need to be considered carefully when setting up such a Living Lab, concerning the selection of participants, maintenance of participants’ motivation, establishment of a trust relationship, and the coordination of collaboration.</span></li>
<li id="PHS"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PHS"><span class="letterCode" style="float:right">PHS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PHS">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466145">The Challenges and Potential of End-User Gesture Customization</a></span><br />
<span class="authors">U. Oh (Univ. of Maryland, USA), L. Findlater</span>
<div class="authorList"><span><span class="author">U. Oh</span> (Univ. of Maryland, USA)</span><span><span class="author">L. Findlater</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">We present a study on end-user gesture creation to understand users’ thought processes and the challenges encountered. Our findings provide insight for how to better support gesture customization. </span><span class="abstract">The vast majority of work on understanding and supporting the gesture creation process has focused on professional designers. In contrast, gesture customization by end users—which may offer better memorability, efficiency and accessibility than pre-defined gestures—has received little attention. To understand the end-user gesture creation process, we conducted a study where 20 participants were asked to: (1) exhaustively create new gestures for an open-ended use case; (2) exhaustively create new gestures for 12 specific use cases; (3) judge the saliency of different touchscreen gesture features. Our findings showed that even when asked to create novel gestures, participants tended to focus on the familiar. Misconceptions about the gesture recognizer’s abilities were also evident, and in some cases constrained the range of gestures that participants created. Finally, as a calibration point for future research, we used a simple gesture recognizer ($N) to analyze recognition accuracy of the participants’ custom gesture sets: accuracy was 68–88% on average, depending on the amount of training and the customization scenario. We conclude with implications for the design of a mixed-initiative approach to support custom gesture creation.</span></li>
<li id="NPV"class="presentation engineering"><a href="http://chi2013.acm.org/previews/paper.html#NPV"><span class="letterCode" style="float:right">NPV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NPV">Wed. 2pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481387">ZoomBoard: A Diminutive QWERTY Soft Keyboard Using Iterative Zooming for Ultra-Small Devices</a></span><br />
<span class="authors">S. Oney (Carnegie Mellon Univ., USA), C. Harrison, A. Ogan, J. Wiese</span>
<div class="authorList"><span><span class="author">S. Oney</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">C. Harrison</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Ogan</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Wiese</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We present Zoomboard, a keyboard that uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size.</span><span class="abstract">The proliferation of touchscreen devices has made soft keyboards a routine part of life. However, ultra-small computing platforms like the Sony SmartWatch and Apple iPod Nano lack a means of text entry. This limits their potential, despite the fact they are quite capable computers. In this work, we present a soft keyboard interaction technique called ZoomBoard that enables text entry on ultra-small devices. Our approach uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size. We based our design on a QWERTY layout, so that it is immediately familiar to users and leverages existing skill. As the ultimate test, we ran a text entry experiment on a keyboard measuring just 16 x 6mm – smaller than a US penny. After eight practice trials, users achieved an average of 9.3 words per minute, with accuracy comparable to a full-sized physical keyboard. This compares favorably to existing mobile text input methods.</span></li>
<li id="PHD"class="presentation health games"><a href="http://chi2013.acm.org/previews/paper.html#PHD"><span class="letterCode" style="float:right">PHD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PHD">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481341">Tailoring Persuasive Health Games to Gamer Type</a></span><br />
<span class="authors">R. Orji (Univ. of Saskatchewan, CA), R. Mandryk, J. Vassileva, K. Gerling</span>
<div class="authorList"><span><span class="author">R. Orji</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">R. Mandryk</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">J. Vassileva</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">K. Gerling</span> (Univ. of Saskatchewan, CA)</span></div>
<p><span class="cbStatement">We developed models of the efficacy of different motivators of health behavior. Serious game designers can use our results to tailor their games to different player types, potentially increasing the efficacy of persuasive health games</span><span class="abstract">Persuasive games are an effective approach for motivating health behavior, and recent years have seen an increase in games designed for changing human behaviors or attitudes. However, these games are limited in two major ways: first, they are not based on theories of what motivates healthy behavior change. This makes it difficult to evaluate why a persuasive approach works. Second, most persuasive games treat players as a monolithic group. As an attempt to resolve these weaknesses, we conducted a large-scale survey of 642 gamers’ eating habits and their associated determinants of healthy behavior to understand how health behavior relates to gamer type. We developed seven different models of healthy eating behavior for the gamer types identified by BrainHex. We then explored the differences between the models and created two approaches for effective persuasive game design based on our results. The first is a one-size-fits-all approach that will motivate the majority of the population, while not demotivating any players. The second is a personalized approach that will best motivate a particular type of gamer. Finally, to make our approaches actionable in persuasive game design, we map common game mechanics to the determinants of healthy behavior.</span></li>
<li id="NRJ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NRJ"><span class="letterCode" style="float:right">NRJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NRJ">Mon. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470681">3D Object Position using Automatic Viewpoint Transitions</a></span><br />
<span class="authors">M. Ortega (CNRS, FR)</span>
<div class="authorList"><span><span class="author">M. Ortega</span> (CNRS, FR)</span></div>
<p><span class="cbStatement">IUCA is a new technique for 3D objects manipulation. IUCA proposes to interact in a full-resolution perspective view by integrating transients animated transitions to orthographic views into the manipulation task.   </span><span class="abstract">This paper presents IUCA (Interaction Using Camera Animations), a new interaction technique for 3D objects manipulation. IUCA allows efficient interaction in a full-resolution perspective view by integrating transients animated transitions to orthographic views into the manipulation task. This provides an interaction in context, with precise object positioning and alignment. An evaluation of the technique shows that,  compared to the classical configurations, IUCA allows to reduce pointing time by 14% on average. Testing with professional 3D designers and novice users indicate that IUCA is easy to use and to learn; and that users feel comfortable with it.</span></li>
<li id="PEL"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PEL"><span class="letterCode" style="float:right">PEL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEL">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481383">Improving Two-Thumb Text Entry  on Touchscreen Devices</a></span><br />
<span class="authors">A. Oulasvirta (Max Planck Institute for Informatics, DE), A. Reichel, W. Li, Y. Zhang, M. Bachynskyi, K. Vertanen, P. Kristensson</span>
<div class="authorList"><span><span class="author">A. Oulasvirta</span> (Max Planck Institute for Informatics, DE)</span><span><span class="author">A. Reichel</span></span><span><span class="author">W. Li</span></span><span><span class="author">Y. Zhang</span></span><span><span class="author">M. Bachynskyi</span></span><span><span class="author">K. Vertanen</span> (Montana Tech of The Univ. of Montana, USA)</span><span><span class="author">P. Kristensson</span> (Univ. of St Andrews, UK)</span></div>
<p><span class="cbStatement">We designed a split keyboard to improve two-thumb text entry on tablet devices.   KALQ&#8217;s design considers grip, coordinated performance of the two thumbs, and linguistic and motor errors.</span><span class="abstract">We study the design of split keyboards for fast text entry with two thumbs on mobile touchscreen devices. The layout of KALQ was determined through first studying how users should grip a device with two hands. We then assigned letters to keys computationally, using a model of two-thumb tapping. KALQ minimizes thumb travel distance and maximizes alternation between thumbs. An error correction algorithm was added to help address linguistic and motor errors. Users reached a rate of 37 words per minute (with a 5% error rate) after a training program. </span></li>
<li id="PNZ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PNZ"><span class="letterCode" style="float:right">PNZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNZ">Tue. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466169">Information Capacity of Full-Body Movements</a></span><br />
<span class="authors">A. Oulasvirta (Max Planck Institute for Informatics, DE), T. Roos, A. Modig, L. Leppänen</span>
<div class="authorList"><span><span class="author">A. Oulasvirta</span> (Max Planck Institute for Informatics, DE)</span><span><span class="author">T. Roos</span> (Univ. of Helsinki, FI)</span><span><span class="author">A. Modig</span> (Aalto Univ., FI)</span><span><span class="author">L. Leppänen</span></span></div>
<p><span class="cbStatement">Presents a novel metric for the information capacity of full-body movements.</span><span class="abstract">We present a novel metric for information capacity of full-body movements. It accommodates HCI scenarios involving continuous movement of multiple limbs. Throughput is calculated as mutual information in repeated motor sequences. It is affected by the complexity of movements and the precision with which an actor reproduces them. Computation requires decorrelating co-dependencies of movement features (e.g., wrist and elbow) and temporal alignment of sequences. HCI researchers can use the metric as an analysis tool when designing and studying user interfaces.</span></li>
<li id="PNJ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PNJ"><span class="letterCode" style="float:right">PNJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNJ">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466192">WatchIt: Simple Gestures and Eyes-free Interaction for Wristwatches and Bracelets</a></span><br />
<span class="authors">S. PERRAULT (Telecom ParisTech, FR), E. Lecolinet, J. Eagan, Y. GUIARD</span>
<div class="authorList"><span><span class="author">S. PERRAULT</span> (Telecom ParisTech, FR)</span><span><span class="author">E. Lecolinet</span> (Telecom ParisTech, FR)</span><span><span class="author">J. Eagan</span> (Telecom ParisTech – CNRS LTCI UMR 5141 , FR)</span><span><span class="author">Y. GUIARD</span> (Telecom ParisTech, FR)</span></div>
<p><span class="cbStatement">WatchIt is a prototype device that extends interaction from a watch screen to a wristband or bracelet.  We evaluate its use for discrete gestures, continuous control, and eyes-free usage.</span><span class="abstract">We present WatchIt, a prototype device that extends interaction beyond the watch surface to the wristband, and two interaction techniques for command selection and execution. Because the small screen of wristwatch computers suffers from visual occlusion and the fat finger problem, we investigated the use of the wristband as an available interaction resource. Not only does WatchIt use a cheap, energy efficient and invisible technology, but it involves simple, basic gestures that allow good performance after little training, as suggested by the results of a pilot study. We propose a novel gesture technique and an adaptation of an existing menu technique suitable for wristband interaction. In a user study, we investigated their usage in eyes-free contexts, finding that they perform well. Finally, we present techniques where the bracelet is used in addition to the screen to provide precise continuous control over list scrolling. We also report on a preliminary survey of traditional and digital jewelry that points to the high frequency of watches and bracelets in both genders and gives a sense of the tasks people feel like performing on such devices. </span></li>
<li id="PKT"class="presentation design games"><a href="http://chi2013.acm.org/previews/paper.html#PKT"><span class="letterCode" style="float:right">PKT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PKT">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466267">A Tribute to Mad Skill: Expert Amateur Visuality and World of Warcraft Machinima</a></span><br />
<span class="authors">T. Pace (Indiana Univ. Bloomington, USA), A. Toombs, S. Gross, T. Pattin, J. Bardzell, S. Bardzell</span>
<div class="authorList"><span><span class="author">T. Pace</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">A. Toombs</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">S. Gross</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">T. Pattin</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">J. Bardzell</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">S. Bardzell</span> (Indiana Univ. Bloomington, USA)</span></div>
<p><span class="cbStatement">Analyzing a canon of 300 World of Warcraft machinima, we present findings on the role of creativity support tools in fostering visual design skills among expert amateur machinimators.</span><span class="abstract">In this paper, we look at the prominent World of Warcraft machinima community as an expert amateur online com-munity and present a multi-part study of a canon of the most successful works (i.e., machinima videos) produced by this community. By focusing our study on its roughly 300 most successful examples, the determination of which we explain in the paper, we are able to highlight the evolv-ing visual practices, tools, and aesthetic sensibilities of the community. Chiefly, our study identifies how creativity support tools and visual practices are inextricably linked and mutually support the in-kind development of the other. For WoW machinima and its producers, the affordance of creativity tools and the cultivation of visual skill synced at key moments and in powerful ways to support the rapid growth, experimentation, and refinement of amateur exper-tise at the individual and community levels.</span></li>
<li id="NGN"class="presentation engineering ux games arts"><a href="http://chi2013.acm.org/previews/paper.html#NGN"><span class="letterCode" style="float:right">NGN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NGN">Wed. 9am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481303">Reflexive Loopers for Solo Musical Improvisation</a></span><br />
<span class="authors">F. Pachet (Sony CSL Paris, FR), P. Roy, J. Moreira, M. d&#8217;Inverno</span>
<div class="authorList"><span><span class="author">F. Pachet</span> (Sony CSL Paris, FR)</span><span><span class="author">P. Roy</span> (Sony CSL, FR)</span><span><span class="author">J. Moreira</span> (Sony CSL, FR)</span><span><span class="author">M. d&#8217;Inverno</span> (Sony CSL, FR)</span></div>
<p><span class="cbStatement">We describe a system that automatically learns the accompaniement style of a musician from a real-time jazz performance. The system can then be used to perform trios with themselves.</span><span class="abstract">Loop pedals are real-time samplers that playback audio  played previously by a musician. Such pedals are routinely  used for music practice or outdoor “busking”. However,  loop pedals always playback the same material, which can  make performances monotonous and boring both to the  musician and the audience, preventing their widespread  uptake in professional concerts. In response, we propose a  new approach to loop pedals that addresses this issue,  which is based on an analytical multi-modal representation  of the audio input. Instead of simply playing back prerecorded  audio, our system enables real-time generation of  an audio accompaniment reacting to what is currently being  performed by the musician. By combining different modes  of performance – e.g. bass line, chords, solo &#8211; from the musician  and system automatically, solo musicians can perform  duets or trios with themselves, without engendering  the so-called canned (boringly repetitive and unresponsive)  music effect of loop pedals. We describe the technology,  based on supervised classification and concatenative synthesis,  and then illustrate our approach on solo performances  of jazz standards by guitar. We claim this approach  opens up new avenues for concert performance.</span></li>
<li id="PQZ"class="presentation design health"><a href="http://chi2013.acm.org/previews/paper.html#PQZ"><span class="letterCode" style="float:right">PQZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQZ">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466232">Technology Preferences and Routines for Sharing Health Information during the Treatment of a Chronic Illness</a></span><br />
<span class="authors">C. Pang (Simon Fraser Univ., CA), C. Neustaedter, B. Riecke, E. Oduor, S. Hillman</span>
<div class="authorList"><span><span class="author">C. Pang</span> (Simon Fraser Univ., CA)</span><span><span class="author">C. Neustaedter</span> (Simon Fraser Univ., CA)</span><span><span class="author">B. Riecke</span> (Simon Fraser Univ., CA)</span><span><span class="author">E. Oduor</span> (Simon Fraser Univ., CA)</span><span><span class="author">S. Hillman</span> (Simon Fraser Univ., CA)</span></div>
<p><span class="cbStatement">Describes design implications for technologies to support sharing health information within families coping with a chronic illness. Using a mixed-method approach, presents findings outlining affective benefits and costs of communication tools.</span><span class="abstract">When a patient has a chronic illness, such as heart disease or cancer, it can be challenging for distributed family members to stay aware of the patient’s health status. A variety of technologies are available to support health information sharing (e.g., phone, video chat, social media), yet we still do not have a detailed understanding of which technologies are preferred and what challenges people still face when sharing information with them. To explore this, we conducted a mixed-method study—involving a survey and in-depth interviews—with people about their health information sharing routines and preferences for different technologies. Regardless of physical distance between distributed family members, synchronous methods of communication afforded the opportunity to provide affective support while asynchronous methods of communication were deemed to be the least intrusive. With family members adopting certain roles during the treatment of chronic illnesses, our findings suggest the need to design tools that mediate sharing health information across distance and age gaps, with consideration to respecting patient privacy while sharing health information.</span></li>
<li id="NKF"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NKF"><span class="letterCode" style="float:right">NKF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NKF">Thu. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466470">Understanding the Privacy-Personalization Dilemma for Web Search: A User Perspective</a></span><br />
<span class="authors">S. Panjwani (Alcatel-Lucent Bell Labs, IN), N. Shrivastava, S. Shukla, S. Jaiswal</span>
<div class="authorList"><span><span class="author">S. Panjwani</span> (Alcatel-Lucent Bell Labs, IN)</span><span><span class="author">N. Shrivastava</span> (Alcatel-Lucent Bell Labs, IN)</span><span><span class="author">S. Shukla</span> (Indian Institute of Technology Kharagpur, IN)</span><span><span class="author">S. Jaiswal</span> (Alcatel-Lucent Bell Labs, IN)</span></div>
<p><span class="cbStatement">This paper aims to understand users’ perceptions of privacy in web search and how these perceptions interact with their desire for personalized search results.</span><span class="abstract">Contemporary search engines use a variety of techniques to personalize search results based on users&#8217; past queries. While studies have found that users generally prefer personalized search results to non-personalized ones, recent surveys also indicate growing reservations with respect to personalization because of its privacy implications. In this paper, we take a deeper look at privacy considerations of users during web search and explore how users&#8217; preferences for privacy and personalization interact when undertaking this activity. We conduct an empirical study over Google search, involving 25 participants in India and their respective web search histories. Our finding is that users exhibit a slight preference for personalization in their search results but are usually willing to &#8220;give up&#8221; personalization when searching for topics they deem sensitive. We discuss implications of these results for the design of privacy-preserving tools for web search.</span></li>
<li id="PTG"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PTG"><span class="letterCode" style="float:right">PTG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PTG">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481290">Listen to it yourself!  Evaluating Usability of &#8220;What&#8217;s Around Me?&#8221; for the Blind</a></span><br />
<span class="authors">S. Panëels (McGill Univ., CA), A. Olmos, J. Blum, J. Cooperstock</span>
<div class="authorList"><span><span class="author">S. Panëels</span> (McGill Univ., CA)</span><span><span class="author">A. Olmos</span> (McGill Univ., CA)</span><span><span class="author">J. Blum</span> (McGill Univ., CA)</span><span><span class="author">J. Cooperstock</span> (McGill Univ., CA)</span></div>
<p><span class="cbStatement">We present the results of the usability evaluation, conducted in realistic settings, of a novel spatial awareness smartphone application that conveys surrounding points of interest to the blind.  </span><span class="abstract">Although multiple GPS-based navigation applications exist for the visually impaired, these are typically poorly suited for in-situ exploration, require cumbersome hardware, lack support for widely accessible geographic databases, or do not take advantage of advanced functionality such as spatialized audio rendering.  These shortcomings led to our development of a novel spatial awareness application that leverages the capabilities of a smartphone coupled with worldwide geographic databases and spatialized audio rendering to convey surrounding points of interest.  This paper describes the usability evaluation of our system through a task-based study and a longer-term deployment, each conducted with six blind users in real settings.    The findings highlight the importance of testing in ecologically valid contexts over sufficient periods to face real-world challenges, including balancing quality versus quantity for audio information, overcoming limitations imposed by sensor accuracy and quality of database information, and paying appropriate design attention to physical interaction with the device.</span></li>
<li id="PTE"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PTE"><span class="letterCode" style="float:right">PTE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTE">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466222">The Roles of Touch during Phone Conversations: Long-Distance Couples’ Use of POKE in Their Homes</a></span><br />
<span class="authors">Y. Park (KAIST (Korea Advanced Institute of Science and Technology), KR), K. Baek, T. Nam</span>
<div class="authorList"><span><span class="author">Y. Park</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">K. Baek</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">T. Nam</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span></div>
<p><span class="cbStatement">Describes the roles of touch during phone conversations by observing couples’ one month use of POKE in their homes. The results show a potential new application for tactile phone conversations.</span><span class="abstract">We report the roles of touch during phone conversations by observing long-distance couples’ one month use of POKE in their homes. POKE enables users to deliver touches through an inflatable surface on the front of the device that receives index finger pressure inputs on the back of another device, while allowing the callers to maintain a conventional phone-calling posture. After a month of use by three couples, we found unexpected roles of touch in that it supported the couples in developing and sharing their tactile vocabularies by applying POKE during various conversational situations. Moreover, the findings confirmed the roles that touch play in face-to-face communication. In particular, POKE was useful for expressing and understanding emotions, resolving conversations smoothly by replacing the words, feeling close to the partner at a distance, and concentrating on the phone conversations. We conclude by discussing the unused situations, privacy issues, and usable targets to improve POKE as a way of future tactile phone conversations.</span></li>
<li id="PSP"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PSP"><span class="letterCode" style="float:right">PSP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PSP">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481338">I am What I Eat: Identity &#038; Critical Thinking in an Online Health Forum for Kids</a></span><br />
<span class="authors">A. Parker (Northeastern Univ., USA), I. McClendon, C. Grevet, V. Ayo, W. Chung, V. Johnson, E. Mynatt</span>
<div class="authorList"><span><span class="author">A. Parker</span> (Northeastern Univ., USA)</span><span><span class="author">I. McClendon</span> (Georgia Institute of Technology, USA)</span><span><span class="author">C. Grevet</span> (Georgia Institute of Technology, USA)</span><span><span class="author">V. Ayo</span> (Georgia Institute of Technology, USA)</span><span><span class="author">W. Chung</span> (Georgia Institute of Technology, USA)</span><span><span class="author">V. Johnson</span> (Emory Univ., USA)</span><span><span class="author">E. Mynatt</span> (Georgia Institute of Technology, USA)</span></div>
<p><span class="cbStatement">We discuss the design and evaluation of an online forum—TalkBack—that encourages children to critically analyze the messaging in food advertisements and their attitudes towards marketed foods. </span><span class="abstract">As kids encounter food advertisements, it is important that they be able to critically evaluate the message’s claims, the healthiness of the promoted product and their desire for it. To explore how technology might help kids develop these skills, we created an online forum called TalkBack that encourages children to critically analyze the messaging in food ads and their attitudes towards marketed foods. We evaluated TalkBack with twenty-eight middle school students in a summer camp program. We discuss how participants appeared to project and protect their sense of self through their interaction with TalkBack. We also describe the limited analytic depth of their forum contributions and suggest directions for HCI research that attempts to encourage critical thinking and health promotion in adolescents.</span></li>
<li id="PDK"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PDK"><span class="letterCode" style="float:right">PDK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PDK">Tue. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466173">PanoInserts: Mobile Spatial Teleconferencing</a></span><br />
<span class="authors">F. Pece (Univ. College London, UK), W. Steptoe, F. Wanner, S. Julier, T. Weyrich, J. Kautz, A. Steed</span>
<div class="authorList"><span><span class="author">F. Pece</span> (Univ. College London, UK)</span><span><span class="author">W. Steptoe</span> (Univ. College London, UK)</span><span><span class="author">F. Wanner</span> (Univ. College London, UK)</span><span><span class="author">S. Julier</span> (Univ. College London, UK)</span><span><span class="author">T. Weyrich</span> (Univ. College London, UK)</span><span><span class="author">J. Kautz</span> (Univ. College London, UK)</span><span><span class="author">A. Steed</span> (Univ. College London, UK)</span></div>
<p><span class="cbStatement">PanoInserts is a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. </span><span class="abstract">We present PanoInserts: a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. We take a static panoramic image of a location into which we insert live videos from smartphones. We use a combination of marker- and image-based tracking to position the video inserts within the panorama, and transmit this representation to a remote viewer. We conduct a user study comparing our system with fully-panoramic video and conventional webcam video conferencing for two spatial reasoning tasks.  Results indicate that our system performs comparably with fully-panoramic video, and better than webcam video conferencing in tasks that require an accurate surrounding representation of the remote space. We discuss the representational properties and usability of varying video presentations, exploring how they are perceived and how they influence users when performing spatial reasoning tasks.</span></li>
<li id="PCR"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PCR"><span class="letterCode" style="float:right">PCR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PCR">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470723">Using fNIRS Brain Sensing to Evaluate Information Visualization Interfaces</a></span><br />
<span class="authors">E. Peck (Tufts Univ., USA), B. Yuksel, A. Ottley, R. Jacob, R. Chang</span>
<div class="authorList"><span><span class="author">E. Peck</span> (Tufts Univ., USA)</span><span><span class="author">B. Yuksel</span> (Tufts Univ., USA)</span><span><span class="author">A. Ottley</span> (Tufts Univ., USA)</span><span><span class="author">R. Jacob</span> (Tufts Univ., USA)</span><span><span class="author">R. Chang</span> (Tufts Univ., USA)</span></div>
<p><span class="cbStatement">We explore the use of fNIRS brain sensing to evaluate information visualization interfaces.</span><span class="abstract">We show how brain sensing can lend insight to the evaluation of visual interfaces and establish a role for fNIRS in visualization. Research suggests that the evaluation of visual design benefits by going beyond performance measures or questionnaires to measurements of the user&#8217;s cognitive state. Unfortunately, objectively and unobtrusively monitoring the brain is difficult. While functional near-infrared spectroscopy (fNIRS) has emerged as a practical brain sensing technology in HCI, visual tasks often rely on the brain&#8217;s quick, massively parallel visual system, which may be inaccessible to this measurement. It is unknown whether fNIRS can distinguish differences in cognitive state that derive from visual design alone. In this paper, we use the classic comparison of bar graphs and pie charts to test the viability of fNIRS for measuring the impact of a visual design on the brain. Our results demonstrate that we can indeed measure this impact, and furthermore measurements indicate that there are not universal differences in bar graphs and pie charts.</span></li>
<li id="PGS"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGS"><span class="letterCode" style="float:right">PGS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PGS">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466441">Interactive Horizon Graphs: Improving the Compact Visualization of Multiple Time Series</a></span><br />
<span class="authors">C. Perin (INRIA, FR), F. Vernier, J. Fekete</span>
<div class="authorList"><span><span class="author">C. Perin</span> (INRIA, FR)</span><span><span class="author">F. Vernier</span> (Univ Paris-Sud, FR)</span><span><span class="author">J. Fekete</span> (INRIA, FR)</span></div>
<p><span class="cbStatement">Interactive Horizon Graphs&#8212;Horizon Graphs with pan and zoom interactions&#8212; significantly increase the number of time series that can be analyzed in parallel for common comparison tasks.</span><span class="abstract">Many approaches have been proposed for the visualization of multiple time series. Two prominent approaches are reduced line charts (RLC), which display small multiples for time series, and the more recent horizon graphs (HG). We propose to unify RLC and HG using a new technique&#8212;interactive horizon graphs (IHG)&#8212;which uses pan and zoom interaction to increase the number of time series that can be analysed in parallel. In a user study we compared RLC, HG, and IHG across several tasks and numbers of time series, focusing on datasets with both large scale and small scale variations. Our results show that IHG outperform the other two techniques in complex comparison and matching tasks where the number of charts is large. In the hardest task PHG have a significantly higher number of good answers (correctness) than HG (+14%) and RLC (+51%) and a lower error magnitude than HG (-64%) and RLC (-86%).</span></li>
<li id="PAZ"class="presentation games"><a href="http://chi2013.acm.org/previews/paper.html#PAZ"><span class="letterCode" style="float:right">PAZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PAZ">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470755">Playing with Leadership and Expertise: Military Tropes and Teamwork in an ARG</a></span><br />
<span class="authors">T. Peyton (The Pennsylvania State Univ., USA), A. Young, W. Lutters</span>
<div class="authorList"><span><span class="author">T. Peyton</span> (The Pennsylvania State Univ., USA)</span><span><span class="author">A. Young</span> (Univ. of Maryland, Baltimore County, USA)</span><span><span class="author">W. Lutters</span> (Univ. of Maryland, Baltimore County, USA)</span></div>
<p><span class="cbStatement">Explores how ARG teams arrange and militarize play within unstructured ludic systems. Illustrates that the development of expertise and emergence of leadership occurs in response to this lack of structure.</span><span class="abstract">Ad-hoc virtual teams often lack tools to formalize leadership and structure collaboration, yet they are often successful. How does this happen? We argue that the emergence of leadership and the development of expertise occurs in the process of taking action and in direct response to a lack of structure. Using a twinned set of eight modality sliders, we examine the interactions of fourteen players in an alternate reality game. We find that players adopted military language and culture to structure and arrange their play. We determine that it is critical to account for the context of play across these modalities in order to design appropriately for effective in-game virtual organizing.</span></li>
<li id="PQV"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PQV"><span class="letterCode" style="float:right">PQV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PQV">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470672">Electric Materialities and Interactive Technology</a></span><br />
<span class="authors">J. Pierce (Carnegie Mellon Univ., USA), E. Paulos</span>
<div class="authorList"><span><span class="author">J. Pierce</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">E. Paulos</span> (Univ. of California, Berkeley, USA)</span></div>
<p><span class="cbStatement">Characterizes electric technology by three forms of materiality: the electric object, its electric materiality, and electric power. Presents and analyzes novel interactive form prototypes. </span><span class="abstract">This paper offers new theoretical and design insights into interactive technology. By initially considering electric technology broadly, our work informs how HCI approaches a range of specific interactive or digital things and materials. Theoretically, we contribute a rigorous analysis of electric technology using the experiential lens of phenomenology. A major result is to characterize electric technology by three forms of materiality: the electric object, its electric materiality, and electric power. In terms of design, we present and analyze novel interactive form prototypes. Our theoretical contributions offer new insight into design artifacts, just as our novel design artifacts help reveal new theoretical insight.</span></li>
<li id="NAC"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/paper.html#NAC"><span class="letterCode" style="float:right">NAC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NAC">Tue. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466165">4 Design Themes for Skateboarding</a></span><br />
<span class="authors">S. Pijnappel (RMIT Univ., AU), F. Mueller</span>
<div class="authorList"><span><span class="author">S. Pijnappel</span> (RMIT Univ., AU)</span><span><span class="author">F. Mueller</span> (RMIT Univ., AU)</span></div>
<p><span class="cbStatement">We explore how to design interactive technologies to enhance the experience of skateboarding, providing thought provoking insights into how technology can have value beyond the context of performance focused sports.</span><span class="abstract">Interactive technology can support exertion activities, with many examples focusing on improving athletic performance. We see an opportunity for technology to also support extreme sports such as skateboarding, which often focus primarily on the experience of doing tricks rather than on athletic performance. However, there is little knowledge on how to design for such experiences. In response, we designed 12 basic skateboarding prototypes inspired by skateboarding theory. Using an autoethnographical approach, we skated with each of these and reflected on our experiences in order to derive four design themes : location of feedback in relation to the skater’s body, timing of feedback in relation to peaks in emotions after attempts, aspects of the trick emphasized by feedback, and aesthetic fittingness of feedback. We hope our work will guide designers of interactive systems for skateboarding, and extreme sports in general, and will therefore further our understanding of how to design for the active human body.</span></li>
<li id="PCZ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PCZ"><span class="letterCode" style="float:right">PCZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PCZ">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466418">The Whats and Hows of Programmers’ Foraging Diets</a></span><br />
<span class="authors">D. Piorkowski (Oregon State Univ., USA), S. Fleming, I. Kwan, M. Burnett, C. Scaffidi, R. Bellamy, J. Jordahl</span>
<div class="authorList"><span><span class="author">D. Piorkowski</span> (Oregon State Univ., USA)</span><span><span class="author">S. Fleming</span> (Univ. of Memphis, USA)</span><span><span class="author">I. Kwan</span> (Oregon State Univ., USA)</span><span><span class="author">M. Burnett</span> (Oregon State Univ., USA)</span><span><span class="author">C. Scaffidi</span> (Oregon State Univ., USA)</span><span><span class="author">R. Bellamy</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">J. Jordahl</span> (Oregon State Univ., USA)</span></div>
<p><span class="cbStatement">Information Foraging Theory investigation into information diets of professional programmers during debugging, and how these diets interact with their foraging strategies. Helps unify Information Foraging Theory with debugging research.</span><span class="abstract">One of the least studied areas of Information Foraging Theory is diet: the information foragers choose to seek.  For example, do foragers choose solely based on cost, or do they stubbornly pursue certain diets regardless of cost? Do their debugging strategies vary with their diets? To investigate &#8220;what&#8221; and &#8220;how&#8221; questions like these for the domain of software debugging, we qualitatively analyzed 9 professional developers&#8217; foraging goals, goal patterns, and strategies. Participants spent 50% of their time foraging. Of their foraging, 58% fell into distinct dietary patterns&#8211;mostly in patterns not previously discussed in the literature. In general, programmers&#8217; foraging strategies leaned more heavily toward enrichment than we expected, but different strategies aligned with different goal types. These and our other findings help fill the gap as to what programmers&#8217; dietary goals are and how their strategies relate to those goals.   </span></li>
<li id="PQC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PQC"><span class="letterCode" style="float:right">PQC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PQC">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481307">Focused and Casual Interactions: Allowing Users to Vary Their Level of Engagement</a></span><br />
<span class="authors">H. Pohl (Univ. of Hanover, DE), R. Murray-Smith</span>
<div class="authorList"><span><span class="author">H. Pohl</span> (Univ. of Hanover, DE)</span><span><span class="author">R. Murray-Smith</span> (Univ. of Glasgow, UK)</span></div>
<p><span class="cbStatement">Investigates how to enable users to vary their engagement in  interactions, allowing them to use casual interactions for less  precision but also with less effort when e.g. tired or busy.</span><span class="abstract">We describe the focused-casual continuum, a framework for describing interaction techniques according to the degree to which they allow users to adapt how much attention and effort they choose to invest in an interaction conditioned on their current situation. Casual interactions are particularly appropriate in scenarios where full engagement with devices is frowned upon socially, is unsafe, physically challenging or too mentally taxing. Novel sensing approaches which go beyond direct touch enable wider use of casual interactions, which will often be &#8216;around device&#8217; interactions. We consider the degree to which previous commercial products and research prototypes can be considered as fitting the focused&#8211;casual framework, and describe the properties using control theoretic concepts. In an experimental study we observe that users naturally apply more precise and more highly engaged interaction techniques when faced with a more challenging task and use more relaxed gestures in easier tasks.</span></li>
<li id="NKQ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NKQ"><span class="letterCode" style="float:right">NKQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NKQ">Tue. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466194">An Interactive Belt-worn Badge</a></span><br />
<span class="authors">N. Pohl (Univ. of Stuttgart, DE), S. Hodges, J. Helmes, N. Villar, T. Paek</span>
<div class="authorList"><span><span class="author">N. Pohl</span> (Univ. of Stuttgart, DE)</span><span><span class="author">S. Hodges</span> (Microsoft Research, UK)</span><span><span class="author">J. Helmes</span> (Microsoft Research, UK)</span><span><span class="author">N. Villar</span> (Microsoft Research, UK)</span><span><span class="author">T. Paek</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">This paper explores an interactive identity badge with an embedded LCD and an input mechanism based on sensing built into the retractable string which attaches it to the wearer’s belt.</span><span class="abstract">In this paper we explore a new type of wearable computing device, an interactive identity badge. An embedded LCD presents dynamic information to the wearer and interaction is facilitated by sensing movement of the retractable string which attaches the unit to the wearer’s belt. This form-factor makes it possible to interact using a single hand, providing lightweight and immediate access to a variety of information when it’s not convenient to pick up, unlock and interact directly with a device like a smartphone. In this paper we present our prototype interactive badge, demonstrate the underlying technology and describe a number of usage scenarios and interaction techniques</span></li>
<li id="NET"class="presentation cci"><a href="http://chi2013.acm.org/previews/paper.html#NET"><span class="letterCode" style="float:right">NET</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NET">Wed. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481402">Interview Approaches to Researching Embodiment</a></span><br />
<span class="authors">S. Price (Institute of Education, UK), C. Jewitt</span>
<div class="authorList"><span><span class="author">S. Price</span> (Institute of Education, UK)</span><span><span class="author">C. Jewitt</span> (Institute of Education, UK)</span></div>
<p><span class="cbStatement">This paper makes a methodological contribution to child computer interaction. It examines three interview approaches, providing guidance on interview choices to explore communicational modes of interaction in tangible learning environments.</span><span class="abstract">The methods of data collection that we choose determine the kinds of data that we have access to, and thus shape analyses. In the context of novel interfaces where different modes, available through the environment and context, mediate the interaction, understanding methodological approaches is critical. This paper examines alternative methods of data collection for exploring student’s embodied interaction with novel technology in a learning context. Specifically it analyses non-facilitated interaction in a tangible learning environment, in conjunction with three different post activity interview approaches: semi-structured interviews; semi-structured interview with video prompted recall; and interviews using the technology itself. Findings suggest that the different interview approaches change the nature of information elicited, and that non-facilitated interaction offers clearer insight into interpretation, both in terms of the meaning that emerges through, and is, therefore, embodied in the interaction, and in terms of representation, directly informing design.</span></li>
<li id="PTM"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PTM"><span class="letterCode" style="float:right">PTM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTM">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466210">Use of an Agile Bridge in the Development of Assistive Technology</a></span><br />
<span class="authors">S. Prior (Univ. of Abertay Dundee, UK), A. Waller, T. Kroll, R. Black</span>
<div class="authorList"><span><span class="author">S. Prior</span> (Univ. of Abertay Dundee, UK)</span><span><span class="author">A. Waller</span> (Univ. of Dundee, UK)</span><span><span class="author">T. Kroll</span> (Univ. of Dundee, UK)</span><span><span class="author">R. Black</span> (Univ. of Dundee, UK)</span></div>
<p><span class="cbStatement">In this paper we present a means for adults with complex communication disabilities to be involved in the User-Centred Design process through the use of a user advocate</span><span class="abstract">Engaging with end users in the development of assistive technologies remains one of the major challenges for researchers and developers in the field of accessibility and HCI. Developing usable software systems for people with complex disabilities is problematic, software developers are wary of using user-centred design, one of the main methods by which usability can be improved, due to concerns about how best to work with adults with complex disabilities, in particular Severe Speech and Physical Impairments (SSPI) and how to involve them in research. This paper reports on how the adoption of an adapted agile approach involving the incorporation of a user advocate on the research team helped in meeting this challenge in one software project and offers suggestions for how this could be used by other development teams. </span></li>
<li id="PCN"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PCN"><span class="letterCode" style="float:right">PCN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCN">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481350">Digital Apartheid: An Ethnographic Account  of Racialised HCI in Cape Town Hip-Hop</a></span><br />
<span class="authors">G. Pritchard (Newcastle Univ., UK), J. Vines</span>
<div class="authorList"><span><span class="author">G. Pritchard</span> (Newcastle Univ., UK)</span><span><span class="author">J. Vines</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">Ethnography of Cape Town hip-hop performers exploring how technology such as social media supports yet inhibits the development and sustainment of their careers. Raises implications for HCI4D and post-colonial computing.</span><span class="abstract">We describe findings from a 15-month ethnography of hip-hop performers in Cape Town, South Africa. Mobile communications and social media are hugely important to the development of these performers’ careers, opening access to collaborators, production tools, audiences and distribution channels. This group go to extraordinary lengths to gain and maintain access to these technologies, often by exploiting their social capital through musical and ethnic networks. We document that even after nearly twenty years of democracy, a ridged separation along racial lines persists, which can be seen in all areas of life including access to and proficiency in digital technologies. We illustrate how hip-hop performers harness these divisions both on and offline in order to distinguish themselves from other artists. Our research raises a number of implications for post-colonial computing, highlighting difficulties related to discontinuous access, and how international preconceptions of identity and authenticity emerge as a consequence of the increased use of communication technology.</span></li>
<li id="NLS"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NLS"><span class="letterCode" style="float:right">NLS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NLS">Mon. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470711">Regularly Visited Patches in Human Mobility</a></span><br />
<span class="authors">Y. Qu (placenous.com, USA), J. Zhang</span>
<div class="authorList"><span><span class="author">Y. Qu</span> (placenous.com, USA)</span><span><span class="author">J. Zhang</span> (Pitney Bowes Inc., USA)</span></div>
<p><span class="cbStatement">This paper proposes a new analytic unit for human mobility research – the patch. Regularly Visited Patches (RVP) identified from GPS-based location data were analyzed, revealing fundamental mobility patterns.	</span><span class="abstract">In this paper, we propose a new analytic unit for human mobility analysis – the patch. We developed a process to identify Regularly Visited Patches (RVP) and a set of metrics to characterize and measure their spatial patterns.  Using a large dataset of Foursquare check-ins as a test bed, we show that RVP analysis reveals fundamental patterns of human mobility and will lead to promising research with strong implications for businesses. </span></li>
<li id="PPB"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PPB"><span class="letterCode" style="float:right">PPB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPB">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466253">In-body Experiences: Embodiment, Control, and Trust in Robot-Mediated Communication</a></span><br />
<span class="authors">I. Rae (Univ. of Wisconsin, Madison, USA), L. Takayama, B. Mutlu</span>
<div class="authorList"><span><span class="author">I. Rae</span> (Univ. of Wisconsin, Madison, USA)</span><span><span class="author">L. Takayama</span> (Willow Garage, USA)</span><span><span class="author">B. Mutlu</span> (Univ. of Wisconsin, Madison, USA)</span></div>
<p><span class="cbStatement">Presents empirical results of a controlled experiment on the effects of embodiment and control on trust in user interactions.  Offers design guidelines and theoretical implications for robot-mediated communication systems.</span><span class="abstract">Communication technologies are becoming increasingly diverse in form and functionality, making it important to identify which aspects of these technologies actually improve geographically distributed communication.  Our study examines two potentially important aspects of communication technologies which appear in robot-mediated communication&#8212;physical embodiment and control of this embodiment.  We studied the impact of physical embodiment and control upon interpersonal trust in a controlled laboratory experiment using three different videoconferencing settings: (1) a handheld tablet controlled by a local user, (2) an embodied system controlled by a local user, and (3) an embodied system controlled by a remote user (n = 29 dyads).  We found that physical embodiment and control by the local user increased the amount of trust built between partners.  These results suggest that both physical embodiment and control of the system influence interpersonal trust in mediated communication and have implications for future system designs.</span></li>
<li id="PBS"class="presentation design cci"><a href="http://chi2013.acm.org/previews/paper.html#PBS"><span class="letterCode" style="float:right">PBS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PBS">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470670">Why Interactive Learning Environments Can Have It All: Resolving Design Conflicts Between Competing Goals</a></span><br />
<span class="authors">M. Rau (Carnegie Mellon Univ., USA), V. Aleven, N. Rummel, S. Rohrbach</span>
<div class="authorList"><span><span class="author">M. Rau</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">V. Aleven</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">N. Rummel</span> (Ruhr-Univ. Bochum, DE)</span><span><span class="author">S. Rohrbach</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We present a principled, approach to resolving conflicts between competing goals in educational settings. We provide evidence that our approach lead to the development of a successful interactive learning environment.</span><span class="abstract">Designing interactive learning environments (ILEs; e.g., intelligent tutoring systems, educational games, etc.) is a challenging interdisciplinary process that needs to satisfy multiple stakeholders. ILEs need to function in real educa-tional settings (e.g., schools) in which a number of goals interact. Several instructional design methodologies exist to help developers address these goals. However, they often lead to conflicting recommendations. Due to the lack of an established methodology to resolve such conflicts, develop-ers of ILEs have to rely on ad-hoc solutions. We present a principled methodology to resolve such conflicts. We build on a well-established design process for creating Cognitive Tutors, a highly effective type of ILE. We extend this pro-cess by integrating methods from multiple disciplines to resolve design conflicts. We illustrate our methodology’s effectiveness by describing the iterative development of the Fractions Tutor, which has proven to be effective in class-room studies with 3,000 4th-6th graders.</span></li>
<li id="PTF"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PTF"><span class="letterCode" style="float:right">PTF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PTF">Wed. 4pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481389">Job Opportunities through Entertainment: Virally Spread Speech-Based Services for Low-Literate Users</a></span><br />
<span class="authors">A. Raza (Carnegie Mellon Univ., USA), F. Ul Haq, Z. Tariq, M. Pervaiz, S. Razaq, U. Saif, R. Rosenfeld</span>
<div class="authorList"><span><span class="author">A. Raza</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">F. Ul Haq</span> (Lahore Univ. of Management Sciences, PK)</span><span><span class="author">Z. Tariq</span> (Lahore Univ. of Management Sciences, PK)</span><span><span class="author">M. Pervaiz</span> (Northeastern Univ., USA)</span><span><span class="author">S. Razaq</span> (Lahore Univ. of Management Sciences, PK)</span><span><span class="author">U. Saif</span> (Lahore Univ. of Management Sciences, PK)</span><span><span class="author">R. Rosenfeld</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">A speech-based entertainment service spread virally to low-literate Pakistani telephone users, exceeding 85,000 users and 495,000 calls in four months, while spreading low-skill job opportunities to 27,000 of them.</span><span class="abstract">We explore how telephone-based services might be mass adopted by low-literate users in the developing world. We focus on speech and push-button dialog systems requiring neither literacy nor training. Building on the success of Polly, a simple telephone-based voice manipulation and forwarding system that was first tested in 2011, we report on its first large-scale sustained deployment. In 24/7 operation in Pakistan since May 9, 2012, as of mid-September Polly has spread to 85,000 users, engaging them in 495,000 interactions, and is continuing to spread to 1,000 new people daily. It has also attracted 27,000 people to a job search service, who in turn listened 279,000 times to job ads and forwarded them 22,000 times to their friends. We report users’ activity over time and across demographics, analyze user behavior within several randomized controlled trials, and describe lessons learned regarding spread, scalability and sustainability of telephone-based speech-based services.</span></li>
<li id="PFY"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PFY"><span class="letterCode" style="float:right">PFY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PFY">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481281">Predicting Users&#8217; First Impressions of Website Aesthetics With a Quantification of Perceived Visual Complexity and Colorfulness</a></span><br />
<span class="authors">K. Reinecke (Harvard Univ., USA), T. Yeh, L. Miratrix, Y. Zhao, R. Mardiko, J. Liu, K. Gajos</span>
<div class="authorList"><span><span class="author">K. Reinecke</span> (Harvard Univ., USA)</span><span><span class="author">T. Yeh</span> (Univ. of Colorado, USA)</span><span><span class="author">L. Miratrix</span> (Harvard Univ., USA)</span><span><span class="author">Y. Zhao</span> (Harvard Univ., USA)</span><span><span class="author">R. Mardiko</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Liu</span> (Harvard Univ., USA)</span><span><span class="author">K. Gajos</span> (Harvard Univ., USA)</span></div>
<p><span class="cbStatement">We collected colorfulness, complexity, and overall visual appeal ratings from 548 volunteers. Utilizing these data, we developed models that accurately predict perceived visual complexity and perceived colorfulness in websites based on computational image statistics.</span><span class="abstract">Users make lasting judgments about a website&#8217;s appeal within a split second of seeing it for the first time. This first impression is influential enough to later affect their opinions of a site&#8217;s usability and trustworthiness. In this paper, we demonstrate a means to predict the initial impression of aesthetics based on perceptual models of a website&#8217;s colorfulness and visual complexity. In an online study, we collected ratings of colorfulness, visual complexity, and visual appeal of a set of 450 websites from 548 volunteers. Based on these data, we developed computational models that accurately measure the perceived visual complexity and colorfulness of website screenshots. In combination with demographic variables such as a user&#8217;s education level and age, these models explain approximately half of the variance in the ratings of aesthetic appeal given after viewing a website for 500ms only.</span></li>
<li id="PFS"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PFS"><span class="letterCode" style="float:right">PFS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PFS">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470709">Designing and Theorizing Co-Located Interactions</a></span><br />
<span class="authors">T. Reitmaier (Univ. of Cape Town, ZA), P. Benz, G. Marsden</span>
<div class="authorList"><span><span class="author">T. Reitmaier</span> (Univ. of Cape Town, ZA)</span><span><span class="author">P. Benz</span> (Univ. of Cape Town, ZA)</span><span><span class="author">G. Marsden</span> (Univ. of Cape Town, ZA)</span></div>
<p><span class="cbStatement">This paper gives an interwoven account of the theoretical and practical work we undertook in pursuit of designing co-located interactions on mobile devices.</span><span class="abstract">This paper gives an interwoven account of the theoretical and practical work we undertook in pursuit of designing co-located interactions. We show how we sensitized ourselves to theory from diverse intellectual disciplines, to develop an analytical lens to better think about co-located interactions. By critiquing current systems and their conceptual foundations, and further interrelating theories particularly in regard to performative aspects of identity and communication, we develop a more nuanced way of thinking about co-located interactions. Drawing on our sensitivities, we show how we generated and are exploring, through the process of design, a set of co-located interactions that are situated within our social ecologies, and contend that our upfront theoretical work enabled us to identify and explore this space in the first place. This highlights the importance of problem framing, especially for projects adopting design methodologies. </span></li>
<li id="PPC"class="presentation games"><a href="http://chi2013.acm.org/previews/paper.html#PPC"><span class="letterCode" style="float:right">PPC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPC">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466138">The Dynamics of Younger and Older Adult’s Paired Behavior when Playing an Interactive Silhouette Game</a></span><br />
<span class="authors">M. Rice (Institute for Infocomm Research, SG), W. Tan, J. Ong, L. Yau, M. Wan, J. Ng</span>
<div class="authorList"><span><span class="author">M. Rice</span> (Institute for Infocomm Research, SG)</span><span><span class="author">W. Tan</span> (Temasek Polytechnic , SG)</span><span><span class="author">J. Ong</span> (Institute for Infocomm Research , SG)</span><span><span class="author">L. Yau</span> (Institute for Infocomm Research, SG)</span><span><span class="author">M. Wan</span> (Institute for Infocomm Research, SG)</span><span><span class="author">J. Ng</span> (Institute for Infocomm Research , SG)</span></div>
<p><span class="cbStatement">We present the design and evaluation of an intergenerational game with 60 younger and older players, and report on the communicative and cooperative interaction, with subsequent recommendations.</span><span class="abstract">In this paper, we report on the findings of an acute trial in which we evaluate the design of a novel gesture-based game. 60 younger and older players, divided into three separate group-types: (i) Young-Young, (ii) Old-Old, and (iii) Young-Old, took part in the study. The primary aim of this work was to evaluate the communicative and cooperative behavior of same-age and mixed-age pairs, with secondary interests in their perceived ease-of-use of the game. A mixed-method approach was used, comprising of direct observations, a post-game questionnaire and paired interviews. Our results identified noticeable differences between the group-types, with the Young-Old showing more physical cooperation, as compared to the same-age groups. The work elaborates on how the young and old differ in expectations and perceived interaction, and concludes with some recommendations for future research.</span></li>
<li id="PAP"class="presentation sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PAP"><span class="letterCode" style="float:right">PAP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PAP">Tue. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466152">At Home with Agents: Exploring Attitudes Towards Future Smart Energy Infrastructures</a></span><br />
<span class="authors">T. Rodden (The Univ. of Nottingham, UK), J. Fischer, N. Pantidi, K. Bachour, S. Moran</span>
<div class="authorList"><span><span class="author">T. Rodden</span> (The Univ. of Nottingham, UK)</span><span><span class="author">J. Fischer</span> (The Univ. of Nottingham, UK)</span><span><span class="author">N. Pantidi</span> (The Univ. of Nottingham, UK)</span><span><span class="author">K. Bachour</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Moran</span> (The Univ. of Nottingham, UK)</span></div>
<p><span class="cbStatement">This paper considers critical socio-economical issues regarding how consumers might relate to future smart energy infrastructures and suggests a number of key design principles to address those.</span><span class="abstract">Energy systems researchers are proposing a broad range of future “smart” energy infrastructures to promote more efficient management of energy resources. This paper considers how consumers might relate to these future smart grids within the UK. To address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. Users’ reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to consider how to design software agents to enhance trust in these socio-economic settings. </span></li>
<li id="NGR"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NGR"><span class="letterCode" style="float:right">NGR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NGR">Tue. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466257">Design Research at CHI and its Applicability to Design Practice</a></span><br />
<span class="authors">D. Roedl (Indiana Univ. Bloomington, USA), E. Stolterman</span>
<div class="authorList"><span><span class="author">D. Roedl</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">E. Stolterman</span> (Indiana Univ. Bloomington, USA)</span></div>
<p><span class="cbStatement">We present an analysis of papers from CHI 2011 and draw on interviews with professional designers to suggest ways that CHI research can better support practice.</span><span class="abstract">This note describes our analysis of 35 papers from CHI 2011 that aim to improve or support interaction design practice. In our analysis, we characterize how these CHI authors conceptualize design practice and the types of contributions they propose. This work is motivated by the recognition that design methods proposed by HCI researchers often do not fit the needs and constraints of professional design practice. As a complement to the analysis of the CHI papers we also interviewed 13 practitioners about their attitudes towards learning new methods and approaches. We conclude the note by offering some critical reflections about how HCI research can better support actual design practice.</span></li>
<li id="NNY"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NNY"><span class="letterCode" style="float:right">NNY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NNY">Thu. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466469">Taking Data Exposure into Account: How Does It Affect the Choice of Sign-in Accounts?</a></span><br />
<span class="authors">S. Ronen (Massachusetts Institute of Technology, USA), O. Riva, M. Johnson, D. Thompson</span>
<div class="authorList"><span><span class="author">S. Ronen</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">O. Riva</span> (Microsoft Research, USA)</span><span><span class="author">M. Johnson</span> (Univ. of California, Berkeley, USA)</span><span><span class="author">D. Thompson</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">We surveyed 575 people to investigate awareness of data exposure when using federated accounts, and willingness to switch accounts given clearer information on data exposure and benefits provided by each.</span><span class="abstract">Online services collect personal data from their users, sometimes with no clear need. We studied how users sign-in to web sites using federated IDs, and found that most survey respondents were not aware of the data they expose. However, when presented with the tradeoffs behind each sign-in option, respondents reported a willingness to change how they sign-in to reduce their data exposure or, in fewer cases, to increase it to receive more benefits from the service. Our findings suggest that data exposure is a concern for users, and that there is a need for finding clearer ways for communicating it for each sign-in option.</span></li>
<li id="PJV"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PJV"><span class="letterCode" style="float:right">PJV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJV">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466218">Designing with Traces</a></span><br />
<span class="authors">D. Rosner (Stanford Univ., USA), M. Ikemiya, D. Kim, K. Koch</span>
<div class="authorList"><span><span class="author">D. Rosner</span> (Stanford Univ., USA)</span><span><span class="author">M. Ikemiya</span> (California College of the Arts, USA)</span><span><span class="author">D. Kim</span> (California College of the Arts, USA)</span><span><span class="author">K. Koch</span> (California College of the Arts, USA)</span></div>
<p><span class="cbStatement">This paper introduces the analytic category of “material traces,” which with design students envision poignant relationships to the non-human, engaged physics learning, and reflection around breakage. </span><span class="abstract">This paper draws on new materialist perspectives to introduce the analytic category of “material traces” to the field of human-computer interaction (HCI). Material traces reveal the dynamic and evocative nature of form by concretizing a unique location in time and space. Traces of skill, use, and time, for example, are valued for their emotional resonance in addition to the pragmatic goals in which they are embedded. Using this category, we develop a framework for design pedagogy that offers the lenses of attributes, entanglements, and trajectories as tools for gaining critical purchase on the objects produced. Mobilizing this framework within a classroom, design students envision poignant relationships to the non-human, engaged physics learning, and opportunities for reflection around breakage and repair. These design examples reveal how the category of material traces comes alive in practice and pedagogy. We end by discussing how this study of traces points to new opportunities for critical reflection in HCI.</span></li>
<li id="PAM"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PAM"><span class="letterCode" style="float:right">PAM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PAM">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470738">Morphees: Toward High “Shape Resolution” in Self-Actuated Flexible Mobile Devices</a></span><br />
<span class="authors">A. Roudaut (Univ. of Bristol, UK), A. Karnik, M. Löchtefeld, S. Subramanian</span>
<div class="authorList"><span><span class="author">A. Roudaut</span> (Univ. of Bristol, UK)</span><span><span class="author">A. Karnik</span> (Univ. of Bristol, UK)</span><span><span class="author">M. Löchtefeld</span> (German Research Center for Artificial Intelligence (DFKI), DE)</span><span><span class="author">S. Subramanian</span> (Univ. of Bristol, UK)</span></div>
<p><span class="cbStatement">We introduce the term shape resolution in 10 features, which adds to the existing definitions of screen and touch resolution and helps the design of shape-shifting mobile devices.</span><span class="abstract">We introduce the term shape resolution, which adds to the existing definitions of screen and touch resolution. We propose a framework, based on a geometric model (Non-Uniform Rational B-splines), which defines a metric for shape resolution in ten features. We illustrate it by comparing the current related work of shape changing devices. We then propose the concept of Morphees that are self-actuated flexible mobile devices adapting their shapes on their own to the context of use in order to offer better affordances. For instance, when a game is launched, the mobile device morphs into a console-like shape by curling two opposite edges to be better grasped with two hands. We then create preliminary prototypes of Morphees in order to explore six different building strategies using advanced shape changing materials (dielectric electro active polymers and shape memory alloys). By comparing the shape resolution of our prototypes, we generate insights to help designers toward creating high shape resolution Morphees.</span></li>
<li id="PAD"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PAD"><span class="letterCode" style="float:right">PAD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAD">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481352">Gesture Output: Eyes-Free Output: Using a Force Feedback Touch Surface</a></span><br />
<span class="authors">A. Roudaut (Hasso Plattner Institute, DE), A. Rau, C. Sterz, M. Plauth, P. Lopes, P. Baudisch</span>
<div class="authorList"><span><span class="author">A. Roudaut</span> (Hasso Plattner Institute, DE)</span><span><span class="author">A. Rau</span> (Hasso Plattner Institute, DE)</span><span><span class="author">C. Sterz</span> (Hasso Plattner Institute, DE)</span><span><span class="author">M. Plauth</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Lopes</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Baudisch</span> (Hasso Plattner Institute, DE)</span></div>
<p><span class="cbStatement">We propose using spatial gestures not only for input but also for output.  Analogous to gesture input, gesture output moves the user’s finger in a gesture, which the user then recognizes.</span><span class="abstract">We propose using spatial gestures not only for input but also for output. Analogous to gesture input, the proposed gesture output moves the user’s finger in a gesture, which the user then recognizes. We use our concept in a mobile scenario where a motion path forming a “5” informs users about new emails, or a heart-shaped path serves as a mes- sage from a friend. We built two prototypes: (1) The long- RangeOuija is a stationary prototype that offers a motion range of up to 4cm; (2) The pocketOuija is self-contained mobile device based on an iPhone with up to 1cm motion range. Both devices actuate the user’s fingers by means of an actuated transparent foil overlaid onto a touchscreen.    We conducted three studies with the longRangeOuija in which participants recognized 2cm marks with 97% accu- racy, Graffiti digits with 98.8%, pairs of Graffiti digits with 90.5%, and Graffiti letters with 93.4%. Participants previ- ously unfamiliar with Graffiti identified 96.2% of digits and 76.4% of letters, suggesting that properly designed gesture output is guessable. After the experiment, the same participants were able to enter 100% of Graffiti digits by heart and 92.2% of letters. This suggests that participants learned gesture input as a side effect of using gesture output on our prototypes.</span></li>
<li id="NNL"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NNL"><span class="letterCode" style="float:right">NNL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NNL">Wed. 9am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481321">Augmented Letters: Mnemonic Gesture-Based Shortcuts</a></span><br />
<span class="authors">Q. Roy (CNRS LTCI UMR 5141, FR), S. Malacria, Y. Guiard, E. Lecolinet, J. Eagan</span>
<div class="authorList"><span><span class="author">Q. Roy</span> (CNRS LTCI UMR 5141, FR)</span><span><span class="author">S. Malacria</span> (Univ. of Canterbury, NZ)</span><span><span class="author">Y. Guiard</span> (Telecom ParisTech – CNRS LTCI UMR 5141, FR)</span><span><span class="author">E. Lecolinet</span> (Telecom ParisTech, FR)</span><span><span class="author">J. Eagan</span> (Telecom ParisTech – CNRS LTCI UMR 5141 , FR)</span></div>
<p><span class="cbStatement">Appending a tail to the first letter of a command: Augmented Letters allows users to memorize larger command shortcut vocabularies than Marking Menus, with no overall speed cost.</span><span class="abstract">We propose Augmented Letters, a new technique aimed at augmenting gesture-based techniques such as Marking Menus by giving them natural, mnemonic associations. Augmented Letters gestures consist of the initial of command names, sketched by hand in the Unistroke style, and affixed with a straight tail. We designed a tentative touch device interaction technique that supports fast interactions with large sets of commands, is easily discoverable, improves user’s recall at no speed cost, and supports fluid transition from novice to expert mode. An experiment suggests that Augmented Letters outperform Marking Menu in terms of user recall.</span></li>
<li id="PBG"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PBG"><span class="letterCode" style="float:right">PBG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBG">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466157">PointAssist: Assisting Individuals with Motor Impairments</a></span><br />
<span class="authors">G. Salivia (Minnesota State Univ., USA), J. Hourcade</span>
<div class="authorList"><span><span class="author">G. Salivia</span> (Minnesota State Univ., USA)</span><span><span class="author">J. Hourcade</span> (Univ. of Iowa, USA)</span></div>
<p><span class="cbStatement">This paper presents results from evaluating PointAssist with participants with motor impairments in a  remote test. It contributes to HCI by showing how PointAssist can be adapted to individual differences.</span><span class="abstract">We tested PointAssist, software that assists in pointing tasks by detecting difficulty through a sub-movement analysis and triggering help, with adjustments proposed to personalize the assistance provided to individuals with motor impairments. A within-subjects study with sixteen individuals with fine motor skills impairments resulted in statistically significant effects on accuracy using Friedman&#8217;s test with chi-square(1)=6.4, p=.011 in favor of personalized PointAssist compared to no assistance.</span></li>
<li id="NRB"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NRB"><span class="letterCode" style="float:right">NRB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NRB">Thu. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466427">Distraction Beyond the Driver: Predicting the Effects of In-Vehicle Interaction on Surrounding Traffic</a></span><br />
<span class="authors">D. Salvucci (Drexel Univ., USA)</span>
<div class="authorList"><span><span class="author">D. Salvucci</span> (Drexel Univ., USA)</span></div>
<p><span class="cbStatement">Describes a method for simulating the effects of driver distraction across multiple vehicles. Allows users to rapidly prototype and evaluate in-vehicle interfaces based on their potential for distraction.  </span><span class="abstract">Recent studies of driver distraction have reported a number of detrimental effects of in-vehicle interaction on driver performance. This paper examines and predicts the potential effects of such interaction on other vehicles around the driver’s vehicle. Specifically, the paper describes how computational cognitive models can be used to predict the complex interactions among several vehicles driving in a line when one or more of the vehicles’ drivers are performing a secondary task (phone dialing). The results of simulating two distinct car-following scenarios illustrate that in-vehicle interaction by one driver can have significant downstream effects on other drivers, especially with respect to speed deviations relative to a lead vehicle. This work generalizes recent work developing computational evaluation tools for user interfaces in complex domains, and further serves as an example of how user interaction in some domains can have broader effects on the community at large.</span></li>
<li id="PMD"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PMD"><span class="letterCode" style="float:right">PMD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PMD">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466432">Designing Graphical Menus for Novices and Experts: Connecting Design Characteristics with Design Goals</a></span><br />
<span class="authors">K. Samp (Digital Enterprise Research Institute, IE)</span>
<div class="authorList"><span><span class="author">K. Samp</span> (Digital Enterprise Research Institute, IE)</span></div>
<p><span class="cbStatement">This paper contributes a design space for graphical menus. It connects a set of design goals with a set of design characteristics. The design space helps create better menus.</span><span class="abstract">This paper presents a design space for graphical menus. We model the design space as a set of design goals, a set of design characteristics, and connections between the two. The design goals are based on novice and expert behaviors. The connections link the choices for design characteristics with the positive or negative effects that these choices have on the design goals. The paper further synthesizes the design space into a succinct form of structured design recommendations. A case study demonstrates how these recommendations can be used to assess and compare the strengths and weaknesses of two menu designs.</span></li>
<li id="PCQ"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PCQ"><span class="letterCode" style="float:right">PCQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PCQ">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466148">Direct Space-Time Trajectory Control  for Visual Media Editing</a></span><br />
<span class="authors">S. Santosa (Univ. of Toronto, CA), F. Chevalier, R. Balakrishnan, K. Singh</span>
<div class="authorList"><span><span class="author">S. Santosa</span> (Univ. of Toronto, CA)</span><span><span class="author">F. Chevalier</span> (Univ. of Toronto, CA)</span><span><span class="author">R. Balakrishnan</span> (Univ. of Toronto, CA)</span><span><span class="author">K. Singh</span> (Univ. of Toronto, CA)</span></div>
<p><span class="cbStatement">An exploration of the design space for using motion trajectories to edit visual elements across space and time. Pen-based techniques are introduced in DirectPaint: a video painting and annotation system.</span><span class="abstract">We explore the design space for using object motion trajectories to create and edit visual elements in various media across space and time. We introduce a suite of pen-based techniques that facilitate fluid stylization, annotation and editing of space-time content such as video, slide presentations and 2D animation, utilizing pressure and multi-touch input. We implemented and evaluated these techniques in DirectPaint, a system for creating free-hand painting and annotation over video. </span></li>
<li id="PRH"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PRH"><span class="letterCode" style="float:right">PRH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PRH">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466241">Design for Forgetting: Disposing of Digital Possessions after a Breakup</a></span><br />
<span class="authors">C. Sas (Lancaster Univ., UK), S. Whittaker</span>
<div class="authorList"><span><span class="author">C. Sas</span> (Lancaster Univ., UK)</span><span><span class="author">S. Whittaker</span> (Univ. of California at Santa Cruz, USA)</span></div>
<p><span class="cbStatement">This paper examines the challenges of digital possessions and their disposal following a romantic breakup. We found that digital possessions are often evocative and upsetting leading to distinct disposal strategies.</span><span class="abstract">People are increasingly acquiring huge collections of digital possessions. Despite some pleas for ‘forgetting’, most theorists argue for retaining all these possessions to enhance ‘total recall’ of our everyday lives. However, there has been little exploration of the negative role of digital possessions when people want to forget aspects of their lives. We report on interviews with 24 people about their possessions after a romantic breakup. We found that digital possessions were often evocative and upsetting in this context, leading to distinct disposal strategies with different outcomes. We advance theory by finding strong evidence for the value of intentional forgetting and provide new data about complex practices associated with the disposal of digital possessions. Our findings led to a number of design implications to help people better manage this process, including automatic harvesting of digital possessions, tools for self-control, artifact crafting as sense-making, and digital spaces for shared possessions.</span></li>
<li id="PKX"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PKX"><span class="letterCode" style="float:right">PKX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PKX">Thu. 11am</a></span><span class="award honorable"></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466430">Testing the Robustness and Performance of Spatially Consistent Interfaces</a></span><br />
<span class="authors">J. Scarr (Univ. of Canterbury, NZ), A. Cockburn, C. Gutwin, S. Malacria</span>
<div class="authorList"><span><span class="author">J. Scarr</span> (Univ. of Canterbury, NZ)</span><span><span class="author">A. Cockburn</span> (Univ. of Canterbury, NZ)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">S. Malacria</span> (Univ. of Canterbury, NZ)</span></div>
<p><span class="cbStatement">Examines how view transformations such as scaling and rotation influence item selection time. Demonstrates that scaling, which maintains spatial consistency, allows faster performance than the commonly used &#8216;reflow&#8217; layout scheme.</span><span class="abstract">Relative spatial consistency – that is, the stable arrangement of objects in a 2D presentation – provides several benefits for interactive interfaces. Spatial consistency allows users to develop memory of object locations, reducing the time needed for visual search, and because spatial memory is long lasting and has a large capacity these performance benefits are enduring and scalable. This suggests that spatial consistency could be used as a fundamental principle for the design of interfaces. However, there are many display situations where the standard presentation is altered in some way: e.g., a window is moved to a new location, scaled, or rotated on a mobile or tabletop display. It is not known whether the benefits of spatial organization are robust to these common kinds of view transformation. To assess these effects, we tested user performance with a spatial interface that had been transformed in several ways, including different degrees of translation, rotation, scaling, and perspective change. We found that performance was not strongly affected by the changes, except in the case of large rotations. To demonstrate the value of spatial consistency over existing mechanisms for dealing with view changes, we compared user performance with a spatially-stable presentation (using scaling) with that of a &#8216;reflowing&#8217; presentation (widely used in current interfaces). This study showed that spatial stability with scaling dramatically outperforms reflowing. This research provides new evidence of spatial consistency&#8217;s value in interface design: it is robust to the view transformations that occur in typical environments, and it provides substantial performance advantages over traditional methods.</span></li>
<li id="PTK"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/paper.html#PTK"><span class="letterCode" style="float:right">PTK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PTK">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470678">Creating and Analyzing Stereoscopic 3D Graphical User Interfaces in Digital Games</a></span><br />
<span class="authors">J. Schild (Univ. of Duisburg-Essen, DE), L. Bölicke, J. LaViola Jr., M. Masuch</span>
<div class="authorList"><span><span class="author">J. Schild</span> (Univ. of Duisburg-Essen, DE)</span><span><span class="author">L. Bölicke</span> (Univ. of Duisburg-Essen, DE)</span><span><span class="author">J. LaViola Jr.</span> (Univ. of Central Florida, USA)</span><span><span class="author">M. Masuch</span> (Univ. of Duisburg-Essen, DE)</span></div>
<p><span class="cbStatement">Supports GUI designers with a design space to create stereoscopic 3D GUIs for games. Our evaluation shows that perceptual, spatial and diegetic integration provide helpful constraints for influencing user experience.</span><span class="abstract">Creating graphical user interfaces (GUI) for stereoscopic 3D (S3D) games is a difficult choice between visual comfort and effect. We present a S3D Game GUI Design Space and a list of S3D-specific attributes that emphasizes integrating visually comfortable interfaces into the game world, story and S3D view. To showcase our approach, we created two GUI concepts and evaluated them with 32 users. Our results show quality improvements for a combination of bottom position and visual attachment for a menu. In a referencing interface, placing the reference near to the target depth significantly improved perceived quality, game integration, and increased presence. These results confirm the need to create S3D GUIs with perceptual constraints in mind, demonstrating the potential to extend the user experience. Additionally, our design space offers a formal and flexible way to create new effects in S3D GUIs.</span></li>
<li id="PTV"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/paper.html#PTV"><span class="letterCode" style="float:right">PTV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTV">Tue. 4pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466227">Screenfinity: Extending the Perception Area of Content on Very Large Public Displays</a></span><br />
<span class="authors">C. Schmidt (Telekom Innovation Laboratories, TU Berlin, DE), J. Müller, G. Bailly</span>
<div class="authorList"><span><span class="author">C. Schmidt</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span><span><span class="author">J. Müller</span> (Univ. of the Arts, DE)</span><span><span class="author">G. Bailly</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span></div>
<p><span class="cbStatement">Presents a model for the perception area of visual interfaces, and a novel public display increasing the perception area and allowing interaction while walking. Useful for designers of large displays.</span><span class="abstract">We propose and validate a model of the perception area of content on public displays in order to predict from where users can read. From this model, we derive Screenfinity, a technique to rotate, translate, and zoom content in order to enable reading while passing by very large displays. Screenfinity is comfortable to read when close, supports different content for different users, does not waste screen real estate and allows expert passers-by to read content while walking. A laboratory study shows that expert users are able to perceive content when it moves. A field study evaluates the effect of Screenfinity on novice users in an ecologically valid setting. We find 1) first time users can read content without slowing down or stopping; 2) Passers-by stopping did so to explore the technology. Users explore the interaction, the limits of the system, manipulate the technology, and look behind the screen.</span></li>
<li id="PBB"class="presentation design engineering"><a href="http://chi2013.acm.org/previews/paper.html#PBB"><span class="letterCode" style="float:right">PBB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PBB">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466457">Personal Clipboards for Individual Copy-and-Paste on Shared Multi-User Surfaces</a></span><br />
<span class="authors">D. Schmidt (Hasso Plattner Institute, DE), C. Sas, H. Gellersen</span>
<div class="authorList"><span><span class="author">D. Schmidt</span> (Hasso Plattner Institute, DE)</span><span><span class="author">C. Sas</span> (Lancaster Univ., UK)</span><span><span class="author">H. Gellersen</span> (Lancaster Univ., UK)</span></div>
<p><span class="cbStatement">Introduces personal clipboards for individual copy-and-paste to multi-user surfaces by implementing three clipboard systems. Provides better understanding of user-identification strategies and can guide the design of personalized surface applications.</span><span class="abstract">Clipboards are omnipresent on today’s personal computing platforms. They provide copy-and-paste functionalities that let users easily reorganize information and quickly transfer data across applications. In this work, we introduce personal clipboards to multi-user surfaces. Personal clipboards enable individual and independent copy-and-paste operations, in the presence of multiple users concurrently sharing the same direct-touch interface. As common surface computing platforms do not distinguish touch input of different users, we have developed clipboards that leverage complementary personalization strategies. Specifically, we have built a context menu clipboard based on implicit user identification of every touch, a clipboard based on personal subareas dynamically placed on the surface, and a handheld clipboard based on integration of personal devices for surface interaction. In a user study, we demonstrate the effectiveness of personal clipboards for shared surfaces, and show that different personalization strategies enable clipboards, albeit with different impacts on interaction characteristics.</span></li>
<li id="PBF"class="presentation sustainability"><a href="http://chi2013.acm.org/previews/paper.html#PBF"><span class="letterCode" style="float:right">PBF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBF">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466154">Cultivating Energy Literacy— Results from a Longitudinal Living Lab Study  of a Home Energy Management System</a></span><br />
<span class="authors">T. Schwartz (Fraunhofer Institute for Applied Information Technology (FIT), DE), S. Denef, G. Stevens, L. Ramirez, V. Wulf</span>
<div class="authorList"><span><span class="author">T. Schwartz</span> (Fraunhofer Institute for Applied Information Technology (FIT), DE)</span><span><span class="author">S. Denef</span> (Fraunhofer Institute for Applied Information Technology (FIT), DE)</span><span><span class="author">G. Stevens</span> (Institut of Information Systems / Univ. of Siegen , DE)</span><span><span class="author">L. Ramirez</span> (Fraunhofer Institute for Applied Information Technology (FIT), DE)</span><span><span class="author">V. Wulf</span> (Univ. of Siegen, DE)</span></div>
<p><span class="cbStatement">The paper presents a 13-month living lab study around the use of Home Energy Management Systems and introduces and discusses the concept of energy literacy as a key observed category.</span><span class="abstract">This paper presents results of a three-year research project focused on the emplacement of Home Energy Management Systems (HEMS) in a living lab setting with seven households. The HEMS used in this study allowed householders to monitor energy consumption both in real-time and in retrospective on the TV and on mobile devices. Contrasting with existing research focused on how technology persuades people to consume less energy, our study uses a grounded approach to analyze HEMS emplacement. As an important result, we present here the issue of ‘energy literacy’. Our study reveals that, by using HEMS, participants became increasingly literate in understanding domestic electricity consumption. We discuss the role HEMS played in that process and how the acquired literacy changed energy consumption patterns. We conclude that literacy in energy consumption has value on its own and explain how eco feedback system designs can benefit from this understanding.</span></li>
<li id="PJY"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PJY"><span class="letterCode" style="float:right">PJY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PJY">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481343">When the Price Is Right: Enabling Time-Dependent Pricing of Broadband Data</a></span><br />
<span class="authors">S. Sen (Princeton Univ., USA), C. Joe-Wong, S. Ha, J. Bawa, M. Chiang</span>
<div class="authorList"><span><span class="author">S. Sen</span> (Princeton Univ., USA)</span><span><span class="author">C. Joe-Wong</span> (Princeton Univ., USA)</span><span><span class="author">S. Ha</span> (Princeton Univ., USA)</span><span><span class="author">J. Bawa</span> (Princeton Univ., USA)</span><span><span class="author">M. Chiang</span> (Princeton Univ., USA)</span></div>
<p><span class="cbStatement">We study economics and user behavior jointly within HCI and report on qualitative findings from a trial of time-dependent pricing for mobile data to help reduce network congestion.</span><span class="abstract">In an era of 108% annual growth in demand for mobile data and $10/GB overage fees, Internet Service Providers (ISPs) are experiencing severe congestion and in turn are hurting consumers with aggressive pricing measures. But smarter practices, such as time-dependent pricing (TDP), reward users for shifting their non-critical demand to off-peak hours and can potentially benefit both users and ISPs. Although dynamic TDP ideas have existed for many years, dynamic pricing for mobile data is only now gaining interest among ISPs. Yet TDP plans require not only systems engineering but also an understanding of economic incentives, user behavior and interface design. In particular, the HCI aspects of communicating price feedback signals from the network and the response of mobile data users need to be studied in the real world. But investigating these issues by deploying a virtual TDP data plan for real ISP customers is challenging and rarely explored. To this end, we carried out the first TDP trial for mobile data in the US with 10 families. We describe the insights gained from the trial, which can help the HCI community as well as ISPs, app developers and designers create tools that empower users to better control their usage and save on their monthly bills, while also alleviating network congestion.</span></li>
<li id="PNN"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PNN"><span class="letterCode" style="float:right">PNN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PNN">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481421">Bezel-Tap Gestures: Quick Activation of Commands from Sleep Mode on Tablets</a></span><br />
<span class="authors">M. Serrano (Telecom ParisTech, FR), E. Lecolinet, Y. GUIARD</span>
<div class="authorList"><span><span class="author">M. Serrano</span> (Telecom ParisTech, FR)</span><span><span class="author">E. Lecolinet</span> (Telecom ParisTech, FR)</span><span><span class="author">Y. GUIARD</span> (Telecom ParisTech, FR)</span></div>
<p><span class="cbStatement">Mobile devices constantly switch to sleep mode to save energy. Our contribution is an  always-available shortcuts technique based on combining a bezel tap and a touchscreen contact. </span><span class="abstract">We present Bezel-Tap Gestures, a novel family of interaction techniques for immediate interaction on handheld tablets regardless of whether the device is alive or in sleep mode. The technique rests on the close succession of two input events: first a bezel tap, whose detection by accelerometers will awake an idle tablet almost instantly, then a screen contact. Field studies confirmed that the probability of this input sequence occurring by chance is very low, excluding the accidental activation concern. One experiment examined the optimal size of the vocabulary of commands for all four regions of the bezel (top, bottom, left, right). Another experiment evaluated two variants of the technique which both allow two-level selection in a hierarchy of commands, the initial bezel tap being followed by either two screen taps or a screen slide. The data suggests that Bezel-Tap Gestures may serve to design large vocabularies of micro-interactions with a sleeping tablet.</span></li>
<li id="PQH"class="presentation ux arts"><a href="http://chi2013.acm.org/previews/paper.html#PQH"><span class="letterCode" style="float:right">PQH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQH">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466266">Let’s Get Together: The Formation and Success of Online Creative Collaborations</a></span><br />
<span class="authors">B. Settles (Carnegie Mellon Univ., USA), S. Dow</span>
<div class="authorList"><span><span class="author">B. Settles</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">S. Dow</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We study an online music community by combining a novel path-based regression analysis of the social network with traditional member surveys, uncovering factors that affect online creative collaborations.</span><span class="abstract">In online creative communities, members work together to produce music, movies, games, and other cultural products. Despite the proliferation of collaboration in these communities, we know little about how these teams form and what leads to their ultimate success. Building on theories of social identity and exchange, we present an exploratory study of an online songwriting community. We analyze four years of longitudinal behavioral data using a novel path-based regression model that accurately predicts and reveals key variables about collab formation. Combined with a large-scale survey of members, we find that communication, nuanced complementary interest and status, and a balanced effort from both parties contribute to successful collaborations. We also discuss several applications of these findings for socio-technical infrastructures that support online creative production.  </span></li>
<li id="NMT"class="presentation management ux"><a href="http://chi2013.acm.org/previews/paper.html#NMT"><span class="letterCode" style="float:right">NMT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NMT">Mon. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470660">Using Contextual Integrity to Examine Interpersonal Information Boundary on Social Network Sites</a></span><br />
<span class="authors">P. Shi (The Pennsylvania State Univ., USA), H. Xu, Y. Chen</span>
<div class="authorList"><span><span class="author">P. Shi</span> (The Pennsylvania State Univ., USA)</span><span><span class="author">H. Xu</span> (The Pennsylvania State Univ., USA)</span><span><span class="author">Y. Chen</span> (Univ. of California, Irvine, USA)</span></div>
<p><span class="cbStatement">Through a case analysis of Friendship Pages on Facebook, this paper identifies users&#8217; interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity.</span><span class="abstract">Although privacy problems in Social Network Sites (SNS) have become more salient than ever in recent years, interpersonal privacy issues in SNS remain understudied. This study aims to generate insights in understanding users&#8217; interpersonal privacy concerns by expounding interpersonal privacy boundaries in SNS. Through a case analysis of Friendship Pages on Facebook, this paper identifies users&#8217; interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity, as well as the tensions that occur within and cross these informational norms. This paper concludes with a discussion of design implications and future research.</span></li>
<li id="PDT"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PDT"><span class="letterCode" style="float:right">PDT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PDT">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481295">SeeSay and HearSay CAPTCHAs for Mobile Interaction</a></span><br />
<span class="authors">S. Shirali-Shahreza (Univ. of Toronto, CA), G. Penn, R. Balakrishnan, Y. Ganjali</span>
<div class="authorList"><span><span class="author">S. Shirali-Shahreza</span> (Univ. of Toronto, CA)</span><span><span class="author">G. Penn</span> (Univ. of Toronto, CA)</span><span><span class="author">R. Balakrishnan</span> (Univ. of Toronto, CA)</span><span><span class="author">Y. Ganjali</span> (Univ. of Toronto, CA)</span></div>
<p><span class="cbStatement">We propose two alternative designs for CAPTCHAs in which the user says the answer instead of typing it. Output stimuli are provided visually (SeeSay) or auditorily (HearSay).</span><span class="abstract">Speech certainly has advantages as an input modality for smartphone applications, especially in scenarios where using touch or keyboard entry is difficult, on increasingly miniaturized devices where useable keyboards are difficult to accommodate, or in scenarios where only small amounts of text need to be input, such as when entering SMS texts or responding to a CAPTCHA challenge. In this paper, we propose two new alternative ways to design CAPTCHAs in which the user says the answer instead of typing it with (a) output stimuli provided visually (SeeSay) or (b) auditorily (HearSay). Our user study results show that SeeSay CAPTCHA requires less time to be solved and users prefer it over current text-based CAPTCHA methods.</span></li>
<li id="PPL"class="presentation sustainability HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PPL"><span class="letterCode" style="float:right">PPL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPL">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466261">Deep Conservation in Urban India and its Implications for the Design of Conservation Technologies</a></span><br />
<span class="authors">Y. Shrinivasan (IBM Research, IN), M. Jain, D. Seetharam, A. Choudhary, E. Huang, T. Dillahunt, J. Mankoff</span>
<div class="authorList"><span><span class="author">Y. Shrinivasan</span> (IBM Research, IN)</span><span><span class="author">M. Jain</span> (IBM Research, IN)</span><span><span class="author">D. Seetharam</span> (IBM Research, IN)</span><span><span class="author">A. Choudhary</span> (IBM Research, IN)</span><span><span class="author">E. Huang</span> (Univ. of Zurich, CH)</span><span><span class="author">T. Dillahunt</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Mankoff</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We present a study of energy, water and fuel conservation practices in  urban India to highlight a culture of deep conservation and identify new  opportunities for relevant resource conservation technologies.</span><span class="abstract">Rapid depletion of fossil fuels and water resources has become an international problem. Urban residential households are among the primary consumers of resources and are deeply affected by resource shortages. Despite the global nature of these problems, most of the solutions being developed to address these issues are based on studies done in the developed world. We present a study of energy, water and fuel conservation practices in urban India. Our study highlights a culture of deep conservation and the results raise questions about the viability of typical solutions such as home energy monitors. We identify new opportunities for design such as point-of-use feedback technologies, modular solutions, distributed energy storage, harnessing by-products and automated load shifting.</span></li>
<li id="NGT"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NGT"><span class="letterCode" style="float:right">NGT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NGT">Wed. 9am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481288">Non-parametric Decision Trees and Online HCI</a></span><br />
<span class="authors">T. Sko (Australian National Univ., AU), H. Gardner, M. Martin</span>
<div class="authorList"><span><span class="author">T. Sko</span> (Australian National Univ., AU)</span><span><span class="author">H. Gardner</span> (Australian National Univ., AU)</span><span><span class="author">M. Martin</span> (Australian National Univ., AU)</span></div>
<p><span class="cbStatement">Through an online study of head interaction techniques, we show that classification and regression trees provide a practical way to analyse the large and complex datasets typical of online HCI.</span><span class="abstract">This paper proposes that online HCI studies (such as web-surveys and remotely monitored usability tests) can benefit from statistical data analysis using modern statistical learning methods such as classification and regression trees (CARTs). Applying CARTs to the often large amount of data yielded by online studies can easily provide clarity concerning the most important effects underlying experimental data in situations where myriad possible factors are under consideration. The feedback provided by such an analysis can also provide valuable reflection on the experimental methodology. We discuss these matters with reference to a study of 1300 participants in a structured experiment concerned with head-interaction techniques for first-person-shooter games. </span></li>
<li id="PHE"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHE"><span class="letterCode" style="float:right">PHE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PHE">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466448">“I read my Twitter the next morning and was astonished” A Conversational Perspective on Twitter Regrets</a></span><br />
<span class="authors">M. Sleeper (Carnegie Mellon Univ., USA), J. Cranshaw, P. Kelley, B. Ur, A. Acquisti, L. Cranor, N. Sadeh</span>
<div class="authorList"><span><span class="author">M. Sleeper</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Cranshaw</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">P. Kelley</span> (Univ. of New Mexico, USA)</span><span><span class="author">B. Ur</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Acquisti</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">L. Cranor</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">N. Sadeh</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">Presents the results of a large-scale online survey that compares regretted tweets and regrets from in-person conversations. Examines the context, timing, means of awareness, and repair strategies for the regrettable messages.</span><span class="abstract">We present the results of an online survey of 1,221 Twitter users, comparing messages individuals regretted either saying during in-person conversations or posting on Twitter. Participants generally reported similar types of regrets in person and on Twitter. In particular, they often regretted messages that were critical of others. However, regretted messages that were cathartic/expressive or revealed too much information were reported at a higher rate for Twitter. Regretted messages on Twitter also reached broader audiences. In addition, we found that participants who posted on Twitter became aware of, and tried to repair, regret more slowly than those reporting in-person regrets. From this comparison of Twitter and in-person regrets, we provide preliminary ideas for tools to help Twitter users avoid and cope with regret. </span></li>
<li id="PMB"class="presentation design engineering games"><a href="http://chi2013.acm.org/previews/paper.html#PMB"><span class="letterCode" style="float:right">PMB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PMB">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470679">BeThere: 3D Mobile Collaboration with Spatial Input</a></span><br />
<span class="authors">R. Sodhi (Univ. of Illinois at Urbana-Champaign, USA), B. Jones, D. Forsyth, B. Bailey, G. Maciocci</span>
<div class="authorList"><span><span class="author">R. Sodhi</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">B. Jones</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">D. Forsyth</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">B. Bailey</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">G. Maciocci</span> (Qualcomm Corporate R&#038;D, UK)</span></div>
<p><span class="cbStatement">We contribute a proof-of-concept system and interactions that show how mobile devices equipped with depth sensors can leverage spatial input and knowledge of our 3D environment to enrich communication.</span><span class="abstract">We present BeThere, a proof-of-concept system designed to explore 3D input for mobile collaborative interactions. With BeThere, we explore 3D gestures and spatial input which al- low remote users to perform a variety of virtual interactions in a local user’s physical environment. Our system is completely self-contained and uses depth sensors to track the location of a user’s fingers as well as to capture the 3D shape of objects in front of the sensor. We illustrate the unique capabilities of our system through a series of interactions that allow users to control and manipulate 3D virtual content. We also pro- vide qualitative feedback from a preliminary user study which confirmed that users can complete a shared collaborative task using our system.</span></li>
<li id="PEQ"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PEQ"><span class="letterCode" style="float:right">PEQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEQ">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481394">Design-Driven Narrative: Using Stories to Prototype and Build Immersive Design Worlds</a></span><br />
<span class="authors">E. Spaulding (AT&#038;T Foundry, USA), H. Faste</span>
<div class="authorList"><span><span class="author">E. Spaulding</span> (AT&#038;T Foundry, USA)</span><span><span class="author">H. Faste</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">This paper examines the role of narrative in the process of interactive experience design, focusing on its potential uses in prototyping to uncover deeper and more meaningful user responses.</span><span class="abstract">This paper examines the role of narrative in the process of interactive experience design, focusing on the potential uses of narrative in prototyping and iteration efforts to uncover deeper and more meaningful responses from users by engaging them in the co-creation of narratives of use around the design. We created a series of narrative fictions with embedded design concepts, and built low-fi prototype artifacts for directed storytelling sessions with twelve participants. We conclude with a discussion of findings regarding the opportunities to more effectively use narrative techniques and immersive storytelling to create valuable experiences between designers and users.</span></li>
<li id="PHP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHP"><span class="letterCode" style="float:right">PHP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PHP">Thu. 11am</a></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466449">Understanding Motivations for Facebook Use: Usage Metrics, Network Structure, and Privacy</a></span><br />
<span class="authors">T. Spiliotopoulos (Univ. of Madeira, PT), I. Oakley</span>
<div class="authorList"><span><span class="author">T. Spiliotopoulos</span> (Univ. of Madeira, PT)</span><span><span class="author">I. Oakley</span> (Univ. of Madeira, PT)</span></div>
<p><span class="cbStatement">A study on motivations for Facebook use that couples social science methods with information captured by the Facebook API in the form of detailed usage data and personal network metrics.</span><span class="abstract">This study explores the links between motives for using a social network service and numerical measures of that activity. Specifically, it identified motives for Facebook use by employing a Uses and Gratifications (U&#038;G) approach and then investigated the extent to which these motives can be predicted through usage and network metrics collected automatically via the Facebook API. In total, 11 Facebook usage metrics and eight personal network metrics served as predictors. Results showed that all three variable types in this expanded U&#038;G frame of analysis (covering social antecedents, usage metrics, and personal network metrics) effectively predicted motives and highlighted interesting behaviors. To further illustrate the power of this framework, the intricate nature of privacy in social media was explored and relationships drawn between privacy attitudes (and acts) and measures of use and network structure.</span></li>
<li id="PHF"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHF"><span class="letterCode" style="float:right">PHF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PHF">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470769">Delivering Patients to Sacré Coeur: Collective Intelligence in Digital Volunteer Communities</a></span><br />
<span class="authors">K. Starbird (Univ. of Washington, USA)</span>
<div class="authorList"><span><span class="author">K. Starbird</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">This study examines the activities of digital volunteers during crisis events, using a distributed cognition perspective to demonstrate how individual ICT users function together as a collectively intelligent cognitive system.</span><span class="abstract">This study examines the information-processing activities of digital volunteers and other connected ICT users in the wake of crisis events. Synthesizing findings from several previous research studies of digital volunteerism, this paper offers a new approach for conceptualizing the activities of digital volunteers, shifting from a focus on organizing to a focus on information movement. Using the lens of distributed cognition, this research describes collective intelligence as transformations of information within a system where cognition is distributed socially across individuals as well as through their tools and resources. This paper demonstrates how digital volunteers, through activities such as relaying, amplifying, verifying, and structuring information, function as a collectively intelligent cognitive system in the wake of disaster events.</span></li>
<li id="PCV"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PCV"><span class="letterCode" style="float:right">PCV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PCV">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470688">Flexpad: Highly Flexible Bending Interactions for Projected Handheld Displays</a></span><br />
<span class="authors">J. Steimle (Massachusetts Institute of Technology, USA), A. Jordt, P. Maes</span>
<div class="authorList"><span><span class="author">J. Steimle</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">A. Jordt</span> (Kiel Univ. of Applied Sciences, DE)</span><span><span class="author">P. Maes</span> (Massachusetts Institute of Technology, USA)</span></div>
<p><span class="cbStatement">Introduces highly flexible handheld displays as user interfaces. Contributes a novel real-time method for capturing complex deformations of flexible surfaces and novel interactions that leverage highly flexible deformations of displays.</span><span class="abstract">Flexpad is an interactive system that combines a depth camera and a projector to transform sheets of plain paper or foam into flexible, highly deformable, and spatially aware handheld displays. We present a novel approach for tracking deformed surfaces from depth images in real time. It captures deformations in high detail, is very robust to occlusions created by the user’s hands and fingers, and does not require any kind of markers or visible texture. As a result, the display is considerably more deformable than in previous work on flexible handheld displays, enabling novel applications that leverage the high expressiveness of detailed deformation. We illustrate these unique capabilities through three application examples: curved cross-cuts in volumetric images, deforming virtual paper characters, and slicing through time in videos. Results from two user studies show that our system is capable of detecting complex deformations and that users are able to perform them quickly and precisely.</span></li>
<li id="PPN"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PPN"><span class="letterCode" style="float:right">PPN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PPN">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470695">Still Looking: Investigating Seamless Gaze-supported Selection, Positioning, and Manipulation of Distant Targets</a></span><br />
<span class="authors">S. Stellmach (Technische Univ. Dresden, DE), R. Dachselt</span>
<div class="authorList"><span><span class="author">S. Stellmach</span> (Technische Univ. Dresden, DE)</span><span><span class="author">R. Dachselt</span> (Technische Univ. Dresden, DE)</span></div>
<p><span class="cbStatement">Describes and compares interaction techniques for combining gaze/head and touch input for fluently selecting, positioning and manipulating distant graphical objects. This can help supporting more seamless interactions with distant displays.</span><span class="abstract">We investigate how to seamlessly bridge the gap between users and distant displays for basic interaction tasks, such as object selection and manipulation. For this, we take advantage of very fast and implicit, yet imprecise gaze- and head-directed input in combination with ubiquitous smartphones for additional manual touch control. We have carefully elaborated two novel and consistent sets of gaze-supported interaction techniques based on touch-enhanced gaze pointers and local magnification lenses. These conflict-free sets allow for fluently selecting and positioning distant targets. Both sets were evaluated in a user study with 16 participants. Overall, users were fastest with a touch-enhanced gaze pointer for selecting and positioning an object after some training. While the positive user feedback for both sets suggests that our proposed gaze- and head-directed interaction techniques are suitable for a convenient and fluent selection and manipulation of distant targets, further improvements are necessary for more precise cursor control.</span></li>
<li id="NFB"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#NFB"><span class="letterCode" style="float:right">NFB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NFB">Tue. 2pm</a></span><span class="award best"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466193">NailDisplay: Bringing an Always Available Visual Display to Fingertips</a></span><br />
<span class="authors">C. Su (National Taiwan Univ., TW), L. Chan, C. Weng, R. Liang, K. Cheng, B. Chen</span>
<div class="authorList"><span><span class="author">C. Su</span> (National Taiwan Univ., TW)</span><span><span class="author">L. Chan</span> (Academia Sinica, TW)</span><span><span class="author">C. Weng</span> (National Taiwan Univ., TW)</span><span><span class="author">R. Liang</span> (Academia Sinica, TW)</span><span><span class="author">K. Cheng</span> (National Taiwan Univ., TW)</span><span><span class="author">B. Chen</span> (National Taiwan Univ., TW)</span></div>
<p><span class="cbStatement">Explores the possibility of turing fingernails into places for system input and visual output by adding a nail-mounted display.</span><span class="abstract">This work presents a novel and always-available nail mounted display known as NailDisplay. The proposed display augments the use of a finger  by allowing for always-available visual feedback owing to its fast accessibility and  binding user controls with the display, i.e. what you control is what you see (through the display). Potential benefits of NailDisplay are demonstrated in three applications: from displaying to combining it with user controls. In the first application, NailDisplay can reveal what is occluded under a finger touch, making it a solution to operate small UI elements. In the second application, NailDisplay is complementary to an imaginary interface,  helping users to learn an imaginary interface (e.g., on the users&#8217; arms) and allowing them to reassure the interface when their memory of it becomes unclear. In the third application, NailDisplay is integrated with rich finger interactions, such as swiping in the air. We also report users&#8217; feedbacks gathered from an explorative user study. </span></li>
<li id="PDE"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PDE"><span class="letterCode" style="float:right">PDE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PDE">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470689">A Multi-touch Interface for Fast Architectural Sketching and Massing</a></span><br />
<span class="authors">Q. Sun (Nanyang Technological Univ., SG), J. Lin, C. Fu, S. Kaijima, Y. He</span>
<div class="authorList"><span><span class="author">Q. Sun</span> (Nanyang Technological Univ., SG)</span><span><span class="author">J. Lin</span> (Xiamen Univ., CN)</span><span><span class="author">C. Fu</span> (Nanyang Technological Univ., SG)</span><span><span class="author">S. Kaijima</span> (Singapore Univ. of Technology and Design, SG)</span><span><span class="author">Y. He</span> (Nanyang Technological Univ., SG)</span></div>
<p><span class="cbStatement">This paper proposes a novel multi-touch interface for architectural Sketching and Massing; it offers a rich set of direct finger gestures for rapid prototyping of contemporary building designs.  </span><span class="abstract">Architectural sketching and massing are used by designers to analyze and explore the design space of buildings.  This paper describes a novel multi-touch interface for fast architectural sketching and massing of tall buildings.  It incorporates a family of multi-touch gestures, enabling one to quickly sketch the 2D contour of a base floor plan and extrude it to model a building with multi-floor structures.  Further, it provides a set of gestures to users: select and edit a range of floors; scale contours of a building; copy, paste, and rotate a building, i.e., create a twisted structure; edit profile curves of a building&#8217;s profile; and collapse and remove a selected range of floors.  The multi-touch system also allows users to apply textures or geometric facades to the building, and to compare different designs side-by-side.  To guide the design process, we describe interactions with a domain expert, a practicing architect.  The final interface is evaluated by architects and students in an architecture department, which demonstrates that the system allows rapid conceptual design and massing of novel multi-story building structures.</span></li>
<li id="PLU"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PLU"><span class="letterCode" style="float:right">PLU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLU">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466230">Messaging to Your Doctors: Understanding Patient-Provider Communications via a Portal System</a></span><br />
<span class="authors">S. Sun (Rutgers Univ., USA), X. Zhou, J. Denny, T. Rosenbloom, H. Xu</span>
<div class="authorList"><span><span class="author">S. Sun</span> (Rutgers Univ., USA)</span><span><span class="author">X. Zhou</span> (Rutgers Univ., USA)</span><span><span class="author">J. Denny</span> (Vanderbilt Univ., USA)</span><span><span class="author">T. Rosenbloom</span> (Vanderbilt Univ., USA)</span><span><span class="author">H. Xu</span> (Vanderbilt Univ., USA)</span></div>
<p><span class="cbStatement">The paper presents a qualitative study on patient-provider communication messages via a patient portal system. We analyze communication themes and investigate portal&#8217;s impacts on healthcare delivery and information management issues.</span><span class="abstract">The patient portal is a relatively new healthcare information technology that enables patients more convenient access to their healthcare information and allows them to send messages to their doctors. Our study examines the themes discussed in these messages and the different ways in which patients communicate with their providers via a portal employed in a large medical center. We also explore the differences between the patient portal and more traditional communication media, and investigated the advantages and potential problems of the portal system. Our findings show a wide variety of topics discussed in the communication messages (such as medication, appointments, laboratory tests, etc.) and how patients provide information, consult with their providers, and express psychosocial and emotional needs. We argue that the patient portal improves the accuracy of communication and could facilitate illness management for patients, especially over a longer term. However, messaging through the patient portal is not popular among patients and the simultaneous use of multiple communication media may create information gaps. More research is needed to better elucidate barriers to the use of patient portals and the optimal methods of communication and information integration given different contexts.</span></li>
<li id="PHU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHU"><span class="letterCode" style="float:right">PHU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PHU">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470758">Improving Digital Object Handoff Using the Space Above the Table</a></span><br />
<span class="authors">S. Sutcliffe (Univ. of Saskatchewan, CA), Z. Ivkovic, D. Flatla, A. Pavlovych, I. Stavness, C. Gutwin</span>
<div class="authorList"><span><span class="author">S. Sutcliffe</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">Z. Ivkovic</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">D. Flatla</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">A. Pavlovych</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">I. Stavness</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span></div>
<p><span class="cbStatement">We developed and evaluated two new above-the-table digital object handoff techniques, Force-Field and a new innovation ElectroTouch, and found they are significantly faster and less error-prone than traditional surface-only techniques.</span><span class="abstract">Object handoff – that is, passing an object or tool to another person – is an extremely common activity in collaborative tabletop work. On digital tables, object handoff is typically accomplished by sliding them on the table surface – but surface-only interactions can be slow and error-prone, particularly when there are multiple people carrying out multiple handoffs. An alternative approach is to use the space above the table for object handoff; this provides more room to move, but requires above-surface tracking. We have developed two above-the-surface handoff techniques that use simple and inexpensive tracking: a force-field technique that uses a depth camera to determine hand proximity, and an electromagnetic-field technique called ElectroTouch that provides positive indication when people touch hands over the table. We compared the new techniques to three kinds of surface-only handoff (sliding, flicking, and surface-only Force-Fields). The study showed that the above-surface techniques significantly improved both speed and accuracy, and that ElectroTouch was the best technique overall. This work provides designers with practical new techniques for substantially increasing performance and interaction richness on digital tables.</span></li>
<li id="PQE"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PQE"><span class="letterCode" style="float:right">PQE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQE">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466128">ARTFuL: Adaptive Review Technology for Flipped Learning</a></span><br />
<span class="authors">D. Szafir (Univ. of Wisconsin, Madison, USA), B. Mutlu</span>
<div class="authorList"><span><span class="author">D. Szafir</span> (Univ. of Wisconsin, Madison, USA)</span><span><span class="author">B. Mutlu</span> (Univ. of Wisconsin, Madison, USA)</span></div>
<p><span class="cbStatement">Presents adaptive content review technology for students engaged in online learning and empirical results supporting student learning gains. Offers design guidelines for technological support for flipped learning.</span><span class="abstract">Internet technology is revolutionizing education. Teachers are developing massive open online courses (MOOCs) and using innovative practices such as flipped learning in which students watch lectures at home and engage in hands-on, problem solving activities in class. This work seeks to explore the design space afforded by these novel educational paradigms and to develop technology for improving student learning. Our design, based on the technique of adaptive content review, monitors student attention during educational presentations and determines which lecture topic students might benefit the most from reviewing. An evaluation of our technology within the context of an online art history lesson demonstrated that adaptively reviewing lesson content improved student recall abilities 29% over a baseline system and was able to match recall gains achieved by a full lesson review in less time. Our findings offer guidelines for a novel design space in dynamic educational technology that might support both teachers and online tutoring systems.</span></li>
<li id="PSL"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PSL"><span class="letterCode" style="float:right">PSL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PSL">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466223">The Design and Field Observation of a Haptic Notification System for Timing Awareness During Oral Presentations</a></span><br />
<span class="authors">D. Tam (Univ. of British Columbia, CA), K. MacLean, J. McGrenere, K. Kuchenbecker</span>
<div class="authorList"><span><span class="author">D. Tam</span> (Univ. of British Columbia, CA)</span><span><span class="author">K. MacLean</span> (Univ. of British Columbia, CA)</span><span><span class="author">J. McGrenere</span> (Univ. of British Columbia, CA)</span><span><span class="author">K. Kuchenbecker</span> (Univ. of Pennsylvania, USA)</span></div>
<p><span class="cbStatement">A novel presentation timing approach (automated tactile cues augment chair-speaker communication) is explored with iterative design and observation in live conference settings. Qualitative evaluation generates stakeholder needs and design recommendations.</span><span class="abstract">To moderate oral presentations a chair must manage time, and communicate time parameters to speakers through a variety of means. But speakers often miss time cues, chairs cannot confirm their receipt, and the broken dialogue can be a sideshow for the audience. We developed HaNS, a wireless wrist-worn chair-speaker Haptic Notification System that delivers tactile cues for time-managing oral presentations, and performed field observations at university research seminars and two mid-sized academic conferences (input from 66 speakers, 21 chairs, and 65 audience members). Results indicate that HaNS can improve a user’s awareness of time, facilitate chair-speaker coordination, and reduce distraction of speaker and audience through its private communication channel. Eliminating overruns will require improvement in speaker ‘internal’ control, which our results suggest HaNS can also support given practice. We conclude with design guidelines for both conference-deployed and personal timing tools, using touch or another notification modality.</span></li>
<li id="NCK"class="presentation games sustainability"><a href="http://chi2013.acm.org/previews/paper.html#NCK"><span class="letterCode" style="float:right">NCK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NCK">Thu. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466464">Three Perspectives on Behavior Change for Serious Games</a></span><br />
<span class="authors">J. Tanenbaum (Simon Fraser Univ., CA), A. Antle, J. Robinson</span>
<div class="authorList"><span><span class="author">J. Tanenbaum</span> (Simon Fraser Univ., CA)</span><span><span class="author">A. Antle</span> (Simon Fraser Univ., CA)</span><span><span class="author">J. Robinson</span> (Univ. of British Columbia, CA)</span></div>
<p><span class="cbStatement">We introduce a model of behavior change and persuasion from Environmental Studies and consider its application for serious games for sustainability alongside two other commonly used models.</span><span class="abstract">Research into the effects of serious games often engages with interdisciplinary models of how human behaviors are shaped and changed over time. To better understand these different perspectives we articulate three cognitive models of behavior change and consider the potential of these models to support a deeper understanding of behavior change in serious games. Two of these models – Information Deficit and Procedural Rhetoric – have already been employed in the design of serious games, while the third – Emergent Dialogue – is introduced from the field of Environmental Studies.  We situate this discussion within a context of designing games for public engagement with issues of environmental sustainability.</span></li>
<li id="PJD"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PJD"><span class="letterCode" style="float:right">PJD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PJD">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481360">Democratizing Technology: Pleasure, Utility and Expressiveness in DIY and Maker Practice</a></span><br />
<span class="authors">J. Tanenbaum (Simon Fraser Univ., CA), A. Williams, A. Desjardins, K. Tanenbaum</span>
<div class="authorList"><span><span class="author">J. Tanenbaum</span> (Simon Fraser Univ., CA)</span><span><span class="author">A. Williams</span> (Wyld Collective Ltd, CA)</span><span><span class="author">A. Desjardins</span> (Simon Fraser Univ., CA)</span><span><span class="author">K. Tanenbaum</span> (Simon Fraser Univ., CA)</span></div>
<p><span class="cbStatement">A critical analysis of the practices, values, and politics of Maker and DIY Culture and its implications for HCI Research.</span><span class="abstract">DIY, hacking, and craft have recently drawn attention in HCI and CSCW, largely as a collaborative and creative hobbyist practice. We shift the focus from the recreational elements of this practice to the ways in which it democratizes design and manufacturing. This democratized technological practice, we argue, unifies playfulness, utility, and expressiveness, relying on some industrial infrastructures while creating demand for new types of tools and literacies. Thriving on top of collaborative digital systems, the Maker movement both implicates and impacts professional designers. As users move more towards personalization and reappropriation, new design opportunities are created for HCI.</span></li>
<li id="NFJ"class="presentation design ux cci"><a href="http://chi2013.acm.org/previews/paper.html#NFJ"><span class="letterCode" style="float:right">NFJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NFJ">Tue. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466175">HomeProxy: Exploring a Physical Proxy for Video Communication in the Home</a></span><br />
<span class="authors">J. Tang (Microsoft Research, USA), R. Xiao, A. Hoff, G. Venolia, P. Therien, A. Roseway</span>
<div class="authorList"><span><span class="author">J. Tang</span> (Microsoft Research, USA)</span><span><span class="author">R. Xiao</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Hoff</span> (Microsoft Research, USA)</span><span><span class="author">G. Venolia</span> (Microsoft Research, USA)</span><span><span class="author">P. Therien</span> (Microsoft Research, USA)</span><span><span class="author">A. Roseway</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">HomeProxy is a prototype system that supports video messaging in the home. It explores a “no-touch” user experience that allows transitioning from recorded to live video messages. </span><span class="abstract">HomeProxy is a research prototype that explores supporting video communication in the home among distributed family members through a physical proxy. It leverages a physical artifact dedicated to representing remote family members to make it easier to share activities with them. HomeProxy combines a form factor designed for the home environment with a “no-touch” user experience and an interface that responsively transitions between recorded and live video messages. We designed and implemented a prototype and conducted a pilot study with eight pairs of users. Our study demonstrated the challenges of a no-touch interface and the promise of offering quick video messaging in the home. </span></li>
<li id="PCP"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PCP"><span class="letterCode" style="float:right">PCP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PCP">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470720">Improving Teamwork Using Real-Time Language Feedback</a></span><br />
<span class="authors">Y. Tausczik (Carnegie Mellon Univ., USA), J. Pennebaker</span>
<div class="authorList"><span><span class="author">Y. Tausczik</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Pennebaker</span> (The Univ. of Texas at Austin, USA)</span></div>
<p><span class="cbStatement">We develop a real-time language feedback system that monitors the communication patterns among students in a discussion group and provides real-time instructions to shape the way the group works together.</span><span class="abstract">We develop and evaluate a real-time language feedback system that monitors the communication patterns among students in a discussion group and provides real-time instructions to shape the way the group works together. As an initial step, we determine which group processes are related to better outcomes. We then experimentally test the efficacy of providing real-time instructions which target two of these group processes. The feedback system was successfully able to shape the way groups worked together. However, only appropriate feedback given to groups that were not working well together from the start was able to improve group performance.</span></li>
<li id="PPS"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PPS"><span class="letterCode" style="float:right">PPS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PPS">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470725">At the Interface of Biology and Computation</a></span><br />
<span class="authors">A. Taylor (Microsoft Research, UK), N. Piterman, S. Ishtiaq, J. Fisher, B. Cook, C. Cockerton, S. Bourton, D. Benque</span>
<div class="authorList"><span><span class="author">A. Taylor</span> (Microsoft Research, UK)</span><span><span class="author">N. Piterman</span> (Univ. of Leicester, UK)</span><span><span class="author">S. Ishtiaq</span> (Microsoft Research, UK)</span><span><span class="author">J. Fisher</span> (Microsoft Research, UK)</span><span><span class="author">B. Cook</span> (Microsoft Research, UK)</span><span><span class="author">C. Cockerton</span> (Microsoft Research, UK)</span><span><span class="author">S. Bourton</span> (QuantumBlack, UK)</span><span><span class="author">D. Benque</span> (Royal college of Art, UK)</span></div>
<p><span class="cbStatement">Presents study of scientific tool for proving stabilization in biological systems. Shows how such tools, using new computational techniques, can introduce frictions but that these frictions can be used constructively.</span><span class="abstract">Representing a new class of tool for biological modeling, Bio Model Analyzer (BMA) uses sophisticated computational techniques to determine stabilization in cellular networks. This paper presents designs aimed at easing the problems that can arise when such techniques—using distinct approaches to conceptualizing networks—are applied in biology. The work also engages with more fundamental issues being discussed in the philosophy of science and science studies. It shows how scientific ways of knowing are constituted in routine interactions with tools like BMA, where the emphasis is on the practical business at hand, even when seemingly deep conceptual problems exist. For design, this perspective refigures the frictions raised when computation is used to model biology. Rather than obstacles, they can be seen as opportunities for opening up different ways of knowing. </span></li>
<li id="PGB"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGB"><span class="letterCode" style="float:right">PGB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGB">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466206">Leaving the Wild: Lessons from Community Technology Handovers</a></span><br />
<span class="authors">N. Taylor (Newcastle Univ., UK), K. Cheverst, P. Wright, P. Olivier</span>
<div class="authorList"><span><span class="author">N. Taylor</span> (Newcastle Univ., UK)</span><span><span class="author">K. Cheverst</span> (Lancaster Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">We examine two cases where research prototypes were handed over to participants at the end of projects and suggest best practices for leaving technologies in the wild.</span><span class="abstract">As research increasingly turns to work ‘in the wild’ to design and evaluate technologies under real-world conditions, little consideration has been given to what happens when research ends. In many cases, users are heavily involved in the design process and encouraged to integrate the resulting technologies into their lives before they are withdrawn, while in some cases technologies are being left in place after research concludes. Often, little is done to assess the impact and legacy of these deployments. In this paper, we return to two examples in which we designed technologies with the involvement of communities and examine what steps were taken to ensure their long-term viability and what happened following the departure of researchers. From these examples, we provide guidelines for planning and executing technology handovers when conducting research with communities. </span></li>
<li id="PDQ"class="presentation engineering games"><a href="http://chi2013.acm.org/previews/paper.html#PDQ"><span class="letterCode" style="float:right">PDQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PDQ">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470677">Pointing at 3D Target Projections with One-Eyed and Stereo Cursors</a></span><br />
<span class="authors">R. Teather (York Univ., CA), W. Stuerzlinger</span>
<div class="authorList"><span><span class="author">R. Teather</span> (York Univ., CA)</span><span><span class="author">W. Stuerzlinger</span> (York Univ., CA)</span></div>
<p><span class="cbStatement">We investigate 2D-projected 3D pointing tasks. In particular, we look at the modeling of perspective-scaled 3D targets in screen-plane pointing, while comparing mouse and remote pointing techniques.</span><span class="abstract">We present a study of cursors for selecting 2D-projected 3D targets. We compared a stereo- and mono-rendered (one-eyed) cursor using two mouse-based and two remote pointing techniques in a 3D Fitts’ law pointing experiment. The first experiment used targets at fixed depths. Results indicate that one-eyed cursors only improve screen-plane pointing techniques, and that constant target depth does not influence pointing throughput. A second experiment included pointing between targets at varying depths and used only “screen-plane” pointing techniques. Our results suggest that in the absence of stereo cue conflicts, screen-space projections of Fitts’ law parameters (target size and distance) yield constant throughput despite target depth differences and produce better models of performance. </span></li>
<li id="PEJ"class="presentation design health"><a href="http://chi2013.acm.org/previews/paper.html#PEJ"><span class="letterCode" style="float:right">PEJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEJ">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481366">Design to Promote Mindfulness Practice and Sense of Self for Vulnerable Women in Secure Hospital Services</a></span><br />
<span class="authors">A. Thieme (Newcastle Univ., UK), J. Wallace, P. Johnson, J. McCarthy, S. Lindley, P. Wright, P. Olivier, T. Meyer</span>
<div class="authorList"><span><span class="author">A. Thieme</span> (Newcastle Univ., UK)</span><span><span class="author">J. Wallace</span> (Northumbria Univ., UK)</span><span><span class="author">P. Johnson</span> (Calderstones Partnership NHS Foundation Trust, UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span><span><span class="author">S. Lindley</span> (Microsoft Research, UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span><span><span class="author">T. Meyer</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">Introduces the design concept of interactive artifacts to engage women with severe mental health problems in therapeutic skills practice. Provides insights from our collaboration with hospital staff for the design.</span><span class="abstract">In the field of mental health care technologies, very limited attention has been given to the design of interventions for individuals who undergo treatment for severe mental health problems in intense care contexts. Exploring novel designs to engage vulnerable psychiatric patients in therapeutic skills practice and expanding on the potential of technology to promote mental health, the paper introduces the design concept of the Spheres of Wellbeing. A set of interactive artifacts is developed specifically for women with a dual diagnosis of a Learning Disability and Borderline Personality Disorder, living in the medium secure services of a forensic hospital in the UK. The women present a difficult to treat group due to extremely challenging behaviors and a fundamental lack of motivation to engage in therapy. The Spheres are designed to assist the women in practices of mindfulness, to help them tolerate emotional distress and to strengthen their sense of self, all of which are vital components of their specialist treatment Dialectical Behavioral Therapy (DBT). The Spheres are intended to supplement the therapy of the women and to contribute to our understanding of designing technology to enhance mental wellbeing and quality of life more generally.</span></li>
<li id="PLQ"class="presentation design engineering health"><a href="http://chi2013.acm.org/previews/paper.html#PLQ"><span class="letterCode" style="float:right">PLQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLQ">Tue. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466190">Reasons to Question Seven Segment Displays</a></span><br />
<span class="authors">H. Thimbleby (Swansea Univ., UK)</span>
<div class="authorList"><span><span class="author">H. Thimbleby</span> (Swansea Univ., UK)</span></div>
<p><span class="cbStatement">Seven segment displays are familiar and ubiquitous, yet their use is problematic. This paper reviews many readability and use problems, and provides a range design questions and fixes.</span><span class="abstract">Seven segment number displays are ubiquitous and popular. They are simple and familiar. They seem to make economic sense, and with only seven segments they require little wiring and electronics to support. They are cheap to buy and cheap to use; they make seemingly effective and unproblematic products.     This paper illustrates many examples of problematic uses of seven segment displays that could have been avoided. More generally, the paper raises design questions and some solutions to be considered when designing numerical displays, and certainly before uncritically using seven segment displays. Although there are markets and applications where cost may be an overriding consideration, for safety critical and other dependable types of use (including general purpose devices that may sometimes be used for critical tasks) more legible alternatives than standard seven segment displays should be preferred. </span></li>
<li id="PTU"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PTU"><span class="letterCode" style="float:right">PTU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTU">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466215">Authoring Personal Histories: Exploring the Timeline as a Framework for Meaning Making</a></span><br />
<span class="authors">E. Thiry (Pennsylvania State Univ., USA), S. Lindley, R. Banks, T. Regan</span>
<div class="authorList"><span><span class="author">E. Thiry</span> (Pennsylvania State Univ., USA)</span><span><span class="author">S. Lindley</span> (Microsoft Research, UK)</span><span><span class="author">R. Banks</span> (Microsoft Research, UK)</span><span><span class="author">T. Regan</span> (Microsoft Research, UK)</span></div>
<p><span class="cbStatement">We present a study of how older people made digital timelines using Project Greenwich. We explore how the constraints of the timeline metaphor offer a framework for authoring and making.</span><span class="abstract">It has been argued that technologies for ‘memory’ should be designed to support creativity and meaning building, rather than the passive capture of cues for remembering [25]. We report findings from a study inspired by this insight, in which older people made personal digital timelines using a new tool called Project Greenwich. We explore how the constraints of the timeline metaphor offer a framework for authoring, and examine how timelines can be used to underpin meaning building in relation to personal content. We highlight the importance of making, this being a vehicle for connecting with others in the present, and a potential means of emphasizing those elements of the past felt to be most salient when looking back.</span></li>
<li id="PSG"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PSG"><span class="letterCode" style="float:right">PSG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PSG">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470696">Individual User Characteristics and Information Visualization: Connecting the Dots through Eye Tracking</a></span><br />
<span class="authors">D. Toker (Univ. of British Columbia, CA), C. Conati, B. Steichen, G. Carenini</span>
<div class="authorList"><span><span class="author">D. Toker</span> (Univ. of British Columbia, CA)</span><span><span class="author">C. Conati</span> (Univ. of British Columbia, CA)</span><span><span class="author">B. Steichen</span> (Univ. of British Columbia, CA)</span><span><span class="author">G. Carenini</span> (Univ. of British Columbia, CA)</span></div>
<p><span class="cbStatement">We present results from an eye tracking user study, showing that a user’s cognitive abilities have a significant impact on gaze behavior when performing common information visualization tasks.</span><span class="abstract">There is increasing evidence that users’ characteristics such as cognitive abilities and personality have an impact on the effectiveness of information visualization techniques. This paper investigates the relationship between such characteristics and fine-grained user attention patterns. In particular, we present results from an eye tracking user study involving bar graphs and radar graphs, showing that a user’s cognitive abilities such as perceptual speed and verbal working memory have a significant impact on gaze behavior, both in general and in relation to task difficulty and visualization type. These results are discussed in view of our long-term goal of designing information visualisation systems that can dynamically adapt to individual user characteristics.</span></li>
<li id="PGV"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PGV"><span class="letterCode" style="float:right">PGV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PGV">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481285">Analyzing Users&#8217; Narratives to Understand Experience with Interactive Products</a></span><br />
<span class="authors">A. Tuch (Univ. of Copenhagen, DK), R. Trusell, K. Hornbæk</span>
<div class="authorList"><span><span class="author">A. Tuch</span> (Univ. of Copenhagen, DK)</span><span><span class="author">R. Trusell</span> (Univ. of Copenhagen, DK)</span><span><span class="author">K. Hornbæk</span> (Univ. of Copenhagen, DK)</span></div>
<p><span class="cbStatement">Analyzes narratives of experience with interactive technology with manual and automatic methods. Helps understand the content of such experiences and the relative benefits of methods for studying them. </span><span class="abstract">Recent research in user experience (UX) has studied narratives, users&#8217; account of their interaction with technology. It has emphasized specific constructs (e.g., affect, needs, hedonics) and their interrelation, but rarely analyzed the content of the narratives. We analyze the content and structure of 691 user-generated narratives on positive and negative experiences with technology. We use a multi-method approach consisting of manual (structural analysis of narratives) as well as of automated content analysis methods (psycholinguistic analysis and machine learning). These analyses show converging evidence that positive narratives predominantly concern social aspects such as family and friends. In addition, technology is positively experienced when it enables users to do things more efficiently or in a new way. In contrast, negative narratives often express anger and frustration due to technological failures. Our multi-method approach illustrates the potential of automated (as opposed to manual) content analysis methods for studying text-based experience reports. </span></li>
<li id="PPK"class="presentation ux health"><a href="http://chi2013.acm.org/previews/paper.html#PPK"><span class="letterCode" style="float:right">PPK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPK">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466159">Exploring &#038; Designing Tools to Enhance Falls Rehabilitation in the Home</a></span><br />
<span class="authors">S. Uzor (Glasgow Caledonian Univ., UK), L. Baillie</span>
<div class="authorList"><span><span class="author">S. Uzor</span> (Glasgow Caledonian Univ., UK)</span><span><span class="author">L. Baillie</span> (Glasgow Caledonian Univ., UK)</span></div>
<p><span class="cbStatement">The studies described in the paper explored the usability and acceptance of two distinct types of visual feedback for unsupervised rehabilitation in the home. </span><span class="abstract">Falls are the leading cause of accidental injury-related deaths in the elderly; a fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes involving exercise have proved the most successful way to reduce the risk of falls. However, the limitations of standard care (e.g. booklets) could prevent home users from receiving the full therapeutic benefit that rehabilitation offers. Having consulted users and health experts, we developed games, and visualizations for falls rehabilitation that we believe could potentially overcome the main barriers to effective rehabilitation in the home. In this paper, we describe user studies that we carried out with older adults to evaluate the use of these visual tools versus standard care, both in the laboratory and in the home.  Our main findings show that our visualizations and games were able to overcome the major limitations of standard care, and that they were usable and acceptable to the end users.  </span></li>
<li id="PTR"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PTR"><span class="letterCode" style="float:right">PTR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PTR">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466476">Reveal-it!: The Impact of a Social Visualization Projection on Public Awareness and Discourse</a></span><br />
<span class="authors">N. Valkanova (Univ. Pompeu Fabra, ES), S. Jorda, M. Tomitsch, A. Vande Moere</span>
<div class="authorList"><span><span class="author">N. Valkanova</span> (Univ. Pompeu Fabra, ES)</span><span><span class="author">S. Jorda</span> (Univ. Pompeu Fabra, ES)</span><span><span class="author">M. Tomitsch</span> (Design Lab &#8211; Faculty of Architecture, Design &#038; Planning, The Univ. of Sydney, AU)</span><span><span class="author">A. Vande Moere</span> (KU Leuven &#8211; Univ. of Leuven, BE)</span></div>
<p><span class="cbStatement">This paper investigates the challenges for a public visualization of a socially-relevant dataset, for the goal of changing the civic awareness of onlookers, through the evaluation of three real-world case studies.</span><span class="abstract">Public displays and projections are becoming increasingly available in various informal urban settings. However, their potential impact on informing and engaging citizens on relevant issues has still been largely unexplored. In this paper, we show that visualizations displayed in public settings are able to increase social awareness and discourse by exposing underlying patterns in data that is submitted by citizens. We thus introduce the design and evaluation of Reveal-it!, a public, interactive projection that facilitates the comparison of the energy consumptions of individuals and communities. Our in-the-wild deployment in three distinct physical locations provided insights into: 1) how people responded to this form of display in different contexts; 2) how it influenced people’s perception and discussion of individual and communal data; and 3) the implications for a public visualization as a tool for increasing awareness and discourse. We conclude by discussing emerging participant behaviors, as well as some challenges involved in facilitating a socially motivated crowd-sourced visualization in the public context.  </span></li>
<li id="PDD"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PDD"><span class="letterCode" style="float:right">PDD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PDD">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481324">Carpe ́ Data: Supporting Serendipitous Data Integration in Personal Information Management</a></span><br />
<span class="authors">M. Van Kleek (Univ. of Southampton, UK), D. Smith, H. Packer, J. Skinner, N. Shadbolt</span>
<div class="authorList"><span><span class="author">M. Van Kleek</span> (Univ. of Southampton, UK)</span><span><span class="author">D. Smith</span> (Univ. of Southampton, UK)</span><span><span class="author">H. Packer</span> (Univ. of Southampton, UK)</span><span><span class="author">J. Skinner</span> (Univ. of Southampton, UK)</span><span><span class="author">N. Shadbolt</span> (Univ. of Southampton, UK)</span></div>
<p><span class="cbStatement">This paper focuses on the problem of user-driven data integration on the Web, with the objective of enabling end-users to use the emerging ecosystems of structured data APIs and feeds.</span><span class="abstract">The information processing capabilities of humans enable them to opportunistically draw and integrate knowledge from nearly any information source.  However, the integration of digital, structured data from diverse sources remains difficult, due to problems of heterogeneity that arise when data modelled separately are brought together.  In this paper, we present an investigation of the feasibility of extending Personal Information Management (PIM) tools to support lightweight, user-driven mixing of previously un-integrated data, with the objective of allowing  users to take advantage of the emerging ecosystems of structured data currently becoming available.  In this study, we conducted an exploratory, sequential, mixed-method investigation, starting with two pre-studies of the data integration needs and challenges, respectively, of Web-based data sources. Observations from these pre-studies led to DataPalette, an interface that introduced simple co-reference and group multi-path-selection mechanisms for working with terminologically and structurally heterogeneous data.  Our lab study showed that participants readily understood the new interaction mechanisms which were introduced.  Participants made more carefully justified decisions, even while weighing a greater number of factors, moreover expending less effort, during subjective-choice tasks when using DataPalette, than with a control set-up.   </span></li>
<li id="NEV"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NEV"><span class="letterCode" style="float:right">NEV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NEV">Mon. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470692">Small, Medium, or Large? Estimating the User-Perceived Scale of Stroke Gestures</a></span><br />
<span class="authors">R. Vatavu (Univ. Stefan cel Mare of Suceava, RO), G. Casiez, L. Grisoni</span>
<div class="authorList"><span><span class="author">R. Vatavu</span> (Univ. Stefan cel Mare of Suceava, RO)</span><span><span class="author">G. Casiez</span> (LIFL &#038; INRIA Lille, Univ. of Lille, FR)</span><span><span class="author">L. Grisoni</span> (Univ. Lille, FR)</span></div>
<p><span class="cbStatement">We explore scale as parameter for gesture commands. We deliver a training-free, user- and device-independent scale estimator that can be integrated into existing gestural interfaces with three lines of code.</span><span class="abstract">We show that large consensus exists among users in the way they articulate stroke gestures at various scales (i.e., small, medium, and large), and formulate a simple rule that estimates the user-intended scale of input gestures with 87% accuracy. Our estimator can enhance current gestural interfaces by leveraging scale as a natural parameter for gesture input, reflective of user perception (i.e., no training required). Gesture scale can simplify gesture set design, improve gesture-to-function mappings, and reduce the need for users to learn and for recognizers to discriminate unnecessary symbols.</span></li>
<li id="PQL"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PQL"><span class="letterCode" style="float:right">PQL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQL">Tue. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466171">MotionMA: Motion Modelling and Analysis by Demonstration</a></span><br />
<span class="authors">E. Velloso (Lancaster Univ., UK), A. Bulling, H. Gellersen</span>
<div class="authorList"><span><span class="author">E. Velloso</span> (Lancaster Univ., UK)</span><span><span class="author">A. Bulling</span> (Max Planck Institute for Informatics, DE)</span><span><span class="author">H. Gellersen</span> (Lancaster Univ., UK)</span></div>
<p><span class="cbStatement">This work describes MotionMA, a system that extracts a quantitative model of movements and generates an analysis and feedback interface for helping other users perform them.</span><span class="abstract">Particularly in sports or physical rehabilitation, users have to perform body movements in a specific manner for the exercises to be most effective. It remains a challenge for experts to specify how to perform such movements so that an automated system can analyse further performances of it. In a user study with 10 participants we show that experts&#8217; explicit estimates do not correspond to their performances. To address this issue we present MotionMA, a system that: (1) automatically extracts a model of movements demonstrated by one user, e.g. a trainer, (2) assesses the performance of other users repeating this movement in real time, and (3) provides real-time feedback on how to improve their performance.  We evaluated the system in a second study in which 10 other participants used the system to demonstrate arbitrary movements. Our results demonstrate that MotionMA is able to extract an accurate movement model to spot mistakes and variations in movement execution.</span></li>
<li id="PSZ"class="presentation design ux health cci"><a href="http://chi2013.acm.org/previews/paper.html#PSZ"><span class="letterCode" style="float:right">PSZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PSZ">Thu. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466437">TOBY: Early Intervention in Autism through Technology</a></span><br />
<span class="authors">S. Venkatesh (Deakin Univ., AU), S. Greenhill, D. Phung, T. Duong, B. Adams</span>
<div class="authorList"><span><span class="author">S. Venkatesh</span> (Deakin Univ., AU)</span><span><span class="author">S. Greenhill</span> (Curtin Univ., AU)</span><span><span class="author">D. Phung</span> (Deakin Univ., AU)</span><span><span class="author">T. Duong</span> (Deakin Univ., AU)</span><span><span class="author">B. Adams</span> (Curtin Univ., AU)</span></div>
<p><span class="cbStatement">We describe an innovative iPad application for early intervention in autism named TOBY (Therapy Outcome By You). Field trials results are also presented to validate the framework.</span><span class="abstract">We describe TOBY Playpad, an early intervention program for children with Autism Spectrum Disorder (ASD). TOBY teaches the teacher &#8212; the parent &#8212; during the crucial period following diagnosis, which often coincides with no access to formal therapy. We reflect on TOBY&#8217;s evolution from table-top aid for flashcards to an iPad app covering a syllabus of 326 activities across 51 skills known to be deficient for ASD children, such imitation, joint attention and language. The design challenges unique to TOBY are the need to adapt to marked differences in each child&#8217;s skills and rate of development (a trait of ASD) and teach parents unfamiliar concepts core to behavioural therapy, such as reinforcement, prompting, and fading. We report on three trials that successively decrease oversight and increase parental autonomy, and demonstrate clear evidence of learning. TOBY&#8217;s uniquely intertwined Natural Environment Tasks are found to be effective for children and popular with parents.</span></li>
<li id="PNS"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PNS"><span class="letterCode" style="float:right">PNS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNS">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466255">Crossing the Bridge over Norman&#8217;s Gulf of Execution: Revealing Feedforward&#8217;s True Identity</a></span><br />
<span class="authors">J. Vermeulen (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE), K. Luyten, E. van den Hoven, K. Coninx</span>
<div class="authorList"><span><span class="author">J. Vermeulen</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span><span><span class="author">K. Luyten</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span><span><span class="author">E. van den Hoven</span> (Univ. of Technology, Sydney, AU)</span><span><span class="author">K. Coninx</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span></div>
<p><span class="cbStatement">We reframe feedforward and disambiguate it from feedback and perceived affordances. We describe a reference framework for designers that allows them to explore and recognize different opportunities for feedforward.</span><span class="abstract">Feedback and affordances are two of the most well-known principles in interaction design. Unfortunately, the related and equally important notion of feedforward has not been given as much consideration. Nevertheless, feedforward is a powerful design principle for bridging Norman’s Gulf of Execution. We reframe feedforward by disambiguating it from related design principles such as feedback and perceived affordances, and identify new classes of feedforward. In addition, we present a reference framework that provides a means for designers to explore and recognize different opportunities for feedforward.</span></li>
<li id="PBN"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PBN"><span class="letterCode" style="float:right">PBN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBN">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466247">HCI in the Press: Online Public Reactions to Mass Media Portrayals of HCI Research</a></span><br />
<span class="authors">J. Vines (Newcastle Univ., UK), A. Thieme, R. Comber, M. Blythe, P. Wright, P. Olivier</span>
<div class="authorList"><span><span class="author">J. Vines</span> (Newcastle Univ., UK)</span><span><span class="author">A. Thieme</span> (Newcastle Univ., UK)</span><span><span class="author">R. Comber</span> (Newcastle Univ., UK)</span><span><span class="author">M. Blythe</span> (Northumbria Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">Describes the use of mass-media to provoke online public commentaries of HCI projects. Will benefit those wanting to engage the public in their research and understand associated strengths and weaknesses.</span><span class="abstract">HCI researchers working in publically funded institutions are increasingly encouraged to engage the public in their research. Mass media is often seen as an effective medium with which to communicate research to large parts of the population. We present an account of three HCI projects that have used engagements with mass media in order to communicate research to the public. We describe the motivations for working with mass media and the mechanics of writing press releases. A grounded theory analysis of online public responses to the projects in the mass media leads us to identify a number of concerns about how research is portrayed by news outlets and thus interpreted by the public. Tensions about technologies and wider societal issues were revealed that might normally be hidden when using traditional user-centred methods. We critically reflect on the efficacy of using the mass media in research and provide guidance for HCI researchers wishing to engage in dialogues with the public in the future.</span></li>
<li id="PBE"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PBE"><span class="letterCode" style="float:right">PBE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PBE">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470716">Configuring Participation: On How We Involve People In Design</a></span><br />
<span class="authors">J. Vines (Newcastle Univ., UK), R. Clarke, P. Wright, J. McCarthy, P. Olivier</span>
<div class="authorList"><span><span class="author">J. Vines</span> (Newcastle Univ., UK)</span><span><span class="author">R. Clarke</span> (Newcastle Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">Critically examines the goals of user participation in design processes in contemporary HCI. Highlights limitations in how participatory processes are documented by the community, and outlines strategies for future research.</span><span class="abstract">The term ‘participation’ is traditionally used in HCI to describe the involvement of users and stakeholders in design processes, with a pretext of distributing control to participants to shape their technological future. In this paper we ask whether these values can hold up in practice, particularly as participation takes on new meanings and incorporates new perspectives. We argue that much HCI research leans towards configuring participation. In discussing this claim we explore three questions that we consider important for understanding how HCI configures participation; Who initiates, directs and benefits from user participation in design? In what forms does user participation occur? How is control shared with users in design? In answering these questions we consider the conceptual, ethical and pragmatic problems this raises for current participatory HCI research. Finally, we offer directions for future work explicitly dealing with the configuration of participation.</span></li>
<li id="PFR"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PFR"><span class="letterCode" style="float:right">PFR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PFR">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470759">An Evaluation of State Switching Methods for Indirect Touch Systems</a></span><br />
<span class="authors">S. Voelker (RWTH Aachen Univ., DE), C. Wacharamanotham, J. Borchers</span>
<div class="authorList"><span><span class="author">S. Voelker</span> (RWTH Aachen Univ., DE)</span><span><span class="author">C. Wacharamanotham</span> (RWTH Aachen Univ., DE)</span><span><span class="author">J. Borchers</span> (RWTH Aachen Univ., DE)</span></div>
<p><span class="cbStatement">Comparing four different state switching techniques for indirect touch systems that allow the users to rest their arms on the surfaces while they are in the Tracking state.</span><span class="abstract">Indirect touch systems combine a horizontal touch input surface with a vertical display for output. While this division is ergonomically superior to simple direct-touch displays for many tasks, users are no longer looking at their hands when touching. This requires the system to support an intermediate “tracking” state that lets users aim at objects without trigger- ing a selection, similar to the hover state in mouse-based UIs. We present an empirical analysis of several interaction techniques for indirect touch systems to switch to this intermediate state, and derive design recommendations for incorporat- ing it into such systems.</span></li>
<li id="PPM"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PPM"><span class="letterCode" style="float:right">PPM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PPM">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481313">Turbulence in the Clouds: Challenges of Cloud-Based Information Work</a></span><br />
<span class="authors">A. Voida (Univeristy of California, Irvine, USA), J. Olson, G. Olson</span>
<div class="authorList"><span><span class="author">A. Voida</span> (Univeristy of California, Irvine, USA)</span><span><span class="author">J. Olson</span> (Univ. of California, Irvine, USA)</span><span><span class="author">G. Olson</span> (Univ. of California, Irvine, USA)</span></div>
<p><span class="cbStatement">Presents results of a qualitative study of information management in the cloud. Describes challenges that will be relevant to designers involved with both cloud-based services and federated identity management.</span><span class="abstract">We report on a qualitative study of the user experience of cloud-based information work. We characterize the information work practices and challenges that exist largely at the different intersections of three constructs—cloud-based services, collaborations, and digital identifiers. We also demonstrate how the misalignment of these three constructs is experienced as a “losing battle” that has led to miscommunication among collaborators, the abandonment of cloud-based services, and the irreparable blurring of digital identities.</span></li>
<li id="NQT"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NQT"><span class="letterCode" style="float:right">NQT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NQT">Tue. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466166">Bodily Interaction in the Dark</a></span><br />
<span class="authors">L. Vongsathorn (Univ. of Oxford, UK), K. O&#8217;Hara, H. Mentis</span>
<div class="authorList"><span><span class="author">L. Vongsathorn</span> (Univ. of Oxford, UK)</span><span><span class="author">K. O&#8217;Hara</span> (Microsoft Research, UK)</span><span><span class="author">H. Mentis</span> (Microsoft Research, UK)</span></div>
<p><span class="cbStatement">Describes a body-centric, sound-based interaction using the Microsoft Kinect device, which is performed in the dark. The interaction is designed and analysed in the context of somaesthetics.</span><span class="abstract">In light of the growing interest in designing for new body-movement based interfaces through somaesthetics and somatic awareness, we created a sound-based interaction using the Microsoft Kinect device, which is performed in the dark. The absence of visual feedback led participants to deeply focus on the movement of their bodies, and to have a different awareness of their bodies and the space around them. The notable difference between performing this inter-action in light and dark suggests that non-visual based interfaces are a fruitful area to explore in somaesthetic interaction.</span></li>
<li id="PBT"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PBT"><span class="letterCode" style="float:right">PBT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBT">Tue. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466170">Body-centric Design Space for Multi-surface Interaction</a></span><br />
<span class="authors">J. Wagner (INRIA, FR), M. Nancel, S. Gustafson, S. Huot, W. Mackay</span>
<div class="authorList"><span><span class="author">J. Wagner</span> (INRIA, FR)</span><span><span class="author">M. Nancel</span> (Univ. Paris Sud, FR)</span><span><span class="author">S. Gustafson</span> (Hasso Plattner Institute, DE)</span><span><span class="author">S. Huot</span> (INRIA, FR)</span><span><span class="author">W. Mackay</span> (INRIA, FR)</span></div>
<p><span class="cbStatement">BodyScape, a body-centric design space, allows researchers and practitioners to describe, classify and systematically compare existing multi-surface interaction techniques, individually or in combination, as well as generate new interaction techniques.  </span><span class="abstract">We introduce BodyScape, a body-centric design space that allows us to describe, classify and systematically compare multi-surface interaction techniques, both individually and in combination.  BodyScape reflects the relationship between users and their environment, specifically how different body parts enhance or restrict movement within particular interaction techniques and can be used to analyze existing techniques or suggest new ones.  We illustrate the use of BodyScape by comparing two free-hand techniques, on-body touch and mid-air pointing, first separately, then combined.   We found that touching the torso is faster than touching the lower legs, since it affects the user&#8217;s balance;  and touching targets on the dominant arm is slower than targets on the torso  because the user must compensate for the applied force. </span></li>
<li id="PAN"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PAN"><span class="letterCode" style="float:right">PAN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PAN">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466458">Collaborative Sensemaking on a Digital Tabletop and Personal Tablets: Prioritization, Comparisons, and Tableaux</a></span><br />
<span class="authors">J. Wallace, S. Scott, C. MacGregor</span>
<div class="authorList"><span><span class="author">J. Wallace</span></span><span><span class="author">S. Scott</span> (Univ. of Waterloo, CA)</span><span><span class="author">C. MacGregor</span></span></div>
<p><span class="cbStatement">We describe an investigation of the support that three different display configurations provided for a collaborative sensemaking task: a digital table; personal tablets; and both the tabletop and personal tablets.</span><span class="abstract">We describe an investigation of the support that three different display configurations provided for a collaborative sensemaking task: a digital table; personal tablets; and both the tabletop and personal tablets. Mixed-methods analyses revealed that the presence of a digital tabletop display led to improved sensemaking performance, and identified activities that were supported by the shared workspace. The digital tabletop supported a group&#8217;s ability to prioritize information, to make comparisons between task data, and to form and critique the group&#8217;s working hypothesis. Analyses of group performance revealed a positive correlation with equity of member participation using the shared digital table, and a negative correlation of equity of member participation using personal tablets. Implications for the support of sensemaking groups, and the use of equity of member participation as a predictive measure of their performance are discussed.</span></li>
<li id="PAB"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PAB"><span class="letterCode" style="float:right">PAB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PAB">Thu. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466473">Making Design Probes Work</a></span><br />
<span class="authors">J. Wallace (Northumbria Univ., UK), J. McCarthy, P. Wright, P. Olivier</span>
<div class="authorList"><span><span class="author">J. Wallace</span> (Northumbria Univ., UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">We present a synthetic account of Probe design and use over a decade conceptualizing the relationship between the properties of probes and their use in design projects.</span><span class="abstract">Probes have been adopted with great enthusiasm in both Design and HCI. The heterogeneity with which they have been used in practice reflects how the method has proved elusive for many. Originators and commentators of probes have discussed misinterpretations of the method, highlighting the lack of accounts that describe in detail the design of probes and their use with participants. This paper discusses our particular use of Design Probes as directed craft objects that are both tools for design and tools for exploration across a number of projects, spanning a decade, centered on self-identity and personal significance. In offering an example of what a framework for probe design and use might look like, we attempt to address the identified lacuna, providing a synthetic account of probe design and use over an extended period and conceptualizing the relationship between the properties of probes and their use in design projects.</span></li>
<li id="PAQ"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PAQ"><span class="letterCode" style="float:right">PAQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAQ">Wed. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481363">A Design-led Inquiry into Personhood in Dementia</a></span><br />
<span class="authors">J. Wallace (Northumbria Univ., UK), P. Wright, J. McCarthy, D. Green, J. Thomas, P. Olivier</span>
<div class="authorList"><span><span class="author">J. Wallace</span> (Northumbria Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span><span><span class="author">D. Green</span> (Newcastle Univ., UK)</span><span><span class="author">J. Thomas</span> (Northumbria Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">A design-led, co-creative inquiry into personhood with Gillian, who has dementia, and John her husband &#8211; mediated by Design Probes and resulting in Digital Jewellery to support personhood and relationships.</span><span class="abstract">Writers and practitioners in dementia care have invoked personhood to offer potential for preserving the agency of people living with dementia. In this context we use personhood to explore how relationships bring agentive potential to experience-centered design through a co-creative, design-led inquiry with Gillian, a woman living with dementia, and John her husband. We designed bespoke probes to empathically engage the couple in the design of both jewellery and digital jewellery to support Gillian’s personhood. Our design activity addressed the relationships involved in the context of Gillian’s family life and the progression of her illness and how they could be mediated technologically. Reminiscence became, through Gillian and John’s own hands, acts of sense making and legacy. The process of design became the way of conducting the inquiry and the designed artifacts became ways of posing questions to make sense of our experiences together.</span></li>
<li id="PDY"class="presentation cci"><a href="http://chi2013.acm.org/previews/paper.html#PDY"><span class="letterCode" style="float:right">PDY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PDY">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481400">FACIT PD: A Framework for Analysis and Creation of Intergenerational Techniques for Participatory Design</a></span><br />
<span class="authors">G. Walsh (Univ. of Baltimore, USA), E. Foss, J. Yip, A. Druin</span>
<div class="authorList"><span><span class="author">G. Walsh</span> (Univ. of Baltimore, USA)</span><span><span class="author">E. Foss</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Yip</span> (Univ. of Maryland, USA)</span><span><span class="author">A. Druin</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">This paper describes a framework that can aid design teams in choosing or designing new techniques to design with children regardless of the subject area or method being used.</span><span class="abstract">In this paper, we present a framework that describes commonly used design techniques for Participatory Design with children. Although there are many currently used techniques for designing with children, researchers working in differing contexts and in a changing technological landscape find themselves facing difficult design situations. The FACIT PD framework presented in this paper can aid in choosing existing design techniques or in developing new techniques regardless of the stage in the design cycle, the technology being developed, or philosophical approach to design method. The framework consists of eight dimensions, concerning the design partners, the design goal, and the design technique. The partner dimensions are partner experience and need for accommodation. The design goal dimensions are design space and maturity of design. The technique dimensions include: cost, portability, technology and physical interaction. Three cases will be presented which describe new techniques developed using the framework and two cases will describe existing techniques. </span></li>
<li id="PEZ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PEZ"><span class="letterCode" style="float:right">PEZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PEZ">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470774">StrikeAPose: Revealing Mid-Air Gestures on Public Displays</a></span><br />
<span class="authors">R. Walter (Telekom Innovation Laboratories, TU Berlin, DE), G. Bailly, J. Müller</span>
<div class="authorList"><span><span class="author">R. Walter</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span><span><span class="author">G. Bailly</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span><span><span class="author">J. Müller</span> (Univ. of the Arts, DE)</span></div>
<p><span class="cbStatement">Proposes three strategies to reveal mid-air gestures on interactive public displays and introduces the Teapot gesture as a novel initial mid-air gesture. Shows that users naturally explore gesture variations.</span><span class="abstract">We investigate how to reveal an initial mid-air gesture on interactive public displays. This initial gesture can serve as gesture registration for advanced operations. We propose three strategies to reveal the initial gesture: spatial division, temporal division and integration. Spatial division permanently shows the gesture on a dedicated screen area. Temporal division interrupts the application to reveal the gesture. Integration embeds gesture hints directly in the application. We also propose a novel initial gesture called Teapot to illustrate our strategies. We report on a laboratory and field study. Our main findings are: A large percentage of all users execute the gesture, especially with spatial division (56%). Users intuitively discover a gesture vocabulary by exploring variations of the Teapot gesture by themselves, as well as by imitating and extending other users&#8217; variations.</span></li>
<li id="NDL"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NDL"><span class="letterCode" style="float:right">NDL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NDL">Mon. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470659">Gender, Topic, and Audience Response: An Analysis of User-Generated Content on Facebook</a></span><br />
<span class="authors">Y. Wang (Carnegie Mellon Univ., USA), M. Burke, R. Kraut</span>
<div class="authorList"><span><span class="author">Y. Wang</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">M. Burke</span> (Facebook, Inc., USA)</span><span><span class="author">R. Kraut</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">This paper identifies topics that men and women talk about in Facebook status updates and determines which topics are more likely to receive feedback.</span><span class="abstract">Although both men and women communicate frequently on Facebook, we know little about what they talk about, whether their topics differ and how their network responds. Using Latent Dirichlet Allocation (LDA), we identify topics from more than half a million Facebook status updates and determine which topics are more likely to receive feedback, such as likes and comments. Women tend to share more personal topics (e.g., family matters), while men discuss more public ones (e.g., politics and sports). Generally, women receive more feedback than men, but &#8220;male&#8221; topics (those more often posted by men) receive more feedback, especially when posted by women.</span></li>
<li id="NKM"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#NKM"><span class="letterCode" style="float:right">NKM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NKM">Wed. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481375">A Comparative Evaluation of Multiple Chat Stream Interfaces for Information-intensive Environments</a></span><br />
<span class="authors">Y. Wang (Univ. of California, Irvine, USA), A. Echenique, M. Shelton, G. Mark</span>
<div class="authorList"><span><span class="author">Y. Wang</span> (Univ. of California, Irvine, USA)</span><span><span class="author">A. Echenique</span> (Univ. of California, Irvine, USA)</span><span><span class="author">M. Shelton</span> (Univ. of California, Irvine, USA)</span><span><span class="author">G. Mark</span> (Univ. of California, Irvine, USA)</span></div>
<p><span class="cbStatement">We evaluated two text-based chat interfaces to inform the design of large-scale text information visualizations for information workers who monitor real-time text streams.</span><span class="abstract">For information workers who monitor numerous constantly updating data streams, conserving cognitive resources is crucial. This study evaluated how an interface affects information workers’ ability to grasp critical information from multiple text-based chat streams under time pressure. We designed and built a working prototype that displays ten chat streams simultaneously in standard chat windows (ST) and ticker tapes (TT). We conducted a lab experiment to evaluate differences in how these two interfaces support signal and context detection. We found that with ST, participants detected significantly more target words (SAT words) with rarer frequency and significantly more context information (disaster facts) than with TT. Our results show that while TT is potentially better for overview scanning of multiple streams, ST is likely to be better for multi-tasking. Our study informs the design of future multi-chat systems so that large amounts of information can be easier to detect and process.</span></li>
<li id="NMX"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NMX"><span class="letterCode" style="float:right">NMX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NMX">Tue. 9am</a></span><span class="award repliCHI"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466139">Multiple Notification Modalities and Older Users</a></span><br />
<span class="authors">D. Warnock (Univ. of Glasgow, UK), S. Brewster, M. McGee-Lennon</span>
<div class="authorList"><span><span class="author">D. Warnock</span> (Univ. of Glasgow, UK)</span><span><span class="author">S. Brewster</span> (Univ. of Glasgow, UK)</span><span><span class="author">M. McGee-Lennon</span> (Univ. of Glasgow, UK)</span></div>
<p><span class="cbStatement">An experiment tested the way older users react to notifications delivered in 8 different modalities. Interesting differences were found between notifications requiring a response and ones that should be ignored.</span><span class="abstract">Multimodal interaction can make home care reminder systems more accessible to their users, most of whom are older and/or have sensory impairments. Existing research into the properties of different notification modalities have used younger participants rather than members of the older population at which they are aimed. This paper presents the results of a user study with older adults that examined how different notification modalities affected (a) performance in a card matching game and (b) how effective the different modalities were at delivering information. Participants were all aged over 50 and notifications were delivered using textual, pictographic, abstract visual, speech, Earcon, Auditory Icon, tactile and olfactory modalities while playing the game. The results showed that older users were influenced by the same factors as younger users, yet there were subjective differences. The implications for the design of multimodal reminder systems for home care are discussed.</span></li>
<li id="NBL"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#NBL"><span class="letterCode" style="float:right">NBL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NBL">Wed. 9am</a></span><span class="award repliCHI"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481298">Swipe Vs. Scroll: Web Page Switching on Mobile Browsers</a></span><br />
<span class="authors">A. Warr (Google, Inc., USA), E. Chi</span>
<div class="authorList"><span><span class="author">A. Warr</span> (Google, Inc., USA)</span><span><span class="author">E. Chi</span> (Google, Inc., USA)</span></div>
<p><span class="cbStatement">We present an experiment comparing Safari’s pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome.</span><span class="abstract">Tabbed web browsing interfaces enable users to multi-task and easily switch between open web pages. However, tabbed browsing is difficult for mobile web browsers due to the limited screen space and the reduced precision of touch. We present an experiment comparing Safari’s pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome. The results of our experiment show that cards-based switching interface allows for faster switching and is less frustrating, with no significant effect on error rates. We generalize these findings, and provide design implications for mobile information spaces.</span></li>
<li id="NRZ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#NRZ"><span class="letterCode" style="float:right">NRZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NRZ">Mon. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470740">Bending the Rules: Bend Gesture Classification for Flexible Displays</a></span><br />
<span class="authors">K. Warren (Carleton Univ., CA), J. Lo, V. Vadgama, A. Girouard</span>
<div class="authorList"><span><span class="author">K. Warren</span> (Carleton Univ., CA)</span><span><span class="author">J. Lo</span> (Carleton Univ., CA)</span><span><span class="author">V. Vadgama</span> (Carleton Univ., CA)</span><span><span class="author">A. Girouard</span> (Carleton Univ., CA)</span></div>
<p><span class="cbStatement">We propose a bend gesture classification scheme and we evaluate how users naturally perform bend gestures on deformable displays with minimal instruction.</span><span class="abstract">Bend gestures have a large number of degrees of freedom and therefore offer a rich interaction language. We propose a classification scheme for bend gestures, and explore how users perform these bend gestures along four classification criterion: location, direction, size, and angle. We collected 36 unique bend gestures performed three times by each participant. The results suggest a strong agreement among participants for preferences of location and direction. Size and angle were difficult for users to differentiate. Finally, users performed and perceived two distinct levels of magnitude. We propose recommendations for designing bend gestures with flexible displays. </span></li>
<li id="PFV"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PFV"><span class="letterCode" style="float:right">PFV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PFV">Mon. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470662">Older Adults as Digital Content Producers</a></span><br />
<span class="authors">J. Waycott (The Univ. of Melbourne, AU), F. Vetere, S. Pedell, L. Kulik, E. Ozanne, A. Gruner, J. Downs</span>
<div class="authorList"><span><span class="author">J. Waycott</span> (The Univ. of Melbourne, AU)</span><span><span class="author">F. Vetere</span> (The Univ. of Melbourne, AU)</span><span><span class="author">S. Pedell</span></span><span><span class="author">L. Kulik</span> (The Univ. of Melbourne, AU)</span><span><span class="author">E. Ozanne</span> (The Univ. of Melbourne, AU)</span><span><span class="author">A. Gruner</span> (Benetas Aged Care Services, AU)</span><span><span class="author">J. Downs</span> (The Univ. of Melbourne, AU)</span></div>
<p><span class="cbStatement">This paper examines the self-expression and social engagement that occurred when older adults used an iPad application to create and share photographs and messages within a small peer community. </span><span class="abstract">Older adults are normally characterized as consumers, rather than producers, of digital content. Current research concerning the design of technologies for older adults typically focuses on providing access to digital resources. Access is important, but is often insufficient, especially when establishing new social relationships. This paper investigates the nature and role of digital content that has been created by older adults, for the purpose of forging new relationships. We present a unique field study in which seven older adults (aged 71-92 years), who did not know each other, used a prototype iPad application (Enmesh) to create and share photographs and messages. The findings demonstrate that older adults, even those in the “oldest old” age group, embraced opportunities to express themselves creatively through digital content production. We show that self-expression and social engagement with peers can be realized when socio-technical systems are suitably designed to allow older adults to create and share their own digital content.</span></li>
<li id="PTL"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PTL"><span class="letterCode" style="float:right">PTL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTL">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466243">Instagram at the Museum: Communicating the Museum Experience through Social Photo Sharing</a></span><br />
<span class="authors">A. Weilenmann (Univ. of Gothenburg, SE), T. Hillman, B. Jungselius</span>
<div class="authorList"><span><span class="author">A. Weilenmann</span> (Univ. of Gothenburg, SE)</span><span><span class="author">T. Hillman</span> (Univ. of Gothenburg, SE)</span><span><span class="author">B. Jungselius</span> (Univ. of Gothenburg, SE)</span></div>
<p><span class="cbStatement">Analyzing both instagrams and practices of instagramming, we examine the resources and concerns that shape the user-driven creation, organisation and sharing of social, multi-layered, aesthetic documents of museum experiences.</span><span class="abstract">The everyday use of smartphones with high quality built-in cameras has lead to an increase in museum visitors’ use of these devices to document and share their museum experiences. In this paper, we investigate how one particular photo sharing application, Instagram, is used to communicate visitors’ experiences while visiting a museum of natural history. Based on an analysis of 222 instagrams created in the museum, as well as 14 interviews with the visitors who created them, we unpack the compositional resources and concerns contributing to the creation of instagrams in this particular context. By re-categorizing and re-configuring the museum environment, instagrammers work to construct their own narratives from their visits. These findings are then used to discuss what emerging multimedia practices imply for the visitors’ engagement with and documentation of museum exhibits. Drawing upon these practices, we discuss the connection between online social media dialogue and the museum site. </span></li>
<li id="PSC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PSC"><span class="letterCode" style="float:right">PSC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PSC">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481296">Phoneprioception: Enabling Mobile Phones to Infer Where They Are Kept</a></span><br />
<span class="authors">J. Wiese (Carnegie Mellon Univ., USA), T. Saponas, A. Brush</span>
<div class="authorList"><span><span class="author">J. Wiese</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">T. Saponas</span> (Microsoft Research, USA)</span><span><span class="author">A. Brush</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">We examined where people keep their phones through interviews and an ESM study and demonstrate that reasonably accurate classifications are possible with industry-standard sensors, improved by several other low-cost sensors.</span><span class="abstract">Enabling phones to infer whether they are currently in a pocket, purse or on a table facilitates a range of new inter-actions from placement-dependent notifications setting to preventing “pocket dialing.” We collected data from 693 participants to understand where people keep their phone in different contexts and why. Using this data, we identified three placement personas: Single Place Pat, Consistent Ca-sey, and All-over Alex. Based on these results, we collected two weeks of labeled accelerometer data in-situ from 32 participants. We used this data to build models for inferring phone placement, achieving an accuracy of approximately 85% for inferring whether the phone is in an enclosed loca-tion and for inferring if the phone is on the user. Finally, we prototyped a capacitive grid and a multispectral sensor and collected data from 15 participants in a laboratory to under-stand the added value of these sensors.</span></li>
<li id="NPG"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NPG"><span class="letterCode" style="float:right">NPG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NPG">Tue. 4pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466238">The Wheels are Turning: Content Rotation on Steering Wheel Displays</a></span><br />
<span class="authors">D. Wilfinger (Univ. of Salzburg, AT), M. Murer, S. Osswald, A. Meschtscherjakov, M. Tscheligi</span>
<div class="authorList"><span><span class="author">D. Wilfinger</span> (Univ. of Salzburg, AT)</span><span><span class="author">M. Murer</span> (Univ. of Salzburg, AT)</span><span><span class="author">S. Osswald</span> (Univ. of Salzburg, AT)</span><span><span class="author">A. Meschtscherjakov</span> (Univ. of Salzburg, AT)</span><span><span class="author">M. Tscheligi</span> (Univ. of Salzburg, AT)</span></div>
<p><span class="cbStatement">This paper investigates how the content of steering wheel mounted displays should react to a rotation of the wheel. Three alternatives are tested and compared with a dashboard display.</span><span class="abstract">The steering wheel is a promising space for the integration of displays since in the car there is very limited space for integrating interactive modalities for the driver that are close to the preferred field of view as well as in an easy to reach position. When the wheel is turned, the screen content could change its orientation to increase the readability and therefore reduce the distraction from the road. Thus, this paper describes three different content rotation behaviors for steering wheel displays. To investigate what effect these behaviors have on the driver in terms of visual distraction from the road we conducted a user study with eye tracking asking participants to read the current speed. We found no differences in terms of distraction and response time between the different rotation behaviors. Compared to a similar display in a dashboard position the visual distraction was reduced.</span></li>
<li id="NTX"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#NTX"><span class="letterCode" style="float:right">NTX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NTX">Wed. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481332">Using Redundancy to Detect Human Error</a></span><br />
<span class="authors">S. Wiseman (Univ. College London, UK), A. Cox, D. Brumby, S. Gould, S. O&#8217;Carroll</span>
<div class="authorList"><span><span class="author">S. Wiseman</span> (Univ. College London, UK)</span><span><span class="author">A. Cox</span> (Univ. College London, UK)</span><span><span class="author">D. Brumby</span> (Univ. College London, UK)</span><span><span class="author">S. Gould</span> (Univ. College London, UK)</span><span><span class="author">S. O&#8217;Carroll</span> (Univ. College London, UK)</span></div>
<p><span class="cbStatement">We explore ways in which a checksum may be used to prevent number entry errors. We look at two methods for implementing the system and highlight the benefits of each.</span><span class="abstract">Number entry is a common task in many domains. In safety-critical environments such as air traffic control or on hospital wards, incorrect number entry can have serious harmful consequences. Research has investigated how interface designs can help prevent users from making number entry errors. In this paper, we present an experimental evaluation of two possible interface designs aimed at helping users detect number entry errors using the idea of a checksum: an additional (redundant) number that is related to the to-be-entered numbers in such a way that it is sufficient to verify the correctness of the checksum, as opposed to checking each of the entered numbers. The first interface requires users to check their own work with the help of the checksum; the second requires the user to enter the checksum along with the other numbers so that the system can do the checking. In each case, two numbers needed to be entered, while the third number served as a checksum. With the first interface, users caught only 36% of their errors. The second interface resulted in all errors being caught, but the need to enter the checksum increased entry time by 46%. When participants were allowed to choose between the two interfaces, they chose the second interface in only 12% of the cases. Although these results cannot be generalized to other specific contexts, the results illustrate the strengths and weaknesses of each way of using checksums to catch number entry errors. Hence our study can serve as a starting point for efforts to improve each method.</span></li>
<li id="PLZ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PLZ"><span class="letterCode" style="float:right">PLZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLZ">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466262">Fighting against the Wall: Social Media use by Political Activists in a Palestinian Village</a></span><br />
<span class="authors">V. Wulf (Univ. of Siegen, DE), K. Aal, I. Abu Kteish, M. Atam, K. Schubert , G. Yerousis, D. Randall, M. Rohde </span>
<div class="authorList"><span><span class="author">V. Wulf</span> (Univ. of Siegen, DE)</span><span><span class="author">K. Aal</span> (Univ. of Siegen, DE)</span><span><span class="author">I. Abu Kteish</span> (Birzeit Univ., IL)</span><span><span class="author">M. Atam</span> (Univ. of Siegen, DE)</span><span><span class="author">K. Schubert </span> (Univ. of Siegen, DE)</span><span><span class="author">G. Yerousis</span> (Birzeit Univ., PS)</span><span><span class="author">D. Randall</span> (Univ. of Siegen, DE)</span><span><span class="author">M. Rohde </span> (Univ. of Siegen, DE)</span></div>
<p><span class="cbStatement">We analyze practices of political activists in a Palestinian village, who demonstrate against Israel’s settlement policy and the separation wall. We describe how social media is appropriated to facilitate interaction ‘on the ground’.</span><span class="abstract">We analyze practices of political activists in a Palestinian village located in the West Bank. Activists organize weekly demonstrations against Israel’s settlement policy and the separation wall. Over a period of 28 months, we conducted a field study consisting of eight days ‘on the ground’ observation and interviewing, and extensive monitoring of Internet communication. We describe the activists’ background and their efforts to organize these demonstrations under conditions of military occupation. Over time, we observe the role both digital and material factors play in the organization of protest. Specifically, we analyze how Email and Facebook were appropriated to facilitate interaction ‘on the ground’.</span></li>
<li id="PCG"class="presentation ux HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PCG"><span class="letterCode" style="float:right">PCG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCG">Wed. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481391">Hustling Online: Understanding Consolidated Facebook Use in an Informal Settlement in Nairobi</a></span><br />
<span class="authors">S. Wyche (Michigan State Univeristy, USA), F. Andrea, S. Yardi Schoenebeck</span>
<div class="authorList"><span><span class="author">S. Wyche</span> (Michigan State Univeristy, USA)</span><span><span class="author">F. Andrea</span> (Drexel Univ., USA)</span><span><span class="author">S. Yardi Schoenebeck</span> (Univ. of Michigan, USA)</span></div>
<p><span class="cbStatement">This is the first study of Facebook use in a Nairobi slum. We find that to overcome the costs associated with Internet use, residents consolidated diverse online activities onto Facebook.</span><span class="abstract">Facebook is a global phenomenon, yet little is known about use of the site in urban parts of the developing world where the social network’s users are increasingly located. We qualitatively studied Facebook use among 28 young adults living in Viwandani, an informal settlement, or slum, in Nairobi, Kenya. We find that to overcome the costs associated with Internet use, participants consolidated diverse online activities onto Facebook; here we focus on the most common practice—using Facebook to support income generation. Viwandani residents used the site to look for employment opportunities, market themselves, and seek remittances from friends and family abroad. We use our findings to motivate a design agenda for the urban poor built on an understanding that Facebook is used, with mixed-success, to support income generation. A key part of this agenda calls for developing ICT interventions grounded in users’ existing practices rather than introducing new and unfamiliar ones. </span></li>
<li id="PCD"class="presentation design HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PCD"><span class="letterCode" style="float:right">PCD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCD">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481381">“I want to imagine how that place looks”: Designing Technologies to Support Connectivity Between Africans Living Abroad and Home</a></span><br />
<span class="authors">S. Wyche (Michigan State Univeristy, USA), M. Chetty</span>
<div class="authorList"><span><span class="author">S. Wyche</span> (Michigan State Univeristy, USA)</span><span><span class="author">M. Chetty</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">We asked African-born students how they used ICTs to connect with family  in their home countries. Findings informed a  prototype we evaluated. We discuss novel features to include in interfaces designed to support transnational communication.</span><span class="abstract">Uneven access to Information and Communication Technologies (ICTs) in parts of the African continent make it challenging for some Africans who migrate to the U.S. to communicate with family members in their countries of origin. However, Internet access is becoming more widespread throughout the continent and this development presents an opportunity to explore how future interactive systems can support exchanges between families with members living in developed and less developed countries. To investigate these design possibilities we interviewed 27 African-born students, currently living in Virginia, U.S., and asked them how they used ICTs to connect with family members in their home countries. Our findings informed the development of a low-fidelity prototype that eight students lived with for four to five months. Findings from this deployment study motivate a discussion regarding features to include in interfaces designed to support transnational family communication. Features include personally meaningful imagery, country specific content, and the ability to monitor the weather and changing currency rates in migrants’ countries of origin.</span></li>
<li id="PPT"class="presentation design HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PPT"><span class="letterCode" style="float:right">PPT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPT">Tue. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466260">Powering the Cellphone Revolution: Findings from Mobile Phone Charging Trials in Off-Grid Kenya</a></span><br />
<span class="authors">S. Wyche (Michigan State Univeristy, USA), L. Murphy</span>
<div class="authorList"><span><span class="author">S. Wyche</span> (Michigan State Univeristy, USA)</span><span><span class="author">L. Murphy</span> (Tulane Univ., USA)</span></div>
<p><span class="cbStatement">We provide empirical evidence demonstrating the potential for human-powered devices to meet the phone charging needs of rural, off-grid, mobile phone users in Africa. </span><span class="abstract">Can human-powered devices solve the electricity gap for the millions of rural Africans adopting mobile phones? Findings from our long-term evaluation of two personal crank-based charging systems in Kenya reveal that small hand and leg-powered devices do have potential to meet the needs of rural mobile phone users. Unfortunately, device breakage, theft and incompatibility with handsets, coupled with lack of consumer credit and poorly functioning markets for these goods mean these represent only a partial solution to the mobile phone charging problem. Drawing from our fieldwork, we motivate a HCI4D/ICTD design and evaluation agenda that better accounts for unique individuals’ geographic, financial, and economic circumstances or their “human computer ecosystem”. Key strategies for implementing this agenda are engaging with diverse users on their own terms and conducting long-term qualitative evaluations to reveal how acceptance and usability change over time.</span></li>
<li id="PJZ"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PJZ"><span class="letterCode" style="float:right">PJZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJZ">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466113">WorldKit: Rapid and Easy Creation of Ad-hoc Interactive Applications on Everyday Surfaces</a></span><br />
<span class="authors">R. Xiao (Carnegie Mellon Univ., USA), C. Harrison, S. Hudson</span>
<div class="authorList"><span><span class="author">R. Xiao</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">C. Harrison</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">S. Hudson</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">Describes a paired depth-camera and projector system for on-the-world interaction and a software kit for application development: provides an inexpensive way to support interactions on everyday surfaces.</span><span class="abstract">Instant access to computing, when and where we need it, has long been one of the aims of research areas such as ubiquitous computing. In this paper, we describe the WorldKit system, which makes use of a paired depth camera and projector to make ordinary surfaces instantly interactive. Using this system, touch-based interactivity can, without prior calibration, be placed on nearly any unmodified surface literally with a wave of the hand, as can other new forms of sensed interaction. From a user perspective, such interfaces are easy enough to instantiate that they could, if desired, be recreated or modified &#8220;each time we sat down&#8221; by &#8220;painting&#8221; them next to us. From the programmer&#8217;s perspective, our system encapsulates these capabilities in a simple set of abstractions that make the creation of interfaces quick and easy. Further, it is extensible to new, custom interactors in a way that closely mimics conventional 2D graphical user interfaces, hiding much of the complexity of working in this new domain. We detail the hardware and software implementation of our system, and several example applications built using the library.</span></li>
<li id="PKH"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PKH"><span class="letterCode" style="float:right">PKH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PKH">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470729">CommunityCompare: Visually Comparing Communities for Online Community Leaders in the Enterprise</a></span><br />
<span class="authors">A. Xu (Univ. of Illinois at Urbana-Champaign, USA), J. Chen, T. Matthews, M. Muller, H. Badenes</span>
<div class="authorList"><span><span class="author">A. Xu</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">J. Chen</span> (IBM Research, USA)</span><span><span class="author">T. Matthews</span> (IBM Research, USA)</span><span><span class="author">M. Muller</span> (IBM T.J. Watson Research, USA)</span><span><span class="author">H. Badenes</span> (IBM, AR)</span></div>
<p><span class="cbStatement">Design and evaluation of a new visual, comparison-based analytic system, CommunityCompare, to help leaders assess and identify actions to improve community health. Can enhance design of systems for community leaders.</span><span class="abstract">Online communities are important in enterprises, helping workers to build skills and collaborate. Despite their unique and critical role fostering successful communities, community leaders have little direct support in existing technologies. We introduce CommunityCompare, an interactive visual analytic system to enable leaders to make sense of their community’s activity with comparisons. Composed of a parallel coordinates plot, various control widgets, and a preview of example posts from communities, the system supports comparisons with hundreds of related communities on multiple metrics and the ability to learn by example. We motivate and inform the system design with formative interviews of community leaders. From additional interviews, a field deployment, and surveys of leaders, we show how the system enabled leaders to assess community performance in the context of other comparable communities, learn about community dynamics through data exploration, and identify examples of top performing communities from which to learn. We conclude by discussing how our system and design lessons generalize.</span></li>
<li id="PED"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PED"><span class="letterCode" style="float:right">PED</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PED">Wed. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481308">Designing Engagement-aware Agents for Multiparty Conversations</a></span><br />
<span class="authors">Q. Xu (Institute for Infocomm Research, A*STAR, SG), L. Li, G. Wang</span>
<div class="authorList"><span><span class="author">Q. Xu</span> (Institute for Infocomm Research, A*STAR, SG)</span><span><span class="author">L. Li</span> (Institute for Infocomm Research, ASTAR, SG)</span><span><span class="author">G. Wang</span> (Institute for Infocomm Research, ASTAR, SG)</span></div>
<p><span class="cbStatement">Presents quantitative methods to evaluate users’ engagement state and intentions from visual cues. Can assist the design of conversational agents for multiparty dialog in the public space.</span><span class="abstract">Recognizing users’ engagement state and intentions is a pressing task for computational agents to facilitate fluid conversations in situated interactions. We investigate how to quantitatively evaluate high-level user engagement and intentions based on low-level visual cues, and how to design engagement-aware behaviors for the conversational agents to behave in a sociable manner. Drawing on machine learning techniques, we propose two computational models to quantify users’ attention saliency and engagement intentions. Their performances are validated by a close match between the predicted values and the ground truth annotation data. Next, we design a novel engagement-aware behavior model for the agent to adjust its direction of attention and manage the conversational floor based on the estimated users’ engagement. In a user study, we evaluated the agent’s behaviors in a multiparty dialog scenario. The results show that the agent’s engagement-aware behaviors significantly improved the effectiveness of communication and positively affected users’ experience.</span></li>
<li id="NDZ"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#NDZ"><span class="letterCode" style="float:right">NDZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NDZ">Wed. 9am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481297">Facilitating Parallel Web Browsing through Multiple-Page View</a></span><br />
<span class="authors">W. Xu (Tsinghua Univ., CN), C. Yu, S. Zhao, J. Liu, Y. Shi</span>
<div class="authorList"><span><span class="author">W. Xu</span> (Tsinghua Univ., CN)</span><span><span class="author">C. Yu</span> (Tsinghua Univ., CN)</span><span><span class="author">S. Zhao</span> (Tsinghua Univ., CN)</span><span><span class="author">J. Liu</span> (Tsinghua Univ., CN)</span><span><span class="author">Y. Shi</span> (Tsinghua Univ., CN)</span></div>
<p><span class="cbStatement">We propose the multiple-page view to provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers.</span><span class="abstract">Parallel web browsing describes the behavior where users visit web pages in multiple concurrent threads. Qualitative studies have observed this activity being performed with multiple browser windows or tabs. However, these solutions are not satisfying since a large amount of time is wasted on switch among windows and tabs. In this paper, we propose the multiple-page view to facilitate parallel web browsing. Specifically, we provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers. Through user study and survey, we found that 2-4 pages within the window size were preferred for multiple-page view in spite of the diverse screen sizes and resolutions. Analytical results of logs from the user study also showed an improvement of 26.3% in users’ efficiency of performing parallel web browsing tasks, compared to traditional browsing with multiple windows or tabs.</span></li>
<li id="PHR"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PHR"><span class="letterCode" style="float:right">PHR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PHR">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481365">Understanding the Conflicting Demands of Family Caregivers Caring for Depressed Family Members</a></span><br />
<span class="authors">N. Yamashita (NTT Communication Science Laboratories, JP), H. Kuzuoka, K. Hirata, T. Kudo</span>
<div class="authorList"><span><span class="author">N. Yamashita</span> (NTT Communication Science Laboratories, JP)</span><span><span class="author">H. Kuzuoka</span> (Univ. of Tsukuba, JP)</span><span><span class="author">K. Hirata</span> (Future Univ. Hakodate, JP)</span><span><span class="author">T. Kudo</span> (Osaka Univ., JP)</span></div>
<p><span class="cbStatement">Uncovers the challenges faced by family caregivers of depressed sufferes. Suggest design implications for technologies to improve the wellness of such family caregivers.</span><span class="abstract">Depression is one of the most common disabilities in developed countries. Despite its often devastating impact on families, scant research has focused on how to facilitate the well-being of family caregivers. The aim of this paper is to uncover the challenges faced by family caregivers and support their well-being with the use of technologies. To understand the emotional and social burden of caregivers and how they handle their stress, we conducted in-depth interviews with 15 individuals who have cared for a depressed family member. Our findings reveal the multifaceted dilemma of caring for a depressed family member as well as the various strategies engaged in by caregivers to improve their own situations. Based on our findings, we suggest design implications for healthcare technologies to improve the wellness of caregivers who are looking after depressed family members.</span></li>
<li id="PPQ"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PPQ"><span class="letterCode" style="float:right">PPQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PPQ">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466212">I Can Do Text Analytics! Designing Development Tools for Novice Developers</a></span><br />
<span class="authors">H. Yang (IBM Research, USA), D. Pupons-Wickham, L. Chiticariu, Y. Li, B. Nguyen, A. Carreno-Fuentes</span>
<div class="authorList"><span><span class="author">H. Yang</span> (IBM Research, USA)</span><span><span class="author">D. Pupons-Wickham</span> (IBM Silicon Valley Lab, USA)</span><span><span class="author">L. Chiticariu</span> (IBM Research, USA)</span><span><span class="author">Y. Li</span> (IBM Research, USA)</span><span><span class="author">B. Nguyen</span> (IBM Silicon Valley Lab, USA)</span><span><span class="author">A. Carreno-Fuentes</span> (IBM Research, USA)</span></div>
<p><span class="cbStatement">Describe a user centered iterative design process that developed a tool for text analytics, which enables novice developers to write high quality information extractors on par with state of the art with minimal training.</span><span class="abstract">Text analytics, an increasingly important application domain, is hampered by the high barrier to entry due to the many conceptual difficulties novice developers encounter. This work addresses the problem by developing a tool to guide novice developers to adopt the best practices employed by expert developers in text analytics and to quickly harness the full power of the underlying system. Taking a user centered task analytical approach, the tool development went through multiple design iterations and evaluation cycles. In the latest evaluation, we found that our tool enables novice developers to develop high quality extractors on par with the state of art within a few hours and with minimal training. Finally, we discuss our experience and lessons learned in the context of designing user interfaces to reduce the barriers to entry into complex domains of expertise.  </span></li>
<li id="PDR"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PDR"><span class="letterCode" style="float:right">PDR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PDR">Thu. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466468">Shifting Dynamics or Breaking Sacred Traditions? The Role of Technology in Twelve-Step Fellowships</a></span><br />
<span class="authors">S. Yarosh (AT&#038;T Research Labs, USA)</span>
<div class="authorList"><span><span class="author">S. Yarosh</span> (AT&#038;T Research Labs, USA)</span></div>
<p><span class="cbStatement">Presents in-depth interviews with member of twelve-step recovery groups to understand the role of technology in these communities. Relates these findings to wider questions of design in social computing.</span><span class="abstract">Twelve-step fellowships are the most common long-term maintenance program for recovery from alcoholism and addiction. Informed by six months of participatory observation of twelve-step fellowship meetings and service structure, I conducted in-depth interviews with twelve members of Alcoholics Anonymous (AA) and Narcotics Anonymous (NA) about the role of technology in recovery. I found that there are a number of tensions in how technology is perceived and adopted. As technology and twelve-step fellowships interact, issues of anonymity, identity, consensus, access, unity, autonomy, and physical presence are foregrounded. I relate these findings to the broader research landscape and provide implications for future design in this space. </span></li>
<li id="NRX"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#NRX"><span class="letterCode" style="float:right">NRX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NRX">Thu. 2pm</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466454">Critical Perspective on Persuasive Technology Reconsidered</a></span><br />
<span class="authors">F. Yetim (Univ. of Oulu, FI)</span>
<div class="authorList"><span><span class="author">F. Yetim</span> (Univ. of Oulu, FI)</span></div>
<p><span class="cbStatement">This paper reflects on the critical perspective on persuasive technology and offers an alternative perspective. It contributes to the HCI field by calling attention to alternative reflective concepts and emerging relevant works. </span><span class="abstract">Critical researchers in HCI have recently faulted Persuasive Technology (PT) for taking a modernist approach and suggested ways for redirecting research. This paper reflects on this critical perspective and compares it with Habermas’s critical perspective. I claim that the recent critiques of PT are grounded on a narrow and pessimistic concept of modernism, and that Habermas’s works, rarely taken into account in the HCI community, can serve as an alternative lens for reflective analysis and design and can provide a foundation for justifying design decisions while realizing the unfulfilled potentials of PT. Beyond offering critical analysis and reflections, this paper contributes to the HCI field by calling attention to alternative reflective concepts and emerging relevant works. </span></li>
<li id="PEG"class="presentation engineering ux"><a href="http://chi2013.acm.org/previews/paper.html#PEG"><span class="letterCode" style="float:right">PEG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEG">Wed. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481384">Making Touchscreen Keyboards Adaptive to Keys, Hand Postures,  and Individuals &#8211; A Hierarchical Spatial Backoff Model Approach</a></span><br />
<span class="authors">Y. Yin (Massachusetts Institute of Technology, USA), T. Ouyang, K. Partridge, S. Zhai</span>
<div class="authorList"><span><span class="author">Y. Yin</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">T. Ouyang</span> (Google, Inc., USA)</span><span><span class="author">K. Partridge</span> (Google, Inc., USA)</span><span><span class="author">S. Zhai</span> (Google, Inc., USA)</span></div>
<p><span class="cbStatement">We propose a hierarchical spatial backoff model for improving text entry accuracy on touchscreen keyboards. This approach adapts the underlying spatial model to input hand postures, individuals, and key positions, reducing error rate by 13.2%.</span><span class="abstract">We propose a new approach for improving text entry accuracy on touchscreen  keyboards by adapting the underlying spatial model to factors such as input hand postures, individuals, and target key positions. To combine these factors together, we introduce a hierarchical spatial backoff model (SBM) that consists of submodels with different levels of complexity. The most general model includes no adaptive factors, whereas the most specific model includes all three. Considering that in practice people may switch hand postures (e.g., from two-thumb to one-finger) to better suit a situation, and that the specific submodels may take time to train for each user,  a specific submodel should be applied only if its corresponding input posture can be identified with confidence, and if the submodel has enough training data from the user.  We   introduce the textit{backoff} mechanism to fall back to a simpler model if   either of these conditions are not met.  We implemented a prototype system   capable of reducing the language-model-independent error rate by 13.2% using an  online posture classifier with  86.4% accuracy.  Further improvements in error  rate may be possible with even better posture classification. </span></li>
<li id="PKB"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PKB"><span class="letterCode" style="float:right">PKB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PKB">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466117">Designing Web-Connected Physical Artefacts for the ‘Aesthetic’ of the Home</a></span><br />
<span class="authors">S. Ylirisku (Aalto Univ., FI), S. Lindley, G. Jacucci, R. Banks, C. Stewart, A. Sellen, R. Harper, T. Regan</span>
<div class="authorList"><span><span class="author">S. Ylirisku</span> (Aalto Univ., FI)</span><span><span class="author">S. Lindley</span> (Microsoft Research, UK)</span><span><span class="author">G. Jacucci</span> (Helsinki Institute for Information Technology, FI)</span><span><span class="author">R. Banks</span> (Microsoft Research, UK)</span><span><span class="author">C. Stewart</span> (Univ. of Dundee, UK)</span><span><span class="author">A. Sellen</span> (Microsoft Research, UK)</span><span><span class="author">R. Harper</span> (Microsoft Research, UK)</span><span><span class="author">T. Regan</span> (Microsoft Research, UK)</span></div>
<p><span class="cbStatement">In this paper we ask what it means to design domestic web-connected technologies, placing the aesthetic of the home and home life at the centre of our design exploration.</span><span class="abstract">Web-based technologies are often built to capitalize on the flexibility and fluidity that is supported by the internet, with the value of ‘access anywhere’ underpinning a blurring of boundaries across home and work. Yet the home is well known in HCI to have a unique set of qualities that can use-fully be drawn upon when designing to support domestic life. In this paper we ask what it means to design domestic web-connected technologies, placing the aesthetic and ma-terial properties intrinsic to the home and home life at the centre of our design exploration. We present three concepts that were selected and prototyped from a broader process of research-through-design: Tokens of Search provides tangi-ble handles to web resources; Hole in Space connects the home intimately to a remote place; and Manhattan enables the tangible exploration of events in the community, putting the home at the centre. Discussions in the paper consider not only how aesthetics is articulated in the material and digital properties of the artefacts, but also how a considera-tion of the properties of the home can create a potentially new design space to explore.</span></li>
<li id="PSS"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PSS"><span class="letterCode" style="float:right">PSS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PSS">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470714">Probing Bus Stop for Insights on Transit Co-design</a></span><br />
<span class="authors">D. Yoo (Univ. of Washington, USA), J. Zimmerman, T. Hirsch</span>
<div class="authorList"><span><span class="author">D. Yoo</span> (Univ. of Washington, USA)</span><span><span class="author">J. Zimmerman</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">T. Hirsch</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">We investigate how social computing might support citizens co-design their transit service. We conducted a field study with public transit riders, exploring the issues and controversies that reveal conflicting communities.</span><span class="abstract">Social computing provides a new way for citizens to engage with their public service. Our research investigates how social computing might support citizens co-design their transit service. We conducted a field study with public transit riders, exploring the issues and controversies that reveal conflicting communities. Our analyses revealed three insights. First, encourage citizens to share what they see as the rationale for current service offerings. Second, encourage citizens to share the consequences of current services and of proposed changes and new designs. Third, focus on producing a shared citizen and service provider understanding of what the goals and mission of the public service should be.</span></li>
<li id="PBM"class="presentation design HCI4D"><a href="http://chi2013.acm.org/previews/paper.html#PBM"><span class="letterCode" style="float:right">PBM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PBM">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481349">Envisioning Across Generations: A Multi-lifespan Information System for International Justice in Rwanda</a></span><br />
<span class="authors">D. Yoo (Univ. of Washington, USA), M. Lake, T. Nilsen, M. Utter, R. Alsdorf, T. Bizimana, L. Nathan, M. Ring, E. Utter, R. Utter, B. Friedman</span>
<div class="authorList"><span><span class="author">D. Yoo</span> (Univ. of Washington, USA)</span><span><span class="author">M. Lake</span> (Univ. of Washington, USA)</span><span><span class="author">T. Nilsen</span> (Univ. of Washington, USA)</span><span><span class="author">M. Utter</span> (Univ. of Washington, USA)</span><span><span class="author">R. Alsdorf</span> (unaffiliated, USA)</span><span><span class="author">T. Bizimana</span> (Healing and Rebuilding our Communities, RW)</span><span><span class="author">L. Nathan</span> (Univ. of British Columbia, CA)</span><span><span class="author">M. Ring</span> (Univ. of Washington, USA)</span><span><span class="author">E. Utter</span> (unaffiliated, USA)</span><span><span class="author">R. Utter</span> (unaffiliated, USA)</span><span><span class="author">B. Friedman</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">With this research we investigate how to account for multi-generational perspectives in the design of multi-lifespan information systems, particularly in support of long-term peace-building and international justice. </span><span class="abstract">With this research we investigate how to account for multi-generational perspectives in the design of multi-lifespan information systems, particularly in support of long-term peace-building and international justice. We do our work in the context of the publicly available Voices from the Rwanda Tribunal testbed, a historically significant collection of video interviews with personnel from the International Criminal Tribunal for Rwanda. In the research reported here, we worked with 109 Rwandan adults and youth from perpetrator and survivor communities in three provincial cities in Rwanda (Byumba, Kibuye, and Gisenyi) to understand the potentials and challenges they envision for the interview collection. Participants envisioned five categories of long-term positive outcomes for individuals and society from a multi-lifespan information system for the interview collection; and eight categories of challenges to realize those potential outcomes. In terms of multi-generational perspectives, while adults and youth tended to share an overall vision for the long-term potential of such a system, adults emphasized actionable tasks while youth educational benefits. Based on the findings, we highlight issues for appropriation of multi-lifespan information systems and reflect on our methods for eliciting multi-generational perspectives on information system design in a post-conflict society.</span></li>
<li id="PSR"class="presentation design"><a href="http://chi2013.acm.org/previews/paper.html#PSR"><span class="letterCode" style="float:right">PSR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PSR">Mon. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470715">A Value Sensitive Action-Reflection Model: Evolving a Co-Design Space with Stakeholder and Designer Prompts</a></span><br />
<span class="authors">D. Yoo (Univ. of Washington, USA), A. Huldtgren, J. Woelfer, D. Hendry, B. Friedman</span>
<div class="authorList"><span><span class="author">D. Yoo</span> (Univ. of Washington, USA)</span><span><span class="author">A. Huldtgren</span> (Delft Univ. of Technology, NL)</span><span><span class="author">J. Woelfer</span> (Univ. of Washington, USA)</span><span><span class="author">D. Hendry</span> (Univ. of Washington , USA)</span><span><span class="author">B. Friedman</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">We introduce the Value Sensitive Action-Reflection Model: a co-design method focus on the social context of use and values that lie with individuals, groups, and societies.</span><span class="abstract">We introduce a design method for evolving a co-design space to support stakeholders untrained in design. Specifically, the purpose of the method is to expand and shape a co-design space so that stakeholders, acting as designers, focus not only on the form and function of a tool being envisioned but also on the social context of its use and values that lie with individuals, groups, and societies. The method introduces value sensitive stakeholder prompts and designer prompts into a co-design process, creating a particular kind of reflection-on-action cycle. The prompts provide a means for bringing empirical data on values and theoretical perspective into the co-design process. We present the method in terms of a general model, the Value Sensitive Action-Reflection Model; place the model within discourse on co-design spaces; and illustrate the model with a discussion of its application in a lo-fi prototyping activity around safety for homeless young people. We conclude with reflections on the model and method.</span></li>
<li id="NDN"class="presentation ux games"><a href="http://chi2013.acm.org/previews/paper.html#NDN"><span class="letterCode" style="float:right">NDN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NDN">Thu. 11am</a></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466428">I Feel For My Avatar: Embodied Perception in VEs</a></span><br />
<span class="authors">S. You (Univ. of Michigan, USA), S. Sundar</span>
<div class="authorList"><span><span class="author">S. You</span> (Univ. of Michigan, USA)</span><span><span class="author">S. Sundar</span> (The Pennsylvania State Univ., USA)</span></div>
<p><span class="cbStatement">Experimental evidence of the embodied perception in the virtual environments (VEs). Users felt burdened, when their customized avatars were burdened in the virtual environments.</span><span class="abstract">Visual perception is dependent upon one’s physical state. The apparent inclination of a hill is overestimated when the observer is carrying a heavy backpack. But, what if the hill is a virtual one and the user is about to navigate the virtual environment through an avatar? In a 2 (user with a backpack vs. user without the backpack) × 2 (avatar with a virtual backpack vs. avatar without a virtual backpack) × 2 (customized avatar vs. assigned avatar) between-subjects experiment (N = 121), participants estimated the hill as being steeper when using a customized avatar rather than an assigned one. When the avatar is encumbered by a heavy virtual backpack, those with a customized avatar perceived the virtual hill as being more difficult to climb. Avatar customization and the physical resources of the avatar (operationalized here in the form of a ‘virtual’ backpack) were found to be key predictors of embodied perception in virtual environments (VE). This has implications for the design of games and interventions that make use of VEs.</span></li>
<li id="PNX"class="presentation design games cci"><a href="http://chi2013.acm.org/previews/paper.html#PNX"><span class="letterCode" style="float:right">PNX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNX">Tue. 9am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466120">Pass the iPad: Collaborative Creating and  Sharing in Family Groups</a></span><br />
<span class="authors">N. Yuill (Univ. of Sussex, UK), Y. Rogers, J. Rick</span>
<div class="authorList"><span><span class="author">N. Yuill</span> (Univ. of Sussex, UK)</span><span><span class="author">Y. Rogers</span> (Univ. College London, UK)</span><span><span class="author">J. Rick</span> (Saarland Univ., DE)</span></div>
<p><span class="cbStatement">Reports two studies of a tablet app to support co-creation in family groups. Relates findings to use of tablets as &#8216;scrap computers&#8217;.</span><span class="abstract">The increasingly cross-generational use of personal technology portrays families each absorbed in individual devices. Tablets potentially support multi-user working but are currently used as personal devices primarily for consumption, or individual or web-based games. Could tablets support creative co-located groupwork in families and how does such creative work differ from the same task on paper? We designed and evaluated an app requiring individual and group co-creation in families. 262 family groups visiting a science fair played the collaborative drawing game on paper and iPads. Group creations were rated significantly more original and cohesive on iPads than paper. Detailed video analysis of seven family groups showed how tablets support embodiment and use of digital traces, and how the different media sustain individual and shared actions at different stages in the creative process. We sketch out implications for ownership and ‘scrap computers’: going beyond personally-owned devices and developing collaborative apps to support groupwork with tablets.</span></li>
<li id="PTN"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PTN"><span class="letterCode" style="float:right">PTN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTN">Tue. 4pm</a></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466233">A Text Message a Day Keeps the Pulmonologist Away</a></span><br />
<span class="authors">T. Yun (Samsung Electronics, KR), R. Arriaga</span>
<div class="authorList"><span><span class="author">T. Yun</span> (Samsung Electronics, KR)</span><span><span class="author">R. Arriaga</span> (Georgia Institute of Technology, USA)</span></div>
<p><span class="cbStatement">This paper encourages the use of ubiquitous technology for the primary stakeholder, and  promotes designing technology to both replicate and extend results by using a social theory of behavior change.</span><span class="abstract">The goal of this study was to extend and replicate an SMS health intervention for pediatric asthma patients. This intervention was designed using the Health Belief Model (HBM). Thirty patients were randomly assigned to one of three conditions. In the Knowledge condition patients were queried about their asthma knowledge every other day. In the Knowledge and Symptoms condition patients received a daily text message. They were queried about their symptoms and knowledge of asthma on alternate days. The Control group received no texts. Our main finding is that daily text messages lead to improved health outcomes.     We explain our results in the context of interview data and the HBM. We conclude by suggesting that the HBM can be used to inform and evaluate system design for chronic care beyond asthma and by considering the role that replication studies can play in HCI research.   </span></li>
<li id="PQM"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PQM"><span class="letterCode" style="float:right">PQM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PQM">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470775">SideWays: A Gaze Interface for Spontaneous Interaction with Situated Displays</a></span><br />
<span class="authors">Y. Zhang (Lancaster Univ., UK), A. Bulling, H. Gellersen</span>
<div class="authorList"><span><span class="author">Y. Zhang</span> (Lancaster Univ., UK)</span><span><span class="author">A. Bulling</span> (Max Planck Institute for Informatics, DE)</span><span><span class="author">H. Gellersen</span> (Lancaster Univ., UK)</span></div>
<p><span class="cbStatement">Presents a system that uses light weight computer vision techniques for calibration-free eye tracking. The system enables hands-free spontaneous interaction with situated displays using eye gaze.</span><span class="abstract">Eye gaze is compelling for interaction with situated displays as we naturally use our eyes to engage with them. In this work we present SideWays, a novel person-independent eye gaze interface that supports spontaneous interaction with displays: users can just walk up to a display and immediately interact using their eyes, without any prior user calibration or training. Requiring only a single off-the-shelf camera and lightweight image processing, SideWays robustly detects whether users attend to the centre of the display or cast glances to the left or right. The system supports an interaction model in which attention to the central display is the default state, while &#8220;sidelong glances&#8221; trigger input or actions. The robustness of the system and usability of the interaction model are validated in a study with 14 participants. Analysis of the participants&#8217; strategies in performing different tasks provides insights on gaze control strategies for design of SideWays applications.</span></li>
<li id="PEC"class="presentation "><a href="http://chi2013.acm.org/previews/paper.html#PEC"><span class="letterCode" style="float:right">PEC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEC">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481417">TrailMap: Facilitating Information Seeking in a Multi-Scale Digital Map via Implicit Bookmarking</a></span><br />
<span class="authors">J. Zhao (Univ. of Toronto, CA), D. Wigdor, R. Balakrishnan</span>
<div class="authorList"><span><span class="author">J. Zhao</span> (Univ. of Toronto, CA)</span><span><span class="author">D. Wigdor</span> (Univ. of Toronto, CA)</span><span><span class="author">R. Balakrishnan</span> (Univ. of Toronto, CA)</span></div>
<p><span class="cbStatement">Designed an auto-bookmark generation algorithm according to a user’s interactions in multi-scale digital map exploration and developed a web-application based on the proposed algorithm.</span><span class="abstract">Web applications designed for map exploration in local neighborhoods have become increasingly popular and important in everyday life. During the information-seeking process, users often revisit previously viewed locations, repeat earlier searches, or need to memorize or manually mark areas of interest. To facilitate rapid returns to earlier views during map exploration, we propose a novel algorithm to automatically generate map bookmarks based on a user’s interaction. TrailMap, a web application based on this algorithm, is developed, providing a fluid and effective neighborhood exploration experience. A one-week study is conducted to evaluate TrailMap in users’ everyday web browsing activities. Results showed that TrailMap’s implicit bookmarking mechanism is efficient for map exploration and the interactive and visual nature of the tool is intuitive to users.</span></li>
<li id="PSX"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PSX"><span class="letterCode" style="float:right">PSX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PSX">Mon. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470656">The Many Faces of Facebook: Experiencing Social Media as Performance, Exhibition, and Personal Archive</a></span><br />
<span class="authors">X. Zhao (Cornell Univ., USA), N. Salehi, S. Naranjit, S. Alwaalan, S. Voida, D. Cosley</span>
<div class="authorList"><span><span class="author">X. Zhao</span> (Cornell Univ., USA)</span><span><span class="author">N. Salehi</span> (Sharif Univ. of Technology, IR)</span><span><span class="author">S. Naranjit</span> (Cornell Univ., USA)</span><span><span class="author">S. Alwaalan</span> (King Saud Univ., SA)</span><span><span class="author">S. Voida</span> (Cornell Univ., USA)</span><span><span class="author">D. Cosley</span> (Cornell Univ., USA)</span></div>
<p><span class="cbStatement">We bring new perspectives to the design of social media by drawing from Goffman’s theatrical metaphor and Hogan’s exhibition approach to explore how people manage social media data over time. </span><span class="abstract">The growing use of social media means that an increasing amount of people’s lives are visible online. We draw from Goffman’s theatrical metaphor and Hogan’s exhibition ap-proach to explore how people manage their personal collec-tion of social media data over time. We conducted a quali-tative study of 13 participants to reveal their day-to-day decision-making about producing and curating digital traces on Facebook. Their goals and strategies showed that people experience the Facebook platform as consisting of three different functional regions: a performance region for man-aging recent data and impression management, an exhibi-tion region for longer term presentation of self-image, and a personal region for archiving meaningful facets of life. Further, users’ need for presenting and archiving data in these three regions is mediated by temporality. These find-ings trigger a discussion of how to design social media that support these dynamic and sometimes conflicting needs.</span></li>
<li id="PCF"class="presentation management"><a href="http://chi2013.acm.org/previews/paper.html#PCF"><span class="letterCode" style="float:right">PCF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCF">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481311">Effects of Peer Feedback on Contribution: A Field Experiment in Wikipedia</a></span><br />
<span class="authors">H. Zhu (Carnegie Mellon Univ., USA), A. Zhang, J. He, R. Kraut, A. Kittur</span>
<div class="authorList"><span><span class="author">H. Zhu</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Zhang</span></span><span><span class="author">J. He</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">R. Kraut</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Kittur</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">The paper furthers our understanding of the effects of peer feedback in online communities and provides practical guidance to design more effective peer feedback systems.</span><span class="abstract">One of the most significant challenges for many online communities is increasing members’ contributions over time. Prior studies on peer feedback in online communities have suggested its impact on contribution, but have been limited by their correlational nature. In this paper, we conducted a field experiment on Wikipedia to test the effects of different feedback types (positive feedback, negative feedback, directive feedback, and social feedback) on members’ contribution. Our results characterize the effects of different feedback types, and suggest trade-offs in the effects of feedback between the focal task and general motivation, as well as differences in how newcomers and experienced editors respond to peer feedback. This research provides insights into the mechanisms underlying peer feedback in online communities and practical guidance to design more effective peer feedback systems.</span></li>
<li id="PNQ"class="presentation design engineering"><a href="http://chi2013.acm.org/previews/paper.html#PNQ"><span class="letterCode" style="float:right">PNQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PNQ">Mon. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470748">AutoGami: A Low-cost Rapid Prototyping Toolkit for Automated Movable Paper Craft</a></span><br />
<span class="authors">K. Zhu (National Univ. of Singapore, SG), S. Zhao</span>
<div class="authorList"><span><span class="author">K. Zhu</span> (National Univ. of Singapore, SG)</span><span><span class="author">S. Zhao</span> (National Univ. of Singapore, SG)</span></div>
<p><span class="cbStatement">We presents a systematic analysis of the design space for automated movable paper craft, and developed a low-cost rapid prototyping toolkit for automated movable paper craft using the technology of selective inductive power transmission.  </span><span class="abstract">AutoGami is a toolkit for designing automated movable paper craft using the technology of selective inductive power transmission. AutoGami has hardware and software components that allow users to design and implement automated movable paper craft without any prerequisite knowledge of electronics; it also supports rapid prototyping. Apart from developing the toolkit, we have analyzed the design space of movable paper craft and developed a taxonomy to facilitate the design of automated paper craft. AutoGami made consistently strong showings in design workshops, confirming its viability in supporting engagement and creativity as well as its usability in storytelling through paper craft. Additional highlights include rapid prototyping of product design as well as interaction design such as human-robot interactions.</span></li>
<li id="NNF"class="presentation design engineering ux arts"><a href="http://chi2013.acm.org/previews/paper.html#NNF"><span class="letterCode" style="float:right">NNF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NNF">Wed. 2pm</a></span><span class="award best"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481361">FreeD – A Freehand Digital Sculpting Tool</a></span><br />
<span class="authors">A. Zoran (Massachusetts Institute of Technology, USA), J. Paradiso</span>
<div class="authorList"><span><span class="author">A. Zoran</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">J. Paradiso</span></span></div>
<p><span class="cbStatement">This paper explores the intersection of craft and digital fabrication through the FreeD, a handheld milling device, preserving the maker’s freedom to sculpt and carve based on virtual 3D models.  </span><span class="abstract">In this paper, we present an approach to combining digital fabrication and craft, emphasizing the user experience. While many researchers strive to enable makers to design and produce 3D objects, our research seeks to present a new fabrication approach to make unique, one-of-a-kind artifacts. To that end, we developed the FreeD, a hand-held digital milling device. The system is guided and monitored by a computer while preserving the maker’s freedom to sculpt and carve, and to manipulate the work in many creative ways. Relying on a predesigned 3D model, the computer gets into action only when the milling bit risks the object’s integrity, by slowing down the spindle’s speed or by drawing back the shaft, while the rest of the time it allows complete gestural freedom. We describe the key concepts of our work and its motivation, present the FreeD’s architecture and technology, and discuss two projects made with the tool.</span></li>
<li id="PEF"class="presentation ux"><a href="http://chi2013.acm.org/previews/paper.html#PEF"><span class="letterCode" style="float:right">PEF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PEF">Wed. 11am</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481344">Mobile Advertising: Evaluating the Effects of Animation, User and Content Relevance</a></span><br />
<span class="authors">M. de Sa (Facebook, Inc., USA), V. Navalpakkam, E. Churchill</span>
<div class="authorList"><span><span class="author">M. de Sa</span> (Facebook, Inc., USA)</span><span><span class="author">V. Navalpakkam</span> (Google, Inc., USA)</span><span><span class="author">E. Churchill</span> (eBay Research Lab, USA)</span></div>
<p><span class="cbStatement">Study on animation, user and content relevance on mobile ads. Results indicate personal relevance leads to better experiences, content relevance to better ad recall and blinking animation affects user experience.</span><span class="abstract">The potential for user-relevant, context-appropriate,  targeted advertising on mobile devices is enormous given  device improvements and advances in personal and  location-based data collection. However, little is known  about how users experience display advertisements (‘ads’)  on mobile devices, or what factors drive mobile ad  effectiveness. In this paper, we investigate users’  experiences of display advertising on mobile devices. We  consider three factors that are often studied in desktop  settings –the ad’s level of personal relevance to the user, its  relevance to the page content, and within-ad properties,  with a particular focus on the level of animation in the ad.  Our findings reveal a few surprises. First, personal  relevance to the user has little or no impact on ad efficacy  measured by recall. Instead, content relevance boosts ad  recall. Second, user relevance leads to a more pleasant and  interesting experience, but content relevance has no effect.  Third, contrary to the popular notion that animation often  leads to more effective ads by garnering more user  attention, we find that a simple type of animation, such as  blinking animation, negatively affects user experience and  reduces ad recall. Our findings, while focused on  advertising, offer insights for design of mobile content  presentation in general.</span></li>
<li id="PNR"class="presentation design ux"><a href="http://chi2013.acm.org/previews/paper.html#PNR"><span class="letterCode" style="float:right">PNR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PNR">Wed. 4pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481399">Design Research by Proxy: using Children as Researchers to gain Contextual Knowledge about User Experience.</a></span><br />
<span class="authors">F. van Doorn, P. Stappers, M. Gielen</span>
<div class="authorList"><span><span class="author">F. van Doorn</span></span><span><span class="author">P. Stappers</span></span><span><span class="author">M. Gielen</span></span></div>
<p><span class="cbStatement">This paper explores the use of participants as research collaborators in contextual user research. A case study was conducted to investigate if and how children can perform as research collaborators. </span><span class="abstract">This paper explores the use of participants as research collaborators in the domain of contextual user research. In participatory- and co-design, users participate increasingly early in the design process. When conducting user research in order to gain contextual knowledge about the lives, experiences and wishes of users, collaborators can be of help in setting up, conducting research and analyzing the data. A case study was conducted to investigate if and how children are able to perform as research collaborators. Children conducted interviews with other participants, and in doing increased their knowledge about people close to them, and about themselves. The gained insights were personal and the used personas proved to be a valuable tool. In the role of researcher, the children discovered similarities and differences between themselves and others. Besides gaining valuable insights from their participants, they accessed and shared their own experiences, so while listening to others, the children got sensitized themselves. In other words, the current study found that next to gathering more data, “super-sources” are created when children become research collaborators.</span></li>
<li id="PGP"class="presentation health"><a href="http://chi2013.acm.org/previews/paper.html#PGP"><span class="letterCode" style="float:right">PGP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGP">Tue. 2pm</a></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466196">SimMed: Combining Simulation and Interactive Tabletops for Medical Education</a></span><br />
<span class="authors">U. von Zadow (Archimedes Exhibitions GmbH, DE), S. Buron, T. Harms, F. Behringer, K. Sostmann, R. Dachselt</span>
<div class="authorList"><span><span class="author">U. von Zadow</span> (Archimedes Exhibitions GmbH, DE)</span><span><span class="author">S. Buron</span> (Charité-Univ., DE)</span><span><span class="author">T. Harms</span> (Charité-Univ., DE)</span><span><span class="author">F. Behringer</span> (Charité-Univ., DE)</span><span><span class="author">K. Sostmann</span> (Charité-Univ., DE)</span><span><span class="author">R. Dachselt</span> (Technische Univ. Dresden, DE)</span></div>
<p><span class="cbStatement">SimMed supports collaborative medical education using a life-sized virtual patient on a multitouch tabletop. We address the interplay between realism, immersion and training goals in this context.</span><span class="abstract">A large body of work asserts that interactive tabletops are well suited for group work, and numerous studies have examined these devices in educational contexts. However, few of the described systems support simulations for collaborative learning, and none of them explicitly address immersion. We present SimMed, a system allowing medical students to collaboratively diagnose and treat a virtual patient using an interactive tabletop. The hybrid user interface combines elements of virtual reality with multitouch input. The paper delineates the development process of the system and rationale behind a range of interface design decisions. Thereby, the role of realism in gaining procedural knowledge is discussed &#8211; in particular, the interplay between realism, immersion and training goals. We implemented several medical test cases and evaluated our approach with a user study that suggests the great potential of the system. Results show a high level of immersion, cooperation and engagement by the students.</span></li>
</ul>
						
					</div><!-- .entry-content -->
				</div><!-- #post-## -->
				

<div style="clear:both;"></div>	
				<div style="clear:both;width:100%;">
	
	<div style="float:left;width:48%;"></div>
	<div  style="float:right;width:48%;"></div>
</div>
								
<!-- You can start editing here. -->


			<!-- If comments are closed. -->
		<p class="nocomments"></p>

	
	<div  style="clear:both;"></div><div style="clear:both;height:40px;"></div>
      
                      <div class="clr"></div>
                </div><!--content midd end -->
        <!-- c-ao 23jan13 adjustment for page id 1213 to make it wider and eliminate the right sidebar -->
				
        </div><!-- content wrapper end -->
        
              <div id="footer"><!--footer-->
        
        				<div id="footer_nav">
                
                                <ul>                   
<!--                                     <li><a href="#">Home</a></li>
                                     <li><a href="#">Sample Page</a></li>
                                     <li><a href="#">Sample Page 2</a></li>               -->     
                                </ul>
                
                		</div>
                        
                        
                         <div id="copyright">
                        
                        		© copyright 2012, <a href=""> ACM SIGCHI</a>
      <a href="http://jigsaw.w3.org/css-validator/check/referer">
</a>   
                        
               	    </div>
        
       			 </div><!--footer end-->

        
        

<div class="clr"></div>
</div><!--####  wrapper  ###-->




</body>
</html>