<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>


<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<script src="../scripts/jQuery.js"></script>
	<script type="text/javascript"> 
function toggleText(el)
{
	var v = el.value;
	var defaulttext="Type to filter..."
	
   //Remove text to allow editing   
    if(el.className=="inactive") {
        el.value = "";
        el.className = "active";
    }
	
    else {
	/*
         //Remove whitespace
        if(v.indexOf(" ")!=-1) {
                split = v.split(" ").join("");
                v = split;
        }
*/
          //Change to inactive state
        if(v=="") {
                el.value = defaulttext;
                el.className = "inactive";
        }
    }
	
}
		
		$(document).ready(function() {

			var sessions = $("td.session");
			var sessionDetails = $("td.session_details");
			var searchTimeout = null;
			
			var savedSearch = "";
			var mode = "live";


			jQuery.expr[':'].Contain = function(a,i,m){
			    return (a.textContent || a.innerText || "").toLowerCase().indexOf(m[3].toLowerCase())>=0;
			};
		

			$("td.session_details").parent().hide();
			$("td.session_details").hide();
			$("span.togglePapers").hide();
			
			$("a.title").click(function() {
				$(this).parent().click();
				return false;
			});
			
			$("td.session").each(function(index) {
				var id = $(this).attr("id");				
				var details = $("td#" + id + "_details");
				
				if (details.length == 1) {
					$(this).addClass("expandable");
				}
			});
			
			$("td.expandable").click(function() {
				
				if (mode == "print") {
					return false;
				}
				
				var id = $(this).attr("id");				
				var details = $("td#" + id + "_details");
				
				if (details.length == 0) {
					return;
				}
				
				var alreadyShowing = $(this).hasClass("expanded");

				$(this).parent().next().find("td.session_details").hide();
				$(this).parent().next().hide();
				$(this).siblings("td.time").attr("rowspan", 1);
				$(this).parent().children().removeClass("expanded");

				if (!alreadyShowing) {
					$(this).siblings("td.time").attr("rowspan", 2);
					details.parent().show();
					details.show();
					$(this).addClass("expanded");
					abstracts = details.find("span.abstractText");
					if (abstracts.length == 1) {
						abstracts.show();
					}
				}
			});
			
			
			function expandAbstractsFor(id) {
				$("td#" + id + "_details").find("span.abstractText").toggle();
			}
									
			function filterSessions() {
				var search = $("input#filter").val();
				if (search != "") {
					
					// Fade all sessions and details
					sessions.fadeTo(0, 0.33);
					sessionDetails.filter(":visible").fadeTo(0, 0.33);
					
					sessionDetails.filter(":Contain(" + search + ")").each(function(index) {
						$(this).filter(":visible").fadeTo(0, 1.0)
						var sID = $(this).attr("id").split("_")[0];
						$("td#" + sID).fadeTo(0, 1.0);
					});
					
					sessions.filter(":Contain(" + search + ")").each(function(index) {
						var sID = $(this).attr("id");
						$(this).fadeTo(0, 1.0);
						$("div#" + sID + "_details").filter(":visible").fadeTo(0, 1.0);
					});

				} else {
					sessions.filter(":visible").fadeTo(0, 1.0);
					sessionDetails.filter(":visible").fadeTo(0, 1.0);
				}
				location.hash = escape(search);
			}

			/*
			$("input#filter").click(function() {
				$(this).attr("value", "");
				$(this).keyup();
			});
			*/
			
			$("input#filter").keyup(function() {
				clearTimeout(searchTimeout);
				searchTimeout = setTimeout(filterSessions, 200);
			});
			
			
			$("span.toggleAbstract").toggle(
				function () {
			    	$(this).next("span.abstractText").show();
				},
			    function () {
			    	$(this).next("span.abstractText").hide();
			    }
			);
			
			
			$("input.sessioncheck").click(function(event) {
				event.stopPropagation();
				
				var sessionId = $(this).parent().attr("id");
				var details = $("td#" + sessionId + "_details");
				
				var paperchecks = details.children("div.paper").children("input.papercheck");
				paperchecks.attr("checked", $(this).attr("checked"));
			
				/*
				if ($(this).attr("checked")) {
					$(this).next("span.paperschecked").text("" + paperchecks.length);
				} else {
					if ($(this).next("span.paperschecked").text() == $(this).nextAll("span.totalpapers").text()) {
						$(this).next("span.paperschecked").text("0");
					} else {
						$(this).attr("checked", true);
						paperchecks.attr("checked", true);
						$(this).next("span.paperschecked").text("" + paperchecks.length);
					}
				}
				*/
			
				fadeChecked();
			
			});
			
			$("input.papercheck").click(function() {
				var sessionId  = $(this).parent().parent().attr("id").split("_", 1)[0];
				var checkCount = $(this).parent().parent().children("div.paper").children("input:checked").length;
				$("td#" + sessionId + " > span.paperschecked").text("" + checkCount);
				if (checkCount > 0) {
					$("td#" + sessionId + " > input.sessioncheck").attr("checked", true);
				} else {
					$("td#" + sessionId + " > input.sessioncheck").attr("checked", false);
				}
				
				fadeChecked();
			});
			
			
			function printMode() {
				savedSearch = $("input#filter").val();
				$("input#filter").val("");
				filterSessions();
				$("input#filter").attr("disabled", "disabled");
				mode = "print";
			}
			
			function liveMode() {
				$("input#filter").removeAttr("disabled");
				$("input#filter").val(savedSearch);
				filterSessions();
				mode = "live";
			}
			
			
			function fadeChecked() {
				if ($("input#showChecked").attr("checked")) {
					
					printMode();
					
					$("div.paper > input.papercheck:not(:checked)").parent().fadeTo(0, 0.75);
					$("div.paper > input.papercheck:checked").parent().fadeTo(0, 1.0);
					
					$("td.session > input.sessioncheck:not(:checked)").parent().fadeTo(0, 0.75).each(function(index) {
						$("td#" + $(this).attr("id") + "_details").hide();
						$(this).removeClass("expanded");
						$(this).hide();
					});
					
					$("td.session > input.sessioncheck:checked").parent().fadeTo(0, 1.0).each(function(index) {
						$("td#" + $(this).attr("id") + "_details").show();
						$("td#" + $(this).attr("id") + "_details").parent().show();
						$(this).parent().next().show();
						$(this).siblings("td.time").attr("rowspan", 2);
						$(this).addClass("expanded");
					});

					$("tr.details_row > td").each(function(index) {
						var detailsShown = $(this).parent().children("td.session_details:visible").length;
						var newColspan = $(this).parent().prev("tr.timeslot").children("td.session").length / detailsShown;
						//$(this).parent().children("td.session_details:visible").attr("colspan", newColspan);
						$(this).parent().children("td.session_details:visible").attr("colspan", 1);
					});

				} else {
					
					$("div.paper").fadeTo(0, 1.0);
					$("td.session_details").hide();
					$("td.session_details").parent().hide();
					$("td.session_details").each(function(index) {
						$(this).attr("colspan", $(this).parent().prev("tr.timeslot").children("td.session").length);
					});
					$("td.time").attr("rowspan", 1);
					$("td.session").show();
					$("td.session").removeClass("expanded");
					
					liveMode();
					
				}
			}
			
			$("input#showChecked").click(function() {
				fadeChecked();
			});

			var query = location.hash.replace("#", "");
			if (query != "") {
				if ($("td#" + query).length == 1) {
					$("td#" + query).click();
					expandAbstractsFor(query);
				} else if ($("div#" + query).length == 1) {
					var submission = $("div#" + query);
					var sessionId = submission.parent().attr("id").split("_")[0];
					$("td#" + sessionId).click();
					submission.find("span.abstractText").show();
				} else {
					$("input#filter").val(unescape(query));
					filterSessions();
				}
			}
            
        });
     
	</script> 
	
	<style type="text/css">
		
		/* CSS RESET */
		
		html, body, div, span, applet, object, iframe,
		h1, h2, h3, h4, h5, h6, p, blockquote, pre,
		a, abbr, acronym, address, big, cite, code,
		del, dfn, em, font, img, ins, kbd, q, s, samp,
		small, strike, strong, sub, sup, tt, var,
		b, u, i, center,
		dl, dt, dd, ol, ul, li,
		fieldset, form, label, legend,
		table, caption, tbody, tfoot, thead, tr, th, td {
			margin: 0;
			padding: 0;
			border: 0;
			font-size: 100%;
			vertical-align: baseline;
			background: transparent;
		}
		body {
			line-height: 1;
		}
		ol, ul {
			list-style: none;
		}
		blockquote, q {
			quotes: none;
		}
		blockquote:before, blockquote:after,
		q:before, q:after {
			content: '';
			content: none;
		}

		/* remember to define focus styles! 
		:focus {
			outline: 0;
		}
		*/
		/* remember to highlight inserts somehow! */
		ins {
			text-decoration: none;
		}
		del {
			text-decoration: line-through;
			font-weight: normal;
		}

		/* tables still need 'cellspacing="0"' in the markup 
		table {
			border-collapse: collapse;
			border-spacing: 0;
		}
		*/
		/* END CSS RESET */
		
		
		body {
			font-family: Helvetica;
			margin: 0em 1em;
		}
		
		
		table.program {
			margin: 1em;
			line-height: 1.25em;
			table-layout: fixed;
		}
		
		td {
			font-size: 0.8em;
			min-width: 5em;
		}
		
		tr.timeslot td {
			padding: 1em;
			border: 1px solid #AAA;
			border-top-width: 1px;
			border-left-width: 0px;
		}

		tr.timeslot td:first-child {
			border-left-width: 1px;
		}

		tr.closer td {
			border-top: 1px solid #AAA;
		}
		
		
		td.time {
			text-align: center;
			vertical-align: top;
			background-color: #EBEBEB;
			font-weight: bold;
			line-height: 1.5em;
			width: 5em;
			max-width: 5em;
		}

		div.session_box {
			text-align: center;
			width: 10em;
		}
		
		input.sessioncheck {
			margin-top: 1em;
		}
		
		td.session img {
			margin-top: 1em;
			display: inline;
		}
		
		td.expanded {
			border-bottom-width: 0px !important;
			border-bottom-color: #FFF;
			background-color: #EEF;
		}
		
		td.expandable:hover {
			cursor: pointer;
			background-color: #EEF;		
		}
		
		tr.details_row {
			display: none;
		}
		
		td.session_details {
			padding: 1em;
			background-color: #EEF;
			border-bottom: 1px solid #AAA;
			border-right: 1px solid #AAA;
		}
		

		span.type, .title {
			display: block;
		}
		
		span.type {
			font-style: italic;
			width: 10em;
			margin-left: auto;
			margin-right: auto;
		}
		
		span.location {
			white-space: nowrap;
			display: block;
		}
		
		.title {
			font-weight: bold;
			margin: 0.5em 0em;
			text-decoration: underline;
			color: #000;
		}
		
		div.day {
			margin-top: 2em;
			margin-bottom: 5em;
		}
		
		div.day h1 {
			font-size: 1.5em;
		}
		
		div.paper {
			margin-bottom: 4em !important;
		}
		
		div.paper a.title {
			display: inline;
		}
		
		div.paper span.type {
			display: inline;	
		}
		
		div#notice {
			background-color: #DDF;
			padding: 1em;
			line-height: 1.25em;
		}
		
		div#notice > small{
			font-size: 0.8em;
		}
		
		div.authors {
			margin-left: 1em;
			margin-bottom: 0.5em;
			margin-top: 0.5em;
		}
		
		a.author {
			color: #000;
		}
		
		
		div.abstract {
			margin-left: 1em;
			width: 60em;
		}
		
		span.toggleAbstract {
			font-weight: bold;
			cursor: pointer;
		}
		
		span.abstractText {
			display: none;
		}
		
		input.papercheck {
			margin-right: 0.75em;
			margin-left: 1em;
		}
		
		.affiliation {
			font-style: italic;
			color: #000;
		}
		
		div#searchArea {
			margin: 2em;
			font-weight: bold;
		}
		
		div#searchArea span {
			margin: 0em 1em;
			text-transform: uppercase;
			font-variant: small-caps;
			font-weight: bold;
		}

		div#searchArea input#filter {
			font-size: 1em;
			text-transform: uppercase;
			font-variant: small-caps;
			font-weight: bold;
		}

		div#pageLinks {
			margin-top: 2em;
			margin-left: 1em;
		}
		
		div#pageLinks a {
			text-transform: uppercase;
			font-variant: small-caps;
			margin: 0em 1em;
		}
		
		div.session_link_div {
			text-align: right;
			width: 100%;
			background-color: #FCC;
		}
		
		div#jumpLinks {
			margin: 2em 1em;
		}
		
		div#jumpLinks a {
			text-transform: uppercase;
			font-variant: small-caps;
			margin: 0em 1em;
		}
		
	</style>

	
    <title>CHI 2011 Program</title>
    <link rel="stylesheet" href="main.css" />
    
    <script src="../scripts/setup-json.js"></script>
    <script src="setup.js"></script>
    <style>
		
#filter.active {
    color: black;
}

#filter.inactive {
    color: #909090;
}	
	
a.sort-link{
	background-color: #005868;
    color: #FFFFFF;
    font-size: 8pt;
    height: 28px;
    text-align: center;
    text-decoration: none;
    margin: 5px;
	padding: 5px;
}	

.jumpto{
	padding: 5px;
}

.title {
			font-weight: bold;
			margin: 0.5em 0em;
			text-decoration: none;
			color: #015869;
		}

tr.timeslot td.time {
	text-align: center;
	vertical-align: top;
	background-color: #d4f3f6;
	font-weight: bold;
	line-height: 1.5em;
	width: 5em;
	max-width: 5em;
}
tr.timeslot td.expanded {
			background-color: #7bcae1;
			color: #fff
		}
td.expanded {
	border-bottom-width: 0px !important;
	border-bottom-color: #FFF;
	background-color: #7bcae1;
	color: #fff
}
		
td.session:hover {
	background-color: #7bcae1;
	color: #fff
}

td.session_details {
    background-color:  #7bcae1;
    border-bottom: 1px solid #AAAAAA;
    border-right: 1px solid #AAAAAA;
    padding: 1em;
}

#main-div h2, h1 {
    color: #000000;
}

div#jumpLinks a {
    font-variant: small-caps;
    margin: 0 1em;
    text-transform: uppercase;
}
    </style>
	

</head>

<body >
<div id="logo-placeholder">
</div>

<img alt="chi2011 logo" src="images/chi_authorsearch_head2.png"/>
<div id="main-nav" style="left:235px">
	<div id="title" style="color: #FFFFFF; position: absolute; top:120px; font-size: 24px; left: 30px">
		CHI 2011 Advance Technical Conference Program
	</div>
	<a href="program.html" alt="Conference" style="background-image: url('images/chi_author_programBTN.png'); position: absolute; left: 30px; top: 160px; height: 27px; width: 155px"></a>
	
	<a href="byAuthor.html" alt="Sort by Author" style="background-image: url('images/chi_author_sort01BTN.png'); position: absolute; left: 195px; top: 160px; height: 27px; width: 155px"></a>
	
	<a href="byAffiliation.html" alt="Sort by Affiliation" style="background-image: url('images/chi_author_sort02BTN.png'); position: absolute; left: 360px; top: 160px; height: 27px; width: 155px"></a>
		
	<input id="filter" type="text" style="width: 200px; position: absolute; left: 30px; top: 200px" value="Type to filter..." class="inactive">

	</div> 
</div>


<div id="main-div" style="top:270px">
<br>
<br>
<!--
<a class="sort-link" href="program.html">CONFERENCE PROGRAM</a> 
<a class="sort-link" href="byAuthor.html">SORT BY AUTHOR</a> 
<a class="sort-link" href="byAffiliation.html">SORT BY AFFLIATION</a>  

<div id="searchArea"> 
		Filter by session title, papers, authors, abstracts, location... : 
		<input id="filter" type="text" value="" />
	</div> 
-->
	

<div id="jumpLinks"><a href="#day0">Friday, May 06</a><a href="#day1">Saturday, May 07</a><a href="#day2">Sunday, May 08</a><a href="#day3">Monday, May 09</a><a href="#day4">Tuesday, May 10</a><a href="#day5">Wednesday, May 11</a><a href="#day6">Thursday, May 12</a></div><div class="day" id="day0"><h1>Friday, May 06, 2011</h1><table cellspacing="0" class="program" id="day_0">
<tr class="timeslot">
<td class="time">16:00<br />-<br />18:00</td>

<td class="session tbd" id="S1001">
<div class="session_box">
<span class="type"></span>
<a href="#S1001" class="title">Registration Open</a>
<span class="location">Ballroom Foyer</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
</table>
</div>

<div class="day" id="day1"><h1>Saturday, May 07, 2011</h1><table cellspacing="0" class="program" id="day_1">
<tr class="timeslot">
<td class="time">07:30<br />-<br />12:00</td>

<td class="session tbd" id="S1002">
<div class="session_box">
<span class="type"></span>
<a href="#S1002" class="title">Registration Open</a>
<span class="location">Ballroom Foyer</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">09:00<br />-<br />18:00</td>

<td class="session " id="S1017">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1017" class="title">&#8220;Privacy for a Networked World&#8221;:  Bridging Theory and Design</a>
<span class="location">216</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1020">
<div class="session_box">
<span class="type"></span>
<a href="#S1020" class="title">Open</a>
<span class="location">221/222</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1008">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1008" class="title">Child Computer Interaction: Workshop on UI Technologies and Educational Pedagogy</a>
<span class="location">119/120</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1016">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1016" class="title">The User in Flux: Bringing HCI and Digital Arts Together to Interrogate Shifting Roles in Interactive Media</a>
<span class="location">215</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1014">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1014" class="title">Video Interaction - Making Broadcasting a Successful Social Media</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1013">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1013" class="title">Analytic Provenance: Process + Interaction + Insight</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1018">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1018" class="title">Designing Interaction for the Cloud</a>
<span class="location">217/218/219</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1021">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1021" class="title">Personal Informatics and HCI: Design, Theory, and Social Implications</a>
<span class="location">223/224</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1015">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1015" class="title">Designer Experience: Exploring Ways to Design in Experience</a>
<span class="location">211</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1006">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1006" class="title">Distributed User Interfaces 2011</a>
<span class="location">116/117</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1009">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1009" class="title">Gamification. Using Game-Design Elements in Non-Gaming Contexts</a>
<span class="location">109</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1010">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1010" class="title">Visible - Actionable - Sustainable: Sustainable Interaction Design in Professional Domains</a>
<span class="location">110</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1003">
<div class="session_box">
<span class="type">Doctoral Consortium</span>
<a href="#S1003" class="title">Doctoral Consortium</a>
<span class="location">113</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1011">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1011" class="title">Data Collection by the People, for the People</a>
<span class="location">212/213/214</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1004">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1004" class="title">HCI, Politics and the City: Engaging with Urban Grassroots Movements for Reflection and Action</a>
<span class="location">114/115</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1019">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1019" class="title">Ethics, Logs and Videotape: Ethics in Large Scale User Trials and User Generated Content</a>
<span class="location">220</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1007">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1007" class="title">Large Displays in Urban Life - from Exhibition Halls to Media Facades</a>
<span class="location">118</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1012">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1012" class="title">Managing UX experience teams: lessons from case studies, establishing best practices</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="18" class="session_details" id="S1017_details"><div class="paper" id="wo133"><a href="#wo133" class="title">&#8220;Privacy for a Networked World&#8221;:  Bridging Theory and Design</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979579&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Airi  Lampinen</span> <span class="affiliation">Helsinki Institute for Information Technology HIIT / Aalto University</span>, <br />
<span class="author">Fred  Stutzman</span> <span class="affiliation">University of North Carolina - Chapel Hill</span>, <br />
<span class="author">Markus  Bylund</span> <span class="affiliation">Swedish Institute of Computer Science</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As our lives are more commonly mediated by IT, an interactional perspective of privacy [7] is increasingly applicable to the study of how people find and construct privacy in socio-technical interactions. This perspective has received increasing attention within the HCI research community in recent years. While the interactional perspective has proven effective as a starting point for theoretical and empirical studies of privacy in relation to everyday use of IT, there remain important open questions regarding how to translate results based on this perspective into design practice. Addressing these questions requires a greater sensitivity to when interactional privacy is applicable, a better understanding of suitable research methods, and more effective means for communicating results to the research and practitioner communities.</span></div></div></td>
<td colspan="18" class="session_details" id="S1008_details"><div class="paper" id="wo162"><a href="#wo162" class="title">Child Computer Interaction: Workshop on UI Technologies and Educational Pedagogy</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979580&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Edward  Tse</span> <span class="affiliation">SMART Technologies</span>, <br />
<span class="author">Johannes  Sch&#246;ning</span> <span class="affiliation">DFKI GmbH</span>, <br />
<span class="author">Jochen  Huber</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Lynn  Marentette</span> <span class="affiliation">Union County Public Schools</span>, <br />
<span class="author">Richard  Beckwith</span> <span class="affiliation">Intel Corporation</span>, <br />
<span class="author">Yvonne  Rogers</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Max  M&#252;hlh&#228;user</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Given the growth of Child Computer Interaction research, next generation HCI technologies play an important role in the future of education. Educators rely on technology to improve and adapt learning to the pedagogical needs of learners. Hence, this community needs to understand how current technology concepts match with current pedagogical paradigms. The classroom is a high stakes environment for experimentation, thus new interaction techniques need to be validated to prove their pedagogical value in the educational setting. This workshop provides a forum to discuss key HCI issues facing next generation education. With a particular focus on child computer interaction, these issues comprise inter alia the interaction with whole class interactive whiteboards, small group interactive multi-touch tables, and individual personal response systems (e.g. mobile devices) in the classroom.</span></div></div></td>
<td colspan="18" class="session_details" id="S1016_details"><div class="paper" id="wo177"><a href="#wo177" class="title">The User in Flux: Bringing HCI and Digital Arts Together to Interrogate Shifting Roles in Interactive Media</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979571&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tuck W Leong</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Lalya  Gaye</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Atau  Tanaka</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Peter C Wright</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the advent of interactive digital media, people are <br /> no longer simply &#8216;users&#8217;. They actively shift between <br /> various roles: author, collaborator, and even performer. <br /> We coin the term &#8220;user in flux&#8221; to problematize static <br /> definitions of &#8220;the user&#8221; and highlight how people&#8217;s <br /> roles and practices switch and evolve when engaged in <br /> such interactions. Drawing on participatory practices <br /> and seeking inspiration from interactive artists, this <br /> workshop explores the &#8221;user in flux&#8221; with an aim to <br /> establish directions and approaches that can revitalize <br /> the HCI community&#8217;s understanding of the user and <br /> inform the design of technologies used for interacting <br /> with digital media, and promote a new research <br /> agenda.</span></div></div></td>
<td colspan="18" class="session_details" id="S1014_details"><div class="paper" id="wo140"><a href="#wo140" class="title">Video Interaction - Making Broadcasting a Successful Social Media</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979578&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Oskar  Juhlin</span> <span class="affiliation">Mobile Life Centre, Stockholm</span>, <br />
<span class="author">Erika  Reponen</span> <span class="affiliation">Nokia Research</span>, <br />
<span class="author">Frank  Bentley</span> <span class="affiliation">Motorola Mobility</span>, <br />
<span class="author">David  Kirk</span> <span class="affiliation">Horizon Digital Economy Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Video has slowly been gaining popularity as a social media. We are now witnessing a step where capture and live broadcasts is released from the constraints of the desktop computer, which further accentuate issues such as video literacy, collaboration, hybridity, utility and privacy, that needs to be addressed in order to make video useful for large user groups.</span></div></div></td>
<td colspan="18" class="session_details" id="S1013_details"><div class="paper" id="wo167"><a href="#wo167" class="title">Analytic Provenance: Process+Interaction+Insight</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979570&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chris  North</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Remco  Chang</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Alex  Endert</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Wenwen  Dou</span> <span class="affiliation">UNC Charlotte</span>, <br />
<span class="author">Richard  May</span> <span class="affiliation">Pacific Northwest National Lab</span>, <br />
<span class="author">Bill  Pike</span> <span class="affiliation">Pacific Northwest National Lab</span>, <br />
<span class="author">Glenn  Fink</span> <span class="affiliation">Pacific Northwest National Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces. One key aspect that separates visual analytics from other related fields (InfoVis, SciVis, HCI) is the focus on analytical reasoning. While the final products generated at from an analytical process are of great value, research has shown that the processes of the analysis themselves are just as important if not more so. These processes not only contain information on individual insights discovered, but also how the users arrive at these insights. This area of research that focuses on understanding a user&#8217;s reasoning process through the study of their interactions with a visualization is called Analytic Provenance, and has demonstrated great potential in becoming a foundation of the science of visual analytics. The goal of this workshop is to provide a forum for researchers and practitioners from academia, national labs, and industry to share methods for capturing, storing, and reusing user interactions and insights. We aim to develop a research agenda for how to better study analytic provenance and utilize the results in assisting users in solving real world problems.</span></div></div></td>
<td colspan="18" class="session_details" id="S1018_details"><div class="paper" id="wo184"><a href="#wo184" class="title">Designing Interaction for the Cloud</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979582&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  England</span> <span class="affiliation">Liverpool John Moores University</span>, <br />
<span class="author">Martin  Randles</span> <span class="affiliation">Liverpool John Moores University</span>, <br />
<span class="author">Azzelarabe  Taleb-Bendiab</span> <span class="affiliation">Liverpool John Moores University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Cloud computing is moving from a buzzword to a set of useful services which promise the benefits of Computing as a utility, removing the responsibility for infrastructure and software application management from end users and organizations. However, the full implications of moving to a cloud-based platform on the user experience are not clear. In this workshop we intend to bring together researchers and practitioners from various fields where cloud computing is becoming an issue. We wish to examine the impact of cloud computing on the design of the user experience at the individual and organizational level.</span></div></div></td>
<td colspan="18" class="session_details" id="S1021_details"><div class="paper" id="wo192"><a href="#wo192" class="title">Personal Informatics and HCI: Design, Theory, and Social Implications</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979573&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ian  Li</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Anind  Dey</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jodi  Forlizzi</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Kristina  H&#246;&#246;k</span> <span class="affiliation">Stockholm University</span>, <br />
<span class="author">Yevgeniy  Medynskiy</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Personal informatics is a class of systems that help people collect personal information to improve self-knowledge. The development of personal informatics applications poses new challenges in human-computer interaction and creates opportunities for collaboration between diverse disciplines, including design, ubiquitous computing, persuasive technology and information visualization. This workshop will continue the conversation from the CHI 2010 workshop and extend the discussion of personal informatics to include behavioral theories that can guide the development of such systems, as well as the social implications of self-tracking.</span></div></div></td>
<td colspan="18" class="session_details" id="S1015_details"><div class="paper" id="wo159"><a href="#wo159" class="title">Designer Experience: Exploring Ways to Design in Experience</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979581&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mika P Nieminen</span> <span class="affiliation">Aalto University School of Science</span>, <br />
<span class="author">Mikael  Runonen</span> <span class="affiliation">Aalto University School of Science</span>, <br />
<span class="author">Marko  Nieminen</span> <span class="affiliation">Aalto University School of Science</span>, <br />
<span class="author">Mari  Tyllinen</span> <span class="affiliation">Aalto University School of Science</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">User-Centered Design (UCD) under the umbrella of user experience (UX) has gained momentum as the de facto standard to produce successful products and services. Use of products is seen as a highly personal and context-sensitive balancing act that derives its uniqueness from the actions and emotions of the users. <br />  <br /> While the definition of UX is still in the making, it is hoped to extend the designing of products beyond functionality toward users&#8217; perceptions and emotions. As the practices for designing UX are emerging, we would like to address the UCD challenge from a different perspective. Therefore, in this paper we introduce designer experience (DX) as a means to design products at an experiential level, that of beyond contextual or empathic design. We welcome critical discussion on the existence and feasibility of DX, seek out available methodology to reliably invoke it, and collect practical future uses for DX. <br /></span></div></div></td>
<td colspan="18" class="session_details" id="S1006_details"><div class="paper" id="wo175"><a href="#wo175" class="title">Distributed User Interfaces 2011</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979576&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jose A.  Gallud</span> <span class="affiliation">Miguel Hernandez University of Elche (UMH)</span>, <br />
<span class="author">Ricardo  Tesoriero</span> <span class="affiliation">University of Castilla-La Mancha (UCLM)</span>, <br />
<span class="author">Jean  Vanderdonckt</span> <span class="affiliation">Catholic University of Lovain</span>, <br />
<span class="author">Mar&#237;a  Lozano</span> <span class="affiliation">University of Castilla-La Mancha</span>, <br />
<span class="author">Victor  Penichet</span> <span class="affiliation">University of Castilla-La Mancha</span>, <br />
<span class="author">Federico  Botella</span> <span class="affiliation">Miguel Hernandez University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This document exposes the most relevant issues regarding the development of Distributed User Interfaces (DUIs) to present the specific features that are not covered by traditional development processes. A transversal approach to tackle these new aspects is also proposed. Therefore, the goal of this workshop is to promote the discussion about the emerging topic of distributed user interfaces, answering a set of key questions: what, when, how, why distribute a user interface among different devices.</span></div></div></td>
<td colspan="18" class="session_details" id="S1009_details"><div class="paper" id="wo166"><a href="#wo166" class="title">Gamification. Using Game-Design Elements in Non-Gaming Contexts</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979575&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sebastian  Deterding</span> <span class="affiliation">Hamburg University</span>, <br />
<span class="author">Miguel  Sicart</span> <span class="affiliation">IT University Copenhagen</span>, <br />
<span class="author">Lennart  Nacke</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Kenton  O'Hara</span> <span class="affiliation">Microsoft Research Cambridge</span>, <br />
<span class="author">Dan  Dixon</span> <span class="affiliation">University of the West of England</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">&#8220;Gamification&#8221; is an informal umbrella term for the use of video game elements in non-gaming systems to improve user experience (UX) and user engagement. The recent introduction of &#8216;gamified&#8217; applications to large audiences promises new additions to the existing rich and diverse research on the heuristics, design patterns and dynamics of games and the positive UX they provide. However, what is lacking for a next step <br /> forward is the integration of this precise diversity of research endeavors. Therefore, this one-day workshop brings together researchers and practitioners to develop a shared understanding of existing approaches and findings around the gamification of information systems, and identify key synergies, opportunities, and questions for future research.</span></div></div></td>
<td colspan="18" class="session_details" id="S1010_details"><div class="paper" id="wo215"><a href="#wo215" class="title">Visible - Actionable - Sustainable: Sustainable Interaction Design in Professional Domains</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979572&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Leonardo  Bonanni</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Daniela K Busse</span> <span class="affiliation">SAP Labs</span>, <br />
<span class="author">John C Thomas</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Eli  Blevis</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Marko  Turpeinen</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Nuno Jardim Nunes</span> <span class="affiliation">University of Madeira</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The growing body of sustainable HCI shows that new interfaces may increase awareness and motivate action for environmental impact. Most of this research has been aimed at consumer decision-making, leaving out many professional domains. This workshop broadens the scope of HCI research to consider new user groups including professional users, educators, designers and engineers, governments and NGO&#8217;s. We propose a broad approach to sustainable HCI for emerging domains: visible - actionable - sustainable. In order to effect sustainable change, new interfaces need to make issues visible in order to promote actionable decisions towards socially and environmentally sustainable ends. These approaches can support sustainable decision-making in product design and a variety of sectors. This workshop will gather interdisciplinary case studies to help identify emerging domains of where sustainable interaction design could provide important social and environmental benefit. The expected outcome is the start of a pattern language for sustainability solutions to the most promising application domains. Patterns are named solutions to recurring problems with enough flexibility to be applied in new contexts. Pattern languages have been developed for architecture and urban planning, object-oriented programming, change management, HCI, and pedagogy.  We choose to structure the workshop around the concepts and techniques of pattern languages because because they focus the attention of the community on creating and sharing expertise on what works in general and in a form and format that is useful to designers who are working on specific solutions for specific contexts. The workshop will consider submissions to inform a pattern language from a number of potential application domains for sustainable interaction design including professional users, education, food and drink, marketing and sales, governments, NGOs, designers and engineers.   <br /></span></div></div></td>
<td colspan="18" class="session_details" id="S1003_details"><div class="paper" id="dc146"><a href="#dc146" class="title">Informing Design of Systems for Intelligence Analysis: Understanding Users, User Tasks, and Tool Usage</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979688&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Youn-ah  Kang</span> <span class="affiliation">Georgia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although intelligence analysts are one of the main target users of visual analytics systems, we still do not understand their work practices and methodologies well. The lack of understanding about how intelligence analysts work and how they can benefit from visual analytics systems has created a gap between tools being developed and real world practices. I argue that we need a better understanding of these analysts and their tool usage to build systems that better support their tasks and add utility to their work practices. By characterizing the analysis process and identifying leverage points for systems through empirical studies, I ultimately seek to develop a set of design guidelines and implications that can be used for building visual analytics systems for intelligence analysis.</span></div></div><div class="paper" id="dc155"><a href="#dc155" class="title">Designing for Movement Experience</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979690&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aaron M Levisohn</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The contribution of the phenomenological aspects of movement to the construction of user experience is relatively unknown. A better understanding of the characteristics of movement experience has the potential to transform the quality of interaction and to assist in the development of alternative interaction methods for ubiquitous and tangible computing systems. The research presented in this paper integrates methods from a diverse range of disciplines &#8211; including design, social science, and somatics &#8211; to identify design principles that can guide the development of systems that incorporate aspects of movement experience.</span></div></div><div class="paper" id="dc106"><a href="#dc106" class="title">Proxemic Interactions in Ubiquitous Computing Ecologies</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979691&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicolai  Marquardt</span> <span class="affiliation">University of Calgary</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An important challenge in ubiquitous computing (ubicomp) is to create techniques that allow people to seamlessly and naturally connect to and interact with the increasing number of digital devices. I propose to leverage the knowledge of people&#8217;s and devices&#8217; spatial relationships &#8211; called proxemics &#8211; in ubicomp interaction design. I introduce my work of proxemic interactions that consider fine-grained information of proxemics to mediate people&#8217;s interactions with digital devices, such as large digital surfaces or portable personal devices. This research includes the design of development tools for programmers creating proxemic-aware systems, and the design and evaluation of such interactive ubicomp systems.</span></div></div><div class="paper" id="dc119"><a href="#dc119" class="title">Modeling Users of Intelligent Systems</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979693&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stephanie  Rosenthal</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While many devices today increasingly have the ability to predict human activities, it is still difficult to build accurate personalized machine learning models. As users today will become responsible for helping to train their own models, we are interested in ways for applications to request labeled data from their users in a non-invasive way. This work focuses on opportunities for intelligent systems to ask their users for help through interactions over an extended period of time in order to improve their machine learning models. We focus on trading off the expected increase in accuracy with the potential interruptions that the questions may cause to improve the usability of such systems.</span></div></div><div class="paper" id="dc137"><a href="#dc137" class="title">Understanding Multitasking as an Adaptive Strategy Selection Process</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979687&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christian P Janssen</span> <span class="affiliation">University College London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The promotion of mobile devices within the field of HCI makes it necessary to better understand how these devices are used in multitasking contexts, so as to prevent accidents. In these contexts, users must choose how to allocate their attention to the tasks that they are engaged in. Using computational cognitive models, I demonstrate why users interleave tasks in particular patterns: to comply with priority objectives and to optimize performance. In future work, I will investigate how users learn to perform in optimum ways, so as to be able to predict performance during a first encounter with novel situations and interfaces.</span></div></div><div class="paper" id="dc143"><a href="#dc143" class="title">Visual Histories of Decision Processes for Creative Collaboration</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979689&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karine  Kozlova</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Collaborative decision making (CDM) is a key aspect of collaboration in both its importance to the process and its internal complexity. In my PhD research I focus on such decision making and its support through the use of history visualization and reconstruction. The goal of this research is to explore the role of history in collaborative activities and to provide a specific set of design guidelines and concepts for technological support of CDM through history capture, recall, review and revision.</span></div></div><div class="paper" id="dc111"><a href="#dc111" class="title">Socialising Presence</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979685&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Gooch</span> <span class="affiliation">Department of Computer Science, University of Bath, Bath, UK, BA2 7AY</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Long distance relationships are not well supported by current communication technologies. Although these technologies are superb at communicating facts, they lack an emotional element which I argue is necessary for people who care about one another and yet who must live apart. My PhD aims to address this problem by examining social presence in technologically mediated relationships. Thus far I have built a number of teletangible devices to mimic human actions across a distance. I will deploy these systems within a number of long-distance relationships. I expect my research to result in new understanding which will lead to communication technologies with higher levels of social presence, thus supporting long-distance relationships.</span></div></div><div class="paper" id="dc148"><a href="#dc148" class="title">The Songs of Our Past: Working with Listening Histories</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979683&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominikus  Baur</span> <span class="affiliation">University of Munich (LMU)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Music listening histories are portraits of a person&#8217;s taste in music. In my research I am exploring this type of data and how user interfaces can be enhanced with it. In this Doctoral Consortium paper I describe my approach towards this goal: Statistical analysis and casual information visualizations can help in finding relevant patterns and aspects in listening histories. Making them available to regular users and asking what they learnt about themselves gives us the chance to find out more about their listening on the minute level of songs. Contextual information such as photos or calendar entries can help trigger memories. In this paper I describe the motivation and goals of my research and my current status. In the end, both the HCI community and end users can benefit from more convenient and sophisticated interfaces for this type of data.</span></div></div><div class="paper" id="dc159"><a href="#dc159" class="title">Self-Disclosure in Social Media</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979695&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Javier  Velasco-Martin</span> <span class="affiliation">School of Information and Library Science The University of North Carolina at Chapel Hill</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computer mediated communication tools have multiplied the possibilities to stay in touch and interact with the people in our social network. The dynamics of use for these tools suggest changes in the context of self-disclosure. Although research has explored online self-disclosure of students (who are expressing large breaches in previous norms of privacy regulation), much less attention has been paid to disclosure behavior of older, and particularly experienced users. A mixed-method approach will be used to explore different aspects of this complex phenomenon, including a survey, interviews and experience sampling. Results of this project should reveal the most salient drivers for online Self-Disclosure for this group.</span></div></div><div class="paper" id="dc102"><a href="#dc102" class="title">Distributed Participatory Design</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979696&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Greg  Walsh</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Children who are not co-located with system developers because of geographic location or time zone difference have ideas that are just as important and valid as children who are easily &#8220;available&#8221;. This problem is the motivation for my thesis work. I propose to design, develop, and research a computer-mediated, geographically distributed, asynchronous tool to facilitate intergenerational participatory design.</span></div></div><div class="paper" id="dc156"><a href="#dc156" class="title">Physical Activity with Digital Companions</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979684&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lorna Rae Boschman</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While a majority of adults in industrialized countries do not exercise frequently enough to sustain physical health, games with an exertive interface &#8211; exergames &#8211; have been proposed as vehicles to increase activity levels. After a brief discussion of my background, I report on fundamental findings from studies conducted by interaction designers, social and computer scientists, and medical professionals whose work has responded to the crisis in physical activity levels. I give an overview of my proposed mixed methods research design, and discuss how I can both contribute and learn from approaches that can successfully support strong study findings.</span></div></div><div class="paper" id="dc103"><a href="#dc103" class="title">Technology Design for Pediatric Asthma Management</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979698&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tae-Jung  Yun</span> <span class="affiliation">Georgia Institute of Technology, Samsung Electronics</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Asthma affects a significant number of children, families, and health care systems. In this work, I discuss the challenges that these stakeholders may face, and present system that may help address some of these challenges. Finally, I highlight the expected contributions of this work.</span></div></div><div class="paper" id="dc132"><a href="#dc132" class="title">Using Language-Retrieved Pictures to Support Intercultural Brainstorming</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979697&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hao-Chuan  Wang</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Group brainstorming is a commonly practiced technique to enhance creative outcomes. Cultural differences in knowledge and perspectives are valuable sources for diversity essential to creative outcomes, while cultural discrepancy in communication and language may impede idea sharing. My dissertation research aims to reconcile the tension between the benefits and obstacles of intercultural brainstorming. The design approach is to augment conversational brainstorming with language-retrieved pictures. Pictures may provide rich stimulation and mediate concepts in a relatively language-independent manner, which may complement the still imperfect machine translation, and make inter-cultural and multi-lingual idea sharing more feasible.</span></div></div><div class="paper" id="dc139"><a href="#dc139" class="title">Designing an Interface for Multimodal Narrative Creation</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979686&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katy  Howland</span> <span class="affiliation">University of Sussex</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many young people struggle with developing writing skills, and computer game creation is a motivating activity with potential in this area. Existing software allows young people to design 3D areas and add game objects, but provides little or no interface support for writing and structuring narratives. This research explores the support required to create 3D multimodal narratives, adopting user-centred methods to design, <br /> build and evaluate a suite of dynamic representational tools. A key interface design challenge is developing representations that foster writing skills without losing the motivational immediacy of the activity.</span></div></div><div class="paper" id="dc114"><a href="#dc114" class="title">Modeling Places for Interactive Media and Entertainment Applications</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979692&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rui  N&#243;brega</span> <span class="affiliation">Universidade Nova de Lisboa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Taking advantage of the multitude of cameras now available and capable of recording all aspects of our lives, this work explores the notion of virtualizing a physical place using cameras and sharing the resulting model with others. This social sharing would create new forms of relationship and common space discovery that would enhance video chats and virtual visiting of physical places. Furthermore, the research will consider the possible interactive applications, from games to augmented reality, which can take advantage of the created spatial and temporal models.</span></div></div><div class="paper" id="dc125"><a href="#dc125" class="title">Pervasive Negabehavior Games for Environmental Sustainability</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979694&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joel  Ross</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pervasive games&#8212;games that expand into everyday life&#8212;offer a potentially powerful method of promoting social good by encouraging people to perform new, positive actions. However, achieving some desired social goals (such as environmental sustainability) may also require people to stop performing undesirable actions&#8212;a form of behavior change that contrasts with common framings of pervasive game-play. I propose to create "Negabehavior Games"&#8212;games that encourage players to adopt "negabehaviors" (a manner of conducting oneself that supplants undesirable actions). This research offers a novel approach to designing pervasive games and other interactive experiences, as well as the potential to encourage people to live more environmentally sustainable lives.</span></div></div></td>
<td colspan="18" class="session_details" id="S1011_details"><div class="paper" id="wo145"><a href="#wo145" class="title">Data Collection by the People, for the People</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979569&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christine  Robson</span> <span class="affiliation">IBM Research - Almaden UC Berkeley EECS</span>, <br />
<span class="author">Sean  Kandel</span> <span class="affiliation">Stanford Computer Science</span>, <br />
<span class="author">Jeffrey  Heer</span> <span class="affiliation">Stanford Computer Science</span>, <br />
<span class="author">Jeffrey  Pierce</span> <span class="affiliation">IBM Research - Almaden</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Data Collection by the People, for the People is a CHI 2011 workshop to explore data from the crowd, bringing together mobile crowdsourcing &amp; participatory urbanism researchers with data analysis and visualization researchers.  The workshop is two-day event beginning with day of field work in the city of Vancouver, trying out mobile crowdsourcing applications and data analysis tools.  Participants are encouraged to contribute applications and tools which they wish to share.  Our goal is to provoke discussion and brainstorming, enabling both data collection researchers and data manipulation/analysis researchers to benefit from mutually learned lessons about crowdsourced data.</span></div></div></td>
<td colspan="18" class="session_details" id="S1004_details"><div class="paper" id="wo128"><a href="#wo128" class="title">HCI, Politics and the City: Engaging with Urban Grassroots Movements for Reflection and Action</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979568&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stacey  Kuznetsov</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">William  Odom</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Vicki  Moulder</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Carl  DiSalvo</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Tad  Hirsch</span> <span class="affiliation">Intel Corporation</span>, <br />
<span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Eric  Paulos</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Grassroots initiatives enable communities of stakeholders to transform urban landscapes and impact broader political and cultural trajectories. In this two-day workshop, we present opportunities to engage HCI research with activist communities in Vancouver, the city hosting CHI&#8217;11. Working directly with local activist organizations, we explore the processes, materials, challenges, and goals of grassroots communities. Our bottom-up approach, including explorations of urban spaces and activist headquarters, participatory design sessions, reflection, critique and creative design of political artifacts will bring together a diverse group of HCI researchers, activists and artists. The workshop will result in concrete strategies for bottom-up activism and serve to inform the design of future interactive systems in the domain of political computing.</span></div></div></td>
<td colspan="18" class="session_details" id="S1019_details"><div class="paper" id="wo216"><a href="#wo216" class="title">Ethics, Logs and Videotape: Ethics in Large Scale User Trials and User Generated Content</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979574&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Chalmers</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Donald  McMillan</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Alistair  Morrison</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Henriette  Cramer</span> <span class="affiliation">SICS / Mobile Life Centre</span>, <br />
<span class="author">Mattias  Rost</span> <span class="affiliation">SICS / Mobile Life Centre</span>, <br />
<span class="author">Wendy  Mackay</span> <span class="affiliation">Universite&#236; de Paris Sud</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As new technologies are appropriated by researchers, the community must come to terms with the evolving ethical responsibilities we have towards participants. This workshop brings together researchers to discuss the ethical issues of running large-scale user trials, and to provide guidance for future research. Trials of the scale of 10s or 100s of thousands of participants offer great potential benefits in terms of attracting users from vastly different geographical and social contexts, but raise significant ethical challenges. The inability to ensure user understanding of the information required to provide informed consent and problems involved in making users aware of the implications of the information being collected all beg the question: how can researchers ethically take advantage of the opportunities these new technologies afford?</span></div></div></td>
<td colspan="18" class="session_details" id="S1007_details"><div class="paper" id="wo197"><a href="#wo197" class="title">Large Displays in Urban Life - from Exhibition Halls to Media Facades</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979577&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Uta  Hinrichs</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">Nina  Valkanova</span> <span class="affiliation">Universitat Pomeu Fabra</span>, <br />
<span class="author">Kai  Kuikkaniemi</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Giulio  Jacucci</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Sheelagh  Carpendale</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">Ernesto  Arroyo</span> <span class="affiliation">Universitat Pomeu Fabra</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent trends show an increasing prevalence of large interactive displays in public urban life. For example, mu-seums, libraries, public plazas, or architectural facades take advantage of interactive technologies that present information in a highly visual and interactive way. Studies confirm the potential of large interactive display installa-tions for educating, entertaining, and providing evocative experiences. This workshop will provide a platform for researchers and practitioners from different disciplines to exchange insights on current research questions in the area. The workshop will focus on how to design large interactive display installations that promote engaging experiences that go beyond playful interaction, and how to evaluate their impact. The goal is to cross-fertilize in-sights from different disciplines, establish a more general understanding of large interactive displays in public urban contexts, and to develop an agenda for future research directions in this area.</span></div></div></td>
<td colspan="18" class="session_details" id="S1012_details"><div class="paper" id="wo122"><a href="#wo122" class="title">Managing UX experience teams: lessons from case studies, establishing best practices</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979567&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dennis  Wixon</span> <span class="affiliation">Microsoft / University of Washington</span>, <br />
<span class="author">Janice  Rohn</span> <span class="affiliation">Experian</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This workshop focuses on managing cross-disciplinary user experience teams to achieve product and corporate success. The workshop brings together a diverse group of leaders in order to create a set of case studies to illuminate challenges and success factors. Emphasis is placed on cross-disciplinary teams, corporate culture and environment, organizational structure, and international considerations. The goal of the workshop is to develop a set of contingent, specific, and applicable guidelines for managing user experience teams in a variety of circumstances based on case studies.</span></div></div></td>
</tr>
</table>
</div>

<div class="day" id="day2"><h1>Sunday, May 08, 2011</h1><table cellspacing="0" class="program" id="day_2">
<tr class="timeslot">
<td class="time">07:30<br />-<br />17:30</td>

<td class="session tbd" id="S1022">
<div class="session_box">
<span class="type"></span>
<a href="#S1022" class="title">Registration Open</a>
<span class="location">Ballroom Foyer</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">09:00<br />-<br />18:00</td>

<td class="session " id="S1036">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1036" class="title">Performative Interaction in Public Space</a>
<span class="location">216</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1024">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1024" class="title">Feminism and Interaction Design</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1027">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1027" class="title">PINC: Persuasion, Influence, Nudge &amp; Coercion through mobile devices</a>
<span class="location">119/120</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1035">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1035" class="title">The User in Flux: Bringing HCI and Digital Arts Together to Interrogate Shifting Roles in Interactive Media</a>
<span class="location">215</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1033">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1033" class="title">Appropriation and Creative Use: Linking User Studies and Design</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1032">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1032" class="title">Analytic Provenance: Process + Interaction + Insight</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1037">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1037" class="title">Crowdsourcing and Human Computation: Systems, Studies and Platforms</a>
<span class="location">217/218/219</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1040">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1040" class="title">Brain and Body Interfaces: Designing for Meaningful Interaction</a>
<span class="location">223/224</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1034">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1034" class="title">Dynamic Accessibility: Accommodating Differences in Ability and Situation</a>
<span class="location">211</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1025">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1025" class="title">Workshop on Embodied Interaction: Theory and Practice in HCI</a>
<span class="location">116/117</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1028">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1028" class="title">Social Game Studies at CHI 2011</a>
<span class="location">109</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1039">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1039" class="title">Transnational HCI: Humans, Computers, and Interactions in Transnational Contexts</a>
<span class="location">221/222</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1029">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1029" class="title">Mobile and Personal Projection</a>
<span class="location">110</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1023">
<div class="session_box">
<span class="type"></span>
<a href="#S1023" class="title">Doctoral Consortium</a>
<span class="location">113</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1030">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1030" class="title">Data Collection by the People, for the People</a>
<span class="location">212/213/214</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1038">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1038" class="title">Bridging Practices, Theories, and Technologies to Support Reminiscence</a>
<span class="location">220</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1026">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1026" class="title">Everyday Practice and Sustainable HCI: Understanding and Learning from Cultures of (Un)Sustainability</a>
<span class="location">118</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1031">
<div class="session_box">
<span class="type">Workshop</span>
<a href="#S1031" class="title">Managing UX experience teams: lessons from case studies, establishing best practices</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="18" class="session_details" id="S1036_details"><div class="paper" id="wo164"><a href="#wo164" class="title">Performative Interaction in Public Space</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979595&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lone Koefoed Hansen</span> <span class="affiliation">Aarhus University</span>, <br />
<span class="author">Julie  Rico</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Giulio  Jacucci</span> <span class="affiliation">Aalto University</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Daniel  Ashbrook</span> <span class="affiliation">Nokia Research Center Hollywood</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Building on the assumption that every human action in public space has a performative aspect, this workshop seeks to explore issues of interactions with technology in public settings. More and more interfaces are used in public on an everyday basis. Simultaneously, metaphors from performance and theatre studies find their way into research on these interfaces, addressing how interaction with technology can be understood in a performative sense. However, the term &#8216;performativity' is rarely addressed in ways that accentuate its nuances and its analytic power, and this is the focus of the workshop. We will examine the design of performative technologies, the evaluation of user experience, the importance of spectator and performer roles, and the social acceptability of performative actions in public spaces.</span></div></div></td>
<td colspan="18" class="session_details" id="S1024_details"><div class="paper" id="wo137"><a href="#wo137" class="title">Feminism and Interaction Design</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979587&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University Bloomington</span>, <br />
<span class="author">Elizabeth  Churchill</span> <span class="affiliation">Yahoo! Research</span>, <br />
<span class="author">Jeffrey  Bardzell</span> <span class="affiliation">Indiana University Bloomington</span>, <br />
<span class="author">Jodi  Forlizzi</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Rebecca  Grinter</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Deborah  Tatar</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This workshop is aimed at exploring the issues at the intersection of feminist thinking and human computer interaction. Both feminism and HCI have made important contributions to social science in the past several decades, but though their potential for overlap seem high, they have not engaged each other directly until recently. In this workshop we will explore diverse--and contentious--ways that feminist perspectives can support user research, design ideation and problem framing, sketching and prototyping, and design criticism and evaluation. The workshop will include fast-moving mini-panels and hands-on group exercises emphasizing feminist interaction criticism and design ideation.</span></div></div></td>
<td colspan="18" class="session_details" id="S1027_details"><div class="paper" id="wo173"><a href="#wo173" class="title">PINC: Persuasion, Influence, Nudge &amp; Coercion through mobile devices</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979586&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Parisa  Eslambolchilar</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Max  Wilson</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">University of Madeira</span>, <br />
<span class="author">Anind  Dey</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This workshop will provide a focal point for research and technology <br /> dedicated to supporting behaviour change through <br /> Persuasion, Influence, Nudge and Coercion (PINC). A particular <br /> focus is on pervasive and mobile technologies and <br /> the unique opportunities they present in this domain (e.g. <br /> in terms of data-capture and timely intervention). Although <br /> much isolated research takes place tackling particular aspects <br /> of this problem space (e.g. persuasion), this workshop will be <br /> the first venue to provide a forum that discusses meta-issues <br /> that apply to behaviour change and pervasive technology, irrespective <br /> of how it is achieved. These issues include: (a) <br /> What novel opportunities do pervasive technologies provide? <br /> (b) When is the appropriate time to begin, reduce or end intervention? <br /> (c) Are PINC methods ethical? and (d) How can <br /> we extend the scale of intervention?Participants are invited <br /> to contribute to the workshop with examples of PINC technologies, <br /> and the event will focus on mapping the conceptual <br /> space, creating novel ideas and interactive applications and <br /> discussing future opportunities. Ultimately, the workshop aspires <br /> to establish a community dedicated to this topic.</span></div></div></td>
<td colspan="18" class="session_details" id="S1035_details"><div class="paper" id="wo177"><a href="#wo177" class="title">The User in Flux: Bringing HCI and Digital Arts Together to Interrogate Shifting Roles in Interactive Media</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979571&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tuck W Leong</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Lalya  Gaye</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Atau  Tanaka</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Peter C Wright</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the advent of interactive digital media, people are <br /> no longer simply &#8216;users&#8217;. They actively shift between <br /> various roles: author, collaborator, and even performer. <br /> We coin the term &#8220;user in flux&#8221; to problematize static <br /> definitions of &#8220;the user&#8221; and highlight how people&#8217;s <br /> roles and practices switch and evolve when engaged in <br /> such interactions. Drawing on participatory practices <br /> and seeking inspiration from interactive artists, this <br /> workshop explores the &#8221;user in flux&#8221; with an aim to <br /> establish directions and approaches that can revitalize <br /> the HCI community&#8217;s understanding of the user and <br /> inform the design of technologies used for interacting <br /> with digital media, and promote a new research <br /> agenda.</span></div></div></td>
<td colspan="18" class="session_details" id="S1033_details"><div class="paper" id="wo141"><a href="#wo141" class="title">Appropriation and Creative Use: Linking User Studies and Design</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979585&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Antti  Salovaara</span> <span class="affiliation">Aalto University and University of Helsinki</span>, <br />
<span class="author">Kristina  H&#246;&#246;k</span> <span class="affiliation">Stockholm University</span>, <br />
<span class="author">Keith  Cheverst</span> <span class="affiliation">Lancaster University</span>, <br />
<span class="author">Michael  Twidale</span> <span class="affiliation">University of Illinois</span>, <br />
<span class="author">Matthew  Chalmers</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Corina  Sas</span> <span class="affiliation">Lancaster University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Appropriation refers to the ways that technologies are &#65279;adapted and repurposed to new purposes of use by individuals, groups or communities. This workshop brings together researchers interested in appropriation from CSCW and design. Until now, these communities have been working separately, despite their converging interests. The workshop is based on roundtable discussions that bring the participants&#8217; qualitative observations and theoretical viewpoints in contact with practical design efforts that support user creativity and appropriation.</span></div></div></td>
<td colspan="18" class="session_details" id="S1032_details"><div class="paper" id="wo167"><a href="#wo167" class="title">Analytic Provenance: Process+Interaction+Insight</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979570&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chris  North</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Remco  Chang</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Alex  Endert</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Wenwen  Dou</span> <span class="affiliation">UNC Charlotte</span>, <br />
<span class="author">Richard  May</span> <span class="affiliation">Pacific Northwest National Lab</span>, <br />
<span class="author">Bill  Pike</span> <span class="affiliation">Pacific Northwest National Lab</span>, <br />
<span class="author">Glenn  Fink</span> <span class="affiliation">Pacific Northwest National Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces. One key aspect that separates visual analytics from other related fields (InfoVis, SciVis, HCI) is the focus on analytical reasoning. While the final products generated at from an analytical process are of great value, research has shown that the processes of the analysis themselves are just as important if not more so. These processes not only contain information on individual insights discovered, but also how the users arrive at these insights. This area of research that focuses on understanding a user&#8217;s reasoning process through the study of their interactions with a visualization is called Analytic Provenance, and has demonstrated great potential in becoming a foundation of the science of visual analytics. The goal of this workshop is to provide a forum for researchers and practitioners from academia, national labs, and industry to share methods for capturing, storing, and reusing user interactions and insights. We aim to develop a research agenda for how to better study analytic provenance and utilize the results in assisting users in solving real world problems.</span></div></div></td>
<td colspan="18" class="session_details" id="S1037_details"><div class="paper" id="wo189"><a href="#wo189" class="title">Crowdsourcing and Human Computation: Systems, Studies and Platforms</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979593&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Bernstein</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Ed H. Chi</span> <span class="affiliation">Google</span>, <br />
<span class="author">Lydia B. Chilton</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Aniket  Kittur</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Robert C. Miller</span> <span class="affiliation">MIT CSAIL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crowdsourcing and human computation are transforming human-computer interaction, and CHI has led the way. The seminal publication in human computation was initially published in CHI in 2004 [1], and the first paper investigating Mechanical Turk as a user study platform has amassed over one hundred citations in two years [5]. However, we are just beginning to stake out a coherent research agenda for the field.  This workshop will bring together researchers in the young field of crowdsourcing and human computation and produce three artifacts: a research agenda for the field, a vision for ideal crowdsourcing platforms, and a group-edited bibliography.  These resources will be publically disseminated on the web and evolved and maintained by the community.</span></div></div></td>
<td colspan="18" class="session_details" id="S1040_details"><div class="paper" id="wo186"><a href="#wo186" class="title">Brain and Body Interfaces: Designing for Meaningful Interaction</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979591&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stephen H Fairclough</span> <span class="affiliation">Liverpool John Moores University</span>, <br />
<span class="author">Kiel  Gilleade</span> <span class="affiliation">Liverpool John Moores University</span>, <br />
<span class="author">Lennart E Nacke</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Regan L Mandryk</span> <span class="affiliation">University of Saskatchewan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The brain and body provide a wealth of information about the physiological, cognitive and emotional state of the user. There is increased opportunity to use these data in computerised systems as forms of input control. As entry level physiological sensors become more widespread, physiological interfaces are liable to become more pervasive in our society (e.g., through mobile phones). While these signals offer new and exciting mechanisms for the control of interactive systems, the issue of whether these physiological interfaces are appropriate for application and offer the user a meaningful level of interaction remains relatively unexplored. This workshop sets out to bring together researchers working in the field of psychophysiological interaction to discuss the issue of how to design physiological interactions that are meaningful for users.</span></div></div></td>
<td colspan="18" class="session_details" id="S1034_details"><div class="paper" id="wo188"><a href="#wo188" class="title">Dynamic Accessibility: Accommodating Differences in Ability and Situation</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979589&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amy  Hurst</span> <span class="affiliation">UMBC</span>, <br />
<span class="author">Krzysztof  Gajos</span> <span class="affiliation">Harvard University</span>, <br />
<span class="author">Leah  Findlater</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob  Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Andrew  Sears</span> <span class="affiliation">UMBC</span>, <br />
<span class="author">Shari  Trewin</span> <span class="affiliation">IBM T. J. Watson Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Human abilities are idiosyncratic and may change frequently. Static one-size-fits-many accessibility solutions miss the opportunities that arise from careful consideration of an individual&#8217;s abilities and fail to address the sometimes dynamic aspect of those abilities, such as when a user&#8217;s activity or context causes a &#8220;situational impairment.&#8221; The goal of this workshop is to bring together researchers and practitioners in accessibility, mobile HCI, and interactive intelligent systems who are pursuing agile, data-driven approaches that enable interactive systems to adapt or become adapted to the needs and abilities of a particular individual in a particular context.</span></div></div></td>
<td colspan="18" class="session_details" id="S1025_details"><div class="paper" id="wo102"><a href="#wo102" class="title">Workshop on Embodied Interaction: Theory and Practice in HCI</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979592&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alissa N Antle</span> <span class="affiliation">Interactive Arts &amp; Technology, Simon Fraser University</span>, <br />
<span class="author">Paul  Marshall</span> <span class="affiliation">Warwick Manufacturing Group,International Digital Laboratory,University of Warwick</span>, <br />
<span class="author">Elise  van den Hoven</span> <span class="affiliation">Industrial Design Department,Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">For over ten years researchers in human-computer interaction (HCI) have explored an embodied perspective that seeks to describe and explain the fundamental role played by the physical body in how we experience, interact with and understand computation in the world we live in. Recently, such a perspective has been used to discuss human actions and interactions with a range of computational applications including tangibles, mobiles, wearables, tabletops and interactive environments. This workshop aims to enable participants to critically explore the different approaches to incorporating an embodied perspective in HCI research, and to develop a shared set of understandings and identification of differences, similarities and synergies between our research approaches.</span></div></div></td>
<td colspan="18" class="session_details" id="S1028_details"><div class="paper" id="wo132"><a href="#wo132" class="title">Social Game Studies at CHI 2011</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979590&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ben  Kirman</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Staffan  Bj&#246;rk</span> <span class="affiliation">Interactive Institute</span>, <br />
<span class="author">Sebastian  Deterding</span> <span class="affiliation">University of Hamburg</span>, <br />
<span class="author">Janne  Paavilainen</span> <span class="affiliation">University of Tampere</span>, <br />
<span class="author">Valentina  Rao</span> <span class="affiliation">Utrecht University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">&#8220;Social games&#8221;, defined as games played and distributed on Social Networks, have become a digital gaming phenomenon. The most popular games boast tens of millions of users each month, employing simple mechanics to reach a vast new audience that was apparently under-served by traditional digital games. Their enormous success raises important academic questions about game design, interface design, psychology and the social power of online networks.  <br /> Social Game Studies at CHI 2011 is a one-day workshop at CHI 2011 that will bring together the CHI community with an inter-disciplinary mix of researchers and practitioners to share findings and explore the issues surrounding this emerging area of research into social games, and highlight the key questions, opportunities and challenges for future academic study. <br /></span></div></div></td>
<td colspan="18" class="session_details" id="S1039_details"><div class="paper" id="wo147"><a href="#wo147" class="title">Transnational HCI: Humans, Computers, and Interactions in Transnational Contexts</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979584&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janet  Vertesi</span> <span class="affiliation">Princeton University</span>, <br />
<span class="author">Silvia  Lindtner</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Irina  Shklovski</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This workshop will consider the implications for conducting research and technology design within and across global and networked sites of technology production and use. In particular, we focus on transnational practices: that is, seeing technology use beyond a single country or culture, but as evolving in relation to global processes, boundary crossings, frictions and hybrid practices. In doing so, we expand upon existing research in HCI to consider the effects, implications for individuals and communities, and design opportunities in times of increased transnational interactions. We hope to broaden the conversation around the impact of technology in global processes by bringing together scholars from HCI and from related humanities, media arts and social sciences disciplines.</span></div></div></td>
<td colspan="18" class="session_details" id="S1029_details"><div class="paper" id="wo117"><a href="#wo117" class="title">Mobile and Personal Projection</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979588&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Raimund  Dachselt</span> <span class="affiliation">University of Magdeburg</span>, <br />
<span class="author">Matt  Jones</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Jonna  H&#228;kkil&#228;</span> <span class="affiliation">Nokia Research Center Tampere</span>, <br />
<span class="author">Markus  L&#246;chtefeld</span> <span class="affiliation">German Research Center for  Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Michael  Rohs</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Enrico  Rukzio</span> <span class="affiliation">University of Duisburg-Essen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The emergence of mobile and personal projection de-vices promises new ways to display and interact with content while the user is mobile, and offer new oppor-tunities and challenges for HCI. This workshop  aims to formulate fundamental research questions around this emerging field and provides a venue for discussion for researchers and practitioners working in this area. We will focus on new interaction techniques, applications, personal projection devices, interaction design, multi-user aspects, multi-modal user interfaces and social implications. Our aim is to foster the evolution of a mo-bile and personal projection community.</span></div></div></td>
<td colspan="18" class="session_details" id="S1030_details"><div class="paper" id="wo145"><a href="#wo145" class="title">Data Collection by the People, for the People</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979569&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christine  Robson</span> <span class="affiliation">IBM Research - Almaden UC Berkeley EECS</span>, <br />
<span class="author">Sean  Kandel</span> <span class="affiliation">Stanford Computer Science</span>, <br />
<span class="author">Jeffrey  Heer</span> <span class="affiliation">Stanford Computer Science</span>, <br />
<span class="author">Jeffrey  Pierce</span> <span class="affiliation">IBM Research - Almaden</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Data Collection by the People, for the People is a CHI 2011 workshop to explore data from the crowd, bringing together mobile crowdsourcing &amp; participatory urbanism researchers with data analysis and visualization researchers.  The workshop is two-day event beginning with day of field work in the city of Vancouver, trying out mobile crowdsourcing applications and data analysis tools.  Participants are encouraged to contribute applications and tools which they wish to share.  Our goal is to provoke discussion and brainstorming, enabling both data collection researchers and data manipulation/analysis researchers to benefit from mutually learned lessons about crowdsourced data.</span></div></div></td>
<td colspan="18" class="session_details" id="S1038_details"><div class="paper" id="wo211"><a href="#wo211" class="title">Bridging Practices, Theories, and Technologies to Support Reminiscence</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979594&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dan  Cosley</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Maurice  Mulvenna</span> <span class="affiliation">University of Ulster</span>, <br />
<span class="author">Victoria  Schwanda</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">S. Tejaswi  Peesapati</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Terence  Wright</span> <span class="affiliation">University of Ulster</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Reminiscence is a valuable human activity; this one-day workshop explores how HCI practice and research can understand and support people in their reminiscing. The workshop has two main goals. First, it hopes to bring together academics and practitioners from both social and technical perspectives who are interested in studying and supporting reminiscence. Second, it hopes to explore key issues around current and potential uses of technology to support reminiscence, including 1) understanding people's current practices around reminiscing, 2) using empirical studies and theories of memory to inform technology designs, 3) evaluating existing technologies for reminiscence, 4) exploring ways that technology might support new reminiscing practices, and 5) supporting social aspects of reminiscence. We are particularly interested in bringing people from outside the CHI community into the workshop to add new perspectives and foster new collaborations around the work. A series of discussion-focused panels organized around the key topics identified by participants will lead to thoughtful examinations of these topics informed by multiple viewpoints. Our tangible planned outputs will be a set of recommendations for further research in this area and an outline plan for grant and book proposals at the intersection of reminiscing and technology.</span></div></div></td>
<td colspan="18" class="session_details" id="S1026_details"><div class="paper" id="wo108"><a href="#wo108" class="title">Everyday Practice and Sustainable HCI: Understanding and Learning from Cultures of (Un)Sustainability</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979583&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Pierce</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Hronn  Brynjarsdottir</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Phoebe  Sengers</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Yolande  Strengers</span> <span class="affiliation">RMIT University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Within the CHI community we have witnessed a broadening of concerns to include various everyday contexts such as the domestic, rural and urban, as well as diverse, underrepresented, and marginalized communities. Such everyday contexts have also <br /> emerged as key areas of focus for sustainable HCI. Not only is everyday life a critical area in which material resources are exchanged, transformed, consumed and disposed, but everyday life is a site for the formation of values, attitudes, routines and habits. This workshop will bring together individuals interested in everyday practice as both a critical site and a critical lens for sustainable HCI research and professional practice. The focus of the workshop is exploring and investigating how descriptions and theories of everyday practice can be employed in order to critically and creatively rethink how HCI frames research and design issues of sustainability&#8212;both collectively as a field and individually in participants&#8217; own work.</span></div></div></td>
<td colspan="18" class="session_details" id="S1031_details"><div class="paper" id="wo122"><a href="#wo122" class="title">Managing UX experience teams: lessons from case studies, establishing best practices</a>&nbsp;-&nbsp;<span class="type">Workshop</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979567&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dennis  Wixon</span> <span class="affiliation">Microsoft / University of Washington</span>, <br />
<span class="author">Janice  Rohn</span> <span class="affiliation">Experian</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This workshop focuses on managing cross-disciplinary user experience teams to achieve product and corporate success. The workshop brings together a diverse group of leaders in order to create a set of case studies to illuminate challenges and success factors. Emphasis is placed on cross-disciplinary teams, corporate culture and environment, organizational structure, and international considerations. The goal of the workshop is to develop a set of contingent, specific, and applicable guidelines for managing user experience teams in a variety of circumstances based on case studies.</span></div></div></td>
</tr>
</table>
</div>

<div class="day" id="day3"><h1>Monday, May 09, 2011</h1><table cellspacing="0" class="program" id="day_3">
<tr class="timeslot">
<td class="time">08:45<br />-<br />10:00</td>

<td  colspan="10" class="session" id="opening">
    <div class="session_box" style="width: 100%; text-align: left;">
    <strong class="type">Opening Plenary</strong>
    <a class="title" href="#opening">My explorations of social media and social media literacies in teaching & learning</a>
    Speaker: <span class="author">Howard Rheingold</span> 
    <span class="affiliation"></span>
    </div>
    </td>
    
</tr>
<tr class="details_row">

    <td colspan="10" class="session_details" id="opening_details">
    <div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span>
    <span class="abstractText">
    <p>
    Although not an educator by trade, I've been interested in the potential 
    of online media for learning since I started exploring what I called 
    "virtual communities" in the 1980s. In particular, I was attracted to the 
    ways online media could facilitate collaborative knowledge sharing and 
    exploration. In 1995, I designed a demonstration of a "university of the 
    future" for NEC corporation. In 2006, I started teaching at UC Berkeley 
    and Stanford. I was initially drawn to formal education because I perceived 
    a need to introduce students to the issues of identity, privacy, collective 
    action, public sphere, social capital raised by our increasing use of what 
    are now called social media. It only made sense to use blogs, wikis, forums, 
    chat, and social bookmarking when introducing these subjects. Contrary to 
    popular beliefs about "digital natives," I soon learned that social media 
    literacies are not uniformly understood by today's students. At the same 
    time, by paying attention to what students were telling me about our encounters, 
    I was led to forms of pedagogy that have existed at least since the time of 
    John Dewey but which have not been practical until the advent of social
    media -- teaching and learning that is more collaborative and inquiry 
    based and which extends beyond the face to face classroom. I'll talk 
    about how I've learned from my students, how we've learned to learn 
    together, and how I am now experimenting with purely online teaching and 
    learning. I'll touch upon the social media literacies that are the 
    subject of my current book in progress: attention, participation, collaboration, 
    crap detection, and network awareness.
    </p>
    
    <p>
    <br />
    <strong>Bio</strong><br />
    There are a lot of voices talking about social media today, but
    Howard Rheingold defined the field before it existed. A noted
    author and commentator, Rheingold has a proven record of
    accurate technology and social forecasting, over two decades of
    syndicated columns, best-selling books, and pioneering online
    enterprises. His latest research and forthcoming book focuses on
    21st century literacies -- how individuals and organizations learn to
    use digital media effectively and credibly. He coined the term "virtual
    community" in 1987.
    </p>
    <p>
    An acknowledged authority on the marriage of mobile phone, PC,
    and wireless internet, Rheingold's previous work reveals how this
    convergence has changed the way we meet, mate, entertain, govern,
    and conduct business. His book <i>Smart Mobs</i>, named one of the "Big
    Ideas books of 2002" by <i>The New York Times</i>, chronicles the new
    forms of collective action and cooperation made possible by mobile
    communications, pervasive computing, and the Internet.
    </p>
    <p>
    Rheingold is the recipient of a 2008 MacArthur Knowledge-
    Networking Grant through the Foundation's Digital Media and
    Learning Competition. He was founding Executive Editor of
    <i>Hotwired</i>, the first commercial webzine where the web-based
    discussion forum and the online banner ad were invented. Rheingold
    has appeared on <i>Today</i>, <i>Good Morning America</i>, <i>ABC Primetime
    Live</i>, CNN, CBS News, NBC News, <i>Macneill-Lehrer Report</i>, NPR's
    <i>Fresh Air</i> and <i>Marketplace</i>. He currently teaches at Stanford
    University.
    </p>
    </span></div>
    </td>
    
</tr>
<tr class="timeslot">
<td class="time">08:00<br />-<br />20:30</td>

<td class="session tbd" id="S1041">
<div class="session_box">
<span class="type"></span>
<a href="#S1041" class="title">Registration Open</a>
<span class="location">Ballroom Foyer</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">10:00<br />-<br />10:30</td>

<td class="session tbd" id="S1043">
<div class="session_box">
<span class="type"></span>
<a href="#S1043" class="title">Madness</a>
<span class="location">Ballroom A/B</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">11:00<br />-<br />12:20</td>

<td class="session " id="S1045">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1045" class="title">CHI 2011 Sustainability Community Invited Panel: Challenges Ahead</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1050">
<div class="session_box">
<span class="type">alt.chi</span>
<a href="#S1050" class="title">alt.chi: Emotions, Ethics, and Civics</a>
<span class="location">119/120</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1044">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1044" class="title">Engineering Automation in Interactive Critical Systems</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1054">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1054" class="title">Olfaction, Breath &amp; Biofeedback</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1059">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1059" class="title">Sex &amp; Bodies</a>
<span class="location">223/224</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1053">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1053" class="title">Telepresence</a>
<span class="location">208/209</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1057">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1057" class="title">Mid-air Pointing &amp; Gestures</a>
<span class="location">217/218/219</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S5001">
<div class="session_box">
<span class="type">Student Research Competition &amp; Works In Progress</span>
<a href="#S5001" class="title">Poster Group 1 Displayed</a>
<span class="location">Ballroom Foyer</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1058">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1058" class="title">Twitter Systems</a>
<span class="location">220/221/222</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1052">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1052" class="title">Health 1: Technology Challenges</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1055">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1055" class="title">Research Methods</a>
<span class="location">212/213/214</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1046">
<div class="session_box">
<span class="type">Special Events</span>
<a href="#S1046" class="title">Invited Talk</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1056">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1056" class="title">Machine Learning</a>
<span class="location">215/216</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>
</tr>
<tr class="details_row"><td colspan="13" class="session_details" id="S1045_details"><div class="paper" id="pl122"><a href="#pl122" class="title">CHI 2011 Sustainability Community Invited Panel: Challenges Ahead</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979484&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Azam  Khan</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">Lyn  Bartram</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Eli  Blevis</span> <span class="affiliation">Indiana University&#8211;Bloomington</span>, <br />
<span class="author">Carl  DiSalvo</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Jon  Froehlich</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Gordon  Kurtenbach</span> <span class="affiliation">Autodesk Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As part of a new CHI Sustainability Community, focused on environmental sustainability, this panel will discuss specific ways in which HCI research will be critical in finding solutions to this global challenge. While research to date has primarily focused on the end consumer, the panel will be challenged with enlarging the discussion to include the designer as a target user and to consider interfaces and interactions that support sustainable design and sustainable manufacturing, as well as sustainable consumption. Specifically, to make real progress, we seek to enumerate ways that HCI needs to grow, as well as to find ways that can help more HCI researchers to become involved.</span></div></div></td>
<td colspan="13" class="session_details" id="S1050_details"><div class="sessionChair"><strong>Session Chair: </strong>Daniel Wigdor (<em>Microsoft Research</em>)</div><div class="paper" id="al171"><a href="#al171" class="title">Does it matter if a computer jokes?</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979604&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Peter  Khooshabeh</span> <span class="affiliation">University of Southern California</span>, <br />
<span class="author">Cade  McCall</span> <span class="affiliation">Max Planck Institute</span>, <br />
<span class="author">Sudeep  Gandhe</span> <span class="affiliation">USC</span>, <br />
<span class="author">Jonathan  Gratch</span> <span class="affiliation">USC</span>, <br />
<span class="author">James  Blascovich</span> <span class="affiliation">University of California, Santa Barbara</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The goal here was to determine whether computer interfaces are capable of social influence via humor. Users interacted with a natural language capable virtual agent that told persuasive information, and they were given the option to use information from the dialogue in order to complete a problem-solving task. Individuals interacting with an ostensibly humorous virtual agent were influenced by it such that those who judged the agent unfunny were less likely to be persuaded and departed from the agent&#8217;s suggestions. We discuss the implications of these results for HCI involving natural language systems and virtual agents.</span></div></div><div class="paper" id="al150"><a href="#al150" class="title">StoryFaces: Children Exploring Emotional Expressions in Storytelling with Video</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979605&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kimiko  Ryokai</span> <span class="affiliation">School of Information Berkeley Center for New Media University of California Berkeley Berkeley, CA 94720 USA</span>, <br />
<span class="author">Robert  Kowalski</span> <span class="affiliation">University of Munich Amalienstr. 17 80333 Munich</span>, <br />
<span class="author">Hayes  Raffle</span> <span class="affiliation">Nokia Research Center Palo Alto 955 Page Mill Road #200 Palo Alto, CA 94304</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce StoryFaces, a new composition and storytelling tool for children to explore the role of emotional expressions in children&#8217;s narrative. StoryFaces invites children to record emotional expressions and then automatically composes these recordings in storybook illustrations. After children watch their faces bring a story to life, they can &#8220;go backstage&#8221; to play with the story by rearranging the videos and altering the story text. This paper presents our exploratory prototype, a design rationale that focuses on supporting children&#8217;s emotional growth through storytelling play and reflection, and reports on a formative evaluation with two children ages 4-6. Results from the evaluation suggest that children ages 4-6 are engaged in the activity, are excited to create a variety of emotional expressions, find the narratives funny yet clear, and work to re-craft and reinterpret story meanings through iterative editing and play with both video and textual content. Our goal is to provoke new ideas about how pretend play with digital tools can empower young children in a narrative process.</span></div></div><div class="paper" id="al144"><a href="#al144" class="title">Web Workers Unite! Addressing Challenges of Online Laborers</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979606&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Benjamin B. Bederson</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Alexander J. Quinn</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The ongoing rise of human computation as a means of solving computational problems has created an environment where human workers are often regarded as nameless, faceless computational resources.  Some people have begun to think of online tasks as a &#8220;remote person call&#8221;.  In this paper, we summarize ethical and practical labor issues surrounding online labor, and offer a set of guidelines for designing and using online labor in ways that support more positive relationships between workers and requesters, so that both can gain the most benefit from the interaction.</span></div></div><div class="paper" id="al103"><a href="#al103" class="title">Design Principles for a New Generic Digital Habitat</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979607&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Olli-Pekka  Pohjola</span> <span class="affiliation">Aalto University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our digital habitat, which today consists of desktops, applications and web pages, should be based on the same abstract concepts &#8211; habitats, spaces, information, objects and mechanisms &#8211; as our physical habitat. This enables people to feel safe, in control, capable and social, in contrast to the widespread feeling of frustration in the today&#8217;s digital society. This paper presents the key principles for designing such a continuum of the physical and digital habitats in which people perform their everyday activities, to which other systems connect and which developers extend with new concepts like ones that current digital habitats do not support.</span></div></div><div class="paper" id="al119"><a href="#al119" class="title">HappinessCounter: Smile-Encouraging Appliance to Increase Positive Mood</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979608&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hitomi  Tsujita</span> <span class="affiliation">Graduate School of Humanities and Sciences Ochanomizu University</span>, <br />
<span class="author">Jun  Rekimoto</span> <span class="affiliation">Interfaculty Initiative in Information Studies The University of Tokyo &amp; Interaction Laboratory Sony Computer Science Laboratories, Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As William James stated, and confirmed by several psychological studies, the act of smiling positively affects on our mental status -- we become happier when we laugh. In this paper, we propose a new digital appliance that naturally encourages the act of smiling in our daily lives. This system is designed mainly for people living alone, who may have difficulty realizing when they are in low spirits and/or difficulty in making themselves smile. Our HappinessCounter combines visual smile recognition, user feedback, and network communication. We installed this system in a home with a single occupant, and the system had positive effects on the user's mood.</span></div></div><div class="paper" id="al169"><a href="#al169" class="title">The Gas Mask: A Probe for Exploring Fearsome Interactions</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979609&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Brendan  Walker</span> <span class="affiliation">University of Nottingham Aerial</span>, <br />
<span class="author">Steve  Benford</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">George  Tomlinson</span> <span class="affiliation">Aerial</span>, <br />
<span class="author">Stefan  Rennick Egglestone</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Stuart  Reeves</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Patrick  Brundell</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Paul  Tennent</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Jo  Cranwell</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Paul  Harter</span> <span class="affiliation">CleverPlugs</span>, <br />
<span class="author">Jo  Longhurst</span> <span class="affiliation">University of Wales</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce an interface for horror-themed entertainment experiences based on integrating breath sensors and WiFi into gas masks. Beyond enabling the practical breath control of entertainment systems, our design aims to heighten the intensity of the experience by amplifying the user&#8217;s awareness of their breathing, as well as their feelings of isolation, claustrophobia and fear. More generally, this interface is intended to act as a technology probe for exploring an emerging research agenda around fearsome interactions. We describe the deployment of our gas masks in two events: as a control mechanism for an interactive ride, and to enhance a theme park horror maze. We identify six broad dimensions &#8211; cultural, visceral, control, social, performance and engineering &#8211; that frame an agenda for future research into fearsome interactions.</span></div></div></td>
<td colspan="13" class="session_details" id="S1044_details"><div class="paper" id="si126"><a href="#si126" class="title">Engineering Automation in Interactive Critical Systems</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979524&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Regina  Bernhaupt</span> <span class="affiliation">ruwido</span>, <br />
<span class="author">Guy  Boy</span> <span class="affiliation">Florida Inst. of Technology</span>, <br />
<span class="author">Michael  Feary</span> <span class="affiliation">NASA Ames Research Center</span>, <br />
<span class="author">Philippe  Palanque</span> <span class="affiliation">Universit&#233; de Toulouse</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This SIG focuses on the engineering of automation in interactive critical systems. Automation has already been studied in a number of (sub-) disciplines and application fields: design, human factors, psychology, (software) engineering, aviation, health care, games. One distinguishing feature of the area we are focusing on is that in the field of interactive critical systems properties such as reliability, dependability and fault-tolerance are as important as usability or user experience.  <br /> The SIG targets at two problem areas: first the engineering of the user interaction with (partly-) autonomous systems: how to design, build and assess autonomous behavior, especially in cases where there is a need to represent on the user interface both autonomous and interactive objects. An example of such integration is the representation of an unmanned aerial vehicle (UAV) (where no direct interaction is possible), together with aircrafts (that have to be instructed by an air traffic controller to avoid the UAV). Second the design and engineering of user interaction in general for autonomous objects/systems (for example a cruise control in a car or an autopilot in an aircraft). <br /> The goal of the SIG is to raise interest in the CHI community on these aspects and to identify a community of researchers and practitioners interested in those more and more prominent issues of interfaces for interactive critical systems. The expected audience should be interested in addressing the issues of integration of mainly unconnected research domains to formulate a new joint research agenda.</span></div></div></td>
<td colspan="13" class="session_details" id="S1054_details"><div class="sessionChair"><strong>Session Chair: </strong>Rob Jacob (<em>Tufts University</em>)</div><div class="paper" id="paper983"><a href="#paper983" class="title">Breath Control of Amusement Rides</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978955&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Duncan  Rowland</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Stefan  Rennick Egglestone</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Steve  Benford</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Brendan  Walker</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Derek  McAuley</span> <span class="affiliation">University of Nottingham</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Emerging robotic technologies are enabling the control of individual seats on rollercoasters and other thrill rides. We explore the potential of breathing as an effective and engaging way of driving this. Observations and interviews from trials of an enhanced bucking bronco ride show that breath-control is fun, challenging and intelligible, and reveal riders&#8223; tactics as they battled the machine. We conclude that breath control is feasible and appropriate for controlling rides, unpack its important characteristics, and consider how it might be built into future ride systems. We argue that the combination of voluntary and involuntary factors in breathing is especially appealing for controlling rides as it balances game-like elements of skill and learning against the thrill of surrendering control to the machine.</span></div></div><div class="paper" id="paper156"><a href="#paper156" class="title">Time Characteristics of Olfaction in a Single Breath</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978956&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daisuke  Noguchi</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Sayumi  Sugimoto</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Yuichi  Bannai</span> <span class="affiliation">Canon Inc.</span>, <br />
<span class="author">Ken-ichi  Okada</span> <span class="affiliation">Keio University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The transmission of olfactory information together with audiovisual <br /> information is now attracting much attention. However, <br /> the information is difficult to synchronize because of <br /> problems of scent lingering in the air and olfactory adaptation. <br /> We aimed at minimizing the amount of odorant presented <br /> to users in order to mitigate these problems, and developed <br /> an olfactory display that is able to present scents <br /> precisely. The display uses pulse ejection, whereby scents <br /> are emitted for only short periods of time. In this study, <br /> we aimed to mitigate the above-mentioned problems and <br /> to measure the time characteristics of olfaction in a single <br /> breath, which are difficult to measure by conventional methods. <br /> As a result, the most effective conditions for using a <br /> small amount of odorant in a single breath were revealed. <br /> These results are expected to ease the synchronization of olfactory <br /> and audiovisual information.</span></div></div><div class="paper" id="paper1892"><a href="#paper1892" class="title">Augmented Reality Flavors: Gustatory Display  Based on Edible Marker and Cross-Modal Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978957&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Takuji  Narumi</span> <span class="affiliation">The University of Tokyo / JSPS</span>, <br />
<span class="author">Shinya  Nishizaka</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Takashi  Kajinami</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Tomohiro  Tanikawa</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Michitaka  Hirose</span> <span class="affiliation">The University of Tokyo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The main contribution of this paper is to realize computer generated augmented flavors and establish a method to integrate gustatory information into computer human interactions. There are several reasons for the scarcity of research on gustatory information. One reason is that taste sensations are affected by a number of factors, such as vision, olfaction and memories. This produces a complex cognition mechanism for a user's gustatory sensation, and makes it difficult to build up a gustatory display which produces a specific taste on demand. <br /> Our hypothesis is that the complexity of gustatory sensation can be applied to the realization of a "Pseudo-gustatory" display that presents the desired flavors by means of a cross-modal effect elicited by visual and olfactory augmented reality. We propose the Edible Marker system, which can detect the state [number/shape/6-degree-of-freedom (DOF) coordinate] of each piece of bitten or divided food in real time, and the "Pseudo-gustation" method to change the perceived taste of food by changing its appearance and scent. We construct "MetaCookie+" as an implementation and discuss its validity through an exploratory study. <br /></span></div></div><div class="paper" id="paper138"><a href="#paper138" class="title">Biofeedback Game Design: Using Direct and Indirect Physiological Control to Enhance Game Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978958&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lennart E Nacke</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Michael  Kalyn</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Calvin  Lough</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Regan L Mandryk</span> <span class="affiliation">University of Saskatchewan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Prior work on physiological game interaction has focused on dynamically adapting games using physiological sensors. In this paper, we propose a classification of direct and indirect physiological sensor input to augment traditional game control. To find out which sensors work best for which game mechanics, we conducted a mixed-methods study using different sensor mappings. Our results show participants have a preference for direct physiological control in games. This has two major design implications for physiologically controlled games: (1) Direct physiological sensors should be mapped intuitively to reflect an action in the virtual world; (2) Indirect physiological input is best used as a dramatic device in games to influence features altering the game world.</span></div></div></td>
<td colspan="13" class="session_details" id="S1059_details"><div class="sessionChair"><strong>Session Chair: </strong>Volker Wulf (<em>University of Siegen</em>)</div><div class="paper" id="paper2030"><a href="#paper2030" class="title">"Pleasure is Your Birthright": Digitally Enabled Designer Sex Toys as a Case of Third-Wave HCI</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978979&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jeffrey  Bardzell</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In the past decade, HCI has become increasingly preoccupied with the deeply subjective qualities of interaction: experience, embodiment, pleasure, intimacy, and so on, an agenda sometimes grouped under the heading of &#8220;third-wave HCI.&#8221; Analytically understanding and designing for such qualities has been an ongoing challenge to the field, in part because its established theories and methodologies are comparatively weak at understanding and being responsive to human subjectivity. In this paper, we present a case study of a group of designers who have, in the past few years, revolutionized their domain&#8212;sex toys&#8212;by combining embodied pleasure, intimate experience, health and wellness, emerging technologies, high-quality design processes, and social activism. We consider the implications this case could have for researchers innovating on especially third-wave HCI design theories, methodologies, and processes.</span></div></div><div class="paper" id="paper602"><a href="#paper602" class="title">Designing a Phone Broadcasting System for Urban Sex Workers in India</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978980&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nithya  Sambasivan</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Julie  Weber</span> <span class="affiliation">Microsoft Research India</span>, <br />
<span class="author">Edward  Cutrell</span> <span class="affiliation">Microsoft Research India</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we present the design, implementation, and deployment of a phone-based broadcasting system designed for reaching out to at-risk populations in urban India. We worked in collaboration with Pragati, a non-governmental organization dedicated to assisting Urban Sex Workers (USWs) in Bangalore, India, with the goal of improving Pragati&#8217;s outreach to the women they serve. We conducted ethnographic action research to understand and address the needs of Pragati and the lifestyles of USWs. Responding to the unique design constraints of the USW community such as specific privacy and timing constraints, a desire to remain invisible, and the unusually high rate of mobile phone use, we designed a phone-based broadcasting system for Pragati. We then deployed the system on four different occasions and application areas. We present the results and key findings from our study, and conclude with a discussion on how designing for particularly difficult cases such as USWs can shed new light on the design of mobile applications for the developing world in general, such as challenging ubiquity and phone numbers as identity.</span></div></div><div class="paper" id="cs206"><a href="#cs206" class="title">Self-Evidence: Applying Somatic Connoisseurship to Experience Design</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979640&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Thecla  Schiphorst</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This design case study examines and illustrates the concept of self-evidence by applying somatic connoisseurship to experience design. It invites a re-thinking of the process of design for technology, one that includes design for the experience of the self. Supported by concepts of somatic phenomenology and discourse surrounding &#8216;felt-life&#8217; within HCI, this case study articulates the concept of self-evidence through the application of somatic body-based practices as a framework for technology design within HCI. The case study utilizes examples from the design process of the interactive, networked wearable art installation called whisper. Concepts of somatic connoisseurship are exemplified throughout all phases of an interdisciplinary artist-led design process.</span></div></div><div class="paper" id="paper1334"><a href="#paper1334" class="title">Bodily Orientations around Mobiles: Lessons learnt in Vanuatu</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978981&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pedro  Ferreira</span> <span class="affiliation">Mobile Life @ Stockholm University</span>, <br />
<span class="author">Kristina  H&#246;&#246;k</span> <span class="affiliation">Mobile Life @ Stockholm University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Since we started carrying mobiles phones, they have altered the ways in which we orient our bodies in the world. Many of those changes are invisible to us &#8211; they have become habits, deeply engrained in our society. To make us more aware of our bodily ways of living with mobiles and open the design space for novel ways of designing mobiles and their interactions, we decided to study one of the last groups of users on earth who had not been exposed to mobiles: the people of Vanuatu. As they had so recently started using mobiles, their use was still in flux: the fragility of the mobile was unusual to them as was the need to move in order to find coverage. They were still getting used to carrying their mobiles and keeping them safe. Their encounters with mobile use exposed the need to consider somaesthetics practices when designing mobiles as they profoundly affect our bodily ways of being in the world.</span></div></div></td>
<td colspan="13" class="session_details" id="S1053_details"><div class="sessionChair"><strong>Session Chair: </strong>Carman Neustaedter (<em>Simon Fraser University</em>)</div><div class="paper" id="paper2161"><a href="#paper2161" class="title">&#8220;Now, I have a body&#8221;: Uses and social norms for mobile remote presence in the workplace</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978950&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Min Kyung  Lee</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Leila  Takayama</span> <span class="affiliation">Willow Garage</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As geographically distributed teams become increasingly common, there are more pressing demands for communication work practices and technologies that support distributed collaboration. One set of technologies that are emerging on the commercial market is mobile remote presence (MRP) systems, physically embodied videoconferencing systems that remote workers use to drive through a workplace, communicating with locals there. Our interviews, observations, and survey results from people, who had 2-18 months of MRP use, showed how remotely-controlled mobility enabled remote workers to live and work with local coworkers almost as if they were physically there. The MRP supported informal communications and connections between distributed coworkers. We also found that the mobile embodiment of the remote worker evoked orientations toward the MRP both as a person and as a machine, leading to formation of new usage norms among remote and local coworkers.</span></div></div><div class="paper" id="paper1715"><a href="#paper1715" class="title">Hands on Hitchcock: Embodied Reference to a Moving Scene</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978951&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Paul  Luff</span> <span class="affiliation">King's College, London</span>, <br />
<span class="author">Naomi  Yamashita</span> <span class="affiliation">NTT</span>, <br />
<span class="author">Hideaki  Kuzuoka</span> <span class="affiliation">University of Tsukuba</span>, <br />
<span class="author">Christian  Heath</span> <span class="affiliation">King's College, London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we report on some experiments with a high fidelity media space, t-Room, an immersive system that presents full scale, real-time images of co-participants who are in similar spaces many miles apart. Although being designed to provide a coherent environment for interaction the system introduces a number of incongruities, both in time and space. Drawing on some quasi-naturalistic experiments, where the participants were required to analyse complex data, we consider how the participants manage these incongruities. We conclude by briefly discussing the resources people utilize to produce and recognize conduct in embodied spaces.</span></div></div><div class="paper" id="paper601"><a href="#paper601" class="title">Exploring Camera Viewpoint Control Models for a Multi-Tasking Setting in Teleoperation</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978952&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dingyun  Zhu</span> <span class="affiliation">CSIRO / ANU</span>, <br />
<span class="author">Tom  Gedeon</span> <span class="affiliation">ANU</span>, <br />
<span class="author">Ken  Taylor</span> <span class="affiliation">CSIRO</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Control of camera viewpoint plays a vital role in many teleoperation activities, as watching live video streams is still the fundamental way for operators to obtain situational awareness from remote environments. Motivated by a real-world industrial setting in mining teleoperation, we explore several possible solutions to resolve a common multi-tasking situation where an operator is required to control a robot and simultaneously perform remote camera operation. Conventional control interfaces are predominantly used in such teleoperation settings, but could overload an operator&#8217;s hand-operation capability, and require frequent attention switches and thus could decrease productivity.  <br />  <br /> We report on an empirical user study in a model multi-tasking teleoperation setting where the user has a main task which requires their attention. We compare three different camera viewpoint control models: (1) dual manual control, (2) natural interaction (combining eye gaze and head motion) and (3) autonomous tracking. The results indicate the advantages of using the natural interaction model, while the manual control model performed the worst. <br /></span></div></div><div class="paper" id="paper762"><a href="#paper762" class="title">Zoom Cameras and Movable Displays Enhance Social Telepresence</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978953&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hideyuki  Nakanishi</span> <span class="affiliation">Osaka University</span>, <br />
<span class="author">Kei  Kato</span> <span class="affiliation">Osaka University</span>, <br />
<span class="author">Hiroshi  Ishiguro</span> <span class="affiliation">Osaka University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper shows that the augmentation of a remote person&#8217;s positional movement enhances social telepresence. There are three possible ways of representing a remote person&#8217;s movement toward the user in visual communication: a) the remote person&#8217;s movement toward the remote camera, b) the remote camera&#8217;s zooming in to enlarge the remote person&#8217;s picture, and c) a forward movement of the display that is displaying the remote person. We conducted an experiment to see the relationship among these three ways and the effects of a remote camera&#8217;s zooming and a display&#8217;s movement on social telepresence. In the experiment, we observed that the remote person&#8217;s movement lowered the reality of conversations, and the remote camera&#8217;s zooming lowered the visual quality. However, social telepresence was enhanced when both the person&#8217;s movement and the camera&#8217;s zooming occurred simultaneously. We also observed that a 6-centimeter movement of the display enhanced social telepresence, whether the remote person moved or not.</span></div></div></td>
<td colspan="13" class="session_details" id="S1057_details"><div class="sessionChair"><strong>Session Chair: </strong>Michael Rohs (<em>LMU Munich</em>)</div><div class="paper" id="paper128"><a href="#paper128" class="title">Mid-air Pan-and-Zoom on Wall-sized Displays</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978969&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathieu  Nancel</span> <span class="affiliation">Univ. Paris-Sud &amp; CNRS; INRIA</span>, <br />
<span class="author">Julie  Wagner</span> <span class="affiliation">INRIA; Univ. Paris-Sud &amp; CNRS</span>, <br />
<span class="author">Emmanuel  Pietriga</span> <span class="affiliation">INRIA; Univ. Paris-Sud &amp; CNRS</span>, <br />
<span class="author">Olivier  Chapuis</span> <span class="affiliation">Univ. Paris-Sud &amp; CNRS; INRIA</span>, <br />
<span class="author">Wendy  Mackay</span> <span class="affiliation">INRIA; Univ. Paris-Sud &amp; CNRS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Very-high-resolution wall-sized displays offer new opportunities for interacting with large data sets. While pointing on this type of display has been studied extensively, higher-level, more complex tasks such as pan-zoom navigation have received little attention. It thus remains unclear which techniques are best suited to perform multiscale navigation in these environments. Building upon empirical data gathered from studies of pan-and-zoom on desktop computers and studies of remote pointing, we identified three key factors for the design of mid-air pan-and-zoom techniques: uni- vs. bimanual interaction, linear vs. circular movements, and level of guidance to accomplish the gestures in mid-air. After an extensive phase of iterative design and pilot testing, we ran a controlled experiment aimed at better understanding the influence of these factors on task performance. Significant effects were obtained for all three factors:  bimanual interaction, linear gestures and a high level of guidance resulted in significantly improved performance. Moreover, the interaction effects among some of the dimensions suggest possible combinations for more complex, real-world tasks.</span></div></div><div class="paper" id="paper1779"><a href="#paper1779" class="title">Gesture Select: Acquiring Remote Targets on Large Displays without Pointing</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978970&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew  Bragdon</span> <span class="affiliation">Brown University</span>, <br />
<span class="author">Hsu-Sheng  Ko</span> <span class="affiliation">Brown University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">When working at a large wall display, even if partially utilized, many targets are likely to be distant from the user, requiring walking, which is slow, and interrupts workflow. We propose a novel technique for selecting remote targets called Gesture Select, in which users draw an initial mark, in a target&#8217;s direction; rectilinear gestures represented as icons are dynamically overlaid on targets within a region of interest; the user then continues by drawing the continuation mark corresponding to the target, to select it. Extensions to this technique to support working with remote content for an extended period, and learning gesture shortcuts are presented. A formal experiment indicates Gesture Select significantly outperformed direct selection for mid/far targets. Further analysis suggests Gesture Select performance is principally affected by the extent to which users can read the gestures, influenced by distance and perspective warping, and the gesture complexity in the ROI. The results of a second 2-D experiment with labeled targets indicate Gesture Select significantly outperformed direct selection and an existing technique.</span></div></div><div class="paper" id="paper1795"><a href="#paper1795" class="title">User-Defined Motion Gestures for Mobile Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978971&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jaime  Ruiz</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Yang  Li</span> <span class="affiliation">Google Research</span>, <br />
<span class="author">Edward  Lank</span> <span class="affiliation">University of Waterloo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Modern smartphones contain sophisticated sensors to monitor three-dimensional movement of the device. These sensors permit devices to recognize motion gestures&#8212;deliberate movements of the device by end-users to invoke commands. However, little is known about best-practices in motion gesture design for the mobile computing paradigm. To address this issue, we present the results of a guessability study that elicits end-user motion gestures to invoke commands on a smartphone device. We demonstrate that consensus exists among our participants on parameters of movement and on mappings of motion gestures onto commands. We use this consensus to develop a taxonomy for motion gestures and to specify an end-user inspired motion gesture set. We highlight the implications of this work to the design of smartphone applications and hardware. Finally, we argue that our results influence best practices in design for all gestural interfaces.</span></div></div><div class="paper" id="paper2078"><a href="#paper2078" class="title">Gesture Avatar: A Technique for Operating Mobile User Interfaces Using Gestures</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978972&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hao  L&#252;</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Yang  Li</span> <span class="affiliation">Google Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Finger-based touch input has become a major interaction modality for mobile user interfaces. However, due to the low precision of finger input, small user interface components are often difficult to acquire and operate on a mobile device. It is even harder when the user is on the go and unable to pay close attention to the interface. In this paper, we present Gesture Avatar, a novel interaction technique that allows users to operate existing arbitrary user interfaces using gestures. It leverages the visibility of graphical user interfaces and the casual interaction of gestures. Gesture Avatar can be used to enhance a range of mobile interactions. A user study we conducted showed that compared to Shift (an alternative technique for target acquisition tasks), Gesture Avatar performed at a much lower error rate on various target sizes and significantly faster on small targets (1mm). It also showed that using Gesture Avatar while walking did not significantly impact its performance, which makes it suitable for mobile uses.</span></div></div></td>
<td colspan="13" class="session_details" id="S5001_details"><div class="paper" id="wp114"><a href="#wp114" class="title">Low Cost vs. High-End Eye Tracking for Usability Testing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979744&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sune Alstrup Johansen</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Javier  San Agustin</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Henrik  Skovsgaard</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">John Paulin Hansen</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Martin  Tall</span> <span class="affiliation">Duke University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Accuracy of an open source remote eye tracking system and a state-of-the-art commercial eye tracker was measured 4 times during a usability test. Results from 9 participants showed both devices to be fairly stable over time, but the commercial tracker was more accurate with a mean error of 31 pixels against 59 pixels using the low cost system. This suggests that low cost eye tracking can become a viable alternative, when usability studies need not to distinguish between, for instance, particular words or menu items that participants are looking at, but only between larger areas-of-interest they pay attention to.</span></div></div><div class="paper" id="wp118"><a href="#wp118" class="title">A Crowdsourcing Model for Receiving Design Critique</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979745&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anbang  Xu</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span>, <br />
<span class="author">Brian P. Bailey</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designers in many domains are increasingly turning to online communities to receive critiques of early design ideas. However, members of these communities may not contribute an effective critique due to limited skills, motivation, or time, and therefore many critiques may not go beyond &#8220;I (don&#8217;t) like it&#8221;. We propose a new approach for designers to receive online critique. Our approach is novel because it adopts a theoretical framework for effective critique and implements the framework on a popular crowdsourcing platform. Preliminary results show that our approach allows designers to acquire quality critiques in a timely manner that compare favorably with critiques produced from a well-known online community.</span></div></div><div class="paper" id="wp119"><a href="#wp119" class="title">Touch-Bookmark: A Lightweight Navigation and Bookmarking Technique for E-Books</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979746&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dongwook  Yoon</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Yongjun  Cho</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Kiwon  Yeom</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Ji-Hyung  Park</span> <span class="affiliation">Korea Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The navigation function of an e-book significantly influences its usability. In this paper, we introduce Touch-Bookmark (TB), a multitouch navigation technique for e-books. TB enables users to bookmark a page in a casual manner and return to it quickly when required. Moreover, the users can flip between two remote pages by using simple gestures. In a usability test conducted to evaluate our prototype, users found the technique easy to learn, natural to use, and useful for navigation. Analysis of the patterns of interaction gestures helped identify human factors that should be considered when designing touch interfaces for e-books. The factors include navigation strategies, patterns of interaction gestures, types of books, and motor memory.</span></div></div><div class="paper" id="wp127"><a href="#wp127" class="title">Understanding Email Communication of Persons with Aphasia</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979747&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abdullah  Al Mahmud</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Jean-Bernard  Martens</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An email program has been developed by the Aphasia Union Netherlands (AVN) to enhance communication between aphasics mutually and with their therapists. In this paper we report intermediate evaluation results of the AVN email program. We evaluated the email program in two ways: a. by analyzing the AVN email server logs and b. by collecting subjective responses through questionnaires. Our results indicate that both aphasics and therapists find the email program useful, despite the fact that they expressed several criticisms about its usability. Therefore, some changes are required to make the program better useable and more widely accessible for the target group.</span></div></div><div class="paper" id="wp133"><a href="#wp133" class="title">A Context-Sensitive Device to Help People with Autism Cope with Anxiety</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979748&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marziya  Mohammedali</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Dinh  Phung</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Brett  Adams</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Svetha  Venkatesh</span> <span class="affiliation">Curtin University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe a smartphone application that helps people with Autism Spectrum Disorder (ASD) cope with anxiety attacks. Our prototype provides a one-touch interface for indicating a panic level. The device&#8217;s response&#8212;to instruct, soothe, and/or contact carers&#8212;is sensitive to the user&#8217;s context, consisting of time, location, ambient noise, and nearby friends. Formative evaluation unearths a critical challenge to building assistive technologies for ASD sufferers: can regimented interfaces foster flexible behaviour? Our observations suggest that a delicate balance of design goals is required for a viable assistive technology.</span></div></div><div class="paper" id="wp147"><a href="#wp147" class="title">The Effects of Screen-Size and Communication Modality on Psychology of Mobile Device Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979749&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ki Joon  Kim</span> <span class="affiliation">SungKyunKwan University</span>, <br />
<span class="author">S. Shyam  Sundar</span> <span class="affiliation">Pennsylvania State University</span>, <br />
<span class="author">Eunil  Park</span> <span class="affiliation">SungKyunKwan University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Does screen-size matter in mobile devices? There appears to be a move toward larger screens, with recent launches of Apple&#8217;s iPad and Samsung&#8217;s Galaxy Tab, but do these devices undercut the perceived mobility and affect user attitudes toward the technology? To answer these and related questions, the present study examines the effects of screen-size and communication modality (text vs. video) on mobile device users&#8217; perception of mobility and content as well as attitudes toward technology acceptance. Preliminary data from a between-subjects experiment show that smaller screen-size elicited greater perceived mobility while larger screen-size was key to greater enjoyment. News story in video format played a crucial role in providing greater enjoyment and newsworthiness of the news story while news in text format was perceived to be easier to use on a mobile device. Design implications and limitations are discussed, as we prepare for a constructive replication.</span></div></div><div class="paper" id="wp150"><a href="#wp150" class="title">On the use of pervasive computing to support patients with obsessive compulsive disorder</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979750&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vassilis-Javed  Khan</span> <span class="affiliation">NHTV Breda University of Applied Sciences</span>, <br />
<span class="author">Panos  Markopoulos</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Nynke  Spijksma</span> <span class="affiliation">Marina de Wolf Hospital</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Obsessive-compulsive disorder (OCD) is a psychiatric disorder affecting 2% to 3% of world population. Patients having this disorder engage in repetitive and discomforting behaviors usually linked to controlling or cleaning. The potential of technical solutions trying to support both patients and therapists has been to a limited extent explored with some encouraging results. However, the use of a mobile phone application has not yet been explored. We present a study of a distributed application, partly running on mobile phone and partly on a website, with four patients suffering from OCD and their therapist. Our qualitative evaluation yields encouraging conclusions for practitioners and developers of such applications.</span></div></div><div class="paper" id="wp153"><a href="#wp153" class="title">Living with Pain, Staying in Touch: Exploring the Communication Needs of Older Adults with Chronic Pain</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979751&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jessica M David</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Alison  Benjamin</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Ronald M Baecker</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Diane J Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Jeremy P Birnholtz</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">For older adults with chronic pain, maintaining social ties can be difficult. Both chronic pain and social isolation compound each other and are associated with poor health outcomes. Our research explores how technology can be used to facilitate communication and support for older adults with chronic pain. We report on preliminary results of field research with 20 participants and deployment of a digital communicating picture frame prototype. We found that chronic pain introduces unique barriers to synchronous contact and that our prototype seemed to fit the needs of these individuals by supporting meaningful asynchronous communication with the possibility for adjustable reciprocity.</span></div></div><div class="paper" id="wp161"><a href="#wp161" class="title">Ambient Displays: Influencing Movement Patterns</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979752&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tasos  Varoudis</span> <span class="affiliation">arch+ech Architecture</span>, <br />
<span class="author">Sheep  Dalton</span> <span class="affiliation">Open University</span>, <br />
<span class="author">Katerina  Alexiou</span> <span class="affiliation">Open University</span>, <br />
<span class="author">Theodore  Zamenopoulos</span> <span class="affiliation">Open University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Ambient displays are gradually augmenting the principal static elements of architecture, such as walls, transforming space into a dynamic and ever-changing environment. Does the addition of such digital elements influence people&#8217;s perception and understanding of space around them? If so, do ambient displays lead to behavioral changes like people&#8217;s movement in such environments? In this particular study, a series of experiments were conducted to investigate public interior spaces with embedded ambient displays. The findings are then presented showing how the presence of an ambient display through its visual depth affects and changes movement patterns. This study discusses the ability of an ambient display to refine navigation paths and suggests that its visual depth can enhance its effectiveness.</span></div></div><div class="paper" id="wp162"><a href="#wp162" class="title">A Tactile Friend Sense for Keeping Groups Together</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979753&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Martin  Pielot</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Benjamin  Poppinga</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Wilko  Heuten</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Susanne  Boll</span> <span class="affiliation">University of Oldenburg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Visiting crowded places at night in a group of friends is a common leisure activity in many parts of the world. However, the chaotic nature of such place makes it difficult to keep the group together. Constantly watching out for the others or frequent use of technology (e.g. phone calls or Google Latitude) may be contradictory to the idea of having a jolly night out. We therefore designed FriendSense, a mobile application that acts as a pervasive anchor to one of the friends. Beyond existing solutions it allows to continuously sense the anchored friend&#8217;s location through vibro-tactile feedback. In a preliminary field study we investigated how this added sense affects a night out at an Oktoberfest-like festival. We found evidence that FriendSense users were more confident and less stressed with keeping the group together.</span></div></div><div class="paper" id="wp165"><a href="#wp165" class="title">Recompose: Direct and Gestural Interaction with an Actuated Surface</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979754&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Blackshaw</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Anthony  DeVincenzi</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">David  Lakatos</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Daniel  Leithinger</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present Recompose, a new system for manipulation of an actuated surface. By collectively utilizing the body as a tool for direct manipulation alongside gestural input for functional manipulation, we show how a user is afforded unprecedented control over an actuated surface. We describe a number of interaction techniques exploring the shared space of direct and gestural input, demonstrating how their combined use can greatly enhance creation and manipulation beyond unaided human capability.</span></div></div><div class="paper" id="wp169"><a href="#wp169" class="title">Make a Trip an Experience: Sharing In-Car Information with Passengers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979755&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ohad  Inbar</span> <span class="affiliation">Ben-Gurion University of the Negev</span>, <br />
<span class="author">Noam  Tractinsky</span> <span class="affiliation">Ben-Gurion University of the Negev</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Current in-vehicle information systems (IVIS) are designed for use by a single entity &#8211; the driver. In this paper we propose that the benefits of IVIS can increase if we also consider the needs of passengers and their potential contribution as additional information handlers who buffer the driver from information overload. The benefits these &#8220;incidental users&#8221; of IVIS can reap from having trip-related information shared with them include reduced boredom, increased trust and a sense of inclusion. Drivers&#8217; benefits include less distraction caused by questions previously aimed at them as the exclusive owners of the trip-related information, and reduced information load by allowing passengers to actively control selected in-car systems.</span></div></div><div class="paper" id="wp171"><a href="#wp171" class="title">Effects of Different Types of Artifacts on Interpretations of Artificial Subtle Expressions (ASEs)</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979756&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Takanori  Komatsu</span> <span class="affiliation">Shinshu University</span>, <br />
<span class="author">Seiji  Yamada</span> <span class="affiliation">National Institute of Informatics</span>, <br />
<span class="author">Kazuki  Kobayashi</span> <span class="affiliation">Shinshu University</span>, <br />
<span class="author">Kotaro  Funakoshi</span> <span class="affiliation">Honda Research Institute</span>, <br />
<span class="author">Mikio  Nakano</span> <span class="affiliation">Honda Research Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">So far, we already confirmed that the artificial subtle expressions (ASEs) from a robot could convey its internal states to participants accurately and intuitively. In this paper, we investigated whether the ASEs from an on-screen artifact could also convey the artifact&#8217;s internal states to participants in order to confirm whether the ASEs can be interpreted consistently for  various types of artifacts. The results clearly showed that the ASEs&#8217; interpretations from on-screen artifact were consistent with the ones from robotic agent.</span></div></div><div class="paper" id="wp174"><a href="#wp174" class="title">Adaptive Eye-Gaze-Guided Interfaces: Design &amp; Performance Evaluation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979757&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Oleg  Komogortsev</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Corey  Holland</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Jose  Camou</span> <span class="affiliation">Texas State University-San Marcos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper considers the effects of user interface adaptation based on regional eye tracker accuracy to improve user performance and satisfaction in an eye-gaze-guided application. We objectively and subjectively evaluated the differences between an adaptive interface, in which navigational elements were placed in regions of highest accuracy, and its inverted counterpart, in which navigational elements were placed in regions of lowest accuracy. The results indicate that by accounting for regional accuracy the adaptive interface was able to provide a significant improvement in user performance, though this effect had little bearing on user satisfaction.</span></div></div><div class="paper" id="wp183"><a href="#wp183" class="title">RegionalSliding: Enhancing Target Selection on Touchscreen-Based Mobile Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979758&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wenchang  Xu</span> <span class="affiliation">Tsinghua University</span>, <br />
<span class="author">Chun  Yu</span> <span class="affiliation">Tsinghua University</span>, <br />
<span class="author">Yuanchun  Shi</span> <span class="affiliation">Tsinghua University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Target selection on mobile devices with touchscreens usually gets users into trouble due to the occlusion of the target by the user&#8217;s finger and ambiguity about which part of the finger generates the result point. In this paper, we propose a novel technique to enhance target selection on touchscreen-based mobile devices, named RegionalSliding, which selectively renders the initially &#8220;selected&#8221; target as well as its &#8220;surrounding&#8221; targets in a non-occluded area when users press down on the screen and enables users to complete the selection with sliding gestures according to the visual feedback from the rendered area. A preliminary user study shows that RegionalSliding increases the selection accuracy and brings good user experience.</span></div></div><div class="paper" id="wp191"><a href="#wp191" class="title">Why not Use Mobile Phones? An Observational Study of Medical Work</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979759&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">So Young  Lee</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Sun Young  Park</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Yunan  Chen</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous studies suggest that mobile phones could prevent many communication and information breakdowns that commonly occur in a hospital environment. However, the actual benefits of mobile phones in medical work remain unexplored. We studied mobile phone usage among nurses in an Emergency Department (ED). Surprisingly, mobile phones were not favored by our study participants. We found that mobile phones do not support essential characteristics of nursing work in ED because they lack support for group awareness, informative interruption, and role-based calling. The findings suggest that the design of mobile devices should support nurses&#8217; share of work responsibilities and the need for information transparency.</span></div></div><div class="paper" id="wp209"><a href="#wp209" class="title">Enhancing Outdoor Navigation Systems through Vibrotactile Feedback</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979760&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominik  Bial</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Dagmar  Kern</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Florian  Alt</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Albrecht  Schmidt</span> <span class="affiliation">University of Stuttgart</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While driving many tasks compete for the attention of the user, mainly via the audio and visual channel. When designing systems depending upon providing feedback to users (e.g., navigation systems), it is a crucial prerequisite to minimize influence on and distraction <br /> from the driving task. This becomes even more important when designing systems for the use on motorbikes; space for output devices is scarce, as people are wearing helmets visual feedback is often difficult due to lighting conditions, and audio feedback is limited. <br /> In a first step we aimed at creating an understanding as to how information could be communicated in a meaningful way using vibrotactile signals. Therefore, we investigated suitable positions of actuators on the hand, appropriate length of the vibration stimulus, <br /> and different vibration patterns. We built a first prototype with 4 vibration actuators attached to the fingertips and asked 4 participants to test our prototype while driving. With this work we envision to lay the foundations for vibrotactile support in navigation systems.</span></div></div><div class="paper" id="wp210"><a href="#wp210" class="title">Us&#8217;em: Motivating Stroke Survivors to Use their Impaired Arm and Hand in Daily Life</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979761&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luuk  Beursgens</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Freek  Boesten</span> <span class="affiliation">Maastricht University</span>, <br />
<span class="author">Annick  Timmermans</span> <span class="affiliation">Adelante Rehabilitation Centre</span>, <br />
<span class="author">Henk  Seelen</span> <span class="affiliation">Adelante Rehabilitation Centre</span>, <br />
<span class="author">Panos  Markopoulos</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Stroke leaves the majority of its survivors with an impairment of the upper extremity that seriously reduces their quality of life and their ability to live independently. Rehabilitation research has shown that extensive usage of the impaired arm in everyday life can improve arm-hand performance, even in chronic stages after stroke. Such usage though is difficult for patients who need some help to be reminded and motivated for using the impaired arm. This paper presents the user centered design and initial evaluation of Us&#8217;em, a watch-like device that provides feedback to patients regarding the usage of their impaired arm-hand in relation to their non-affected upper extremity in order to motivate them to use their affected arm more.</span></div></div><div class="paper" id="wp217"><a href="#wp217" class="title">Duet for Solo Piano: MirrorFugue for Single User Playing with Recorded Performances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979762&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Xiao  Xiao</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">MirrorFugue is an interface that supports symmetric, real-time collaboration on the piano using spatial metaphors to communicate the hand gesture of collaborators. In this paper, we present an extension of MirrorFugue to support single-user interactions with recorded material and outline usage scenarios focusing on practicing and self-reflection. Based on interviews with expert musicians, we discuss how single-user interactions on MirrorFugue relate to larger themes in music learning and suggest directions for future research.</span></div></div><div class="paper" id="wp226"><a href="#wp226" class="title">OpenID-Enabled Browser: Towards Usable and Secure Web Single Sign-On</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979763&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">San-Tsai  Sun</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Eric  Pospisil</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Ildar  Muslukhov</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Nuray  Dindar</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">OpenID is an open and promising Web single sign-on solution; however, the interaction flows provided by OpenID are inconsistent, counter-intuitive, and vulnerable to phishing attacks. In this work, we investigated the challenges web users face when using OpenID for authentication, and designed a phishing-resistant, privacy-preserving browser add-on to provide a consistent and intuitive single sign-on user experience for the average web users.</span></div></div><div class="paper" id="wp237"><a href="#wp237" class="title">Children may Expect Drag-and-Drop Instead of Point-and-Click</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979764&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wolmet  Barendregt</span> <span class="affiliation">University of Gothenburg</span>, <br />
<span class="author">Mathilde M.  Bekker</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present evidence from a pilot study that children may have started to expect the drag-and-drop interaction style. This is in contrast with probably the most cited paper on this topic from 2001, stating that point-and-click is the most appropriate interaction style for children between 6 and 12 years old. Instead of providing children with information on the interaction style expected we developed two point-and-click interfaces and let children explore those interfaces themselves. Children consistently tried to apply the drag-and-drop interaction style both initially and after having discovered the point-and-click style, resulting in problems in interacting with the interfaces. This was especially clear for the type of action having a natural mapping to holding down the mouse-button, such as cutting or drawing lines. In summary, it appears that children have begun to expect the drag-and-drop interaction style and that deviating from this standard may result in serious usability problems.</span></div></div><div class="paper" id="wp243"><a href="#wp243" class="title">SoloFind: Chains of Interactions with a Mobile Retail Experience System</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979765&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alexander  Wiethoff</span> <span class="affiliation">Ludwig-Maximilians-Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Gregor  Broll</span> <span class="affiliation">DOCOMO Euro-Labs</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents SoloFind, a mobile retail experience system for large consumer electronic stores that helps users to retrieve product information. A tangible user interface (TUI) allows customers to collect product information via a simple, Near Field Communication (NFC) based interaction. This data can be customized, reviewed and compared at an interactive kiosk. The simple, touch-like interaction with NFC provides a seamless user experience for customers. This paper focuses on the design of SoloFind, its features and their preliminary evaluation with an experience prototype.</span></div></div><div class="paper" id="wp244"><a href="#wp244" class="title">Squeeze vs. Tilt: A Comparative Study Using Continuous Tactile Feedback</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979766&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eve  Hoggan</span> <span class="affiliation">University of Helsinki HIIT</span>, <br />
<span class="author">Dari  Trendafilov</span> <span class="affiliation">Nokia</span>, <br />
<span class="author">Teemu  Ahmaniemi</span> <span class="affiliation">Nokia</span>, <br />
<span class="author">Roope  Raisamo</span> <span class="affiliation">University of Tampere</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an investigation into the performance of squeezing as a manipulative interaction technique in comparison to tilting with an aim to answer two questions: is squeezing an effective input technique for mobile devices and can tactile feedback improve performance? The experiment results show that both input methods are viable but squeezing is significantly faster and more sustainable than tilting (with and without tactile feedback).</span></div></div><div class="paper" id="wp246"><a href="#wp246" class="title">Evaluating an Automatic Rotation Feature in Collaborative Tabletop Workspaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979767&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gianluca  Schiavo</span> <span class="affiliation">University of Padova</span>, <br />
<span class="author">Giulio  Jacucci</span> <span class="affiliation">University of Helsinki</span>, <br />
<span class="author">Tommi  Ilmonen</span> <span class="affiliation">Multitouch Ltd.</span>, <br />
<span class="author">Luciano  Gamberini</span> <span class="affiliation">University of Padova</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Tabletops are commonly used for collaboration but would benefit from features that help orient objects to individual users disposed around the display.  We propose an approach of automatic orientation based on fingers and hand detection as a proxy to determine the position of the user. To contribute to the discussion of the relevance of automatic rotation, we present a comparison study of pairs of participants engaged in both loosely and tightly coupled tasks. We collected performance measures, questionnaires and analyze interactions from video recordings. The results show that automatic rotation is more suitable when the collaboration is loosely coupled. Conversely, in tightly coupled tasks performance are worse and user ratings low when automatic rotations are enabled. We conclude that features such as automatic orientation on tabletop are important and promising but that they need to be critically assessed with respect to their effects on collaboration in both tightly and loosely coupled tasks.</span></div></div><div class="paper" id="wp250"><a href="#wp250" class="title">Participatory Sensing for Community Building</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979768&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Whitney</span> <span class="affiliation">University of North Carolina, Charlotte</span>, <br />
<span class="author">Heather  Richter Lipford</span> <span class="affiliation">University of North Carolina, Charlotte</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this research, we explore the viability of using participatory sensing as a means to enhance a sense of community. To accomplish this, we are developing and deploying a suite of participatory sensing applications, where users explicitly report on the state of their environment, such as the location of the bus. In doing so, community members become reliant on each other for valuable information about the community. By better understanding the relationship between participatory sensing and community, we inform the design and research of similar participatory sensing, or crowd-sourced sensing applications.</span></div></div><div class="paper" id="wp251"><a href="#wp251" class="title">Towards User-Centered Mashups: Exploring User Needs for Composite Web Services</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979769&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kaisa  V&#228;&#228;n&#228;nen-Vainio-Mattila</span> <span class="affiliation">Tampere University of Technology</span>, <br />
<span class="author">Minna  W&#228;ljas</span> <span class="affiliation">Tampere University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The Web contains a vast amount of services supporting users in various facets of life. In mashup or composite Web services, elements from various services are combined to create a service which suits users&#8217; needs. Our goal was to explore what kind of composite services users would need. We conducted semi-structured interviews with nine Web service users to investigate their experiences of service composition and expectations to future services. We also asked the participants to sketch their ideal composite service UI for both PC and mobile device. Our results indicate that service users do not yet have much experience of mashups but there is a need to merge functionality and data from different services to achieve the customized, integrated Web service. This work contributes to the development of future Web services and mashup tools.</span></div></div><div class="paper" id="wp254"><a href="#wp254" class="title">Five Strategies for Supporting Healthy Behavior Change</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979770&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yevgeniy  Medynskiy</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Svetlana  Yarosh</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Elizabeth  Mynatt</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There is an ongoing search for theoretical foundations and design principles for interactive systems that support healthy behavior change. In this work-in-progress, we present several behavior change strategies that are currently used in effective health self-management interventions. We then discuss how these strategies can be used in applications that support behavior change in the health/wellness domain.</span></div></div><div class="paper" id="wp264"><a href="#wp264" class="title">Interaction and Rendering Techniques for Handheld Phantograms</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979771&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Finn  Ericsson</span> <span class="affiliation">KTH</span>, <br />
<span class="author">Alex  Olwal</span> <span class="affiliation">KTH</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a number of rendering and interaction techniques that exploit the user's viewpoint for improved realism and immersion in 3D applications on handheld devices. <br />  <br /> Unlike 3D graphics on stationary screens, graphics on handheld devices are seldom regarded from a fixed perspective. This is particularly true for recent mobile platforms, where it is increasingly popular to use device orientation for interaction. We describe a set of techniques for improved perception of rendered 3D content. View-point correct anamorphosis and stereoscopy are discussed along with ways to approximate the spatial relationship between the user and the device. <br />  <br /> We present the design and implementation of a prototype phantogram viewer that was used to explore these methods for interaction with real-time photorealistic 3D models on commercially available mobile devices.</span></div></div><div class="paper" id="wp271"><a href="#wp271" class="title">Puchi Planet : A Tangible Interface Design for Hospitalized Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979772&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shinsuke  Akabane</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Johnson  Leu</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Hiromi  Iwadate</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Jae Won  Choi</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Chin Ching  Chang</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Saori  Nakayama</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Madoka  Terasaki</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Hala  Eldemellawy</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Masa  Inakage</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Susumu  Furukawa</span> <span class="affiliation">Keio University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes the concept, design and prototype of a tangible user interface (TUI) based toy set for the purpose to bring fun into the lives of hospitalized children. The objective is to encourage children to interact with others and satisfy their curiosity of the outside world. This prototype takes the form of a play set that provides the experience of taking a jet tour and seeing different scenes around the world.</span></div></div><div class="paper" id="wp278"><a href="#wp278" class="title">CapWidgets: Tangile Widgets versus Multi-Touch Controls on Mobile Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979773&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sven  Kratz</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Tilo  Westermann</span> <span class="affiliation">Deutsche Telekom Laboratories, TU Berlin</span>, <br />
<span class="author">Michael  Rohs</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Georg  Essl</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present CapWidgets, passive tangible controls for capacitive touch screens. CapWidgets bring back physical controls to off-the-shelf multi-touch surfaces as found in mobile phones and tablet computers. While the user touches the widget, the surface detects the capacitive marker on the widget&#8217;s underside. We study the relative performance of this tangible interaction with direct multi-touch interaction and our experimental results show that user performance and preferences are not automatically in favor of tangible widgets and careful design is necessary to validate their properties.</span></div></div><div class="paper" id="wp281"><a href="#wp281" class="title">Me Hates This: Exploring Different Levels of User Feedback for (Usability) Bug Reporting</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979774&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Florian  Heller</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Leonhard  Lichtschlag</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Moritz  Wittenhagen</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Thorsten  Karrer</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">User feedback for deployed software systems ranges from simple one-bit-feedback to full-blown bug reports. While detailed bug reports are very helpful for the developers to track down problems, the expertise and commitment required from the user is high. We analyzed existing user report systems and propose a flexible and independent hard- and software architecture to collect user feedback. We report our results from a preliminary two-week user study testing the system in the field and discuss challenges and solutions for the collection of multiple levels of user feedback through different modalities.</span></div></div><div class="paper" id="wp283"><a href="#wp283" class="title">TOK &#8211; a Tangible Interface for Storytelling</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979775&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cristina  Sylla</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Pedro  Branco</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Clara  Coutinho</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Eduarda  Coquet</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">David  &#352;karoupka</span> <span class="affiliation">Brno University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the design of the first prototype of TOK - a tangible interface for children to create their own stories. Based on data collected with two groups of five years old preschoolers we present our findings regarding the interaction design of the system. The picture cards have shown to generate ideas, acting as input for the creation of stories, promoting creativity while proposing a framework that supports and guides the construction of logical structures. This is a first step in an effort to build a toolkit of tangible interfaces allowing children and teachers to build their own digital enhanced learning activities.</span></div></div><div class="paper" id="wp289"><a href="#wp289" class="title">Collision Avoidance in Virtual Environments through Aural Spacial Awareness</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979776&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christian  Afonso</span> <span class="affiliation">University of Hamburg</span>, <br />
<span class="author">Steffi  Beckhaus</span> <span class="affiliation">University of Hamburg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe a new technique to make users aurally aware of walls surrounding them in a Virtual Environment (VE). This Collision Avoidance (CA) technique improves upon familiar Collision Notification (CN) feedback by constantly informing the user of his proximity to his surroundings through the playback of directional sounds. To render the aural CA feedback we use spatial sound played over surround loudspeakers, in addition to haptic feedback from a vibrating sound floor to signify collisions.</span></div></div><div class="paper" id="wp290"><a href="#wp290" class="title">Evaluating the Embodiment Benefits of a Paper-Based TUI for Educational Simulations</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979777&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tia  Shelley</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Leilah  Lyons</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Moira  Zellner</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Emily  Minor</span> <span class="affiliation">University of Illinois at Chicago</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many claims have been made regarding the potential benefits of Tangible User Interfaces (TUIs). Presented here is an experiment assessing the usability, problem solving, and collaboration benefits of a TUI for direct placement tasks in spatially-explicit simulations for environmental science education. To create a low-cost deployment for single-computer classrooms, the TUI uses a webcam and computer vision to recognize the placement of paper symbols on a map. An authentic green infrastructure urban planning problem was used as the task for a within-subjects with rotation experiment with 20 pairs of participants. Because no prior experimental study has isolated the influence of the embodied nature of the TUI on usability, problem solving, and collaboration, a control condition was designed to highlight the impact of embodiment. While this study did not establish the usability benefits suggested by prior research, certain problem solving and collaboration advantages were measured.</span></div></div><div class="paper" id="wp295"><a href="#wp295" class="title">The Life Frame: Responding to the Elderly People's Need of Remembering</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979778&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sabina  Giorgi</span> <span class="affiliation">Sapienza University of Rome</span>, <br />
<span class="author">Alessandra  Talamo</span> <span class="affiliation">Sapienza university of Rome</span>, <br />
<span class="author">Barbara  Mellini</span> <span class="affiliation">Sapienza University of Rome</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The paper describes the research project &#8220;The Life frame&#8221; which aims to investigate the added value of digitizing memories for elderly people. It reports the ethnographic research undertaken in order to develop a framework including both devices and services. Data were gathered on the use of mementos in the homes of 241 elderly people and on the technologies that they used, the purpose being to identify the different psychological functions that mementos perform in the homes of this specific target group and to understand the potential use of digital technologies. In the paper we discuss our findings and initial insights for the design of the Life Frame, a device integrated with services for enhancing elderly people&#8217;s personal memories.</span></div></div><div class="paper" id="wp300"><a href="#wp300" class="title">Framework for Measuring Social Affinity for CSCW Software</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979779&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael A Oren</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Stephen B Gilbert</span> <span class="affiliation">Iowa State Universtiy</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Using surveys as a means for assessing group common ground has the possibility of social desirability bias where the results may suggest a higher team affinity rating than may actually exist. To evaluate efforts to improve affinity within interdisciplinary design teams, we developed an empirical measurement of affinity based on behavior and conversation in order to compare affinity differences between workgroups more precisely. This methodology can be used for remote or co-located teams and offers HCI researchers a more powerful method of evaluating group affinity.</span></div></div><div class="paper" id="wp301"><a href="#wp301" class="title">Move-It: Interactive Sticky Notes Actuated by Shape Memory Alloys</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979780&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kathrin  Probst</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Thomas  Seifried</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Michael  Haller</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Kentaro  Yasu</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Maki  Sugimoto</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Masahiko  Inami</span> <span class="affiliation">Keio University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A lot of people still rely on pen and paper for taking short notes. Post-Its&#174; are still the most popular paper media for informal note taking. In this paper, we present the design and implementation of Move-It, a system that combines the affordances of note taking on paper with the capabilities of computer systems. Furthermore, we present how common Post-It&#174; notes can be actuated by shape memory alloys, thus become interactive sticky notes giving active physical feedback.</span></div></div><div class="paper" id="wp302"><a href="#wp302" class="title">Child-robot Interaction: Playing Alone or Together?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979781&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Suleman  Shahid</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span>, <br />
<span class="author">Emiel  Krahmer</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span>, <br />
<span class="author">Marc  Swerts</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we propose a new method to evaluate child-robot interaction, by asking whether playing a game with a state-of-the-art social robot is more similar to playing this game alone or with a friend. Subjective fun scores suggest that children have more fun playing with the robot than playing alone, but have more fun still when playing with a friend. A perception test of selected fragments indicates that children are more expressive when playing with the robot than they are when playing alone, but less expressive than when playing with a friend. Taken together these results show that playing a game together with a state-of-the-art social robot is more fun than playing alone, and approaches playing with a friend, although more work needs to be done to achieve the latter level.</span></div></div><div class="paper" id="wp307"><a href="#wp307" class="title">Topicality, Time, and Sentiment in Online News Comments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979782&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicholas  Diakopoulos</span> <span class="affiliation">Rutgers University</span>, <br />
<span class="author">Mor  Naaman</span> <span class="affiliation">Rutgers University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we examine the relationships between news comment topicality, temporality, sentiment, and quality in a dataset of 54,540 news comments. Initial observations indicate that comment sentiments, both positive and negative, can be useful indicators of discourse quality, and that aggregate temporal patterns in positive sentiment exist on comment threads.</span></div></div><div class="paper" id="wp308"><a href="#wp308" class="title">Children&#8217;s Drawing and Telling of Sustainability in the Home</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979783&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Audrey  Desjardins</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes a pilot study about children&#8217;s perspective on environmental sustainability in the home through the drawing-telling technique. We utilize the drawing-telling technique as described by Susan Wright [6] for interviewing children about issues related to sustainability. The participants (children from age 10 to 13) were asked to draw two houses (current and ideal) and then describe their drawings in terms of sustainable actions and features. This pilot study is an initial step to investigate if there are opportunities to develop eco-visualizations (EVs) with children in mind and shows that the drawing-telling technique is useful in researching sustainability and children.</span></div></div><div class="paper" id="wp310"><a href="#wp310" class="title">MusEEGk: A Brain Computer Musical Interface</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979784&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yee Chieh (Denise)  Chew</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Eric  Caspary</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a novel integration of a brain-computer interface (BCI) with a music step sequencer composition program. Previous BCIs that utilize EEG data to form music provide users little control over the final composition or do not provide enough feedback. Our interface allows a user to create and modify a melody in real time and provides continuous aural and visual feedback to the user, thus affording them a controllable means to achieve creative expression.</span></div></div><div class="paper" id="wp313"><a href="#wp313" class="title">TableCross: Exuding a Shared Space into Personal Spaces to Encourage Its Voluntary Maintenance</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979785&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kazushi  Nishimoto</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Akari  Ikenoue</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Koji  Shimizu</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Tomonori  Tajima</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Yuta  Tanaka</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Yutaka  Baba</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Xihong  Wang</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A shared space should be cooperatively maintained by all users. However, due to social loafing, often nobody maintains it and its condition worsens. We propose exudation of a shared space. Part of a shared space is exuded into personal workspaces so that office workers are forced to subjectively experience the atmosphere of the shared space, even while they remain at their personal workspaces. This paper illustrates the first prototype named &#8220;TableCross,&#8221; which reflects the degree of disorder of a table in a shared space to the desktop of each worker&#8217;s PC. We also report some results of our pilot user study.</span></div></div><div class="paper" id="wp318"><a href="#wp318" class="title">Interactivity Sketcher: Crafting and Experiencing Interactivity Qualities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979786&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jong-bum  Woo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Da-jung  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Suin  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Jaesung  Jo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we introduce the Interactivity Sketcher, which is an interactivity designing tool that can visualize and experience invisible interactivity in a tangible way by controlling Interactivity Attributes(IAs). The Interactivity Sketcher is composed of the IA application, input devices, output devices, and IA controllers. The Interactivity Sketcher can help to explore various qualities of interactivity by visualizing and manipulating the relationship between an input and an output through the IA controllers and the IA application. We expect that this tool will enable interaction designers to visualize their own thoughts of interactivity qualities so that they will be able to create their design as if they had &#8216;sketched&#8217; it.</span></div></div><div class="paper" id="wp323"><a href="#wp323" class="title">Predictive Error Behavior Model of On-screen Keyboard Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979787&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Siddharth  Jain</span> <span class="affiliation">IIT Guwahati</span>, <br />
<span class="author">Samit  Bhattacharya</span> <span class="affiliation">IIT Guwahati</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">On-screen keyboards are becoming ubiquitous with increasing use in mobile devices and touch-screens. In this work, we present a novel predictive error model which relates accuracy of an on-screen keyboard user to a given layout using the distance between keys. The model is developed from empirical data with the aim to predict the error rate of a user from the layout specification alone. Our proposed model can be combined with the existing quantitative design approaches for designing keyboards having high text-entry speed and accuracy.</span></div></div><div class="paper" id="wp338"><a href="#wp338" class="title">Weak Inter-Rater Reliability In Heuristic Evaluation Of Video Games</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979788&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gareth R White</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Pejman  Mirza-babaei</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Graham  McAllister</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Judith  Good</span> <span class="affiliation">The University of Sussex</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Heuristic evaluation promises to be a low-cost usability evaluation method, but is fraught with problems of subjective interpretation, and a proliferation of competing and contradictory heuristic lists. This is particularly true in the field of games research where no rigorous comparative validation has yet been published. In order to validate the available heuristics, a user test of a commercial game is conducted with 6 participants in which 88 issues are identified, against which 146 heuristics are rated for relevance by 3 evaluators. Weak inter-rater reliability is calculated with Krippendorff's Alpha of 0.343, refuting validation of any of the available heuristics. This weak reliability is due to the high complexity of video games, resulting in evaluators interpreting different reasonable causes and solutions for the issues, and hence the wide variance in their ratings of the heuristics.</span></div></div><div class="paper" id="wp339"><a href="#wp339" class="title">guitAR &#8211; Supporting Guitar Learning through Mobile Projection</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979789&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Markus  L&#246;chtefeld</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Sven  Gehring</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Ralf  Jung</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Antonio  Kr&#252;ger</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The guitar is one of the most widespread instruments amongst autodidacts, but even though a huge amount of learning material exists, it is still hard to learn especially without a guitar teacher. In this paper we propose an Augmented Reality application called guitAR that assists guitar students mastering their instrument using a projector phone. With the projector phone mounted at the headstock of the guitar, the fret board and the strings of the guitar are in the field of projection of the phone. By projecting instructions directly onto the strings of the guitar the user is easily able to realize where the fingers have to be placed on the fretboard (fingering) to play a certain chord or a tone sequence correctly.</span></div></div><div class="paper" id="wp343"><a href="#wp343" class="title">Emotion Faces: the Design and Evaluation of a Game for Preschool Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979790&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lynne  Humphries</span> <span class="affiliation">University of Sunderland</span>, <br />
<span class="author">Sharon  McDonald</span> <span class="affiliation">University of Sunderland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the design and initial evaluation of an interactive game that enables preschool children to practise a basic social skill: emotion recognition.  Users construct faces to represent 5 basic emotions through the manipulation of individual face parts.  An iterative user-centred design process was used to gather image and sound data for the game.  A field evaluation revealed that the children (7 boys and 4 girls) enjoyed playing the game and were able to match facial expression to emotions. Girls employed a different approach to game play than boys and achieved a higher success rate but made fewer overall attempts.  Affective and co-operative activity was evident with the children showing joint attention and mirroring of emotions during play.</span></div></div><div class="paper" id="wp345"><a href="#wp345" class="title">Exploring Trust in Group-to-Group Video-Conferencing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979791&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Petr  Slov&#225;k</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Peter  Nov&#225;k</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Pavel  Troubil</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Petr  Holub</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Erik C. Hofer</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous work has shown that supporting trust via computer-mediated communication can be a challenge, especially among strangers. In this paper, we report on an experiment comparing two group-to-group video-conferencing environments and face-to-face communication in their ability to support trust and mutual cooperation in a social dilemma task. There are pronounced differences in participant behaviour between the two video-conferencing designs, indicating higher mutual trust in one of the video-conferencing conditions. The decisive factor seems to be a discrepancy in the type of group identity that develops during the game. Moreover, our results suggest that a combination of personal displays and a unique video-stream of each participant present in the better video-conferencing condition contributed to this result.</span></div></div><div class="paper" id="wp349"><a href="#wp349" class="title">From dance to touch : movement qualities for interaction design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979792&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sarah  Fdili Alaoui</span> <span class="affiliation">LIMSI-CNRS and IRCAM-CNRS</span>, <br />
<span class="author">Baptiste  Caramiaux</span> <span class="affiliation">IRCAM-CNRS</span>, <br />
<span class="author">Marcos  Serrano</span> <span class="affiliation">ENSADLab/Drii</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we address the question of extending user experience in large scale tactile displays. Our contribution is a non task-oriented interaction technique based on modern dance for the creation of aesthetically pleasant large scale tactile interfaces. This approach is based on dance movement qualities applied to touch interaction allowing for natural gestures in large touch displays. We used specific movements from a choreographic glossary and developed a robust movement quality recognition process. To illustrate our approach, we propose a media installation called A light touch, where touch is used to control a light spot reacting to movement qualities.</span></div></div><div class="paper" id="wp350"><a href="#wp350" class="title">The Diversity Donut: Enabling Participant Control Over the Diversity of Recommended Responses</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979793&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Wong</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Siamak  Faridani</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Ephrat  Bitton</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Ken  Goldberg</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Most online discussion interfaces organize textual responses using linear lists.  Such lists do not scale to the number of responses and cannot convey the diversity of the participants who have contributed. The Opinion Space system is designed to address these issues. In this paper, we augment Opinion Space with two features. The first is a new user interface tool and recommendation system: the Diversity Donut (Figure 1). While the Diversity Donut did not establish a statistical advantage over other recommendation methods, participant self-reported data suggested that participants found the Diversity Donut to yield the most diverse set of comments. The second contribution is a new dimensionality reduction technique in Opinion Space: Canonical Correlation Analysis (CCA). Our analysis suggests that CCA is a better algorithm for opinion visualization than Principal Component Analysis (PCA).</span></div></div><div class="paper" id="wp351"><a href="#wp351" class="title">Beyond Pointing and Clicking: How do Newer Interaction Modalities Affect User Engagement?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979794&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S. Shyam  Sundar</span> <span class="affiliation">Penn State University, Sungkyunkwan University</span>, <br />
<span class="author">Qian  Xu</span> <span class="affiliation">Elon University</span>, <br />
<span class="author">Saraswathi  Bellur</span> <span class="affiliation">Penn State University</span>, <br />
<span class="author">Jeeyun  Oh</span> <span class="affiliation">Penn State University</span>, <br />
<span class="author">Haiyan  Jia</span> <span class="affiliation">Penn State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Modern interfaces offer users a wider range of interaction modalities beyond pointing and clicking, such as dragging, sliding, zooming, and flipping through images. But, do they offer any distinct psychological advantages? We address this question with an experiment (N = 128) testing the relative contributions made by six interaction modalities (zoom-in/out, drag, slide, mouse-over, cover-flow and click-to-download) to user engagement with identical content. Data suggest that slide is better at aiding memory than the other modalities, whereas cover-flow and mouse-over generate more user actions. Mouse-over, click-to-download, and zoom-in/out tend to foster more favorable attitudes among power users, whereas cover-flow and slide generate more positive attitudes among non-power users. Design implications are discussed.</span></div></div><div class="paper" id="wp352"><a href="#wp352" class="title">BiCEP: Bimanual Color Exploration Plugin</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979795&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Berto  Gonzalez</span> <span class="affiliation">UNC Charlotte</span>, <br />
<span class="author">Celine  Latulipe</span> <span class="affiliation">UNC Charlotte</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe a bimanual color exploration plugin (BiCEP) that allows a user to choose colors along three dimensions: hue, saturation, and brightness without mode switching between these dimensions. The plugin differs from other color selection tools by allowing users to simultaneously change all three dimensions utilizing a laptop trackpad with multi-touch tracking capabilities. We believe this methodology will improve the range of color exploration by allowing users to more easily explore a wider range of colors.</span></div></div><div class="paper" id="wp661"><a href="#wp661" class="title">MultiPress: Releasing Keys for MultiTap Segmentation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979796&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seunghwan  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Jaehyun  Han</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Geehyuk  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While MultiTap is one of the most popular text entry methods for mobile phones, it has a fundamental weakness known as MultiTap segmentation problem. Based on the observation that the thumb does not leave the keys between tapping actions, we designed a MultiTap segmentation method where the release action of the thumb is used to indicate input completion. A user study using a touch-sensing keypad prototype to explore the feasibility of the idea and a comparison test to access its benefit revealed promising results supporting the effectiveness of the proposed segmentation method.</span></div></div><div class="paper" id="wp670"><a href="#wp670" class="title">Arrange-A-Space: Tabletop Interfaces and Gender Collaboration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979797&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Richert</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Ammar  Halabi</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Anna  Eaglin</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Matthew  Edwards</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Collaborative technologies, such as shared tabletop interfaces, are becoming increasingly pervasive. Meanwhile, social dynamics have long been a major area of inquiry in HCI and CSCW. With a few notable exceptions, little has been done that addresses the roles gender identities play in shaping collaborative work. In this paper, we make the case for a deeper consideration of gender in our field through a study that investigates issues surrounding gendered collaboration around a tabletop interface. We report our findings and conclude with recommendations for future work in this area.</span></div></div><div class="paper" id="wp680"><a href="#wp680" class="title">Informed Consent and Users' Attitudes to Logging in Large Scale Trials</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979798&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alistair  Morrison</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Owain  Brown</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Donald  McMillan</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Matthew  Chalmers</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The HCI community has begun to use &#8216;app store&#8217;-style software repositories as a distribution channel for research applications. A number of ethical challenges present themselves in this setting, not least that of gaining informed consent from potential participants before logging data on their use of the software. We note that standard &#8216;terms and conditions&#8217; pages have proved unsuccessful in communicating relevant information to users, and explore further means of conveying researchers&#8217; intent and allowing opt-out mechanisms. We test the hypothesis that revealing collected information to users will affect their level of concern at being recorded and find that users are more concerned when presented with a personalised representation of recorded data, and consequently stop using the application sooner. Also described is a means of allowing between-groups experiments in such mass participation trials.</span></div></div><div class="paper" id="wp689"><a href="#wp689" class="title">Gathering Text Entry Metrics on Android Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979799&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Steven J. Castellucci</span> <span class="affiliation">York University</span>, <br />
<span class="author">I. Scott MacKenzie</span> <span class="affiliation">York University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We developed an application to gather text entry speed and accuracy metrics on Android devices. This paper details the features of the application and describes a pilot study to demonstrate its utility. We evaluated and compared three mobile text entry methods: QWERTY typing, handwriting recognition, and shape writing recognition. Handwriting was the slowest and least accurate technique. QWERTY was faster than shape writing, but we found no significant difference in accuracy between the two techniques.</span></div></div><div class="paper" id="wp695"><a href="#wp695" class="title">Mobile Phones and Information Capture in the Workplace</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979800&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amrita  Thakur</span> <span class="affiliation">Ricoh Innovations, Inc.  Stanford University</span>, <br />
<span class="author">Michael  Gormish</span> <span class="affiliation">Ricoh Innovations, Inc.</span>, <br />
<span class="author">Berna  Erol</span> <span class="affiliation">Ricoh Innovations, Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Smartphones (mobile phones with downloadable applications) are being used for far more than making calls and reading email. We investigated the use of phones for information capture for work purposes through interviews, multiple free response surveys, and two multiple choice surveys. While we expected and found taking pictures to be useful for work, we were surprised at the extent of audio, video, and note taking done on the phone, and the impact on other devices. Our work also suggests future mobile information capture for work will increase more due to cultural changes than technological improvements.</span></div></div><div class="paper" id="wp696"><a href="#wp696" class="title">Phone-Based Motion Control in VR - Analysis of degrees of freedom</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979801&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amal  Benzina</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Marcus  Toennis</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Gudrun  Klinker</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Ashry  Mohamed</span> <span class="affiliation">The German University in Cairo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce a one-handed travel technique for virtual environments (VE), we call Phone-Based Motion Control. The travel technique uses a mobile phone with integrated sensors as a 3D spatial input device. We benefit from the touch capability to change the viewpoint translation in the VE, while the orientation of the viewpoint in the VE is controlled by the built-in sensors. The travel interaction clearly distinguishes between translation (touch based translation control) and rotation (steer based rotation control), putting each set of degrees of freedom to a separate interaction technique. <br /> This work examines how many degrees of freedom are needed to perform the travel task as easy as possible. It also investigates different mapping functions between the user's actions and the viewpoint reactions in the VR. For that purpose, four metaphors are developed for the steer based rotation control technique. The results of the user study indicate the trend that 4 DOF metaphors perform best, and that the usage of a mobile roll to control the viewpoint is the desired mapping. <br /></span></div></div><div class="paper" id="wp700"><a href="#wp700" class="title">Crowdsourcing Suggestions to Programming Problems for Dynamic Web Development Languages</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979802&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dhawal  Mujumdar</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Manuel  Kallenbach</span> <span class="affiliation">RWTH Aachen</span>, <br />
<span class="author">Brandon  Liu</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Developers increasingly consult online examples and message boards to find solutions to common programming tasks. On the web, finding solutions to debugging problems is harder than searching for working code. Prior research introduced a social recommender system, HelpMeOut, that crowdsources debugging suggestions by presenting fixes to errors that peers have applied in the past. However, HelpMeOut only worked for statically typed, compiled programming languages like Java. We investigate how suggestions can be provided for dynamic, interpreted web development languages. Our primary insight is to instrument test-driven development to collect examples of bug fixes. We present Crowd::Debug, a tool for Ruby programmers that realizes these benefits.</span></div></div><div class="paper" id="wp701"><a href="#wp701" class="title">Video Summarization via Crowdsourcing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979803&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shao-Yu  Wu</span> <span class="affiliation">Academia Sinica</span>, <br />
<span class="author">Ruck  Thawonmas</span> <span class="affiliation">Ritsumeikan University</span>, <br />
<span class="author">Kuan-Ta  Chen</span> <span class="affiliation">Academia Sinica</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although video summarization has been studied extensively, existing schemes are neither lightweight nor generalizable to all types of video content. To generate accurate abstractions of all types of video, we propose a framework called Click2SMRY, which leverages the wisdom of the crowd to generate video summaries with a low workload for workers. The framework is lightweight because workers only need to click a dedicated key when they feel that the video being played is reaching a highlight. One unique feature of the framework is that it can generate different abstraction levels of video summaries according to viewers&#8217; preferences in real time. The results of experiments conducted to evaluate the framework demonstrate that it can generate satisfactory summaries for different types of video clips.</span></div></div><div class="paper" id="wp702"><a href="#wp702" class="title">&#8220;I Don&#8217;t Like Crumbs on My Keyboard&#8221;: Eating Behaviors of World of Warcraft Players</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979804&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Natalie  DeWitt</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">David  Lohrmann</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computer gamers are often categorized as being unhealthy due to lack of physical activity and poor eating habits. This mixed methods study revealed that computer gamers, specifically World of Warcraft players, are highly conscious of their food choices and eating decisions either because they value their health or because certain foods impede game play. In order to facilitate healthy behaviors in the game, researchers must consider the reasons why gamers choose certain foods to consume during game play.</span></div></div><div class="paper" id="wp704"><a href="#wp704" class="title">Investigating Phicon Feedback in Non-Visual Tangible User Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979805&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  McGookin</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We investigated ways that users could interact with Phicons in non-visual tabletop tangible user interfaces (TUIs). We carried out a brainstorming and rapid prototyping session with a blind usability expert, using two different non-visual TUI scenarios to quickly explore the design space. From this, we derived a basic set of guidelines and interactions that are common in both scenarios, and which we believe are common in most non-visual tabletop TUI applications.  Future work is focused on validating our findings in a fully functioning system.</span></div></div><div class="paper" id="wp705"><a href="#wp705" class="title">VisualWikiCurator: A Corporate Wiki Plugin</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979806&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicholas  Kong</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Gregorio  Convertino</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Benjamin  Hanrahan</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Ed  Chi</span> <span class="affiliation">Palo Alto Research Center (PARC)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Knowledge workers who maintain corporate wikis face high costs for organizing and updating content on wikis. This problem leads to low adoption rates and compromises the utility of such tools in organizations. We describe a system that seeks to reduce the interactions costs of updating and organizing wiki pages by combining human and machine intelligence. We then present preliminary results of an ongoing evaluation of the tool.</span></div></div><div class="paper" id="wp706"><a href="#wp706" class="title">Descriptive Analysis of Physical Activity Conversations on Twitter</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979807&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Logan  Kendall</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Andrea  Hartzler</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Predrag  Klasnja</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Wanda  Pratt</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores how people are using Twitter.com to manage and share information about health-promoting physical activity. We analyzed archived posts, called &#8220;tweets&#8221;, from Twitter.com to learn about the range, patterns, and captured metadata associated with muscle-strengthening, aerobic, and flexibility-enhancing physical activities. The content analysis describes how people are using Twitter to post about their health-related fitness activities. These findings can support the design of supportive tools and applications connected with the social media platform.</span></div></div><div class="paper" id="wp711"><a href="#wp711" class="title">Social Yoga Mats: Reinforcing Synergy between Physical and Social Activity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979808&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karl  Maybach</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Arun  Nagargoje</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Tomas  Sokoler</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper discusses our early research into the design space for digital technologies that extend the existing synergistic relationship between physical and social activity from fitness centers to the home. We focus on yoga activity for senior citizens and explore the concept of social yoga mats, which spread awareness of individuals&#8217; exercise activities within a peer group. We describe the concept, hardware sketches, exploratory co-design process and discuss our findings and early reflections into this design space. <br /></span></div></div><div class="paper" id="wp713"><a href="#wp713" class="title">Understanding and Designing Cool Technologies for Teenagers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979809&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janet  Read</span> <span class="affiliation">University of Central Lancashire</span>, <br />
<span class="author">Daniel  Fitton</span> <span class="affiliation">University of Central Lancashire</span>, <br />
<span class="author">Benjamin  Cowan</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Russell  Beale</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Yukang  Guo</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Matthew  Horton</span> <span class="affiliation">University of Central Lancashire</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes how initial principles for the designs of an interactive application were informed from a study of &#8216;coolness&#8217; with two different ages of teenagers.  The study used drawings to examine how teenagers might design their environments and these were then analysed by the research team based on a set of characteristics of cool that were drawn from the literature. Results from the teenagers&#8217; drawings demonstrate some change in emphasis between the younger and older age groups and between the genders.  A design space around innovation and rebellion is implicated in the findings.</span></div></div><div class="paper" id="wp717"><a href="#wp717" class="title">Automatically adapting web pages to heterogeneous devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979810&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chinmay Eishan Kulkarni</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott R Klemmer</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Smartphones and other handheld devices have become popular and powerful Internet access devices, yet the Web is still largely optimized for the desktop. We describe a system that automatically transforms desktop-optimized pages to ones better suited to the target device. The system leverages existing platform-customized sites as examples of good design, identifies consistent components across these sites, and renders the desktop page into these components.</span></div></div><div class="paper" id="wp721"><a href="#wp721" class="title">Leveraging Trust Relationships in Digital Backchannel Communications</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979811&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Syavash  Nobarany</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mona  Haraty</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney S Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Brian D Fisher</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Discussions during lecture can clarify lecture points for audience members and help them deepen their understanding. However, the fast-pace of lectures and the large number of attendees can make these discussions impossible. Although digital backchannels have been used to address this problem, they present some drawbacks such as increasing distractions and not providing valuable information. We suggest incorporating audience members&#8217; levels of trust in the knowledge of other members into the design of backchannel communication systems. Based on this approach, we present methods and design considerations to overcome the aforementioned drawbacks of the previous backchannel communication systems.</span></div></div><div class="paper" id="wp724"><a href="#wp724" class="title">Promoting A Physical Security Mental Model For Personal Firewall Warnings</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979812&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Fahimeh  Raja</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Steven  Hsu</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kai-Le  Wang</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We used an iterative process to design personal firewall warnings in which the functionality of a firewall is visualized based on a physical security mental model. We performed a study to determine the degree to which our proposed warnings are understandable for our participants, and the degree to which they convey the risks and encourage safe behavior as compared to warnings based on those from a popular personal firewall. Initial results show that our warnings facilitate the comprehension of warning information, better communicate risk, and increase the likelihood of safe behavior. Moreover, they provided participants with a better understanding of both the functionality of a personal firewall and the consequences of their actions.</span></div></div><div class="paper" id="wp725"><a href="#wp725" class="title">The Role of Commitment Devices and Self-shaping in Persuasive Technology</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979813&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Neema  Moraveji</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Ryo  Akasaka</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Roy  Pea</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">B.J.  Fogg</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We examine the role of self-shaping and commitment devices in persuasive systems. Self-shaping refers to the practice of taking purposeful action in modifying one&#8217;s environment in order to shape or influence one&#8217;s own future behavior. We present results from a survey of 23 users that assessed the role self-shaping plays in their use of persuasive technologies. A second survey elicited 65 self-shaping designs from 41 expert users, finding the Fogg Behavior Model describes how the designs were indeed persuasive. We then reviewed 85 tools based on this model to show the two dimensions that can be used to organize persuasive devices: (1) salience of a tool&#8217;s self-shaping features and (2) their intended flexibility. The resulting four categories of tools are useful for researchers and designers of persuasive systems.</span></div></div><div class="paper" id="wp726"><a href="#wp726" class="title">Trust-aware Privacy Control for Social Media</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979814&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Na  Li</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span>, <br />
<span class="author">Maryam  Najafian Razavi</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span>, <br />
<span class="author">Denis  Gillet</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Due to the huge exposure of personal information in social media, a challenge now is to design effective privacy mechanisms that protect against unauthorized access to social data. In this paper, a trust model for social media is first presented. Based on the trust model, a trust-aware privacy control protocol is proposed, that exploits the underlying inter-entity trust information. The objective is to design a fine-grained privacy scheme that ensures a user&#8217;s online information is disclosed only to sufficiently trustworthy parties.</span></div></div><div class="paper" id="wp727"><a href="#wp727" class="title">Four Factors of Change &#8211; Adaptations of Everyday Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979815&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Leah  Maestri</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper is a follow up study of a 2005-2006 study of everyday design. This follow-up study is an opportunity to gain insights into the social evolution of everyday design systems in the home. We report on changes to five systems and discuss how these changes occurred over the last four to five years. We identify four factors related to the changes 1) shared intent 2) mutual intelligibility, 3) materiality-substitutability, and 4) fit.</span></div></div><div class="paper" id="wp730"><a href="#wp730" class="title">Designing Flexible EMR Systems for Recording and Summarizing Doctor-Patient Interactions</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979816&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyle  Larkin</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Aisling  Kelliher</span> <span class="affiliation">Arizona State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Electronic Medical Records (EMR) are increasingly transitioning from desktop systems to mobile devices. This innovation presents challenges to medical practitioners in terms of doctor-patient interaction, patient record integrity and continuing reliance on paper-based annotation schemas. We describe findings from a pilot study of EMR use by physicians in a family medical clinic and propose guidelines for the design of mobile EMR systems. These guidelines seek to fuse the dynamic capabilities of digital systems with the immediacy and personal nature of paper-based records.</span></div></div><div class="paper" id="wp734"><a href="#wp734" class="title">intangibleCanvas: Free-Air Finger Painting on a Projected Canvas</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979817&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Nic  Lupfer</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Bill  Hamilton</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Haiqiao  Lin</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the advent of new sensing technologies, precision free-air interaction is becoming viable as a contender for the next generation of expressive, embodied interaction modalities. ZeroTouch, a novel multi-touch sensor that allows for free-air multi-finger, multi-object sensing, is one example of this next generation of free-air interfaces. We develop its use in a digitally-projected finger painting application, placing the see-through multitouch sensor in direct line-of-sight between an artist and a remote canvas. This allows the artist to reach through the sensor and paint on the intangibleCanvas as if it were directly in front of them. An iPad is employed as a multimodal workspace for color selection. We evaluate the system through an informal walk-up-and-play installation and comparative study, developing implications for interaction design using this type of precision free-air interface.  <br /></span></div></div><div class="paper" id="wp737"><a href="#wp737" class="title">Evaluating Software for Communities Using Social Affordances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979818&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ben  Hanrahan</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Sameer  Ahuja</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Manuel  Perez-Quinones</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Andrea  Kavanaugh</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we discuss the problems faced when building software for communities. In particular, we introduce the formative evaluation method that emerged while developing two social network sites (SNSs). We acknowledge that the success of software for communities is due, in part, to the network effect, which is difficult to predict. We also acknowl- edge that traditional usability (e.g., individual user perfor- mance) is required, but not sufficient, for the success of a social network. We hypothesize that a missing piece of cur- rent evaluations are the social affordances provided by the system and how well they encourage users into social action. In this paper we present the rationale behind our evaluation, two examples of the evaluation, and discuss the evaluation&#8217;s utility and future work.</span></div></div><div class="paper" id="wp738"><a href="#wp738" class="title">Pupillary Response Based Cognitive Workload Index under Luminance and Emotional Changes</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979819&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jie  Xu</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Yang  Wang</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Fang  Chen</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Ho  Choi</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Guanzhong  Li</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Siyuan  Chen</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Sazzad  Hussain</span> <span class="affiliation">National ICT Australia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pupillary response has been widely accepted as a physiological index of cognitive workload. It can be reliably measured with video-based eye trackers in a non-intrusive way. However, in practice commonly used measures such as pupil size or dilation might fail to evaluate cognitive workload due to various factors unrelated to workload, including luminance condition and emotional arousal. In this work, we investigate machine learning based feature extraction techniques that can both robustly index cognitive workload and adaptively handle changes of pupillary response caused by confounding factors unrelated to workload.</span></div></div><div class="paper" id="wp740"><a href="#wp740" class="title">Heuristics for Evaluating IT Security Management Tools</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979820&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pooya  Jaferian</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Andreas  Sotirakopoulos</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The usability of IT security management (ITSM) tools is hard to evaluate by regular methods, making heuristic evaluation attractive. However, ITSM occurs within a complex and collaborative context that involves diverse stakeholders; this makes standard usability heuristics difficult to apply. We propose a set of ITSM usability heuristics that are based on activity theory and supported by prior research. We performed a study to compare the use of the ITSM heuristics to Nielsen's heuristics for the evaluation of a commercial identity management system. Our preliminary results show that our new ITSM heuristics performed well in finding usability problems. However, we need to perform the study with more participants and perform more detailed analysis to precisely show the differences in applying the ITSM heuristics as compared to Nielsen&#8217;s heuristics.</span></div></div><div class="paper" id="wp742"><a href="#wp742" class="title">Who Needs Energy Management? Reducing Energy Consumption in Manufacturing Industries - Early Results of Research into Industrial Energy Management Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span><div class="authors"><span class="author">Daniela K.  Busse</span> <span class="affiliation">SAP Labs (Palo Alto)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this Work-in-Progress report, research into the potential target users for an Industrial Energy Management solution is being discussed with reference to both on-site and remote user interviews conducted in 2010 with Energy Managers of several US companies in high energy-intensity manufacturing industries.</span></div></div><div class="paper" id="wp743"><a href="#wp743" class="title">Supporting Visually Impaired Navigation:  A Needs-finding Study</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979822&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pablo-Alejandro  Quinones</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Tammy  Greene</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Rayoung  Yang</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Mark  Newman</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we investigate the requirements for designing systems to support wayfinding for visually impaired individuals. We report the results of an interview study with 20 individuals with visual impairments, asking about their way-finding tools, techniques, and obstacles. Our findings provide an account of the practices followed when navigating familiar, unfamiliar, and dynamic environments, and common breakdowns encountered during the wayfinding process. The findings from this study suggest ways of implementing a location-based system to assist in the recovery from various obstacles.</span></div></div><div class="paper" id="wp748"><a href="#wp748" class="title">Beyond Drunk Texting: Investigating Recorded Media Sharing at Parties</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979823&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gavin  Elster</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Lawrence  Gabriel</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Anton  Grobman</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We conducted field observations and interviews of college-aged users at parties to understand how they share recorded media. We collected 36 observations from seven private parties and conducted semi-structured follow-up interviews with six selected participants observed at the parties. Three different sharing themes emerged from our data which we term participatory, personal, and open sharing. The type of sharing used in a particular instance was strongly influenced by the context of the environment and the content of the media being shared.</span></div></div><div class="paper" id="wp750"><a href="#wp750" class="title">DARLS: Differencing and Merging Diagrams Using Dual View, Animation, Re-Layout, Layers and a Storyboard</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979824&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Loutfouz  Zaman</span> <span class="affiliation">York University</span>, <br />
<span class="author">Ashish  Kalra</span> <span class="affiliation">NIT Kurukshetra</span>, <br />
<span class="author">Wolfgang  Stuerzlinger</span> <span class="affiliation">York University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a new system for visualizing and merging differences in diagrams. It uses animation, dual views, a storyboard, relative re-layout, and layering to visualize differences. The system is also capable of differencing UML class diagrams. An evaluation produced positive results for animation and dual views with difference layer.</span></div></div><div class="paper" id="wp751"><a href="#wp751" class="title">Audience Visualization Influences Disclosures in Online Social Networks</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979825&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kelly  Caine</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Lorraine G. Kisselburgh</span> <span class="affiliation">Purdue University</span>, <br />
<span class="author">Louise  Lareau</span> <span class="affiliation">Purdue University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">One of the major concerns about online social networks (OSNs) is privacy. We introduce visualization and numeric audience information as potential interface solutions to the problem of privacy behaviors that are misaligned with privacy preferences. Findings from a large experiment with participants of all ages and from a broad range of backgrounds suggest that for both current and potential users, augmenting an interface with a visualization or numeric display of the audience helps people disclose in a way that is more in line with their own preferences. We conclude by proposing that audience visualization and quantification tools have the potential to assist users in achieving their privacy goals while using OSNs and have the potential to enhance privacy in other information systems as well.</span></div></div><div class="paper" id="wp754"><a href="#wp754" class="title">Shepherding the Crowd: Managing and Providing Feedback to Crowd Workers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979826&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Steven  Dow</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Anand  Kulkarni</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Brie  Bunge</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Truc  Nguyen</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott  Klemmer</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Micro-task platforms provide a marketplace for hiring people to do short-term work for small payments. Requesters often struggle to obtain high-quality results, especially on content-creation tasks, because work cannot be easily verified and workers can move to other tasks without consequence. Such platforms provide little opportunity for workers to reflect and improve their task performance. Timely and task-specific feedback can help crowd workers learn, persist, and produce better results. We analyze the design space for crowd feedback and introduce Shepherd, a prototype system for visualizing crowd work, providing feedback, and promoting workers into shepherding roles. This paper describes our current progress and our plans for system development and evaluation.</span></div></div><div class="paper" id="wp760"><a href="#wp760" class="title">Postcolonial Language and Culture Theory for HCI4D</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979827&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Samantha  Merritt</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As technology design spreads to less technologically developed countries, issues of cultural identity, language, and values manifest in the form of methodological and ethical challenges for HCI4D designers. We offer a new theoretical perspective, in the context of HCI4D design, to advance the HCI postcolonial critique and highlight fundamentally Western design practices. Application of Thiong&#8217;o&#8217;s language and culture theory provides a tool for designers and researchers to face assumptions, cultural communication, and the potential repercussions in cross-cultural design. Upon future development, this postcolonial orientation could be used to create responsible, successful designs and create awareness of inadvertent Western language culture embedded in HCI4D design.</span></div></div><div class="paper" id="wp762"><a href="#wp762" class="title">Better Brain Interfacing for the Masses: Progress in Event-Related Potential Detection using Commercial Brain Computer Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979828&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mick  Grierson</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Chris  Kiefer</span> <span class="affiliation">Goldsmiths, University of London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Event-Related Potential (ERP) techniques are commonly used by researchers from a range of disciplines including psychology and medicine to stimulate meaningful ERP signals from the brain and interpret them through Electroencephalography (EEG). ERP signals are in most cases able to reliably reflect cognitive processes, and are widely used in Brain Computer Interface (BCI) research. We present work in progress towards the application of these techniques to emerging consumer-grade BCI technology. Our approach has an impact on the reliability and usability of consumer Brain Computer Interfaces in commercial contexts, and is already being adopted by our industry partners in the games and entertainment sector. It could also significantly reduce the cost and complexity of certain types of large scale ERP research. This work is being undertaken by the Embodied AudioVisual Interaction (EAVI) group at Goldsmiths, University of London, and is supported by the Arts and Humanities Research Council.</span></div></div><div class="paper" id="wp770"><a href="#wp770" class="title">&#8220;Does It Know I&#8217;m Not Maintaining Good Posture?&#8221;: An In-Home Play Study of Wii Fit</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979829&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lindsay  Reynolds</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Steven  Ibara</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Victoria  Schwanda</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Dan  Cosley</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Persuasive technologies designed to improve the health and fitness of users are becoming increasingly popular. One example is Nintendo's Wii Fit, which has achieved commercial success. Despite this success, many people ultimately abandon this technology. Past work explored reasons for leaving, but retroactively. This study examines the reactions of first-time users of Wii Fit, through a one-time interview pilot study as well as an in-depth, month-long study in which participants used Wii Fit in their homes. We briefly present themes from the pilot study, as well as case studies from two month-long study participants, which shows how opinions and behaviors changed over time.</span></div></div><div class="paper" id="wp781"><a href="#wp781" class="title">The Role of Dynamic Digital Menu Boards in Consumer Decision Making</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979830&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anicia  Peters</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Brian  Mennecke</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Digital Signage has become a common-place feature in many public spaces and retail establishments; yet, only limited research has been reported to date on these technologies. For example, questions such as their effect on decision-making, cognitive load, and purchase behavior have yet to be examined. In an effort to attract more attention and increase effectiveness, venders of digital signage are rapidly enhancing features and capabilities for these displays. For example, displays are moving from simple 2d screens to 3d auto-stereoscopic screens, screens featuring multimodal forms of interaction are replacing static displays, and display-only screens are being replaced by displays capable of recognizing user characteristics. An important &#8220;new&#8221; type of display is the dynamic digital menu board, which combines digital signage with the power of video. Surprisingly, despite its increasingly common use in areas as diverse as education and retail, only limited academic research on digital signage has been conducted in areas such as marketing with little attention coming from the HCI field. Our research is focused on addressing this shortcoming by applying theories from HCI, marketing, and information systems to investigate the role of video and dynamic digital menu board display characteristics on consumer decision-making. We hypothesize that each consumer decision-making stage will be affected by the &#8220;vividness&#8221; of video in dynamic digital menu boards.</span></div></div><div class="paper" id="wp784"><a href="#wp784" class="title">CalmMeNow: Exploratory Research and Design of Stress Mitigating Mobile Interventions</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979831&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pablo  Paredes</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Matthew  Chan</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes design explorations for stress mitigation on mobile devices based on three types of interventions: haptic feedback, games and social networks. The paper offers a qualitative assessment of the usability of these three types of interventions together with an initial analysis of their potential efficacy. Social networking and games show great potential for stress relief. Lastly, the paper discusses key findings and considerations for long-term studies of stress mitigation in HCI, as well as a list of aspects to be considered when designing calming interventions.</span></div></div><div class="paper" id="wp787"><a href="#wp787" class="title">Using Gaze Patterns to Study and Predict Reading Struggles due to Distraction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979832&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vidhya  Navalpakkam</span> <span class="affiliation">Yahoo! Research</span>, <br />
<span class="author">Justin  Rao</span> <span class="affiliation">Yahoo! Research</span>, <br />
<span class="author">Malcolm  Slaney</span> <span class="affiliation">Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We analyze gaze patterns to study how users in online reading environments cope with visual distraction, and we report gaze markers that identify reading difficulties due to distraction. The amount of visual distraction is varied from none, medium to high by presenting irrelevant graphics beside the reading content in one of 3 conditions: no graphic, static or animated graphics. We find that under highly-distracting conditions, a struggling reader puts more effort into the text &#8212; she takes a longer time to comprehend the text, performs more fixations on the text and frequently revisits previously read content. Furthermore, she reports an unpleasant reading experience. Interestingly, we find that whether the user is distracted and struggles or not can be predicted from gaze patterns alone with up to 80% accuracy and up to 15% better than with non-gaze based features. This suggests that gaze patterns can be used to detect key events such as user struggle/frustration while reading.</span></div></div><div class="paper" id="wp789"><a href="#wp789" class="title">Facilitating Photographic Documentation of Accessibility in Street Scenes</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979833&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marynel  V&#225;zquez</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Aaron  Steinfeld</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present two interactive approaches for assisting users with visual impairments during photographic documentation of transit accessibility. We are working on an application for camera-enabled mobile devices that drives image composition towards highlighting visual information that is expected to be most relevant. In one interaction modality the user is guided trough small device motions that are expected to center the estimated region of interest in street photographs. In the other modality, the user captures the scene while pictures are processed, and the system alerts when enough data has been collected. The image that best aligns with our attention-getting composition model is then selected for documentation purposes. The specific design of these interactions is evolving to promote small motion behaviors by the user. Future work includes user studies.</span></div></div><div class="paper" id="wp793"><a href="#wp793" class="title">Places in Spaces: Common Ground in Virtual Worlds</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979834&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">N. Sadat  Shami</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Thomas  Erickson</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Wendy  Kellogg</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">David  Levine</span> <span class="affiliation">IBM Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Virtual worlds can allow conversational participants to achieve common ground in situations where the information volume and need for clarification is low. We argue in favor of this assertion through an examination of a semi-structured activity among hundreds of users held in a virtual world. Through the idea of 'implicit grounding', we argue that the affordances of contextualized space can allow users to achieve common ground in a low information volume, low clarification need activity. We use the success of the event to re-examine and extend Clark and Brennan's work on grounding in communication.</span></div></div><div class="paper" id="wp797"><a href="#wp797" class="title">Open Source Interface Politics: Identity, Acceptance, Trust, and Lobbying</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979835&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Roshanak  Zilouchian Moghaddam</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Michael  Twidale</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Kora  Bongen</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A study of the Drupal open source project shows the problematic status of usability designers with respect to the larger developer community. Issues of power, trust, and identity arise and affect the way that usability recommendations are acted on or ignored. Making a straightforward case for a particular interface design can be insufficient to convince developers. Instead various additional lobbying strategies may be employed to build up support for the design.</span></div></div><div class="paper" id="wp799"><a href="#wp799" class="title">Multi-Jump: Jump Roping Over Distances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979836&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lining  Yao</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Sayamindu  Dasgupta</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Nadia  Cheng</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Jason  Spingarn-Koff</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Ostap  Rudakevych</span> <span class="affiliation">Harvard University</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Jump roping, a game in which one or more people twirl a rope while others jump over the rope, promotes social interaction among children while developing their coordination skills and physical fitness. However, the traditional game requires that players be in the same physical location. Our &#8216;Multi-Jump&#8217; jump-roping game platform builds on the traditional game by allowing players to participate remotely by employing an augmented rope system. The game involves full-body motion in a shared game space and is enhanced with live video feeds, player rewards and music. Our work aims to expand exertion interface gaming, or games that deliberately require intense physical effort, with genuine tangible interfaces connected to real-time shared social gaming environments.</span></div></div><div class="paper" id="wp803"><a href="#wp803" class="title">Privacy in Domestic Environments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979837&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Peter J. Radics</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Denis  Gracanin</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While there is a growing body of research on privacy, most of the work puts the focus on information privacy. Physical and psychological privacy issues receive little to no attention. However, the introduction of technology into our lives can cause problems with regard to these aspects of privacy. This is especially true when it comes to our homes, both as nodes of our social life and places for relaxation. This paper presents the results of a study intended to capture a part of the phenomenology of privacy in domestic environments.</span></div></div><div class="paper" id="wp804"><a href="#wp804" class="title">Supporting Children's Creativity through Tangible User Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979838&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Allen  Bevans</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ying-Ting  Hsiao</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa  Antle</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We outline a preliminary research approach intended to explore the potential of tangible user interfaces (TUI&#8217;s) in supporting children&#8217;s creative problem solving activities, specifically those requiring the generation of divergent solutions. Our approach is grounded in theoretical notions taken from psychology, neuroscience, and developmental cognition. We detail a TUI currently in development called the Invention Workbench, and summarize how theoretical considerations have shaped the design of the interface.</span></div></div><div class="paper" id="wp808"><a href="#wp808" class="title">The Role of Modality in Virtual Manipulative Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979839&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seungoh  Paek</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Dan  Hoffman</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Antonios  Saravanos</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">John  Black</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Charles  Kinzer</span> <span class="affiliation">Teachers College, Columbia University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The current study examines aspects of multimedia design in virtual learning environments. It compares touch and mouse input methods in conjunction with audio and visual feedback in an effort to improve young children&#8217;s math learning. Fifty-nine (N=59) second grade students played Puzzle Blocks (PBs), a virtual manipulative designed to introduce students to the concept of multiplication through repetitive addition. All participants showed significant learning outcomes after playing PBs for five sessions. The results show that having auditory feedback is a more influential factor than input method. Implications are discussed.</span></div></div><div class="paper" id="wp812"><a href="#wp812" class="title">Line Following: A Path to Spatial Thinking Skills</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979840&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Megen E Brittell</span> <span class="affiliation">University of Oregon</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Encoding cursor position and directional information in synthesized audio feedback facilitates line following.  This technique will aid interpretation and spatial understanding of irregularly shaped line features (e.g. rivers, state boundaries) making maps more accessible to users who are blind or visually impaired.</span></div></div><div class="paper" id="wp813"><a href="#wp813" class="title">IDEAS: An Interface Design Experience for the Autistic Spectrum</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979841&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Laura  Benton</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Hilary  Johnson</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Mark  Brosnan</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Emma  Ashwin</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Beate  Grawemeyer</span> <span class="affiliation">University of Bath</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designing products and services to meet the specific requirements of children with Autism Spectrum Disorder (ASD) can be difficult due to their wide ranging and individual needs. Participatory Design (PD) is a design method that could be used to better meet these needs, by giving this population an opportunity to directly contribute to software designed for their use. Researchers have begun to involve children with ASD in the design process, but there is not yet a design method specifically adapted to support the potential difficulties this group may experience during PD sessions. This paper presents a new design method, IDEAS, which attempts to fulfill this need. The development of this method is described along with an initial pilot undertaken to determine the feasibility of using this method with an ASD population. The results indicate that the majority of children with ASD were able to produce a successful final design using this method, and have the potential to be involved in PD sessions as part of a design team.</span></div></div><div class="paper" id="wp814"><a href="#wp814" class="title">Enhancing Blog Readability for Non-native English Readers in the Enterprise</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979842&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chen-Hsiang  Yu</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Jennifer  Thom-Santelli</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">David  Millen</span> <span class="affiliation">IBM T.J. Watson Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Blogs are an important platform for people to access and share information, particularly in corporate settings where users rely on these systems for their work. However, because a global enterprise is multilingual, not all employees can understand the shared information in these systems easily if the content is written in a user&#8217;s non-native language. As a result, this research focuses on enhancing the readability of blogs in enterprise social software for this group of users. The pilot user study of Japanese and Chinese bloggers suggest there are two main challenges: finding an interesting blog post to read and encountering difficulties in reading blog posts as currently rendered. Based on these findings, we designed and implemented a Firefox extension, Clearly, which uses web customization techniques to improve these two levels of readability issues.</span></div></div><div class="paper" id="wp815"><a href="#wp815" class="title">Interactive Surface Technology for a Mobile Command Centre</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979843&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Victor  Cheung</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Nader  Cheaib</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Stacey D Scott</span> <span class="affiliation">University of Waterloo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, Contextual Inquiry is used to analyze the work inside a mobile command centre of a volunteer group, which provides specialized services and equipment to support events ranging from community-sponsored events to emergency incidents. The suitability and feasibility of utilizing interactive surface technology to support collaboration and coordination, using the mobile command centre as a hub for multiple agencies, are examined. Findings and lessons learned from this work can also inform the design of such technology for more general event organization and emergency response settings.</span></div></div><div class="paper" id="wp816"><a href="#wp816" class="title">Mobile SoundAR: Your phone on your head</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979844&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Syed  Naseh Hussaini</span> <span class="affiliation">Mobile Life @ II</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sound localization plays an important role in providing a believable sound based augmented reality. Human auditory system uses several cues for sound localization and thus it is important to render these cues in virtual environment as well. Though all cues complement each other, head motion is one cue that can work individually to help locate the direction of sound source. Affixing sensors on the head of the user have been used previously by researchers to reintroduce head motion in virtual soundscape and study it. Modern smart phones with motion detecting sensors are becoming highly pervasive in today's society. Such smart phones open up possibilities for early prototyping and testing of ideas, that previously required high fi gadgetry. Wearing the phone on head can track the head movement using gyroscope and accelerometer. This paper discusses development of prototypes to provide head tracking using iPhone4 to provide a believable sound augmentation.</span></div></div><div class="paper" id="wp817"><a href="#wp817" class="title">Enhancing Mobile Browsing and Reading</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979845&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chen-Hsiang  Yu</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Robert C. Miller</span> <span class="affiliation">MIT CSAIL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although the web browser has become a standard interface for information access on the Web, the mobile web browser on the smartphone does not hold the same interest to mobile users. A survey with 11 mobile users shows that only 18% of the participants like mobile web browsers, whereas 82% of them like other mobile applications. This research focuses on understanding mobile users&#8217; difficulties and proposes innovative ideas to enhance mobile web browsing. This research enhances mobile browsing and reading in three directions: (1) dynamically generating mobile web sites for browsing (2) using orientation sensor information to detect natural interactions and text-to-speech (TTS) to continue reading between different activities, and (3) providing a speech interface to ease web navigation and supporting dialog programming for repetitive tasks. The Read4Me Browser is a prototype system built to demonstrate the proposed ideas.</span></div></div><div class="paper" id="sr133"><a href="#sr133" class="title">Exploring Technological Opportunities for Cognitive Impairment Screening</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979512&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hyungsin  Kim</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, I present continuous research on developing a novel computerized screening tool for people with cognitive impairment. With the quickly growing aging population, more effectively accessible screening tools need to be developed. In order to gain an in-depth understanding of the possible technological opportunities, I conducted clinical practice observations, surveys, and interviews with older adults, as well as medical practitioners, such as neurologists and neuropsychologists. Based on the analysis results, I identify several issues in the current practice. I then present an ongoing progression of the development in order to solve the issues with future directions.</span></div></div><div class="paper" id="sr202"><a href="#sr202" class="title">How User Reviews Influence Older and Younger Adults&#8217; Credibility Judgments of Online Health Information</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979520&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vera  Liao</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A laboratory study was conducted to explore whether user reviews, a common Web 2.0 feature on healthcare website, would have differential influence on younger and older adults&#8217; judgment of information credibility. We found that when credibility cues in user reviews were consistent with those in Website contents, older adults benefited more from this supplementary information than younger adults, which allowed older adults to make better credibility judgments. When credibility cues in user reviews were inconsistent with those in Website contents, older adults were less influenced by the user reviews. Results have important implications on how user reviews may facilitate credibility judgment of online health information by older adults.</span></div></div><div class="paper" id="sr160"><a href="#sr160" class="title">Send Me Bubbles:  Multimodal Performance and Social Acceptability</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979513&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Julie Rico Williamson</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The use of performance as the focus of interaction provides the opportunity for exploratory and individual experiences but can also put users in an uncomfortable position. This paper presents an initial user study of a mobile remote awareness application in which users can control their own fish in a virtual fish tank using multimodal input from an external sensing device, where the input styles are created and performed by participants in an open ended sensing model. The study was designed in order to better understand the issues of performance when audience members are both casual passersby and familiar others watching remotely. Additionally, this study investigated the creation of performances and the effects of props when used in different social settings. The study involved pairs of participants interacting with the system in both public and private locations over repeated sessions. The results of this study show how users created and interpreted performances as well as how their consideration of passersby influenced their experiences.</span></div></div><div class="paper" id="sr166"><a href="#sr166" class="title">Frankenstein and Human Error: Device-Oriented Steps are More Problematic than Task-Oriented Ones</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979514&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Maartje  Ament</span> <span class="affiliation">University College London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Most errors in routine procedures are merely annoying, but they can have severe consequences in safety- critical systems such as medical devices. The current work investigates whether errors are more likely to occur on device-oriented steps (those concerned only with the operation of the device) than on task-oriented ones (those that help the user achieve their main task goal). Error rates were recorded on a routine toy task, with several carefully controlled device- and task- oriented steps. Results show that error rates are substantially higher on device-oriented steps, and step times are longer. The findings demonstrate that a step&#8217;s relevance to the task goal plays an important role in the occurrence of slip errors. They further highlight the problems associated with device-oriented steps, and make a strong case for avoiding them as much as possible in interface design.</span></div></div><div class="paper" id="sr173"><a href="#sr173" class="title">A Scalable and Tiling Multi-Monitor Aware Window Manager</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979515&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joona Antero Laukkanen</span> <span class="affiliation">University of Tampere</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The design of a prototypical scalable and tiling multi-monitor aware window manager is described that may overcome some of the layout management problems encountered with tiling window managers. The system also features a novel approach to monitor configuration in which monitors are treated as independent movable viewports to the large virtual desktop. This approach is expected to address a number of distal access and monitor configuration problems. In particular, it will enable many uses of multiple monitors that require dynamic or flexible monitor configurations.</span></div></div><div class="paper" id="sr175"><a href="#sr175" class="title">Sharing Stories "in the wild:" A Mobile Storytelling Case Study</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979516&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth  Bonsignore</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Today&#8217;s mobile devices are natively equipped with multimedia means for children to capture and share their daily experiences. However, designing authoring tools that effectively integrate the discrete media-capture components of mobile devices to enable rich expression remains a challenge. We report results of a study on the observed use of StoryKit, a mobile application that integrates multimodal media-capture tools to support the creation of multimedia stories on the iPhone/iPod Touch/iPad. The primary objectives of the study were to explore the ways in which StoryKit enables individuals to create and share personal stories; and to investigate how the created stories themselves might inform the design of mobile storytelling applications. Its results suggest that StoryKit&#8217;s relatively simple but well-integrated interface enables the creation of vibrant, varied narratives. Further, genre analysis of the types of stories created revealed a surprising volume and diversity of use in educational contexts.</span></div></div><div class="paper" id="sr195"><a href="#sr195" class="title">Trusting Experience Oriented Design</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979517&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aisling Ann O'Kane</span> <span class="affiliation">Mobile Life @ KTH Royal Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although trust and affective experiences have been linked in HCI research, a connection between traditional trust research for automation and experience design has not be made. This paper aims to start this discussion by showing the connection between experience-oriented HCI design and trust in automation through an experimental study of the Lega, a companion device for enriching experiences in museums. An experience-oriented HCI design approach was used to create this device and although it is not traditional automation, this study presents the links found between this approach and the bases of trust in automation, performance, process, and purpose, with regards to experience qualities of transparency, ambiguity, and usefulness, respectively.</span></div></div><div class="paper" id="sr197"><a href="#sr197" class="title">Code Gestalt: A Software Visualization Tool for Human Beings</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979518&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christopher  Kurtz</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Programmers are often faced with the necessity to visualize source code and grasp its structure. In a survey we studied how developers deal with this task. Based on our findings, we present the software visualization tool Code Gestalt, which assists programmers in quickly creating class diagrams. We evaluated and refined our concept using two prototypes. As a result, Code Gestalt introduces the tag overlay and thematic relations. These augmentations to class diagrams display similarities in the vocabulary used in the underlying source code. This simple, yet effective toolset empowers the user to explore and visualize software systems. The preliminary results of a user study investigating Code Gestalt indicate good usability.</span></div></div><div class="paper" id="sr198"><a href="#sr198" class="title">Cultural Difference in Image Searching</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979519&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wei  Dong</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous studies suggested that people from Eastern and Western cultural origins tagged digital images in different ways due to cultural difference in attentional patterns [2]. This study was conducted to examine whether Easterners and Westerners also exhibited dif-ferent behavioral patterns when searching for digital images. European Americans (EA) and Chinese were asked to general search keywords and to draw ideal target images for image searching tasks. Consistent with previous studies, results showed that Chinese were more likely to generate search keywords describing the overall properties of the target images than EA. When drawing ideal target images, EA assigned more space to the main objects than Chinese. The findings provided significant implications for designing cultural-sensitive tools to facilitate image search.</span></div></div><div class="paper" id="sr219"><a href="#sr219" class="title">The Influence of Grids on Spatial and Content Memory</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979522&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Svenja  Leifert</span> <span class="affiliation">University of Konstanz</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present an experiment that aims at understanding the influence that (visual) grid-based structuring of user interfaces can have on spatial and content memory. By the term grid we refer to two different aspects. On the one hand, this relates to the structured alignment, the layout of objects on a canvas. On the other hand, a grid can also be indicated visually by inserting lines that form an array which divides a canvas into smaller fields. In both cases we detected a strong positive influence on spatial memory. On content memory, however, grids have a less beneficial influence. Only if grid lines are visible, the structured alignment has a positive effect. On the other hand, the visibility of grid lines always leads to worse results in content memory performance, independent of the spatial arrangement.</span></div></div><div class="paper" id="sr215"><a href="#sr215" class="title">Digital Commemoration: Surveying the Social Media Revival of Historical Crises</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979521&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sophia B. Liu</span> <span class="affiliation">University of Colorado at Boulder</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social media has facilitated coordination efforts to help save lives, but are people using social media after the emergency phase? To answer this question, the author conducted a study surveying the social media revival of 111 crisis events that occurred over the past 50 years to examine if social media is being used to commemorate historical crises. Quantitative and qualitative social media metrics on each event were collected to determine their social media presence. The findings show that people are using social media to sustain the living record of past crises as an attempt to prevent disasters and strengthen resilience to future crises. Technological and social hazards that occurred before the social media age tended to exhibit a higher social media presence than natural hazards. Also, the revival of past crises typically occurred when they were linked to recent crises that exhibited similar causes, effects, and vulnerabilities. Issues in the construction and implementation of the survey inform the development of sociotechnical systems designed to collect, manage, and analyze historical events through the cyberinfrastructure.</span></div></div></td>
<td colspan="13" class="session_details" id="S1058_details"><div class="sessionChair"><strong>Session Chair: </strong>Sharoda Paul (<em>PARC</em>)</div><div class="paper" id="paper728"><a href="#paper728" class="title">Speak Little and Well: Recommending Conversations in Online Social Streams</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978974&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jilin  Chen</span> <span class="affiliation">University of Minnesota</span>, <br />
<span class="author">Rowan  Nairn</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Ed  Chi</span> <span class="affiliation">Palo Alto Research Center (PARC)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Conversation is a key element in online social streams such as Twitter and Facebook. However, finding interesting conversations to read is often a challenge, due to information overload and differing user preferences. In this work we explored five algorithms that recommend conversations to Twitter users, utilizing thread length, topic and tie-strength as factors. We compared the algorithms through an online user study and gathered feedback from real Twitter users. In particular, we investigated how users&#8217; purposes of using Twitter affect user preferences for different types of conversations and the performance of different algorithms. Compared to a random baseline, all algorithms recommended more interesting conversations. Further, tie-strength based algorithms performed significantly better for people who use Twitter for social purposes than for people who use Twitter for informational purpose only.</span></div></div><div class="paper" id="paper1080"><a href="#paper1080" class="title">TwitInfo: Aggregating and Visualizing Microblogs for Event Exploration</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978975&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Adam  Marcus</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Michael S Bernstein</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Osama  Badar</span> <span class="affiliation">MIT</span>, <br />
<span class="author">David R Karger</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Samuel R Madden</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Robert C Miller</span> <span class="affiliation">MIT</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Microblogs are a tremendous repository of user-generated content about world events. However, for people trying to understand events by querying services like Twitter, a chronological log of posts makes it very difficult to get a detailed understanding of an event. In this paper, we present TwitInfo, a system for visualizing and summarizing events on Twitter.  TwitInfo allows users to browse a large collection of tweets using a timeline-based display that highlights peaks of high tweet activity. A novel streaming algorithm automatically discovers these peaks and labels them meaningfully using text from the tweets. Users can drill down to subevents, and explore further via geolocation, sentiment, and popular URLs. We contribute a recall-normalized aggregate sentiment visualization to produce more honest sentiment overviews. An evaluation of the system revealed that users were able to reconstruct meaningful summaries of events in a small amount of time. An interview with a Pulitzer Prize-winning journalist suggested that the system would be especially useful for understanding a long-running event and for identifying eyewitnesses. Quantitatively, our system can identify 80-100% of manually labeled peaks, facilitating a relatively complete view of each event studied.</span></div></div><div class="paper" id="paper704"><a href="#paper704" class="title">Tweets from Justin Bieber&#8217;s Heart: The Dynamics of the &#8220;Location&#8221; Field in User Profiles</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978976&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Brent  Hecht</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Lichan  Hong</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Bongwon  Suh</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Ed  Chi</span> <span class="affiliation">Palo Alto Research Center (PARC)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Little research exists on one of the most common, oldest, and most utilized forms of online social geographic information: the &#8220;location&#8221; field found in most virtual community user profiles. We performed the first in-depth study of user behavior with regard to the location field in Twitter user profiles. We found that 34% of users did not provide real location information, frequently incorporating fake locations or sarcastic comments that can fool traditional geographic information tools. When users did input their location, they almost never specified it at a scale any more detailed than their city. In order to determine whether or not natural user behaviors have a real effect on the &#8220;locatability&#8221; of users, we performed a simple machine learning experiment to determine whether we can identify a user&#8217;s location by only looking at what that user tweets. We found that a user&#8217;s country and state can in fact be determined easily with decent accuracy, indicating that users implicitly reveal location information, with or without realizing it. Implications for location-based services and privacy are discussed.</span></div></div><div class="paper" id="paper1208"><a href="#paper1208" class="title">An Open, Social Microcalender for the Enterprise: Timely?</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978977&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Werner  Geyer</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Casey  Dugan</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Beth  Brownholtz</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Mikhil  Masli</span> <span class="affiliation">University of Minnesota</span>, <br />
<span class="author">Elizabeth  Daly</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">David  Millen</span> <span class="affiliation">IBM T.J. Watson Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the system design and rational for a novel social microcalendar called Timely. Our system has been inspired by previous research on calendaring and popular social network applications, in particular microblogging. Timely provides an open, social space for enterprise users to share their events, socialize, and discover what else is going on in their network and beyond. A detailed analysis of the events shared by users during the site&#8217;s first 47 days reveals that users willingly share their time commitments despite an existing culture of restricted calendars.</span></div></div></td>
<td colspan="13" class="session_details" id="S1052_details"><div class="sessionChair"><strong>Session Chair: </strong>Wanda Pratt (<em>University of Washington</em>)</div><div class="paper" id="paper1107"><a href="#paper1107" class="title">Classroom-Based Assistive Technology: Collective Use of Interactive Visual Schedules by Students with Autism</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978944&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Meg  Cramer</span> <span class="affiliation">UC Irvine</span>, <br />
<span class="author">Sen H Hirano</span> <span class="affiliation">UC Irvine</span>, <br />
<span class="author">Monica  Tentori</span> <span class="affiliation">UC Irvine/ Universidad Aut&#243;noma de Baja California</span>, <br />
<span class="author">Michael T Yeganyan</span> <span class="affiliation">UC Irvine</span>, <br />
<span class="author">Gillian R Hayes</span> <span class="affiliation">UC Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">vSked is an interactive and collaborative assistive technology for students with autism, combining visual schedules, choice boards, and a token-based reward system into an integrated classroom system. In this paper, we present the results of a study of three deployments of vSked over the course of a year in two autism classrooms. The results of our study demonstrate that vSked can promote student independence, reduce the quantity of educator-initiated prompts, encourage consistency and predictability, reduce the time required to transition from one activity to another. The findings from this study reveal practices surrounding the use of assistive technologies in classrooms and highlight important considerations for both the design and the evaluation of assistive technologies in the future, especially those destined for classroom use.</span></div></div><div class="paper" id="paper1306"><a href="#paper1306" class="title">Privacy Risks Emerging from the Adoption of Innocuous Wearable Sensors in the Mobile Environment</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978945&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew  Raij</span> <span class="affiliation">University of South Florida</span>, <br />
<span class="author">Animikh  Ghosh</span> <span class="affiliation">SETLabs, InfoSys</span>, <br />
<span class="author">Santosh  Kumar</span> <span class="affiliation">University of Memphis</span>, <br />
<span class="author">Mani  Srivastava</span> <span class="affiliation">University of California, Los Angeles</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Wearable sensors are revolutionizing healthcare and science by enabling capture of physiological, psychological, and behavioral measurements in natural environments. However, these seemingly innocuous measurements can be used to infer potentially private behaviors such as stress, conversation, smoking, drinking, illicit drug usage, and others. We conducted a study to assess how concerned people are about disclosure of a variety of behaviors and contexts that are embedded in wearable sensor data. Our results show participants are most concerned about disclosures of conversation episodes and stress -- inferences that are not yet widely publicized. These concerns are mediated by temporal and physical context associated with the data and the participant's personal stake in the data. Our results provide key guidance on the extent to which people understand the potential for harm and data characteristics researchers should focus on to reduce the perceived harm from such datasets.</span></div></div><div class="paper" id="cs129"><a href="#cs129" class="title">Identification of pointing difficulties of two individuals with Parkinson&#8217;s disease via a sub-movement analysis</a>&nbsp;-&nbsp;<span class="type">Case Study (Short)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979636&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Guarionex  Salivia</span> <span class="affiliation">The University of Iowa</span>, <br />
<span class="author">Juan Pablo  Hourcade</span> <span class="affiliation">The University of Iowa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a study of the sub-movement characteristics of two individuals with Parkinson&#8217;s disease completing pointing tasks. We describe the performance of the two individuals and we compare it with that of young children and older able-body adults. The analysis suggests that we need new strategies that incorporate an individual assessment of difficulties, and provide personalized methods of assistance.</span></div></div><div class="paper" id="paper821"><a href="#paper821" class="title">Interaction Design for Cancer Patients: Do We Need to Take Into Account the Effects of Illness and Medication?</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978946&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anita  Das</span> <span class="affiliation">NTNU</span>, <br />
<span class="author">Arild  Faxvaag</span> <span class="affiliation">NTNU</span>, <br />
<span class="author">Dag  Svan&#230;s</span> <span class="affiliation">NTNU</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we explore how having cancer and receiving therapy influences upon patients&#8217; ability to use an online healthcare system. The motivation is that no empirically based design guidelines are available concerning this user group. Ignoring possible effects of illness and therapy can result in systems with poor usability and user acceptance. A case-control usability test with 14 cancer patients and 14 matched controls revealed that the cancer patients experienced significantly more difficulties compared with the healthy controls using a web-based online healthcare system. We conclude that designers of online healthcare systems need to take into consideration the unique challenges of being ill and/or using medication.</span></div></div><div class="paper" id="paper992"><a href="#paper992" class="title">Simulating the Feel of Brain-Computer Interfaces for Design, Development and Social Interaction</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978947&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Melissa  Quek</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Daniel  Boland</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">John  Williamson</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Roderick  Murray-Smith</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Michele  Tavella</span> <span class="affiliation">&#201;cole Polytechnique F&#233;d&#233;rale de Lausanne</span>, <br />
<span class="author">Serafeim  Perdikis</span> <span class="affiliation">&#201;cole Polytechnique F&#233;d&#233;rale de Lausanne</span>, <br />
<span class="author">Martijn  Schreuder</span> <span class="affiliation">Technische Universit&#228;t Berlin</span>, <br />
<span class="author">Michael  Tangermann</span> <span class="affiliation">Technische Universit&#228;t Berlin</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe an approach to improving the design and development of Brain-Computer Interface (BCI) applications by simulating the error-prone characteristics and subjective feel of electroencephalogram (EEG), motor-imagery based BCIs. BCIs have the potential to enhance the quality of life of people who are severely disabled, but it is often time-consuming to test and develop the systems. Simulation of BCI characteristics allows developers to rapidly test design options, and gain both subjective and quantitative insight into expected behaviour without using an EEG cap. A further motivation for the use of simulation is that `impairing' a person without motor disabilities in a game with a disabled BCI user can create a level playing field and help carers empathise with BCI users. We demonstrate a use of the simulator in controlling a game of Brain Pong.</span></div></div><div class="paper" id="paper1764"><a href="#paper1764" class="title">Characterizing Patient-Friendly &#8220;Micro-Explanations&#8221; of Medical Events</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978948&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lauren  Wilcox</span> <span class="affiliation">Columbia University</span>, <br />
<span class="author">Dan  Morris</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Desney  Tan</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Justin  Gatewood</span> <span class="affiliation">MedStar Institute for Innovation</span>, <br />
<span class="author">Eric  Horvitz</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Patients&#8217; basic understanding of clinical events has been shown to dramatically improve patient care. We propose that the automatic generation of very short micro-explanations, suitable for real-time delivery in clinical settings, can transform patient care by giving patients greater awareness of key events in their electronic medical record. We present results of a survey study indicating that it may be possible to automatically generate such explanations by extracting individual sentences from consumer-facing Web pages. We further inform future work by characterizing physician and non-physician responses to a variety of Web-extracted explanations of medical lab tests.</span></div></div></td>
<td colspan="13" class="session_details" id="S1055_details"><div class="sessionChair"><strong>Session Chair: </strong>Jennifer Lai (<em>IBM T.J. Watson Research Center</em>)</div><div class="paper" id="paper253"><a href="#paper253" class="title">Confessions from a Grounded Theory PhD: Experiences and Lessons Learnt</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978960&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominic  Furniss</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Ann  Blandford</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Paul  Curzon</span> <span class="affiliation">Queen Mary University of London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Grounded Theory (GT) is used within HCI research, but nuances and more modern interpretations of the method are rarely discussed. This paper has two intentions: to offer guidance on practical issues when applying GT, and to clarify the space of methodological possibilities. We describe an extended GT study on understanding why practitioners choose particular usability evaluation methods. We describe five stages in this study to highlight our experiences and choices made. We draw out seven practical and methodological considerations in applying GT in a CHI context. This challenges the more traditional inductive and objective positions on GT use; it sensitizes novices of GT to these issues; and through the extended case study it provides substance for debate on issues that affect those that use qualitative methods more broadly.</span></div></div><div class="paper" id="paper927"><a href="#paper927" class="title">Reflexivity in Digital Anthropology</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978961&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer A Rode</span> <span class="affiliation">Drexel University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There are a variety of forms of ethnography inside and outside HCI each with valid complementary contributions. This paper looks at the practices of digital anthropology and how it contributes to reflexive design in HCI. The paper overviews key aspects its use in HCI, as well as in the anthropological approach. In doing so it relates these practices to participatory design and the socio-technical gap, and the ways ethnography can address them.</span></div></div><div class="paper" id="paper126"><a href="#paper126" class="title">Comparing Activity Theory with Distributed Cognition for Video Analysis: Beyond "Kicking the Tires"</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978962&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eric P. S. Baumer</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Bill  Tomlinson</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The field of HCI is growing, not only in the variety of application areas or the volume of research conducted, but also in the number of analytical approaches for use in the evaluation and design of interactive systems. However, despite the abundance of theoretical frameworks available, relatively little work has directly compared the application of these frameworks. This paper compares video analysis methods based on two analytic frameworks&#8212;activity theory (AT) and distributed cognition (DCog)&#8212;by performing an analysis of the same system from each of the two different theoretical perspectives. The results presented here provide a better understanding of how such theoretically informed methods in practice both resemble and differ from one another. Furthermore, this comparison enables specific insights about each of the theories themselves, as well as more general discussion about the role of theory in HCI.</span></div></div><div class="paper" id="cs192"><a href="#cs192" class="title">From Basecamp to Summit: Scaling Field Research Across 9 Locations</a>&nbsp;-&nbsp;<span class="type">Case Study (Short)</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979638&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jens  Riegelsberger</span> <span class="affiliation">Google UK</span>, <br />
<span class="author">Audrey  Yang</span> <span class="affiliation">Google Inc.</span>, <br />
<span class="author">Konstantin  Samoylov</span> <span class="affiliation">Google Russia</span>, <br />
<span class="author">Elizabeth  Nunge</span> <span class="affiliation">Google Inc.</span>, <br />
<span class="author">Molly  Stevens</span> <span class="affiliation">Google Inc.</span>, <br />
<span class="author">Patrick  Larvie</span> <span class="affiliation">Google Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this case study we discuss the mechanics of running a complex field research project within one week: 32 field visits, 4 countries, 9 locations, 10+ researchers, 30+ observers. We outline the goals that lead to this project plan, and the tools and processes we developed to succeed under the constraints given. We discuss in particular (1) the role of ongoing in-field analysis and data sharing, (2) the role of basecamp as a centralized mission control center and real-time analysis hub, and (3) the added value of running the study and initial analysis in such a compressed time frame. We close with a reflection on the strengths and weaknesses of this approach, as well as ideas for future improvements.</span></div></div><div class="paper" id="paper166"><a href="#paper166" class="title">The Aligned Rank Transform for Nonparametric Factorial Analyses Using Only ANOVA Procedures</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978963&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Leah  Findlater</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Darren  Gergle</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">James J. Higgins</span> <span class="affiliation">Kansas State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Nonparametric data from multi-factor experiments arise often in human-computer interaction (HCI). Examples may include error counts, Likert responses, and preference tallies. But because multiple factors are involved, common nonparametric tests (e.g., Friedman) are inadequate, as they are unable to examine interaction effects. While some statistical techniques exist to handle such data, these techniques are not widely available and are complex. To address these concerns, we present the Aligned Rank Transform (ART) for nonparametric factorial data analysis in HCI. The ART relies on a preprocessing step that &#8220;aligns&#8221; data before applying averaged ranks, after which point common ANOVA procedures can be used, making the ART accessible to anyone familiar with the F-test. Unlike most articles on the ART, which only address two factors, we generalize the ART to N factors. We also provide ARTool and ARTweb, desktop and web-based programs for aligning and ranking data. Our re-examination of some published HCI results exhibits advantages of the ART.</span></div></div></td>
<td colspan="13" class="session_details" id="S1046_details"><div class="paper" id="sp103"><a href="#sp103" class="title">An Informal Walk through 35 Years of Interactive Devices</a>&nbsp;-&nbsp;<span class="type">Special Events</span><div class="authors"><span class="author">Bill  Buxton</span> <span class="affiliation">Microsoft</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">For as long as I can remember, I have collected electronic gadgets and other devices, whose design caught my attention - for both good and bad reasons.  At the same time, I also tended to collect things like associated marketing materials.  After 30+ years, I am glad that I did so, since, despite living in the so-called Information Age, and having access to things like search engines and Wikipedia, etc., a great deal of this rather recent history has been essentially lost.  These are, after all, mainly interactive devices that lived in a time and a context - things that do not photograph well, shall we say, assuming that even much exists in that department (for example, try and find good images (much less screen shots) of the world's first smart phone, and direct antecedent of the iPhone:  the Bell South/IBM Simon ).  This talk is a walk-through of part of my collection, including the devices that will be on display in the exhibition at CHI in Vancouver.  I will talk about what caught my attention with that device, how it relates to other devices in the collection, what the relevance is to design today, and why I think that it is important and worthy of our attention.  Along the way, we will learn as much about human motor control, cognition, and intentions, as we do about technology.  And, most of all, rather than leaving the talk/exhibition being proud of what we are doing today, I suspect and hope that the exposure to this history will leave us all a little humbled, and wondering what the heck we have been doing in the past 30 years, given the existence proofs provided by some of the gems in the collection.   <br />  <br /> That is only as it should be.  To quote the designer Ralph Caplan: <br />  <br /> Santayana taught us that those who do not know history are condemned to repeat it. That surely is true in design as in anything else, but in design there is a corollary: those who do know history are privileged to repeat it at a profit.  <br />  <br /> Brief Bio: <br /> Bill is the author of, Sketching User Experiences:  Getting the Design Right and the Right Design.  A Principal Researcher at MSR, he has a 30 year involvement in research, design and commentary around human aspects of technology.  He was a researcher at Xerox PARC, and Chief Scientist of Alias Research and SGI Inc. He has been awarded three honourary doctorates, is co-recipient of an Academy Award for Scientific and Technical Achievement, received an ACM/SIGCHI Lifetime Achievement Award, and is a Fellow of the ACM. He is an Adjunct Professor at the University of Toronto and Distinguished Professor of Industrial Design at the Technical University Eindhoven.   <br /></span></div></div></td>
<td colspan="13" class="session_details" id="S1056_details"><div class="sessionChair"><strong>Session Chair: </strong>Krzysztof Gajos (<em>Harvard University</em>)</div><div class="paper" id="paper412"><a href="#paper412" class="title">Human Model Evaluation in Interactive Supervised Learning</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978965&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rebecca  Fiebrink</span> <span class="affiliation">Princeton University</span>, <br />
<span class="author">Perry  Cook</span> <span class="affiliation">Princeton University</span>, <br />
<span class="author">Dan  Trueman</span> <span class="affiliation">Princeton University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Model evaluation plays a special role in interactive machine learning (IML) systems in which users rely on their assessment of a model's performance in order to determine how to improve it. A better understanding of what model criteria are important to users can therefore inform the design of user interfaces for model evaluation as well as the choice and design of learning algorithms. We present work studying the evaluation practices of end users interactively building supervised learning systems for real-world gesture analysis problems. We examine users' model evaluation criteria, which span conventionally relevant criteria such as accuracy and cost, as well as novel criteria such as unexpectedness. We observed that users employed evaluation techniques---including cross-validation and direct, real-time evaluation---not only to make relevant judgments of algorithms' performance and interactively improve the trained models, but also to learn to provide more effective training data. Furthermore, we observed that evaluation taught users about what types of models were easy or possible to build, and users sometimes used this information to modify the learning problem definition or their plans for using the trained models in practice. We discuss the implications of these findings with regard to the role of generalization accuracy in IML, the design of new algorithms and interfaces, and the scope of potential benefits of incorporating human interaction in the design of supervised learning systems.</span></div></div><div class="paper" id="paper2368"><a href="#paper2368" class="title">CueT: Human-Guided Fast and Accurate Network Alarm Triage</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978966&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Saleema  Amershi</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Bongshin  Lee</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Ashish  Kapoor</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Ratul  Mahajan</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Blaine  Christian</span> <span class="affiliation">Microsoft Corporation</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Network alarm triage refers to grouping and prioritizing a stream of low-level device health information to help operators find and fix problems. Today, this process tends to be largely manual because existing tools cannot easily evolve with the network. We present CueT, a system that uses interactive machine learning to learn from the triaging decisions of operators. It then uses that learning in novel visualizations to help them quickly and accurately triage alarms. Unlike prior interactive machine learning systems, CueT handles a highly dynamic environment where the groups of interest are not known a-priori and evolve constantly. A user study with real operators and data from a large network shows that CueT significantly improves the speed and accuracy of alarm triage compared to the network&#8217;s current practice.</span></div></div><div class="paper" id="paper275"><a href="#paper275" class="title">Apolo: Making Sense of Large Network Data by Combining Rich User Interaction and Machine Learning</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978967&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Duen Horng (Polo)  Chau</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Aniket  Kittur</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jason I. Hong</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Christos  Faloutsos</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach---combining visualization, rich user interaction and machine learning---to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">14:00<br />-<br />15:20</td>

<td class="session " id="S1061">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1061" class="title">UX Research: What Theoretical Roots Do We Build On &#8211; If Any?</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1066">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1066" class="title">Watching Together</a>
<span class="location">119/120</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1060">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1060" class="title">Touching The 3rd Dimension (T3D)</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1070">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1070" class="title">Gestures</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1075">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1075" class="title">Facebook</a>
<span class="location">223/224</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1069">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1069" class="title">Brain &amp; Bio-sensor Interactions</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1073">
<div class="session_box">
<span class="type">Case Study, Paper &amp; ToCHI</span>
<a href="#S1073" class="title">Meetings &amp; Interaction Spaces</a>
<span class="location">217/218/219</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1074">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1074" class="title">Art, Music &amp; Movement</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1068">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1068" class="title">Health 2: Persuasive Systems</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1071">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1071" class="title">Designing for Values, Democracy &amp; Peace</a>
<span class="location">212/213/214</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1062">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1062" class="title">World of Warcraft as a Global Artifact</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1072">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1072" class="title">Driving</a>
<span class="location">215/216</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>
</tr>
<tr class="details_row"><td colspan="12" class="session_details" id="S1061_details"><div class="paper" id="si120"><a href="#si120" class="title">UX Research: What Theoretical Roots Do We Build On &#8211; If Any?</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979526&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marianna  Obrist</span> <span class="affiliation">University of Salzburg</span>, <br />
<span class="author">Effie  Law</span> <span class="affiliation">University of Leicester</span>, <br />
<span class="author">Kaisa  V&#228;&#228;n&#228;nen-Vainio-Mattila</span> <span class="affiliation">Tampere University of Technology</span>, <br />
<span class="author">Virpi  Roto</span> <span class="affiliation">University of Helsinki</span>, <br />
<span class="author">Arnold  Vermeeren</span> <span class="affiliation">Delft University of Technology</span>, <br />
<span class="author">Kari  Kuutti</span> <span class="affiliation">University of Oulu</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">User Experience (UX) research focusing on the emotional and experiential aspects of system usage is of highly recognized relevance for the CHI community. A lot of work has been conducted with different goals: investigating a common definition and understanding of UX, creating appropriate concepts, frameworks and models for supporting design and development processes, and developing methods and techniques for evaluating UX. However, there is still a lack of in-depth discussions on the theoretical roots and foundations for all of these UX activities in academia and industry. In this SIG we will explore the state of the art in the theory of UX research in order to lay the fundament for further advancements of the UX field. We will also discuss how the theoretical viewpoints can benefit, and be influenced by the UX practitioners&#8217; work.</span></div></div></td>
<td colspan="12" class="session_details" id="S1066_details"><div class="sessionChair"><strong>Session Chair: </strong>Ed Chi (<em>PARC</em>)</div><div class="paper" id="to118"><a href="#to118" class="title">Time Warp Sports for Internet Television</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Dan  Olsen</span> <span class="affiliation">Brigham Young University</span>, <br />
<span class="author">Brett  Partridge</span> <span class="affiliation">Brigham Young University</span>, <br />
<span class="author">Stephen  Lynn</span> <span class="affiliation">Brigham Young University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Internet-based video delivery offers new opportunities for interactive television. The creation and usability of interactive television is very different from desktop or web-based interaction. The concepts of frameworks and genres provides an approach to learnable interaction in an entertainment rather than task-oriented activity. The concept of a framework defines the tools required for both producing and viewing a particular style of interactive video experience. An interactive framework for televised sports is presented. This framework implements a sports television experience that support play-by-play navigation as well as viewer&#8217;s interactive choice of camera angles. Tools for creating and viewing interactive sports are developed in parallel. In-home and in-lab experiments give indications of how sports fans will use interactive television in the future. The experiments demonstrate that fans will use the interaction rather than passively watching, can easily learn the interactive features and strongly prefer the new features over tradition rewind/fast-forward. The data indicates that many users will use the interactive controls to enrich and prolong their viewing rather than simply skipping as rapidly as possible through a game. However, there is also indication that some viewers will simply skip rapidly. There are also indications that the skip vs. review interaction depends on the interest level of current game play.</span></div></div><div class="paper" id="paper1161"><a href="#paper1161" class="title">We Want More: Human-Computer Collaboration in Mobile Social Video Remixing of Music Concerts</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978983&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sami  Vihavainen</span> <span class="affiliation">Helsinki Institute for Information Technology HIIT / Aalto University</span>, <br />
<span class="author">Sujeet  Mate</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Lassi  Sepp&#228;l&#228;</span> <span class="affiliation">Helsinki Institute for Information Technology HIIT / Aalto University</span>, <br />
<span class="author">Francesco  Cricri</span> <span class="affiliation">Tampere University of Technology</span>, <br />
<span class="author">Igor  Curcio</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recording and publishing mobile video clips from music <br /> concerts is popular. There is a high potential to increase the <br /> concert&#8217;s perceived value when producing video remixes <br /> from individual video clips and using them socially. A digital <br /> production of a video remix is an interactive process between <br /> human and computer. However, it is not clear what <br /> the collaboration implications between human and computer <br /> are. <br />  <br /> We present a case study where we compare the processes <br /> and products of manual and automatic mobile video remixing. <br /> We provide results from the first systematic real world <br /> study of the subject. We draw our observations from a user <br /> trial where fans recorded mobile video clips during a rock <br /> concert. <br />  <br /> The results reveal issues on heterogeneous interests of the <br /> stakeholders, unexpected uses of the raw material, the burden <br /> of editing, diverse quality requirements, motivations for <br /> remixing, the effect of understanding the logic of automation, <br /> and the collaborative use of manual and automatic remixing.</span></div></div><div class="paper" id="paper1249"><a href="#paper1249" class="title">Knowing Funny: Genre Perception and Categorization in Social Video Sharing</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978984&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jude  Yew</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">David  Shamma</span> <span class="affiliation">Yahoo! Research</span>, <br />
<span class="author">Elizabeth  Churchill</span> <span class="affiliation">Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Categorization of online videos is often treated as a tag suggestion <br />   task; tags can be generated by individuals or by machine <br />   classification. In this paper, we suggest categorization can be <br />   determined socially, based on people's interactions around media <br />   content without recourse to metadata that are intrinsic to the media <br />   object itself. This work bridges the gap between the human <br />   perception of genre and automatic categorization of genre in <br />   classifying online videos. We present findings from two internet <br />   surveys and from follow-up interviews where we address how people <br />   determine genre classification for videos and how social framing of <br />   video content can alter the perception and categorization of that <br />   content. From these findings, we train a Naive Bayes classifier to <br />   predict genre categories. The trained classifier achieved 82<br />% <br />   accuracy using only social action data, without the use of content <br />   or media-specific metadata. We conclude with implications on how we <br />   categorize and organize media online as well as what our findings <br />   mean for designing and building future tools and interaction <br />   experiences. <br /></span></div></div><div class="paper" id="paper1007"><a href="#paper1007" class="title">Real-Time Nonverbal Opinion Sharing through Mobile Phones during Sports Events</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978985&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alireza  Sahami Shirazi</span> <span class="affiliation">University Duisburg-Essen / University of Stuttgart</span>, <br />
<span class="author">Michael  Rohs</span> <span class="affiliation">Ludwig-Maximilians-Universit&#228;t / Technische Universit&#228;t Berlin</span>, <br />
<span class="author">Robert  Schleicher</span> <span class="affiliation">Technische Universit&#228;t Berlin</span>, <br />
<span class="author">Sven  Kratz</span> <span class="affiliation">Technische Universit&#228;t Berlin / Ludwig-Maximilians-Universit&#228;t</span>, <br />
<span class="author">Alexander  M&#252;ller</span> <span class="affiliation">University Duisburg-Essen</span>, <br />
<span class="author">Albrecht  Schmidt</span> <span class="affiliation">University Duisburg-Essen / University of Stuttgart</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Even with the rise of the World Wide Web, TV has remained <br /> the most pervasive entertainment medium and is <br /> nowadays often used together with other media, which allow <br /> for active participation. The idea of connecting non-collocated <br /> TV viewers via telecommunication technologies, <br /> referred to as Social TV, has recently received considerable <br /> attention. Such systems typically include set-top boxes for <br /> supporting collaboration. In this research we investigate if <br /> real-time opinion sharing about TV shows through a nonverbal <br /> (non-textual) iconic UI on mobile phones is reasonable. <br /> For this purpose we developed a mobile app, made it <br /> available to a large number of users through the Android <br /> Market, and conducted an uncontrolled user study in the <br /> wild during the soccer world cup 2010. The results of the <br /> study indicate that TV viewers who used the app had more <br /> fun and felt more connected to other viewers. We also show <br /> that by monitoring this channel it is possible to collect sentiments <br /> relevant to the broadcasted content in real-time. The <br /> collected data exemplify that the aggregated sentiments <br /> correspond to important moments, and hence can be used to <br /> generate a summary of the event.</span></div></div><div class="paper" id="paper319"><a href="#paper319" class="title">Are we in Sync? Synchronization Requirements for Watching Online Video Together.</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978986&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Geerts</span> <span class="affiliation">K.U.Leuven IBBT</span>, <br />
<span class="author">Ishan  Vaishnavi</span> <span class="affiliation">CWI</span>, <br />
<span class="author">Rufael  Mekuria</span> <span class="affiliation">TNO</span>, <br />
<span class="author">Oskar  van Deventer</span> <span class="affiliation">TNO</span>, <br />
<span class="author">Pablo  Cesar</span> <span class="affiliation">CWI</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Synchronization between locations is an important factor for enabling remote shared experiences. Still, experimental data on what is the acceptable synchronization level is scarce. This paper discusses the synchronization requirements for watching online videos together &#8211; a popular set of services that recreate the shared experience of watching TV together by offering tools to communicate while watching. It studies the noticeability and annoyance of synchronization differences of the video being watched, as well as the impact on users&#8217; feelings of togetherness, both for voice chat and text chat. Results of an experiment with 36 participants show that when using voice chat, users notice synchronization differences sooner, are more annoyed and feel more together than when using text chat. However, users with high text chat activity notice synchronization differences similar to participants using voice chat.</span></div></div></td>
<td colspan="12" class="session_details" id="S1060_details"><div class="paper" id="si113"><a href="#si113" class="title">Touching The 3rd Dimension (T3D)</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979525&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Frank  Steinicke</span> <span class="affiliation">WWU M&#252;nster</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Florian  Daiber</span> <span class="affiliation">DFKI GmbH</span>, <br />
<span class="author">Daniel  Keefe</span> <span class="affiliation">University of Minnesota</span>, <br />
<span class="author">Jean-Baptiste  de la Rivi&#232;re</span> <span class="affiliation">Immersion</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In recent years interactive visualization of 3D data has become increasingly important and widespread due to the requirements of several application areas. However, current user interfaces often lack adequate support for 3D interactions: 2D desktop systems are often limited in cases where natural interaction with 3D content is required, and sophisticated 3D user interfaces consisting of stereoscopic projections and tracked input devices are rarely adopted by ordinary users. Touch interaction has received considerable attention for 2D interfaces, and more recently for 3D interfaces. Many touch devices now support multiple degrees of freedom input by capturing multiple 2D contact positions on the surface as well as varying levels of pressure and even depth. There is, therefore, great potential for multi-touch interfaces to provide the traditionally difficult to achieve combination of natural 3D interaction without any instrumentation. When combined with a stereoscopic display of 3D data as well as 3D depth cameras, we believe that multi-touch technology can form the basis for a next generation of intuitive and expressive 3D user interfaces. Several research groups have begun to explore the potential, limitations, and challenges of this and other 3D touch environments, and first commercial systems are already available.  <br /> The goal of the SIG &#8220;Touching the 3rd Dimension (T3D)&#8221; is to address the research and industrial challenges involved in exploring the space where the flat digital world of surface computing meets the physical, spatially complex, 3D space in which we live. The meeting will provide a common forum to attract groups of conference attendees who share their visions of the future and recent results in the area of improving 3D interaction and visualization by taking advantage of the strengths of advanced multi-touch computing.</span></div></div></td>
<td colspan="12" class="session_details" id="S1070_details"><div class="sessionChair"><strong>Session Chair: </strong>Steven Feiner (<em>Columbia University</em>)</div><div class="paper" id="paper1674"><a href="#paper1674" class="title">RemoteTouch: Touch-Screen-like Interaction in the TV Viewing Environment</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978999&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sangwon  Choi</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Jaehyun  Han</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Geehyuk  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Narae  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Woohun  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We explored the possibility of touch-screen-like interaction with a remote control in the TV-viewing environment. A shadow representing the user's thumb touches the screen, presses a button, flicks a cover-flow list, and draws a simple stroke, while the thumb stays and moves on and above the touchpad. In order to implement the concept we developed an optical touchpad for tracking the thumb hovering over its surface, and designed a TV application to demonstrate possible new interaction styles.  Throughout two iterations of prototyping, we corrected some of our false expectations, and also verified its potential as a viable option for a TV remote control.  This paper presents technical issues and requirements for the hover-tracking touchpad and a complete report of our user studies to explore touch-screen-like interaction for the TV. <br /></span></div></div><div class="paper" id="paper711"><a href="#paper711" class="title">Experimental Analysis of Touch-Screen Gesture Designs in Mobile Environments</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979000&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew  Bragdon</span> <span class="affiliation">Brown University</span>, <br />
<span class="author">Eugene  Nelson</span> <span class="affiliation">Brown University</span>, <br />
<span class="author">Yang  Li</span> <span class="affiliation">Google Research</span>, <br />
<span class="author">Ken  Hinckley</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Direct-touch interaction on mobile phones revolves around screens that compete for visual attention with users&#8217; real-world tasks and activities. This paper investigates the impact of these situational impairments on touch-screen interaction. We probe several design factors for touch-screen gestures, under various levels of environmental demands on attention, in comparison to the status-quo approach of soft buttons. We find that in the presence of environmental distractions, gestures can offer significant performance gains and reduced attentional load, while performing as well as soft buttons when the user&#8217;s attention is focused on the phone. In fact, the speed and accuracy of bezel gestures did not appear to be significantly affected by environment, and some gestures could be articulated eyes-free, with one hand. Bezel-initiated gestures offered the fastest performance, and mark-based gestures were the most accurate. Bezel-initiated marks therefore may offer a promising approach for mobile touch-screen interaction that is less demanding of the user&#8217;s attention.</span></div></div><div class="paper" id="paper1638"><a href="#paper1638" class="title">Usable Gestures for Blind People:  Understanding Preference and Performance</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979001&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shaun K. Kane</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Richard E. Ladner</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Despite growing awareness of the accessibility issues surrounding touch screen use by blind people, designers still face challenges when creating accessible touch screen interfaces. One major stumbling block is a lack of understanding about how blind people actually use touch screens. We conducted two user studies that compared how blind people and sighted people use touch screen gestures. First, we conducted a gesture elicitation study in which 10 blind and 10 sighted people invented gestures to perform common computing tasks on a tablet PC. We found that blind people have different gesture preferences than sighted people, including preferences for edge-based gestures and gestures that involve tapping virtual keys on a keyboard. Second, we conducted a performance study in which the same participants performed a set of reference gestures. We found significant differences in the speed, size, and shape of gestures performed by blind people versus those performed by sighted people. Our results suggest new design guidelines for accessible touch screen interfaces.</span></div></div><div class="paper" id="cs175"><a href="#cs175" class="title">Natural Activation for Gesture Recognition Systems</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979642&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathieu  Hopmann</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Patrick  Salamin</span> <span class="affiliation">Logitech</span>, <br />
<span class="author">Nicolas  Chauvin</span> <span class="affiliation">Logitech</span>, <br />
<span class="author">Fr&#233;d&#233;ric  Vexo</span> <span class="affiliation">Logitech</span>, <br />
<span class="author">Daniel  Thalmann</span> <span class="affiliation">EPFL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Gesture recognition is becoming a popular way of interaction, but still suffers of important drawbacks to be integrated in everyday life devices. One of these drawbacks is the activation of the recognition system &#8211; trigger gesture - which is generally tiring and unnatural. In this paper, we propose two natural solutions to easily activate the gesture interaction. The first one requires a single action from the user: grasping a remote control to start interacting. The second one is completely transparent for the user: the gesture system is only activated when the user&#8217;s gaze points to the screen, i.e. when s/he is looking at it. Our first evaluation with the 2 proposed solutions plus a default implementation suggests that the gaze estimation activation is efficient enough to remove the need of a trigger gesture in order to activate the recognition system.</span></div></div></td>
<td colspan="12" class="session_details" id="S1075_details"><div class="sessionChair"><strong>Session Chair: </strong>Daniela Busse (<em>SAP</em>)</div><div class="paper" id="cs179"><a href="#cs179" class="title">The Talking Poles  Public Art based in Social Design</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979646&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vicki  Moulder</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Lorna  Boschman</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This case study provides insights for artists, designers, and technologists working with community-generated media in the domain of public art.  The authors document their recent public artwork, the Talking Poles, and discuss the adaptation of Human Computer Interaction (HCI) design methods to the project.  Community-generated public art has a direct relationship to the field of HCI through the technology that underlies both social computing and quotidian digital documentation. When acknowledging &#8216;citizen action&#8217; as a component of public art, consideration must also be given to the preservation of the work as representative of an emergent and shared digital world culture.</span></div></div><div class="paper" id="paper1222"><a href="#paper1222" class="title">Life Modes in Social Media</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979022&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Fatih  OZENC</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Shelly  Farnham</span> <span class="affiliation">Yahoo!</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Current social media products such as Facebook and Twitter have not sufficiently addressed how to help users organize people and content streams across different areas of their lives. We conducted a qualitative design research study to explore how we might best leverage natural models of social organization to improve experiences of social media. We found that participants organize their social worlds based on life &#8216;modes&#8217;, i.e., family, work and social. They strategically use communication technologies to manage intimacy levels within these modes, and levels of permeability through the boundaries between these modes. Mobile communication in particular enabled participants to aggregate and share content dynamically across life modes. While exploring problems with managing their social media streams, people showed a strong need for focused sharing &#8211; the ability to share content only with appropriate audiences within certain areas of life.</span></div></div><div class="paper" id="paper1150"><a href="#paper1150" class="title">Social Capital on Facebook: Differentiating Uses and Users</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979023&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Moira  Burke</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Robert  Kraut</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Cameron  Marlow</span> <span class="affiliation">Facebook</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Though social network site use is often treated as a monolithic activity, in which all time is equally &#8220;social&#8221; and its impact the same for all users, we examine how Facebook affects social capital depending upon: (1) types of site activities, contrasting one-on-one communication, broadcasts to wider audiences, and passive consumption of social news, and (2) individual differences among users, including social communication skill and self-esteem. Longitudinal surveys matched to server logs from 415 Facebook users reveal that receiving messages from friends is associated with increases in bridging social capital, but that other uses are not. However, using the site to passively consume news assists those with lower social fluency draw value from their connections. The results inform site designers seeking to increase social connectedness and the value of those connections.</span></div></div><div class="paper" id="paper1616"><a href="#paper1616" class="title">Farmer&#8217;s Tale: A Facebook Game to Promote Volunteerism</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979024&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Don  Sim</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Xiaojuan  Ma</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Shengdong  Zhao</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Jing Ting  Khoo</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Swee Ling  Bay</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Zhenhui  Jiang</span> <span class="affiliation">National University of Singapore</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Volunteering is an important activity that brings great benefits to societies. However, encouraging volunteerism is difficult due to the altruistic nature of volunteer activities and the high resource demand in carrying them out. We have created a Facebook game called &#8220;Farmer&#8217;s Tale&#8221; to attract and make it easier for people to volunteer. We evaluated people&#8217;s acceptance to this novel idea and the results revealed great potential in such type of games.</span></div></div><div class="paper" id="paper1555"><a href="#paper1555" class="title">Identifying Social Capital in the Facebook Interface</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979025&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christian  Yoder</span> <span class="affiliation">UNC-Chapel Hill</span>, <br />
<span class="author">Fred  Stutzman</span> <span class="affiliation">UNC-Chapel Hill</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A number of studies have identified a robust relationship between the use of social network sites, particularly Facebook, and positive outcomes such as social capital. Social network site use is often measured as a function of use frequency, network size, and a range of subjective opinions about the value of the site. This research extends this understanding by exploring the relationship between the use of particular elements of the site and social capital. Our goal in this research is to identify where, in the interface, perceived social capital is most effectively produced and transmitted. We find that, as hypothesized, public, person-to-person communication is positively associated with perceived social capital. Through the use of a structural equation model, we are able to provide in-depth exploration of the relationship between the interface elements and the outcome, perceived social capital.</span></div></div></td>
<td colspan="12" class="session_details" id="S1069_details"><div class="sessionChair"><strong>Session Chair: </strong>Regan Mandryk (<em>University of Saskatchewan</em>)</div><div class="paper" id="paper763"><a href="#paper763" class="title">Embodiment in Brain-Computer Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978994&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kenton  O'Hara</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Abigail  Sellen</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Richard  Harper</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With emerging opportunities for using Brain-Computer Interaction (BCI) in gaming applications, there is a need to understand the opportunities and constraints of this interaction paradigm.  To complement existing laboratory-based studies, there is also a call for the study of BCI in real world contexts. In this paper we present such a real world study of a simple BCI game called MindFlex&#174;, played as a social activity in the home.  In particular, drawing on the philosophical traditions of embodied interaction, we highlight the importance of considering the body in BCI and not simply what is going on in the head. The study shows how people use bodily actions to facilitate control of brain activity but also to make their actions and intentions visible to, and interpretable by, others playing and watching the game. It is the public availability of these bodily actions during BCI that allows action to be socially organised, understood and coordinated with others and through which social relationships can be played out.  We discuss the implications of this perspective and findings for BCI.</span></div></div><div class="paper" id="paper893"><a href="#paper893" class="title">Now where was I? Physiologically-Triggered Bookmarking</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978995&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew K.X.J. Pan</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Jih-Shiang  Chang</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gokhan H. Himmetoglu</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">AJung  Moon</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Thomas W. Hazelton</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Karon E. MacLean</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Elizabeth A. Croft</span> <span class="affiliation">The University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This work explores a novel interaction paradigm driven by implicit, low-attention user control, accomplished by moni-toring a user&#8217;s physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. Here, a user&#8217;s galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our prototype automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted. To test this approach&#8217;s viability, we addressed questions such as: does GSR exhibit a detectable response to interruptions, and how should the interaction utilize this information? In evaluating this system in a controlled environment, we found an OR detection accuracy of 84%; users provided subjective feedback on its accuracy and utility.</span></div></div><div class="paper" id="paper413"><a href="#paper413" class="title">This is Your Brain on Interfaces: Enhancing Usability Testing with Functional Near-Infrared Spectroscopy</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978996&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Leanne  Hirshfield</span> <span class="affiliation">Computer Science Department Hamilton College</span>, <br />
<span class="author">Rebecca  Gulotta</span> <span class="affiliation">Human  Computer Interaction Institute Carnegie Mellon University</span>, <br />
<span class="author">Stuart  Hirshfield</span> <span class="affiliation">Computer Science Department Hamilton College</span>, <br />
<span class="author">Sam  Hincks</span> <span class="affiliation">Computer Science Department Hamilton College</span>, <br />
<span class="author">Matthew  Russell</span> <span class="affiliation">Computer Science Department Hamilton College</span>, <br />
<span class="author">Rachel  Ward</span> <span class="affiliation">Computer Science Department Hamilton College</span>, <br />
<span class="author">Tom  Williams</span> <span class="affiliation">Computer Science Department Hamilton College</span>, <br />
<span class="author">Robert  Jacob</span> <span class="affiliation">Tufts University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This project represents a first step towards bridging the gap between HCI and cognition research.  Using functional near-infrared spectroscopy (fNIRS), we introduce tech-niques to  non-invasively measure a range of cognitive workload states that have implications to HCI research, most directly usability testing. We present a set of usability experiments that illustrates how fNIRS brain measurement provides information about the cognitive demands placed on computer users by different interface designs.</span></div></div><div class="paper" id="paper181"><a href="#paper181" class="title">Sensing Cognitive Multitasking for a  Brain-Based Adaptive User Interface</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978997&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Erin Treacy Solovey</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Francine  Lalooses</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Krysta  Chauncey</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Douglas  Weaver</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Margarita  Parasi</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Matthias  Scheutz</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Angelo  Sassaroli</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Sergio  Fantini</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Paul  Schermerhorn</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Robert J.K. Jacob</span> <span class="affiliation">Tufts University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Multitasking has become an integral part of work environments, even though people are not well-equipped cognitively to handle numerous concurrent tasks effectively. Systems that support such multitasking may produce better performance and less frustration. However, without understanding the user&#8217;s internal processes, it is difficult to determine optimal strategies for adapting interfaces, since all multitasking activity is not identical. We describe two experiments leading toward a system that detects cognitive multitasking processes and uses this information as input to an adaptive interface. Using functional near-infrared spectroscopy sensors, we differentiate four cognitive multitasking processes. These states cannot readily be distinguished using behavioral measures such as response time, accuracy, keystrokes or screen contents. We then present our human-robot system as a proof-of-concept that uses real-time cognitive state information as input and adapts in response. This prototype system serves as a platform to study interfaces that enable better task switching, interruption management, and multitasking.</span></div></div></td>
<td colspan="12" class="session_details" id="S1073_details"><div class="sessionChair"><strong>Session Chair: </strong>Wendy Ju (<em>Stanford University</em>)</div><div class="paper" id="paper417"><a href="#paper417" class="title">Synchronous Interaction Among Hundreds: An Evaluation of a Conference in an Avatar-based Virtual Environment</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979013&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Thomas  Erickson</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">N. Sadat  Shami</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Wendy A. Kellogg</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">David W. Levine</span> <span class="affiliation">IBM T.J. Watson Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents the first in-depth evaluation of a large multi-format virtual conference. The conference took place in an avatar-based 3D virtual world with spatialized audio, and had keynote, poster and social sessions. We studied it by drawing on logs, a survey and interviews with 30 participants. We develop a model &#8211; Coalescence, Focused Interaction, Remixing (CoFIRe) &#8211; of large synchronous interactions, and use it to discuss how the technology supported, or failed to support, the interactions that are the raison d&#8217;etre of conferences. We conclude by discussing the prospects for such large virtual gatherings.</span></div></div><div class="paper" id="paper1652"><a href="#paper1652" class="title">What did I miss? In-Meeting Review using Multimodal Accelerated Instant Replay (AIR) Conferencing</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979014&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sasa  Junuzovic</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Kori  Inkpen</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Rajesh  Hegde</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Zhengyou  Zhang</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">John  Tang</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Christopher  Brooks</span> <span class="affiliation">University of Saskatechewan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">People sometimes miss small parts of meetings and need to quickly catch up without disrupting the rest of the meeting. We developed an Accelerated Instant Replay (AIR) Conferencing system for videoconferencing that enables users to catch up on missed content while the meeting is ongoing. AIR can replay parts of the conference using four different modalities: audio, video, conversation transcript, and shared workspace. We performed two studies to evaluate the system. The first study explored the benefit of AIR catch-up during a live meeting. The results showed that when the full videoconference was reviewed (i.e., all four modalities) at an accelerated rate, users were able to correctly recall a similar amount of information as when listening live. To better understand the benefit of full review, a follow-up study more closely examined the benefits of each of the individual modalities. The results show that users (a) preferred using audio along with any other modality to using audio alone, (b) were most confident and performed best when audio was reviewed with all other modalities, (c) compared to audio-only, had better recall of facts and explanations when reviewing audio together with the shared workspace and transcript modalities, respectively, and (d) performed similarly with audio-only and audio with video review.</span></div></div><div class="paper" id="to108"><a href="#to108" class="title">Blended Interaction Spaces for Distributed Team Collaboration</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Kenton  O'Hara</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Jesper  Kjeldskov</span> <span class="affiliation">Aalborg University</span>, <br />
<span class="author">Jeni  Paay</span> <span class="affiliation">Aalborg University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In recent years there has been an introduction of sophisticated new video conferencing technologies (e.g. HP Halo, Cisco Telepresence) that have led to enhancements in the collaborative user experience over traditional video conferencing technologies. Traditional video conferencing set-ups often distort the shared spatial properties of action and communication due to screen and camera orientation disparities and other asymmetries. These distortions affect access to the common resources used to mutually organize action and communication. By contrast new systems, such as Halo, are physically configured to reduce these asymmetries and orientation disparities, thereby minimizing these spatial distortions. By creating appropriate shared spatial geometries, the distributed spaces become &#8220;blended&#8221; where the spatial geometries of the local space continue coherently across the distributed boundary into the remote site providing the illusion of a single unified space. Drawing on theories of embodied action and workplace design we discuss the importance of this geometric &#8220;blending&#8221; of space for distributed collaboration and how this is achieved in systems such as Halo. We then extend these arguments to explore the concept of Blended Interaction Spaces - blended spaces in which interactive groupware is incorporated in ways spatially consistent with the physical geometries of the video mediated setup. We illustrate this discussion through a system called BISi that introduces interactive horizontal and vertical multipoint surfaces into a blended video mediated collaboration space. In presenting this system, we highlight some of the particular challenges of creating these systems arising from the spatial consequences of different interaction mechanisms (e.g. direct touch or remote control) and how they affect movement and spatial configuration of people in these spaces.</span></div></div><div class="paper" id="cs107"><a href="#cs107" class="title">BISi: a Blended Interaction Space</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" /><div class="authors"><span class="author">Jeni  Paay</span> <span class="affiliation">Aalborg University</span>, <br />
<span class="author">Jesper  Kjeldskov</span> <span class="affiliation">Aalborg University</span>, <br />
<span class="author">Kenton  O'Hara</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Distributed collaboration has been enhanced in recent years by sophisticated new video conferencing setups like HP Halo and Cisco Telepresence, improving the user experience of distributed meeting situations over traditional video conferencing. The experience created can be described as one of &#8220;blending&#8221; distributed physical locations into one shared space. Inspired by this trend, we have been exploring the systematic creation of blended spaces for distributed collaboration through the design of appropriate shared spatial geometries. We present early iterations of our design work: the Blended Interaction Space One prototype, BISi, and the lessons learned from its creation.</span></div></div></td>
<td colspan="12" class="session_details" id="S1074_details"><div class="sessionChair"><strong>Session Chair: </strong>Amy Voida (<em>University of California, Irvine</em>)</div><div class="paper" id="paper324"><a href="#paper324" class="title">MOGCLASS: Evaluation of a Collaborative System of Mobile Devices for Classroom Music Education of Young Children</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979016&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yinsheng  Zhou</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Graham  Percival</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Xinxi  Wang</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Ye  Wang</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Shengdong  Zhao</span> <span class="affiliation">National University of Singapore</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Composition, listening, and performance are essential activities in classroom music education, yet conventional music classes impose unnecessary limitations on students' ability to develop these skills. Based on in-depth fieldwork and a user-centered design approach, we created MOGCLASS, a multimodal collaborative music environment that enhances students&#8217; musical experience and improves teachers' management of the classroom. <br />  <br /> We conducted a two-round system evaluation to improve the prototype and evaluate the system: Improvements were made based on the results from an iterative design evaluation, in which a trial system was implemented. The system then underwent a second round of evaluation through a three-week between-subject controlled experiment in a local primary school. Results showed that MOGCLASS is effective in motivating students to learn music, improving the way they collaborate with other students as well as helping teachers manage the classroom.</span></div></div><div class="paper" id="paper1478"><a href="#paper1478" class="title">Buzzing to Play: Lessons Learned From an In the Wild Study of Real-time Vibrotactile Feedback</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979017&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janet  van der Linden</span> <span class="affiliation">The Open University,</span>, <br />
<span class="author">Rose  Johnson</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Jon  Bird</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Yvonne  Rogers</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Erwin  Schoonderwaldt</span> <span class="affiliation">Institute for Music Physiology and Musicians' Medicine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Vibrotactile feedback offers much potential for facilitating and accelerating how people learn sensory-motor skills that typically take hundreds of hours to learn, such as learning to play a musical instrument, skiing or swimming. However, there is little evidence of this benefit materializing outside of research lab settings. We describe the findings of an in-the-wild study that explored how to integrate vibrotactile feedback into a real-world teaching setting. The focus of the study was on exploring how children of different ages, learning to play the violin, can use real-time vibrotactile feedback. Many of the findings were unexpected, showing how students and their teachers appropriated the technology in creative ways. We present some &#8216;lessons learned&#8217; that are also applicable to other training settings, emphasizing the need to understand how vibrotactile feedback can switch between being foregrounded and backgrounded depending on the demands of the task, the teacher&#8217;s role in making it work and when feedback is most relevant and useful. Finally, we discuss how vibrotactile feedback can provide a new language for talking about the skill being learned that may also play an instrumental role in enhancing learning.</span></div></div><div class="paper" id="paper1826"><a href="#paper1826" class="title">PossessedHand: Techniques for Controlling Human Hands using Electrical Muscles Stimuli</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979018&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Emi  Tamaki</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Takashi  Miyaki</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Jun  Rekimoto</span> <span class="affiliation">The University of Tokyo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">If a device can control human hands, the device can be useful for HCI and tangible application's output. To aid the controlling of finger movement, we present PossessedHand, a device with a forearm belt that can inform when and which fingers should be moved. PossessedHand controls the user's fingers by applying electrical stimulus to the muscles around the forearm. Each muscle is stimulated via 28 electrode pads. Muscles at different depths in the forearm can be selected for simulation by varying the stimulation level. PossessedHand can automatically calibrate the system for individuals. The automatic calibration system estimates relations between each electrode pad, stimulation level and muscle movement.  <br /> Experiments show that PossessedHand can control the motion of 16 joints in the hand. Further, we also discuss an application based on this device to aid inplaying a musical instrument.</span></div></div><div class="paper" id="paper626"><a href="#paper626" class="title">Design Interventions for Open-Air Museums: Applying and Extending the Principles of &#8220;Assembly&#8221;</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979019&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marc  McLoughlin</span> <span class="affiliation">University of Limerick</span>, <br />
<span class="author">Luigina  Ciolfi</span> <span class="affiliation">University of Limerick</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an empirical approach to designing and deploying technologies to support visitor activities in exhibition spaces. Specifically, we focus on the concept of "assembly" and how it was extended and applied to develop an interactive installation for an open-air museum. We argue that this approach to designing for a meaningful visitor experience is particularly suited to open-air visit scenarios; we describe how we have extended the approach and applied it, detailing the resulting multi-device installation that was deployed on site, and presenting some reflections on the usefulness of the assembly concept.</span></div></div><div class="paper" id="paper1945"><a href="#paper1945" class="title">MoBoogie: Creative Expression Through Whole Body Musical Interaction</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979020&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Megan K. Halpern</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Jakob  Tholander</span> <span class="affiliation">Stockholm University</span>, <br />
<span class="author">Max  Evjen</span> <span class="affiliation">Johns Hopkins University</span>, <br />
<span class="author">Stuart  Davis</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Andrew  Ehrlich</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Kyle  Schustak</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Eric P. S. Baumer</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Geri  Gay</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe MoBoogie, an application that allows users to manipulate and arrange music through movement. MoBoogie is designed to foster experiences in creative expression for children and potentially adults. The application responds to users&#8217; movements by changing variables in a continuous stream of music loops. Results from this study suggest that the creative expressions arose in the joint space of movement and music, and did not primarily have to be in one form or the other. This allowed users with limited experience in dance and music making to be creative in such forms of expression.</span></div></div></td>
<td colspan="12" class="session_details" id="S1068_details"><div class="sessionChair"><strong>Session Chair: </strong>Elizabeth Gerber (<em>Segal Design Institute Northwestern University</em>)</div><div class="paper" id="paper175"><a href="#paper175" class="title">Designing for Peer Involvement in Weight Management</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978988&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Julie  Maitland</span> <span class="affiliation">National Research Council of Canada</span>, <br />
<span class="author">Matthew  Chalmers</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The problems of obesity and overweight are commonly cited as the motivation behind recent efforts to develop technology that promotes physical activity. Prompted by the social nature of many of the emerging applications, this paper presents our investigation of the sociality of weight management as experienced by a broad demographic of individuals. Our findings highlight the broad scope of peer involvement, and provide insight into the context and mechanics of related interaction that may prove valuable in informing the next generation of peer-based weight management technology for use in everyday life.</span></div></div><div class="paper" id="paper2238"><a href="#paper2238" class="title">Mining Behavioral Economics to Design Persuasive Technology for Healthy Choices</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978989&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Min Kyung  Lee</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Sara  Kiesler</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jodi  Forlizzi</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Influence through information and feedback has been one of the main approaches of persuasive technology. We propose another approach based on behavioral economics research on decision-making. This approach involves designing the presentation and timing of choices to encourage people to make self-beneficial decisions. We applied three behavioral economics persuasion techniques&#8212;the default option strategy, the planning strategy, and the asymmetric choice strategy&#8212;to promote healthy snacking in the workplace. We tested the strategies in three experimental case studies using a human snack deliverer, a robot, and a snack ordering website. The default and the planning strategies were effective, but they worked differently depending on whether the participants had healthy dietary lifestyles or not. We discuss designs for persuasive technologies that apply behavioral economics.</span></div></div><div class="paper" id="paper250"><a href="#paper250" class="title">Means Based Adaptive Persuasive Systems.</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978990&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Maurits Clemens Kaptein</span> <span class="affiliation">Eindhoven University Of Technology / Philips Research</span>, <br />
<span class="author">Steven  Duplinsky</span> <span class="affiliation">Accenture Technology</span>, <br />
<span class="author">Panos  Markopoulos</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Large differences in individual responses to persuasive strategies suggest the need for systems that rely on persuasion profiles: estimates of an individual user's susceptibility to different persuasive strategies. Establishing an empirical ground supporting decisions regarding user involvement can provide valuable guidelines for the design of such systems. We describe two studies examining the effects of choice, disclosure, and multiple strategy usage on user compliance to persuasive attempts. We show that involving users in the selection of a specific influence strategy can increase compliance, while disclosing the persuasive intent can reduce compliance. Furthermore, we demonstrate that it is not only feasible, but optimal to choose the single correct influence strategy for a given context; even more so than implementing multiple relevant and congruent influence attempts.</span></div></div><div class="paper" id="paper1167"><a href="#paper1167" class="title">Side Effects and &#8216;Gateway&#8217; Tools: Advocating a Broader Look at Evaluating Persuasive Systems</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978991&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Victoria  Schwanda</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Steven  Ibara</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Lindsay  Reynolds</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Dan  Cosley</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper argues for evaluating the impact of persuasive systems on users beyond metrics that focus on system usage, based on an interview study of 16 Wii Fit users. While exploring their experiences and reasons for abandoning the system, two main themes emerged: the tension between Wii Fit as a fitness tool and a game, and ways participants reacted to the system&#8217;s feedback about their weight and performance. Some participants used Wii Fit as a &#8216;gateway fitness&#8217; tool, moving beyond it to other fitness routines. Additionally, some users had significant emotional reactions to the Wii Fit&#8217;s feedback. We argue that these &#8216;side effects&#8217; are crucial considerations for the design and long-term evaluation of persuasive technologies.</span></div></div><div class="paper" id="paper373"><a href="#paper373" class="title">I Will Do It, but I Don&#8217;t Like It: User Reactions to Preference-Inconsistent Recommendations</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1978992&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christina  Schwind</span> <span class="affiliation">Knowledge Media Research Center</span>, <br />
<span class="author">Juergen  Buder</span> <span class="affiliation">Knowledge Media Research Center</span>, <br />
<span class="author">Friedrich W.  Hesse</span> <span class="affiliation">Knowledge Media Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recommender systems have their origin in e-commerce. In this domain the users are meant to like the recommended information. This preference-consistency is not adequate or even desirable for all domains where recommender systems are implemented. One key issue for opinion formation and informed decision making is to be aware of more than one&#8217;s own perspective. However, information search is often biased, because confirming information is favored over opposing information. Therefore it would be useful to recommend information that is inconsistent to users&#8217; prior perspective to help overcome this bias. The present paper deals with an online experiment aimed at investigating the effects of preference-consistent compared to preference-inconsistent recommendations on information selection and evaluation. Results showed a significant reduction of confirmation bias in the condition with preference-inconsistent recommendations. However, participants prefer preference-consistent recommendations in terms of global, cognitive and affective evaluations. We discuss the impact of these findings for application.</span></div></div></td>
<td colspan="12" class="session_details" id="S1071_details"><div class="sessionChair"><strong>Session Chair: </strong>Jofish Kaye (<em>Nokia Research</em>)</div><div class="paper" id="paper1645"><a href="#paper1645" class="title">Fit4Life: The Design of a Persuasive Technology Promoting Healthy Behavior and Ideal Weight</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979003&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stephen  Purpura</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Victoria  Schwanda</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Kaiton  Williams</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">William  Stubler</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Phoebe  Sengers</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This is a critical design paper offering a possible scenario of use intended to provoke reflection about values and politics of design in persuasive computing. We describe the design of a system&#8212;Fit4Life&#8212;that encourages individuals to address the larger goal of reducing obesity in society by promoting individual healthy behaviors. Using the Persuasive Systems Design Model [26], this paper outlines the Fit4Life persuasion context, the technology, its use of persuasive messages, and an experimental design to test the system&#8217;s efficacy. We also contribute a novel discussion of the ethical and sociocultural considerations involved in our design, an issue that has remained largely unaddressed in the existing persuasive technologies literature [29].</span></div></div><div class="paper" id="paper2150"><a href="#paper2150" class="title">Many Bills: Engaging Citizens through Visualizations of Congressional Legislation</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979004&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yannick  Assogba</span> <span class="affiliation">IBM</span>, <br />
<span class="author">Irene  Ros</span> <span class="affiliation">IBM</span>, <br />
<span class="author">Joan  DiMicco</span> <span class="affiliation">IBM</span>, <br />
<span class="author">Matt  McKeon</span> <span class="affiliation">Google</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">US federal legislation is a common subject of discussion and advocacy on the web, inspired by the open government  movement. While the contents of these bills are freely available for download, understanding them is a significant challenge to experts and average citizens alike due to their length, complex language, and obscure topics. To make these important documents more accessible to the general public, we present Many Bills (http://manybills.us): a web-based set of visualization tools that reveals the underlying semantics of a bill. Using machine learning techniques, we classify each bill&#8217;s sections based on existing document-level categories. We then visualize the resulting topic substructure of these bills. These visualizations provide an overview-and-detail view of bills, enabling users to read individual sections of a bill and compare topic patterns across multiple bills. Through an overview of the site&#8217;s user activity and interviews with active users, this paper highlights how Many Bills makes the tasks of reading bills, identifying outlier sections in bills, and understanding congressperson&#8217;s legislative activity more manageable. <br /></span></div></div><div class="paper" id="paper1178"><a href="#paper1178" class="title">HCI for Peace: A Call for Constructive Action</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979005&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Juan Pablo  Hourcade</span> <span class="affiliation">University of Iowa</span>, <br />
<span class="author">Natasha E Bullock-Rest</span> <span class="affiliation">University of Iowa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Peace is an important value for the human-computer interaction research community, yet it has not resulted in the development of a research sub-community or even a research agenda. In this paper we seek to address this void by first motivating the need for computing research on promoting peace and preventing war. We then review evidence on the factors that affect the likelihood that armed conflict will occur, as well as the aspects involved when individuals make moral decisions on whether or not to support a war. Based on this review, we propose a research agenda, citing research examples from the human-computer interaction literature and discussing new ideas.</span></div></div><div class="paper" id="paper1829"><a href="#paper1829" class="title">Evaluating a Pattern-Based Visual Support Approach for Humanitarian Landmine Clearance</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979006&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lahiru G Jayatilaka</span> <span class="affiliation">Harvard University</span>, <br />
<span class="author">Luca F Bertuccelli</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">James  Staszewski</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Krzysztof Z Gajos</span> <span class="affiliation">Harvard University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Unexploded landmines have severe post-conflict humanitarian repercussions: landmines cost lives, limbs and land. For deminers engaged in humanitarian landmine clearance, metal detectors remain the primary detection tool as more sophisticated technologies fail to get adopted due to restrictive cost, low reliability, and limited robustness. Metal detectors are, however, of limited effectiveness, as modern landmines contain only minimal amounts of metal, making them difficult to distinguish from the ubiquitous but harmless metallic clutter littering post-combat areas. We seek to improve the safety and efficiency of the demining process by developing support tools that will enable deminers to make better decisions using feedback from existing metal detectors. To this end, in this paper we propose and evaluate a novel, pattern-based visual support approach inspired by the documented strategies employed by expert deminers. In our laboratory study, participants provided with a prototype of our support tool were 80% less likely to mistake a mine for harmless clutter. A follow-up study demonstrates the potential of our pattern-based approach to enable peer decision-making support during landmine clearance. Lastly, we identify several design opportunities for further improving deminers&#8217; decision making capabilities.</span></div></div></td>
<td colspan="12" class="session_details" id="S1062_details"><div class="paper" id="pl111"><a href="#pl111" class="title">World of Warcraft as a Global Artifact</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979485&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jeffrey  Bardzell</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Bonnie  Nardi</span> <span class="affiliation">University of California</span>, <br />
<span class="author">Lisa  Nakamura</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span>, <br />
<span class="author">Christopher  Paul</span> <span class="affiliation">Seattle University</span>, <br />
<span class="author">Nick  Yee</span> <span class="affiliation">PARC</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The goal of the panel is to engage a group of distinguished scholars from the social sciences and humanities to consider how World of Warcraft, as a virtual world and as a sociotechnical system, creates and sustains a global community, as well as the nature of that community. Panelists will discuss the interlocking human and technical agencies at play in World of Warcraft, the complex social ecology that has evolved around the game, and research strategies that scale to a world of 12 million players.</span></div></div></td>
<td colspan="12" class="session_details" id="S1072_details"><div class="sessionChair"><strong>Session Chair: </strong>Dario Salvucci (<em>Drexel University</em>)</div><div class="paper" id="paper338"><a href="#paper338" class="title">Hang on a Sec! Effects of Proactive Mediation of Phone Conversations while Driving</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979008&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shamsi T. Iqbal</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Eric  Horvitz</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Yun-Cheng  Ju</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Ella  Mathews</span> <span class="affiliation">California Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Conversing on cell phones while driving is a risky, yet commonplace activity. State legislatures in the U.S. have enacted rules that limit hand-held phone conversations while driving but that allow for hands-free conversations. However, studies have demonstrated that the cognitive load of conversation is a significant source of distraction that increases the likelihood of accidents. We explore in a controlled study with a driving simulator the effectiveness of proactive alerting and mediation of communications during phone conversations while driving. We study the use of auditory messages indicating upcoming critical road conditions and placing calls on hold. We found that such actions reduce driving errors and that alerts sharing details about situations were more effective than general alerts. Drivers found such a system valuable in most situations for maintaining driving safety. These results provide evidence that context-sensitive mediation systems could play a valuable role in focusing drivers&#8217; attention on the road during phone conversations.</span></div></div><div class="paper" id="paper254"><a href="#paper254" class="title">Fast or safe? How performance objectives determine modality output choices while interacting on the move</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979009&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Duncan P Brumby</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Samantha C.E. Davies</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Christian P. Janssen</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Justin J. Grace</span> <span class="affiliation">University College London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In-car devices that use audio output have been shown to be less distracting than traditional graphical user interfaces, but can be cumbersome and slow to use. In this paper, we report an experiment that demonstrates how these performance characteristics impact whether people will elect to use an audio interface in a multitasking situation. While steering a simulated vehicle, participants had to locate a source of information in a short passage of text. The text was presented either on a visual interface, or using a text-to-speech audio interface. The relative importance of each task was varied. A no-choice/choice paradigm was used in which participants first gained experience with each of the two interfaces, before being given a choice on which interface to use on later trials. The characteristics of the interaction with the interfaces, as measured in the no-choice phase, and the relative importance of each task, had an impact on which output modality was chosen in the choice phase. Participants that prioritized the secondary task tended to select the (faster yet more distracting) visual interface over the audio interface, and as a result had poorer lane keeping performance. This work demonstrates how a user&#8217;s task objective will influence modality choices with multimodal devices in multitask environments.</span></div></div><div class="paper" id="paper1591"><a href="#paper1591" class="title">Gestural Interaction on the Steering Wheel - Reducing the Visual Demand</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979010&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tanja  D&#246;ring</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Dagmar  Kern</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Paul  Marshall</span> <span class="affiliation">University of Warwick</span>, <br />
<span class="author">Max  Pfeiffer</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Johannes  Sch&#246;ning</span> <span class="affiliation">German Research Center for Artificial Intelligence Saarbr&#252;cken</span>, <br />
<span class="author">Albrecht  Schmidt</span> <span class="affiliation">University of Stuttgart</span>, <br />
<span class="author">Volker  Gruhn</span> <span class="affiliation">University of Duisburg-Essen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Cars offer an increasing number of infotainment systems as well as comfort functions that can be controlled by the driver. In our research, we investigate new interaction techniques that aim to make it easier to interact with these systems while driving. We suggest utilizing the steering wheel as an additional interaction surface. In this paper, we present two user studies conducted with a working prototype of a multi-touch steering wheel. In the first, we developed a user-defined steering wheel gesture set, and in the second, we applied the identified gestures and compared their application to conventional user interaction with infotainment systems in terms of driver distraction. The main outcome was that driver's visual demand is reduced significantly by using gestural interaction on the multi-touch steering wheel.</span></div></div><div class="paper" id="paper1253"><a href="#paper1253" class="title">Usability of Car Dashboard Displays for Elder Drivers</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979011&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">SeungJun  Kim</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Anind  Dey</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Joonhwan  Lee</span> <span class="affiliation">Neowiz Lab</span>, <br />
<span class="author">Jodi  Forlizzi</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The elder population is rising worldwide; in the US, no longer being able to drive is a significant marker of loss of independence. One of the approaches to helping elders drive more safely is to investigate the use of automotive user interface technology, and specifically, to explore the instrument panel (IP) display design to help attract and manage attention and make information easier to interpret. <br /> In this paper, we explore the premise that dashboard displays can be better designed to support elder drivers, their information needs, and their cognitive capabilities. We conducted a study to understand which display design features are critically linked to issues of divided attention and driving performance. We found that contrast of size and reduced clutter are instrumental in enhancing driving performance, particularly for the elder population. Surprisingly, our results showed that color elements have a negative effect on driving performance for elders, while color elements and fills slightly improve performance. We conclude with design implications generated from this work. <br /></span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">16:00<br />-<br />17:20</td>

<td class="session " id="S1077">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1077" class="title">Standards and Policy SIG</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1082">
<div class="session_box">
<span class="type">alt.chi</span>
<a href="#S1082" class="title">alt.chi: Playing Well With Others</a>
<span class="location">119/120</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1076">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1076" class="title">Future of Natural UIs</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1086">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1086" class="title">Tagging</a>
<span class="location">211</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1091">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1091" class="title">Pointing 1</a>
<span class="location">223/224</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1085">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1085" class="title">Human-Robot Interaction</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1089">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1089" class="title">Identity &amp; Virtual Social Interactions</a>
<span class="location">217/218/219</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1090">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1090" class="title">Gestures, Body &amp; Touch</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1084">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1084" class="title">Health 3: Online Communities &amp; Social Interaction</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1087">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1087" class="title">HCI for All</a>
<span class="location">212/213/214</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1078">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1078" class="title">Designing for User Experience: Academia &amp; Industry</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1088">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1088" class="title">Emotional States</a>
<span class="location">215/216</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="12" class="session_details" id="S1077_details"><div class="paper" id="si112"><a href="#si112" class="title">Standards and Policy SIG</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979528&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Arnie  Lund</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Jonathan  Lazar</span> <span class="affiliation">Towson University</span>, <br />
<span class="author">Volker  Wulf</span> <span class="affiliation">University of Siegen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The Standards and Policy SIG will provide an opportunity for SIGCHI communities and others to share activity in the standards and policies relevant to HCI in their respective areas.  There are two goals for the SIG.  One is to collect a list of resources that may be useful for SIGCHI researchers and practitioners.  The other is to identify new opportunities for SIGCHI to provide leadership in the standards and policy area; and to uncover areas where SIGCHI should be coordinating with other societies in areas that impact HCI standards and policies.</span></div></div></td>
<td colspan="12" class="session_details" id="S1082_details"><div class="sessionChair"><strong>Session Chair: </strong>Floyd Mueller (<em>CSIRO</em>)</div><div class="paper" id="al159"><a href="#al159" class="title">RopePlus: Bridging Distances with Social and Kinesthetic Rope Games</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979611&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lining  Yao</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Sayamindu  Dasgupta</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Nadia  Cheng</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Jason  Spingarn-Koff</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Ostap  Rudakevych</span> <span class="affiliation">Harvard University</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Rope-based games such as jump rope, tug-of-war, and kite-flying promote physical activity and social interaction among people of all ages and especially in children during the development of their coordination skills and physical fitness. Our RopePlus system builds on those traditional games by enabling players to participate remotely through interacting with ropes that connect physical and virtual spaces. The RopePlus platform is centered around the rope as a tangible interface with various hardware extensions to allow for multiple playing modes. In this paper, we present two games that have been implemented in detail: a kite-flying game called Multi-Fly and a jump-rope game called Multi-Jump. Our work aims to expand tangible interface gaming to real time social playing environments.</span></div></div><div class="paper" id="al153"><a href="#al153" class="title">Communiclay: A Modular System for Tangible Telekinetic Communication</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979612&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hayes  Raffle</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Ruibing  Wang</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Karim  Seada</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce Communiclay, a modular construction system for tangible kinetic communication of gesture and form over a distance. Users assemble a number of Communiclay nodes into unique configurations, connect their creations to each others&#8217; Communiclay creations on a network, and then physically deform one creation to synchronously output those same gestures on the other networked creations. Communiclay builds on trends in tangible interfaces and explores the ways in which future actuated materials can enable a variety of tangible interfaces. We present applications that stem from past research in tangible media, and describe explorations that address ways in which people make meaning of remote communication through gesture and dynamic physical form. Our hypothesis is that current research in programmable matter will eventually converge with UI research; Communiclay demonstrates that we can begin to explore design and social issues with today&#8217;s technologies.  <br /></span></div></div><div class="paper" id="al170"><a href="#al170" class="title">The Magic Sock Drawer Project</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979613&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Gooch</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Leon  Watts</span> <span class="affiliation">University of Bath</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe the design of a intimate communication system, the Magic Sock Drawer. The system allows close friends to send drawn or typed digital notes to one another which are then automatically printed at the other end. The system allows us to investigate a number of design decisions that will have an impact on how communication systems create feelings of closeness between remote partners. The four design concepts explored include 1-to-1 communication, personalization, tangibility and location. We present the results of a 6-week pilot study using the system and the impact it has had on the study participants&#8217; relationship.</span></div></div><div class="paper" id="al110"><a href="#al110" class="title">Predicting Personality with Social Media</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979614&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Golbeck</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Cristina  Robles</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Karen  Turner</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social media is a place where users present themselves to the world, revealing personal details and insights into their lives. We are beginning to understand how some of this information can be utilized to improve the users' experiences with interfaces and with one another. In this paper, we are interested in the personality of users. Personality has been shown to be relevant to many types of interactions; it has been shown to be useful in predicting job satisfaction, professional and romantic relationship success, and even preference for different interfaces. Until now, to accurately gauge users' personalities, they needed to take a personality test. This made it impractical to use personality analysis in many social media domains. In this paper, we present a method by which a user's personality can be accurately predicted through the publicly available information on their Facebook profile. We will describe the type of data collected, our methods of analysis, and the results of predicting personality traits through machine learning. We then discuss the implications this has for social media design, interface design, and broader domains.</span></div></div><div class="paper" id="al151"><a href="#al151" class="title">Inventive Leisure Practices: Understanding hacking communities as sites of sharing and innovation</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979615&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tricia  Wang</span> <span class="affiliation">UC San Diego</span>, <br />
<span class="author">Joseph 'Jofish'  Kaye</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Hacking, tinkering, DIY, and crafts are increasingly popular forms of leisure that have also become growing sites of study in HCI.  In this work we take a wide view of the similarities and differences between these practices. We explore a broad spectrum of such activities, which we collectively describe as inventive leisure practices (ILP). We ask how members of various hacking communities make sense of their practice and involvement, and discuss 8 themes we found in common in hackers&#8217; practices. We conclude by proposing a working definition for ILPs.</span></div></div><div class="paper" id="al106"><a href="#al106" class="title">Technologies and Social Learning in an Urban After-School Center</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979616&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Louise  Barkhuus</span> <span class="affiliation">UC San Diego</span>, <br />
<span class="author">Robert  Lecusay</span> <span class="affiliation">UC San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we explore this relationship between social learning environments and the technological ecologies that practitioners, learners, and researchers develop to sustain them. Through an examination of ethnographic research conducted at an urban after-school learning program we gain insight into social, technological and power infrastructures that influence learning and interaction in this setting. Adopting a holistic approach we examine how technologies are integrated into activities in this program to support the learning of the after-school youth. We emphasize both positive and negative infrastructures that contribute to the learning environment and discuss how identifying these infrastructures are one of the first steps towards understanding and informing technology design in informal learning settings.</span></div></div></td>
<td colspan="12" class="session_details" id="S1076_details"><div class="paper" id="si102"><a href="#si102" class="title">Future of Natural UIs</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979527&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jhilmil  Jain</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Arnold  Lund</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Dennis  Wixon</span> <span class="affiliation">Microsoft</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This SIG is a forum to advance an integrated approach to multi-modal Natural User Interfaces. Up until now the research and design of NUI interfaces for various modalities (speech, touch, gesture) has proceeded independently.  We propose having an integrated discussion with both academics and practitioners to stimulate the exchange of knowledge about the various modalities and how they might be fruitfully combined, and identifying key areas of future research and design that make the case for multi-modal NUIs. The goal is to not only create a vision of synthetic applications of NUI by connecting researchers but to also discuss ways to make the vision a reality.</span></div></div></td>
<td colspan="12" class="session_details" id="S1086_details"><div class="sessionChair"><strong>Session Chair: </strong>Jennifer Thom-Santelli (<em>IBM Research</em>)</div><div class="paper" id="to105"><a href="#to105" class="title">Semantic Imitation in Social Tagging</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Wai-Tat  Fu</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span>, <br />
<span class="author">Thomas  Kannampallil</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span>, <br />
<span class="author">Ruogu  Kang</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span>, <br />
<span class="author">Jibo  He</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a human information processing model of social tagging and exploratory search called the semantic imitation model. The model assumes that social tags evoke a spontaneous tag-based topic inference process that primes the semantic interpretation of resource contents during exploratory search, and the semantic priming of existing tags in turn influences future tag choices. The model assumes that information goals, imposed by the task demand and information need of the users, influence tag choices, but its effect is mediated by the semantic representation and interpretation of social tags.  The model predicts that (1) users who can see tags created by others (social tags) tend to create tags that are semantically similar to existing social tags, and (2) users who have similar information goals will create tags that are semantically similar to each other, but this effect is mediated by the semantic representation and interpretation of social tags. Results from the experiment comparing tagging behavior between a social group (where participants can see tags created by others) and a nominal group (where participants cannot see tags created by others) confirmed these predictions. The current results highlight the importance of human semantic representations and interpretation in the analysis of large-scale social information systems, and they are critical fro explaining the active, dynamic interactions between human knowledge structures and external folksonomies. Results also demonstrate that analysis at both the individual and social levels are important in understanding emergent patterns in social information systems. Implications on how social tagging systems can facilitate exploratory search, knowledge exchange, and other higher-level human learning activities are discussed.</span></div></div><div class="paper" id="paper2041"><a href="#paper2041" class="title">Examining the Impact of Collaborative Tagging on Sensemaking in Nutrition Management</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979037&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lena  Mamykina</span> <span class="affiliation">Columbia University</span>, <br />
<span class="author">Andrew  Miller</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Catherine  Grevet</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Yevgeniy  Medynskiy</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Michael  Terry</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Elizabeth  Mynatt</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Patricia  Davidson</span> <span class="affiliation">Cardiovascular Care Group</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Collaborative tagging mechanisms are integral to social computing applications in a variety of domains. Their expected benefits include simplified retrieval of digital content, as well as enhanced ability of a community to makes sense of the shared content. We examine the impact of collaborative tagging in context of nutrition management. In a controlled experiment we asked individuals to assess the nutritional value of meals based on photographic images and observed the impact of different types of tags and tagging mechanisms on individuals nutritional sensemaking. The results of the study show that tags enhance individuals&#8217; ability to remember the viewed meals. However, we found that some types of tags can be detrimental to sensemaking, rather than supporting it. These findings stress the importance of tagging vocabularies and suggest a need for expert moderation of community sensemaking.</span></div></div><div class="paper" id="to119"><a href="#to119" class="title">Personalization via Friendsourcing</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Michael  Bernstein</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Desney  Tan</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Greg  Smith</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Mary  Czerwinski</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Eric  Horvitz</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">When information is known only to friends in a social network, traditional crowdsourcing mechanisms struggle to motivate a large enough user population and to ensure accuracy of the collected information. We thus introduce friendsourcing, a form of crowdsourcing aimed at collecting accurate information available only to a small, socially-connected group of individuals. Our approach to friendsourcing is to design socially enjoyable interactions that produce the desired information as a side effect. <br />  <br /> We focus our analysis around Collabio, a novel social tagging game that we developed to encourage friends to tag one another within an online social network. Collabio encourages friends, family, and colleagues to generate useful information about each other. We describe the design space of incentives in social tagging games and evaluate our choices by a combination of usage log analysis and survey data. Data acquired via Collabio is typically accurate and augments tags that could have been found on Facebook or the Web. To complete the arc from data collection to application, we produce a trio of prototype applications to demonstrate how Collabio tags could be utilized: an aggregate tag cloud visualization, a personalized RSS feed, and a question and answer system. The social data powering these applications enables them to address needs previously difficult to support, such as question answering for topics comprehensible only to a few of a user's friends.</span></div></div><div class="paper" id="paper1131"><a href="#paper1131" class="title">Using Tags to Encourage Reflection and Annotation on Data During Nomadic Inquiry</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979038&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Kuhn</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Clara  Cahill</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Chris  Quintana</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Shannon  Schmoll</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Nomadic inquiry may benefit from tagging when used for educational purposes to support reflection and annotation during data collection. To that end we created Zydeco, a mobile system to scaffold learners through the science inquiry process in and out of the classroom, and tested it in a museum with 42 middle school students. Students report that tags encouraged reflection and annotation during data collection, suggesting that tagging can be used to support nomadic inquiry. From this work we present some emerging design recommendations for constructing similar systems.</span></div></div><div class="paper" id="paper1039"><a href="#paper1039" class="title">User Perceptions of the Role and Value of Tags</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979039&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yong-Mi  Kim</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Soo Young  Rieh</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study investigates user ideas about the role and value of tags in social media. An analysis of 45 interviews with heavy Web users reveals that user perceptions of tags differ from common assumptions held by researchers and designers of social tagging systems. Among beliefs held by participants were that tags were query suggestions or links to other pages, sites, or advertisements &#8211; although most identified tags as categories or keywords &#8211; and that tags were generated automatically by the computer system. Several participants believed that tags were intended for not only other users but also systems such as search engines. Our findings indicate that Web users, including those who are taggers themselves, experience a high level of uncertainty and confusion about the nature, purpose and value of tags.</span></div></div></td>
<td colspan="12" class="session_details" id="S1091_details"><div class="sessionChair"><strong>Session Chair: </strong>Emmanuel Pietriga (<em>INRIA; Univ. Paris-Sud &amp; CNRS</em>)</div><div class="paper" id="paper143"><a href="#paper143" class="title">TorusDesktop: Pointing via the Backdoor is Sometimes Shorter</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979064&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">St&#233;phane  Huot</span> <span class="affiliation">Universit&#233; Paris-Sud, CNRS &amp; INRIA</span>, <br />
<span class="author">Olivier  Chapuis</span> <span class="affiliation">CNRS, Universit&#233; Paris-Sud &amp; INRIA</span>, <br />
<span class="author">Pierre  Dragicevic</span> <span class="affiliation">INRIA</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">When pointing to a target on a computer desktop, we may think we are taking the shortest possible path.  But new shortcuts become possible if we allow the mouse cursor to jump from one edge of the screen to the opposite one, i.e., if we turn the desktop into a torus.  We discuss the design of TorusDesktop, a pointing technique that allows to wrap the cursor around screen edges to open this pointing backdoor.  A dead zone and an off-screen cursor feedback make the technique more usable and more compatible with everyday desktop usage.  We report on three controlled experiments conducted to refine the design of the technique and evaluate its performance.  The results suggest clear benefits of using the backdoor when target distance is more than 80<br />% the screen size in our experimental conditions.</span></div></div><div class="paper" id="paper1748"><a href="#paper1748" class="title">Comet and Target Ghost: Techniques for Selecting  Moving Targets</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979065&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Khalad  Hassan</span> <span class="affiliation">University of Manitoba</span>, <br />
<span class="author">Tovi  Grossman</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">Pourang  Irani</span> <span class="affiliation">University of Manitoba</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Numerous applications such as simulations, air traffic control systems, and video surveillance systems are inherently composed of spatial objects that move in a scene. In many instances, users can benefit from tools that allow them to select these targets in real-time, without having to pause the dynamic display. However, selecting moving objects is considerably more difficult and error prone than selecting stationary targets. In this paper, we evaluate the effectiveness of several techniques that assist in selecting moving targets. We present Comet, a technique that enhances tar-gets based on their speed and direction. We also introduce Target Ghost, which allows users to select a static proxy of the target, while leaving the motion uninterrupted. We found a speed benefit for the Comet in a 1D selection task in comparison to other cursor and target enhancements. For 2D selection, Comet outperformed Bubble cursor but only when Target Ghost was not available. We conclude with guidelines for design.</span></div></div><div class="paper" id="paper718"><a href="#paper718" class="title">Acquiring and Pointing:  An Empirical Study of Pen-Tilt-Based Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979066&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yizhong  Xin</span> <span class="affiliation">Kochi University of Technology</span>, <br />
<span class="author">Xiaojun  Bi</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Xiangshi  Ren</span> <span class="affiliation">Kochi University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Research literature has shown that pen tilt is a promising input modality in pen-based interaction. However, the human capability to control pen tilt has not been fully evaluated. This paper systematically investigates the human ability to perform discrete target selection tasks by varying the stylus' tilt angle through two controlled experiments: pen tilt target acquiring  (Experiment 1) and tilt pointing (Experiment 2). Results revealed a decreasing power relationship between angular width and selection time in Experiment 1. The results of Experiment 2 confirmed that pen tilt pointing can be modeled by Fitts' law. Based on our quantitative analysis, we discuss the human ability to control pen tilt and the implications of pen tilt use. We also propose a taxonomy of pen tilt based interaction techniques and showcase a series of possible pen tilt technique designs.</span></div></div><div class="paper" id="paper1452"><a href="#paper1452" class="title">On the Costs of Multiple Trajectory Pointing Methods</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979067&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Philip  Quinn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Kari-Jouko  R&#228;ih&#228;</span> <span class="affiliation">University of Tampere</span>, <br />
<span class="author">Jerome  Delamarche</span> <span class="affiliation">Polytech Paris-Sud</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Several enhanced pointing techniques aim to reduce the Fitts&#8217; law targeting distance by providing multiple target trajectories in the hope that a shorter path is available. However, these techniques introduce a search or decision component to pointing -&#8211; users must examine the alternatives available and decide upon the trajectory to use. We analyse these difficulties, present a methodology for examining them as well as other behaviour issues, and report empirical results of performance with pointer wrapping and Ninja cursors. Results show that offering multiple trajectories incurs a significant search or decision cost, and that users are therefore poor at capitalising on the theoretical benefits of reduced target distance.</span></div></div><div class="paper" id="paper1377"><a href="#paper1377" class="title">Cursor Relocation Techniques to Help Older Adults Find &#8216;Lost&#8217; Cursors</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979068&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nic  Hollinworth</span> <span class="affiliation">University of Reading</span>, <br />
<span class="author">Faustina  Hwang</span> <span class="affiliation">University of Reading</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Older adult computer users often lose track of the mouse cursor and so resort to methods such as mouse shaking or searching the screen to find the cursor again. Hence, this paper describes how a standard optical mouse was modified to include a touch sensor, activated by releasing and touching the mouse, which automatically centers the mouse cursor to the screen, potentially making it easier to find a &#8216;lost&#8217; cursor. Six older adult computer users and six younger computer users were asked to compare the touch sensitive mouse with cursor centering with two alternative techniques for locating the mouse cursor: manually shaking the mouse and using the Windows sonar facility. The time taken to click on a target following a distractor task was recorded, and results show that centering the mouse was the fastest to use, with a 35% improvement over shaking the mouse. Five out of six older participants ranked the touch sensitive mouse with cursor centering as the easiest to use.</span></div></div></td>
<td colspan="12" class="session_details" id="S1085_details"><div class="sessionChair"><strong>Session Chair: </strong>Alonso Vera (<em>NASA Ames Research Center</em>)</div><div class="paper" id="paper182"><a href="#paper182" class="title">Direct Manipulation Through Surrogate Objects</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979033&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Bum chul  Kwon</span> <span class="affiliation">Purdue University</span>, <br />
<span class="author">Waqas  Javed</span> <span class="affiliation">Purdue University</span>, <br />
<span class="author">Niklas  Elmqvist</span> <span class="affiliation">Purdue University</span>, <br />
<span class="author">Ji Soo  Yi</span> <span class="affiliation">Purdue University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Direct manipulation has had major influence on interface design since it was proposed by Shneiderman in 1982.  Although directness generally benefits users, direct manipulation also has weaknesses.  In some cases, such as when a user needs to manipulate small, attribute-rich objects or multiple objects simultaneously, indirect manipulation may be more efficient at the cost of directness or intuitiveness of the interaction.  Several techniques have been developed over the years to address these issues, but these are all isolated and limited efforts with no coherent underlying principle.  We propose the notion of Surrogate Interaction that ties together a large subset of these techniques through the use of a surrogate object that allow users to interact with the surrogate instead of the domain object.  We believe that formalizing this family of interaction techniques will provide an additional and powerful interface design alternative for interaction designers, as well as uncover opportunities for future research.</span></div></div><div class="paper" id="paper1359"><a href="#paper1359" class="title">An Actuated Physical Puppet as an Input Device for Controlling a Digital Manikin</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979034&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wataru  Yoshizaki</span> <span class="affiliation">NAIST AIST</span>, <br />
<span class="author">Yuta  Sugiura</span> <span class="affiliation">Keio University, JST ERATO</span>, <br />
<span class="author">Albert  C Chiou</span> <span class="affiliation">JST ERTO</span>, <br />
<span class="author">Sunao  Hashimoto</span> <span class="affiliation">JST ERATO</span>, <br />
<span class="author">Masahiko  Inami</span> <span class="affiliation">Keio University ,JST ERATO</span>, <br />
<span class="author">Takeo  Igarashi</span> <span class="affiliation">The University of Tokyo, JST ERATO</span>, <br />
<span class="author">Yoshiaki  Akazawa</span> <span class="affiliation">AIST</span>, <br />
<span class="author">Katsuaki  Kawachi</span> <span class="affiliation">AIST</span>, <br />
<span class="author">Satoshi  Kagami</span> <span class="affiliation">AIST NAIST</span>, <br />
<span class="author">Masaaki  Mochimaru</span> <span class="affiliation">AIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an actuated handheld puppet system for controlling the posture of a virtual character. Physical puppet devices have been used in the past to intuitively control character posture. In our research, an actuator is added to each joint of such an input device to provide physical feedback to the user. This enhancement offers many benefits. First, the user can upload pre-defined postures to the device to save time. Second, the system is capable of dynamically adjusting joint stiffness to counteract gravity, while allowing control to be maintained with relatively little force. Third, the system supports natural human body behaviors, such as whole-body reaching and joint coupling. This paper describes the user interface and implementation of the proposed technique and reports the results of expert evaluation. We also conducted two user studies to evaluate the effectiveness of our method.</span></div></div><div class="paper" id="paper1686"><a href="#paper1686" class="title">Roboshop: Multi-layered Sketching Interface For Robot Housework Assignment and Management</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979035&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kexi  Liu</span> <span class="affiliation">Louisiana State University and JST ERATO Igarashi Design Interface Project</span>, <br />
<span class="author">Daisuke  Sakamoto</span> <span class="affiliation">JST ERATO Igarashi Design Interface Project</span>, <br />
<span class="author">Masahiko  Inami</span> <span class="affiliation">Keio University and JST ERATO Igarashi Design Interface Project</span>, <br />
<span class="author">Takeo  Igarashi</span> <span class="affiliation">The University of Tokyo and JST ERATO Igarashi Design Interface Project</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As various home robots come into homes, the need for efficient robot task management tools is arising. Current tools are designed for controlling individual robots independently, so they are not ideally suitable for assigning coordinated action among multiple robots. To address this problem, we developed a management tool for home robots with a graphical editing interface. The user assigns instructions by selecting a tool from a toolbox and sketching on a bird&#8217;s-eye view of the environment. Layering supports the management of multiple tasks in the same room. Layered graphical representation gives a quick overview of and access to rich information tied to the physical environment. This paper describes the prototype system and reports on our evaluation of the system.</span></div></div><div class="paper" id="cs184"><a href="#cs184" class="title">The Shape of Simon: Creative Design of a Humanoid Robot Shell</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979648&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Carla  Diana</span> <span class="affiliation">Smart Design</span>, <br />
<span class="author">Andrea L Thomaz</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In the study of human-robot interaction, the aesthetic <br /> design of socially active machines is a relatively new <br /> endeavor, and there are few precedents on which to <br /> rely for guidance. Whereas some of the early social <br /> robots such as Kismet [1] had expressive body <br /> characteristics such as eyeballs, eyelids and ears, the <br /> form was not unified into a holistic design. That is, <br /> features varied from one another in aesthetic <br /> characteristics, and the overall form still gave the <br /> impression of being a metal frame to which a series of <br /> parts were affixed. As subsequent social robots have <br /> been developed, they have varied wildly in terms of <br /> overall aesthetic creative direction. In the development <br /> of Simon, a humanoid robot currently in progress at the <br /> Georgia Institute of Technology, the authors sought to <br /> give industrial design an important role, and included <br /> creative direction at the very start of the project. <br /> Mechanical design, AI development and industrial <br /> design were all explored in tandem. The shell design, <br /> particularly for the head, was not looked upon as an <br /> external layer that would sheath the underlying <br /> mechanisms, but rather a core means for defining the <br /> robot&#8217;s entire movement and behavioral characteristics.</span></div></div></td>
<td colspan="12" class="session_details" id="S1089_details"><div class="sessionChair"><strong>Session Chair: </strong>Kori Inkpen (<em>Microsoft Research</em>)</div><div class="paper" id="paper687"><a href="#paper687" class="title">Introverted Elves &amp; Conscientious Gnomes: The Expression of Personality in World of Warcraft</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979052&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nick  Yee</span> <span class="affiliation">Palo Alto Research Center</span>, <br />
<span class="author">Nicolas  Ducheneaut</span> <span class="affiliation">Palo Alto Research Center</span>, <br />
<span class="author">Les  Nelson</span> <span class="affiliation">Palo Alto Research Center</span>, <br />
<span class="author">Peter  Likarish</span> <span class="affiliation">University of Iowa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Personality inference can be used for dynamic personalization of content or system customization. In this study, we examined whether and how personality is expressed in Virtual Worlds (VWs). Survey data from 1,040 World of Warcraft players containing demographic and personality variables was paired with their VW behavioral metrics over a four-month period. Many behavioral cues in VWs were found to be related to personality. For example, Extraverts prefer group activities over solo activities. We also found that these behavioral indicators can be used to infer a play-er&#8217;s personality.</span></div></div><div class="paper" id="paper2172"><a href="#paper2172" class="title">Starcraft from the Stands: Understanding the Game Spectator</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979053&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gifford  Cheung</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jeff  Huang</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Video games are primarily designed for the players. However, video game spectating is also a popular activity, boosted by the rise of online video sites and major gaming tournaments. In this paper, we focus on the spectator, who is emerging as an important stakeholder in video games. Our study focuses on Starcraft, a popular real-time strategy game with millions of spectators and high level tournament play. We have collected over a hundred stories of the Starcraft spectator from online sources, aiming for as diverse a group as possible. We make three contributions using this data: i) we find nine personas in the data that tell us who the spectators are and why they spectate; ii) we strive to understand how different stakeholders, like commentators, players, crowds, and game designers, affect the spectator experience; and iii) we infer from the spectators' expressions what makes the game entertaining to watch, forming a theory of distinct types of information asymmetry that create suspense for the spectator. One design implication derived from these findings is that, rather than presenting as much information to the spectator as possible, it is more important for the stakeholders to be able to decide how and when they uncover that information.</span></div></div><div class="paper" id="paper743"><a href="#paper743" class="title">Do Men Heal More When in Drag? Conflicting Identity Cues Between User and Avatar</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979054&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nick  Yee</span> <span class="affiliation">Palo Alto Research Center</span>, <br />
<span class="author">Nicolas  Ducheneaut</span> <span class="affiliation">Palo Alto Research Center</span>, <br />
<span class="author">Mike  Yao</span> <span class="affiliation">City University of Hong Kong</span>, <br />
<span class="author">Les  Nelson</span> <span class="affiliation">Palo Alto Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Studies in the Proteus Effect have shown that users conform to stereotypes associated with their avatar&#8217;s appearance. In this study, we used longitudinal behavioral data from 1,040 users in a virtual world to examine the behavioral outcome of conflicting gender cues between user and avatar. We found that virtual gender had a significant effect on in-game behaviors for both healing and player-vs-player activity.</span></div></div><div class="paper" id="paper1190"><a href="#paper1190" class="title">Is the Media Equation a Flash in the Pan? The Durability and Longevity of Social Responses to Computers.</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979055&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Laura M Pfeifer</span> <span class="affiliation">Northeastern University</span>, <br />
<span class="author">Timothy  Bickmore</span> <span class="affiliation">Northeastern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Research on social responses to computers often assesses only first-impression reactions during a single experimental session, providing limited knowledge about the lasting effect of the results. In this work, we assess the lasting strength of social desirability bias effects on an interface designed to track exercise, manipulated to have high or low personalization (text vs. anthropomorphic conversational character). After 40 days of daily interactions by 25 participants, we found that self-reported exercise was more accurate when reported to the character vs. text. We also find that, for both conditions, participants' decision to initiate a session is greater when they have done more exercise. Moreover, we show that this effect significantly increases over time for participants in the character condition, and decreases for participants in the text condition. This study demonstrates that Media Equation effects can grow stronger or weaker over time, depending upon the presentation of the interface.</span></div></div><div class="paper" id="paper1868"><a href="#paper1868" class="title">What Drives Customization? Control or Identity?</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979056&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sampada  Marathe</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">S. Shyam  Sundar</span> <span class="affiliation">The Pennsylvania State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Customization &#8211; an attribute that lets users take control and make changes to the presentation and functionality of the interface &#8211; is becoming a hallmark of today&#8217;s interactive media devices. What do users experience when they change interface aspects like fonts and colors, skins on mobile phones, speed dial numbers, privacy settings on social networks and different command menus in software? Do they feel in control? Do they see the customized interface as a reflection of who they are? More importantly, is the feeling of being in control a major driver of usage, or does sense of identity &#8211; a personal connection with the interface &#8211; prove more vital? This paper discusses the psychology of customization, reports an empirical user study designed to explore the relationship between customization, sense of control, and sense of identity, and outlines implications for design of customizable interfaces based on the findings.</span></div></div></td>
<td colspan="12" class="session_details" id="S1090_details"><div class="sessionChair"><strong>Session Chair: </strong>Steve Benford (<em>University of Nottingham</em>)</div><div class="paper" id="paper745"><a href="#paper745" class="title">Your Noise is My Command: Sensing Gestures Using the Body as an Antenna</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979058&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gabe  Cohn</span> <span class="affiliation">Microsoft Research, University of Washington</span>, <br />
<span class="author">Daniel  Morris</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Shwetak N Patel</span> <span class="affiliation">Microsoft Research, University of Washington</span>, <br />
<span class="author">Desney S Tan</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch sensing and computer vision have made human-computer interaction possible in environments where keyboards, mice, or other handheld implements are not available or desirable. However, the high cost of instrumenting environments limits the ubiquity of these technologies, particularly in home scenarios where cost constraints dominate installation decisions. Fortunately, home environments frequently offer a signal that is unique to locations and objects within the home: electromagnetic noise. In this work, we use the body as a receiving antenna and leverage this noise for gestural interaction. We demonstrate that it is possible to robustly recognize touched locations on an uninstrumented home wall using no specialized sensors. We conduct a series of experiments to explore the capabilities that this new sensing modality may offer. Specifically, we show robust classification of gestures such as the position of discrete touches around light switches, the particular light switch being touched, which appliances are touched, differentiation between hands, as well as continuous proximity of hand to the switch, among others. We close by discussing opportunities, limitations, and future work.</span></div></div><div class="paper" id="paper883"><a href="#paper883" class="title">Sensor Synaesthesia: Touch in Motion, and Motion in Touch</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979059&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ken  Hinckley</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Hyunyoung  Song</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We explore techniques for hand-held devices that leverage the multimodal combination of touch and motion. Hybrid touch + motion gestures exhibit interaction properties that combine the strengths of multi-touch with those of motion-sensing. This affords touch-enhanced motion gestures, such as one-handed zooming by holding one&#8217;s thumb on the screen while tilting a device. We also consider the reverse perspective, that of motion-enhanced touch, which uses motion sensors to probe what happens underneath the surface of touch. Touching the screen induces secondary accelerations and angular velocities in the sensors. For example, our prototype uses motion sensors to distinguish gently swiping a finger on the screen from &#8220;drags with a hard onset&#8221; to enable more expressive touch interactions.</span></div></div><div class="paper" id="paper720"><a href="#paper720" class="title">Data Miming: Inferring Spatial Object Descriptions from Human Gesture</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979060&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christian  Holz</span> <span class="affiliation">Hasso Plattner Institute</span>, <br />
<span class="author">Andrew  Wilson</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Speakers often use hand gestures when talking about or describing physical objects. Such gesture is particularly useful when the speaker is conveying distinctions of shape that are difficult to describe verbally. We present data miming&#8212;an approach to making sense of gestures as they are used to describe concrete physical objects. We first observe participants as they use gestures to describe real-world objects to another person. From these observations, we derive the data miming approach, which is based on a voxel representation of the space traced by the speaker&#8217;s hands over the duration of the gesture. In a final proof-of-concept study, we demonstrate a prototype implementation of matching the input voxel representation to select among a database of known physical objects.</span></div></div><div class="paper" id="paper823"><a href="#paper823" class="title">Understanding Naturalness and Intuitiveness in Gesture Production: Insights for Touchless Gestural Interfaces</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979061&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sukeshini A Grandhi</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Gina  Joue</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Irene  Mittelberg</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores how interaction with systems using touchless gestures can be made intuitive and natural. Analysis of 912 video clips of gesture production from a user study of 16 subjects communicating transitive actions  (manipulation of objects with or without external tools) indicated that 1) dynamic pantomimic gestures where imagined tool/object is explicitly held are performed more intuitively and easily than gestures where a body part is used to represent the tool/object or compared to static hand poses and 2) gesturing while communicating the transitive action as how the user habitually performs the action (pantomimic action) is perceived to be easier and more natural than gesturing while communicating it as an instruction. These findings provide guidelines for the characteristics of gestures and user mental models one must consciously be concerned with when designing and implementing gesture vocabularies of touchless interaction.</span></div></div><div class="paper" id="paper2215"><a href="#paper2215" class="title">The impact on musculoskeletal system during multitouch tablet interactions</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979062&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cecil  Lozano</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Devin  Jindrich</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Kanav  Kahol</span> <span class="affiliation">Arizona State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">HCI researchers and technologists have heralded multitouch interaction as the technology to drive computing systems into the future. However, as we move towards a world where interaction is based on human body movements that are not well documented or studied, we face a serious and a grave risk of creating technology and systems that may lead to musculoskeletal disorders (MSD&#8217;s). Designers need to be empowered with objective data on the impact of multitouch interactions on the musculoskeletal system to make informed choices in interaction design. In this paper we present an experiment that documents kinematic (movement) and kinetic measures (EMG) when interacting with a multitouch tablet. Results show that multitouch interaction can induce significant stress that may lead to MSDs and care must be taken when designing multitouch interaction.</span></div></div></td>
<td colspan="12" class="session_details" id="S1084_details"><div class="sessionChair"><strong>Session Chair: </strong>Julie Kientz (<em>University of Washington</em>)</div><div class="paper" id="paper209"><a href="#paper209" class="title">Competing Online Viewpoints and Models of Chronic Illness</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979027&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Mankoff</span> <span class="affiliation">Carnegie Mellon</span>, <br />
<span class="author">Kateryna  Kuksenok</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Sara  Kiesler</span> <span class="affiliation">Carnegie Mellon</span>, <br />
<span class="author">Jennifer A.  Rode</span> <span class="affiliation">Drexel University</span>, <br />
<span class="author">Kelly  Waldman</span> <span class="affiliation">Duke University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">People with chronic health problems use online resources to understand and manage their condition, but many such resources can present competing and confusing viewpoints. We surveyed and interviewed with people experiencing prolonged symptoms after a Lyme disease diagnosis. We explore how competing viewpoints in online content affect participants&#8217; understanding of their disease. Our results illustrate how chronically ill people search for information and support, and work to help others over time. Participant identity and beliefs about their illness evolved, and this led many to take on new roles, creating content and advising others who were sick. What we learned about online content creation suggests a need for designs that support this journey and engage with complex issues surrounding online health resources.</span></div></div><div class="paper" id="paper2278"><a href="#paper2278" class="title">Using Interface Cues in Online Health Community Boards to Change Impressions and Encourage User Contribution</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979028&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hyang-Sook  Kim</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">S. Shyam  Sundar</span> <span class="affiliation">The Pennsylvania State University / Sungkyunkwan University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Online health message boards have become popular, as users not only gain information from other users but also share their own experiences. However, as with most venues of user-generated content, there is need to constantly make quality evaluations as one sifts through enormous amounts of content. Can interface cues, conveying (1) pedigree of users posting content and (2) popularity of the posted content, help new users efficiently make credibility assessments? Furthermore, can the assignment of these same cues to their own posts serve to motivate content generation on their part? These questions were investigated in a 2-session between-subjects experiment (N = 99) with a prototype of a message-board that experimentally varied interface cues, and found that popularity indicators are more influential than pedigree indicators for both evaluation of existing content and contribution of new content. Findings also suggest theoretical mechanisms&#8212;involving such concepts as perceived authority, bandwagon effects, sense of agency and sense of community&#8212;by which cues affect user experience, providing rich implications for designing and deploying interface cues.</span></div></div><div class="paper" id="paper880"><a href="#paper880" class="title">ACES: Promoting Empathy Towards Aphasia Through Language Distortion Emulation Software</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979029&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joshua  Hailpern</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Marina  Danilevsky</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Andrew  Harris</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Karrie  Karahalios</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Gary  Dell</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Julie  Hengst</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Individuals with aphasia, an acquired communication disorder, constantly struggle against a world that does not understand them. This lack of empathy and understanding negatively impacts their quality of life. While aphasic individuals may appear to have lost cognitive functioning, their impairment relates to receptive and expressive language, not to thinking processes. We introduce a novel system and model, Aphasia Characteristics Emulation Software (ACES), enabling users (e.g., caregivers, speech therapists and family) to experience, firsthand, the communication-distorting effects of aphasia. By allowing neurologically typical individuals to &#8220;walk in another&#8217;s shoes,&#8221; we aim to increase patience, awareness and understanding. ACES was grounded in the communication science and psychological literature, and informed by an initial pilot study. Results from an evaluation of 64 participants indicate that ACES provides a rich experience that increases understanding and empathy for aphasia.</span></div></div><div class="paper" id="paper798"><a href="#paper798" class="title">Cueing for Drooling in Parkinson's Disease</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979030&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Roisin  McNaney</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Stephen  Lindsay</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Karim  Ladha</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Cassim  Ladha</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Guy  Schofield</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Thomas  Ploetz</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Nils  Hammerla</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Daniel  Jackson</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Richard  Walker</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Nick  Miller</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the development of a socially acceptable cueing device for drooling in Parkinson&#8217;s disease (PD). Sialorrhea, or drooling, is a significant problem associated with PD and has a strong negative emotional impact on those who experience it. Previous studies have shown the potential for managing drooling by using a cueing device. However, the devices used in these studies were deemed unacceptable by their users due to factors such as hearing impairment and social embarrassment. We conducted exploratory scoping work and high fidelity iterative prototyping with people with PD to get their input on the design of a cueing aid and this has given us an insight into challenges that confront users with PD and limit device usability and acceptability. The key finding from working with people with PD was the need for the device to be socially acceptable.</span></div></div><div class="paper" id="paper647"><a href="#paper647" class="title">Evaluating Swabbing: a Touchscreen Input Method for Elderly Users with Tremor</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979031&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chat  Wacharamanotham</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Hurtmanns</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Alexander  Mertens</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Martin  Kronenbuerger</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Christopher  Schlick</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Elderly users suffering from hand tremor have difficulties interacting with touchscreens because of finger oscillation. It has been previously observed that sliding one's finger across the screen may help reduce this oscillation. In this work, we empirically confirm this advantage by (1) measuring finger oscillation during different actions and (2) comparing error rate and user satisfaction between traditional tapping and swabbing in which the user slides his finger towards a target on a screen edge to select it. We found that oscillation is generally reduced during sliding. Also, compared to tapping, swabbing resulted in improved error rates and user satisfaction. We believe that swabbing will make touchscreens more accessible to senior users with tremor.</span></div></div></td>
<td colspan="12" class="session_details" id="S1087_details"><div class="sessionChair"><strong>Session Chair: </strong>Michael Muller (<em>IBM Research</em>)</div><div class="paper" id="paper1899"><a href="#paper1899" class="title">Towards a Feminist HCI Methodology: Social Science, Feminism, and HCI</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979041&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Jeffrey  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With substantial efforts in ubiquitous computing, ICT4D, and sustainable interaction design, among others, HCI is increasingly engaging with matters of social change that go beyond the immediate qualities of interaction. In doing so, HCI takes on scientific and moral concerns. This paper explores the potential for feminist social science to contribute to and potentially benefit from HCI&#8217;s rising interest in social change. It describes how feminist contributions to debates in the philosophy of science have helped clarify relationships among objectivity, values, data collection and interpretation, and social consequences. Feminists have proposed and implemented strategies to pursue scientific and moral agendas together and with equal rigor. In this paper, we assess the epistemologies, methodologies, and methods of feminist social science relative to prior and on-going research efforts in HCI. We conclude by proposing an outline of a feminist HCI methodology.</span></div></div><div class="paper" id="paper460"><a href="#paper460" class="title">Out There</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979042&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex S. Taylor</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">&#8220;Out there&#8221; is increasingly becoming a topic of concern in HCI. Thanks to various clarion calls, researchers in the field are turning their attention to technology-mediated activities that are shaped less by Euro-American sensibilities and defined more by how they are culturally and geographically distinct. Fieldwork and ethnography researchers, for instance, are beginning to investigate ICT use at religious and spiritual sites, by the socially excluded and disenfranchised, and by people in developing regions. In this paper, I concentrate on the latter focus on development to reflect on HCI&#8217;s disciplinary turn &#8220;out there&#8221;. Specifically, I take the following three themes as common rhetorical devices in such work: (i) the network, (ii) difference and (iii) complexity. Through examples, I discuss how each of these themes has been mobilised. I then use materials from anthropology, science and technology studies, and to a lesser extent geography and postcolonial studies to complicate and in some cases question the interpretative frames that are being applied. Thus, my hope is that this paper is seen as a thought piece that deepens our thinking around HCI&#8217;s efforts to look &#8220;out there&#8221; by paying critical attention to what is going on &#8220;in here&#8221;.</span></div></div><div class="paper" id="paper2157"><a href="#paper2157" class="title">How HCI Talks about Sexuality: Discursive Strategies, Blind Spots, and Opportunities for Future Research</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979043&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gopinaath  Kannabiran</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Jeffrey  Bardzell</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The topic of sexuality has been increasingly researched inside the field of HCI. At the same time, and for many reasons, research gaps remain. In this paper, we present a critical analysis of 70 works on this topic spanning the past two decades to understand how we as an academic field talk about sexuality. We use Foucauldian discourse analysis to identify and analyze the various rules of knowledge production on this topic inside our field. By doing so, we expose not only existing gaps in current research literature, but we also gain an understanding of why some of them exist. We suggest some opportunities to make the field more amenable to this kind of research and point out future research directions on sexuality inside the field of HCI.</span></div></div><div class="paper" id="paper1886"><a href="#paper1886" class="title">In the Shadow of Misperception: Assistive Technology Use and Social Interactions</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979044&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kristen  Shinohara</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Few research studies focus on how the use of assistive technologies is affected by social interaction among people. We present an interview study of 20 individuals to determine how assistive technology use is affected by social and professional contexts and interactions. We found that specific assistive devices sometimes marked their users as having disabilities; that functional access took priority over feeling self-conscious when using assistive technologies; and that two misperceptions pervaded assistive technology use: (1) that assistive devices could functionally eliminate a disability, and (2) that people with disabilities would be helpless without their devices. Our findings provide further evidence that accessibility should be built into mainstream technologies. When this is not feasible, assistive devices should incorporate cutting edge technologies and strive to be designed for social acceptability, a new design approach we propose here.</span></div></div></td>
<td colspan="12" class="session_details" id="S1078_details"><div class="paper" id="pl115"><a href="#pl115" class="title">Designing for User Experience: Academia &amp; Industry</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979486&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joseph 'Jofish'  Kaye</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Elizabeth  Buie</span> <span class="affiliation">Luminanze Consulting</span>, <br />
<span class="author">Jettie  Hoonhout</span> <span class="affiliation">Philips Research</span>, <br />
<span class="author">Kristina  H&#246;&#246;k</span> <span class="affiliation">Mobile Life Centre</span>, <br />
<span class="author">Virpi  Roto</span> <span class="affiliation">University of Helsinki</span>, <br />
<span class="author">Scott  Jenson</span> <span class="affiliation">Google</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As the importance of user experience (UX) has grown, so too have attempts to define, delimit, categorize and theorize about it.  In particular, there have been emerging lines of tension in User Experience that parallel the tensions in the larger field of HCI research, particularly between approaches that emphasize the need for representations and understandings of user experience that are precise, comparable, and generalizable, and third-wave approaches that emphasize the richness of situated actions, the inseparability of mind and body, and the contextual dependency of experiences. At the same time, there are tensions between the needs of industry for immediately useful and applicable techniques and methods, and academics&#8217; emphasis on verifiable, repeatable, and theoretically grounded work. <br />  <br /> In this panel, we bring together a number of these threads to discuss the necessity of designing for user experience. How can we connect the different threads of UX work, without erasing the differences between them? Is there any value in theory of UX, and if so, to whom? What actually works in designing for a user experience?  <br /></span></div></div></td>
<td colspan="12" class="session_details" id="S1088_details"><div class="sessionChair"><strong>Session Chair: </strong>Darren Gergle (<em>Northwestern University</em>)</div><div class="paper" id="paper142"><a href="#paper142" class="title">Identifying Emotional States using Keystroke Dynamics</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979046&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Clayton  Epp</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Michael  Lippold</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Regan L Mandryk</span> <span class="affiliation">University of Saskatchewan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The ability to recognize emotions is an important part of building intelligent computers. Emotionally-aware systems would have a rich context from which to make appropriate decisions about how to interact with the user or adapt their system response. There are two main problems with current system approaches for identifying emotions that limit their applicability: they can be invasive and can require costly equipment. Our solution is to determine user emotion by analyzing the rhythm of their typing patterns on a standard keyboard. We conducted a field study where we collected participants&#8217; keystrokes and their emotional states via self-reports. From this data, we extracted keystroke features, and created classifiers for 15 emotional states. Our top results include 2-level classifiers for confidence, hesitance, nervousness, relaxation, sadness, and tiredness with accuracies ranging from 77 to 88%. In addition, we show promise for anger and excitement, with accuracies of 84%.</span></div></div><div class="paper" id="paper667"><a href="#paper667" class="title">PAM: A Photographic Affect Meter For Frequent, In Situ Measurement of Affect</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979047&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">John P Pollak</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Phil J Adams</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Geri  Gay</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The assessment of emotion, or affect, is critical for anyone trying to understand human behavior.  But there is a problem: affect as a state is frequently changing and difficult to recall and express, yet in research, we typically only assess it via a single questionnaire at the end of a study.  This work presents PAM, the Photographic Affect Meter, a novel tool for measuring affect in which users select from a wide variety of photos the one which best suits their current mood.  Our findings indicate that PAM--which takes seconds to complete and is designed to run on modern mobile phones and mobile computing devices--demonstrates strong construct validity across two studies and is very well suited for frequent sampling in context.  This work provides a tool to researchers in need of frequent assessment of affect and guidance to others interested in developing similar measurement tools.</span></div></div><div class="paper" id="paper461"><a href="#paper461" class="title">Affective Computational Priming and Creativity</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979048&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sheena  Lewis</span> <span class="affiliation">Technology and Social Behavior Northwestern University</span>, <br />
<span class="author">Mira  Dontcheva</span> <span class="affiliation">Advanced Technologies Lab Adobe Systems</span>, <br />
<span class="author">Elizabeth  Gerber</span> <span class="affiliation">Segal Design Institute Northwestern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While studies have shown that affect influences creativity, few investigate how affect influences creative performance with creativity support tools. Drawing from methods commonly used in psychology research, we present affective computational priming, a new method for manipulating affect using digitally embedded stimuli. We present two studies that explore computational techniques for inducing positive, neutral, and negative affect and examine the impact on idea generation with creativity support tools. Our results suggest that positive affective computational priming positively influences the quality of ideas generated. We discuss barriers and opportunities for future HCI research and practical applications of affective computational priming when designing creativity support tools.</span></div></div><div class="paper" id="paper1168"><a href="#paper1168" class="title">Upset Now?: Emotion Contagion in Distributed Groups</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979049&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jamie  Guillory</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Jason  Spiegel</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Molly  Drislane</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Benjamin  Weiss</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Walter  Donner</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Jeff  Hancock</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The importance of emotion to group outcomes in FtF highlights the need to understand emotion contagion in distributed groups. The present study examines the transfer of negative emotion in online groups. Negative emotion was induced in one of three group members completing a task in CMC. The data suggest that emotion contagion took place at the group level, with partners experiencing more negative emotion, more disagreement, higher verbosity, and use of more complex language in induced groups compared to control groups. Induced groups also performed better on the group task, raising questions about the effects of negative emotion contagion in online groups.</span></div></div><div class="paper" id="paper592"><a href="#paper592" class="title">Emotion Regulation for Frustrating Driving Contexts</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979050&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Helen  Harris</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Clifford  Nass</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Driving is a challenging task because of the physical, attentional, and emotional demands.  When drivers become frustrated by events their negative emotional state can escalate dangerously.  This study examines behavioral and attitudinal effects of cognitively reframing frustrating events.  Participants (N = 36) were asked to navigate a challenging driving course that included frustrating events such as long lights and being cut-off.  Drivers were randomly assigned to three conditions.  After encountering a frustrating event, drivers in a reappraisal-down condition heard voice prompts that reappraised the event in an effort to deflate negative reactions.  Drivers in the second group, reappraisal&#172;-up, heard voice prompts that brought attention to the negative actions of vehicles and pedestrians.  Drivers in a silent condition drove without hearing any voice prompts.  Participants in the reappraisal-down condition had better driving behavior and reported less negative emotions than participants in the other conditions.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">17:30<br />-<br />19:30</td>

<td class="session tbd" id="S1092">
<div class="session_box">
<span class="type"></span>
<a href="#S1092" class="title">Exhibit Hall Grand Opening Reception</a>
<span class="location">Ballroom C/D</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
</table>
</div>

<div class="day" id="day4"><h1>Tuesday, May 10, 2011</h1><table cellspacing="0" class="program" id="day_4">
<tr class="timeslot">
<td class="time">08:00<br />-<br />8:45</td>

<td class="session tbd" id="S1093">
<div class="session_box">
<span class="type"></span>
<a href="#S1093" class="title">Madness</a>
<span class="location">Ballroom A/B</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session tbd" id="S1094">
<div class="session_box">
<span class="type"></span>
<a href="#S1094" class="title">Registration Open</a>
<span class="location">Ballroom Foyer</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">09:00<br />-<br />10:00</td>

<td class="session " id="S1096">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1096" class="title">Designing for Whole Systems and Services in Healthcare</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1101">
<div class="session_box">
<span class="type"></span>
<a href="#S1101" class="title">Open</a>
<span class="location">119/120</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1095">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1095" class="title">Sustainability Community: Framework &amp; Agenda</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1102">
<div class="session_box">
<span class="type"></span>
<a href="#S1102" class="title">Open</a>
<span class="location">Ballroom 2, Renaissance Hotel</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1105">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1105" class="title">Everyday Information Management</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1110">
<div class="session_box">
<span class="type">alt.chi</span>
<a href="#S1110" class="title">alt.chi: ... and I just Can't Take it Anymore!</a>
<span class="location">223/224</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1104">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1104" class="title">Museums &amp; Public Exhibitions</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1108">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1108" class="title">Death &amp; Bereavement</a>
<span class="location">217/218/219</span>
<strong></strong>

</div>
</td>

<td class="session " id="S5002">
<div class="session_box">
<span class="type">Student Research Competition &amp; Works In Progress</span>
<a href="#S5002" class="title">Poster Group 1 Displayed</a>
<span class="location">Ballroom Foyer</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1109">
<div class="session_box">
<span class="type">Special Events</span>
<a href="#S1109" class="title">SIGCHI Lifetime Research Award</a>
<span class="location">220/221/222</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1103">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1103" class="title">Ambient &amp; Peripheral Computing</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1106">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1106" class="title">Low-cost ICT4D</a>
<span class="location">212/213/214</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1097">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1097" class="title">User Experience Management Post Mergers and Acquisitions</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1107">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1107" class="title">Predicting &amp; Modeling Human Behaviors</a>
<span class="location">215/216</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>
</tr>
<tr class="details_row"><td colspan="14" class="session_details" id="S1096_details"><div class="paper" id="si139"><a href="#si139" class="title">Designing for Whole Systems and Services in Healthcare</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979530&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Peter  Jones</span> <span class="affiliation">Redesign  OCAD University</span>, <br />
<span class="author">David  Cronin</span> <span class="affiliation">Smart Design</span>, <br />
<span class="author">Dean  Karavite</span> <span class="affiliation">Children&#8217;s Hospital of Philadelphia</span>, <br />
<span class="author">Ross  Koppel</span> <span class="affiliation">University of Pennsylvania</span>, <br />
<span class="author">Prudence  Dalrymple</span> <span class="affiliation">Drexel University</span>, <br />
<span class="author">Kai  Zheng</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Michelle  Rogers</span> <span class="affiliation">Drexel University</span>, <br />
<span class="author">Bob  Schumacher</span> <span class="affiliation">User Centric</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This CHI 2011 SIG provides a workshop for collective problem finding and community identification. The goal is to initiate a working group to coordinate systemic design research issues across practitioner communities. This SIG addresses the insufficiency of user-centered design and informatics research to design for system and service-level innovations in healthcare. The SIG seeks to coordinate communications and participation across design practice, research disciplines, and areas of health practice for service system innovation.</span></div></div></td>
<td colspan="14" class="session_details" id="S1095_details"><div class="paper" id="si107"><a href="#si107" class="title">Sustainability Community: Framework &amp; Agenda</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span><div class="authors"><span class="author">Azam  Khan</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">Eli  Blevis</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Daniela  Busse</span> <span class="affiliation">SAP</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This special interest group meeting will bring together human-computer interaction (HCI) researchers who are interested in applying their knowledge and skills to the environmental goals of sustainable production and sustainable consumption. Those new to HCI for sustainability will learn which support and opportunities there are for their contributions, while HCI researchers already working in this area will discover which activities are occurring within and outside the HCI community. A conceptual framework will be presented together with a call to action, followed by a review of past and current HCI activities surrounding sustainability. Finally, an open discussion will develop a reformulation of HCI sustainability research for future CHI meetings.</span></div></div></td>
<td colspan="14" class="session_details" id="S1105_details"><div class="sessionChair"><strong>Session Chair: </strong>David McDonald (<em>University of Washington</em>)</div><div class="paper" id="paper1545"><a href="#paper1545" class="title">&#8220;I Lie to Myself that I Have Freedom in My Own Schedule&#8221;: Productivity Tools and Experiences of Busyness</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979077&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gilly  Leshed</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Phoebe  Sengers</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper examines the relationship between experiences of busyness in everyday life and the use of productivity tools, including planners, calendars and to-do lists. Field study findings demonstrate that American individuals across a demographic range have internalized a cultural emphasis of busyness as a moral value to construct positive identities as busy individuals. At the same time, they struggle with a sense of conflict around busyness, reflected in real-life experiences of clashing priorities, fantasies of downtime, and struggles with anxiety, guilt, and loss of control. Our findings also point to the ways digital and non-digital productivity tools are embedded in experiences and coping practices around busyness. Grounded in our observations we propose design principles for productivity tools that support users&#8217; identities as busy people but also address some of the perils of the American busyness ethic.</span></div></div><div class="paper" id="paper386"><a href="#paper386" class="title">Homebrew Databases: Complexities of Everyday Information Management in Nonprofit Organizations</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979078&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amy  Voida</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Ellie  Harmon</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Ban  Al-Ani</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many people manage a complex assortment of digital information in their lives. Volunteer coordinators at nonprofit organizations are no exception; they collectively manage information about millions of volunteers every year. Yet current information management systems are insufficient for their needs. In this paper, we present results of a qualitative study of the information management practices of volunteer coordinators. We identify the resource constraints and the diverse and fluid information needs, stakeholders, and work contexts that motivate their information management strategies. We characterize the assemblages of information systems that volunteer coordinators have created to satisfice their needs as &#8216;homebrew databases.&#8217; Finally, we identify additional information management challenges that result from the use of these &#8216;homebrew databases,&#8217; highlighting deficiencies in the appropriateness and usability of databases and information management systems, more generally.</span></div></div><div class="paper" id="paper1188"><a href="#paper1188" class="title">How a Freeform Spatial Interface Supports Simple Problem Solving Tasks</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979079&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eser  Kandogan</span> <span class="affiliation">IBM Almaden Research Center</span>, <br />
<span class="author">Juho  Kim</span> <span class="affiliation">IBM Almaden Research Center, Stanford, MIT</span>, <br />
<span class="author">Thomas P. Moran</span> <span class="affiliation">IBM Almaden Research Center</span>, <br />
<span class="author">Pablo  Pedemonte</span> <span class="affiliation">IBM Argentina</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We developed DataBoard, a freeform spatial interface, to support users in simple problem solving tasks. To develop a deeper understanding of the role of space and the tradeoffs between freeform and structured interaction styles in problem solving tasks, we conducted a controlled user study comparing the DataBoard with a spreadsheet and analyzed video data in detail. Beyond improvements in task performance and memory recall, our observations reveal that freeform interfaces can support users in a variety of ways:  representing problems flexibly, developing strategies, executing strategies incrementally, tracking problem state easily, reducing mental computation, and verifying solutions perceptually. The spreadsheet also had advantages, and we discuss the tradeoffs.</span></div></div></td>
<td colspan="14" class="session_details" id="S1110_details"><div class="sessionChair"><strong>Session Chair: </strong>Patrick Baudisch (<em>Hasso Plattner Institute</em>)</div><div class="paper" id="al142"><a href="#al142" class="title">The Trouble with Social Computing Systems Research</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979618&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael S Bernstein</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Mark S Ackerman</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Ed H Chi</span> <span class="affiliation">Google, Inc.</span>, <br />
<span class="author">Robert C Miller</span> <span class="affiliation">MIT</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social computing has led to an explosion of research in understanding users, and it has the potential to similarly revolutionize systems research. However, the number of papers designing and building new sociotechnical systems has not kept pace. We analyze challenges facing social computing systems research, ranging from misaligned methodological incentives, evaluation expectations, double standards, and relevance compared to industry. We suggest improvements for the community to consider so that we can chart the future of our field.</span></div></div><div class="paper" id="al121"><a href="#al121" class="title">Form and Materiality in Interaction Design: A New Approach to HCI</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979619&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Heekyoung  Jung</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Erik  Stolterman</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper is motivated by the increasing significance of form in design and use of interactive artifacts. The objective of this paper is to conceptualize what we mean by form in the context of interaction design and HCI research and how we can approach it in regard to emerging type of digital materiality. To do this, we first examine conceptual dimensions of form in interactive artifacts through the lens of three existing perspectives with their respective focus on: material, meaning, and making. We then apply these perspectives in our analysis of specific forms of interactive artifacts. Based on this analysis, we suggest a model of four different types of forms: the cognitive, embodied, expressive, and exploratory forms. Reflecting on this model, we propose form-driven interaction design research with its epistemological and methodological implications.</span></div></div><div class="paper" id="al122"><a href="#al122" class="title">How Can We Support Users' Preferential Choice?</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979620&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anthony  Jameson</span> <span class="affiliation">DFKI</span>, <br />
<span class="author">Silvia  Gabrielli</span> <span class="affiliation">CREATE-NET</span>, <br />
<span class="author">Per Ola  Kristensson</span> <span class="affiliation">University of Cambridge</span>, <br />
<span class="author">Katharina  Reinecke</span> <span class="affiliation">Harvard University</span>, <br />
<span class="author">Federica  Cena</span> <span class="affiliation">University of Turin</span>, <br />
<span class="author">Cristina  Gena</span> <span class="affiliation">University of Turin</span>, <br />
<span class="author">Fabiana  Vernero</span> <span class="affiliation">University of Turin</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Users of computing technology are constantly making choices about how to use the technology which are "preferential" in the sense that there is no correct or incorrect option. We argue that HCI should devote more attention to helping users to make better preferential choices, tapping into the vast pool of relevant psychological research. After offering a quick high-level overview of this research, we introduce four general strategies for exploiting it in interaction design and illustrate these strategies with reference to examples.  Looking at selected other paradigms that involve influencing preferential choice, we explain how our framework can lead to greater coverage and conceptual clarity. <br /></span></div></div><div class="paper" id="al130"><a href="#al130" class="title">Of Course I Wouldn&#700;t Do That in Real Life: Advancing the Arguments for Increasing Realism in HCI Experiments</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979621&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Letitia  Lew</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Truc  Nguyen</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Solomon  Messing</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Sean  Westwood</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We offer a nuanced examination of the way that realism can impact internal and external validity in HCI experiments. We show that if an HCI experiment lacks realism across any of four dimensions&#8212;appearance, content, task and setting&#8212;the lack of realism can confound the study by interacting with the treatment and weakening internal or external validity. We argue furthermore, that realism can be increased while still maintaining control: analogue experiments allow researchers to conduct experiments in more ecologically valid environments and online experiments bridge the gap between the cleanroom and field. While increasing the level of realism in an experiment can introduce noise, technological developments have made it easier to collect rich analytics on behavior and usage.</span></div></div><div class="paper" id="al111"><a href="#al111" class="title">GoSlow: Designing for Slowness, Reflection and Solitude</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979622&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Justin  Cheng</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Akshay  Bapat</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Gregory  Thomas</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Kevin  Tse</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Nikhil  Nawathe</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Jeremy  Crockett</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Gilly  Leshed</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We are surrounded by technologies that fuel a fast-paced, at-the-moment, connected life. In contrast, GoSlow is a mobile application designed to help users slow down, contemplate, and be alone. Through serendipWe are surrounded by technologies that fuel a fast-paced, at-the-moment, connected life. In contrast, GoSlow is a mobile application designed to help users slow down, contemplate, and be alone. Through serendipitous moments of pause and reflection, GoSlow offers simple ways for users to cut back and relax, provides an outlet for contemplation and reminiscence, and helps them disconnect and get away. Our user study reveals that GoSlow encourages introspective reflection, slowing down, and can help reduce stress with minimal intervention.itous moments of pause and reflection, GoSlow offers simple ways for users to cut back and relax, provides an outlet for contemplation and reminiscence, and helps them disconnect and get away. Our user study reveals that GoSlow encourages introspective reflection, slowing down, and can help reduce stress with minimal intervention.</span></div></div></td>
<td colspan="14" class="session_details" id="S1104_details"><div class="sessionChair"><strong>Session Chair: </strong>Jacquelyn Martino (<em>IBM Research</em>)</div><div class="paper" id="paper2013"><a href="#paper2013" class="title">An Exploratory Study of Input Modalities for Mobile Devices Used with Museum Exhibits</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979075&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Priscilla  Jimenez Pazmino</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Leilah  Lyons</span> <span class="affiliation">University of Illinois at Chicago</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">New of mobile device features and the growing proportion of visitors carrying mobiles allow the range of museum exhibit design possibilities to be expanded. In particular, we see opportunities for using mobiles to help exhibits scale up to support variable-sized groups of visitors, and to support collaborative visitor-visitor interactions. Because exhibit use is generally one-time-only, any interfaces created for these purposes must be easily learnable, or visitors may not use the exhibit at all. To guide the design of learnable mobile interfaces, we chose to employ the Consistency design principle. Consistency was originally applied to desktop UIs, so we extended the definition to cover three new categories of consistency relevant to ubiquitous computing: Within-Device Consistency, Across-Device Consistency and Within-Context Consistency. We experimentally contrasted designs created from these categories. The results show small differences in learnability, but illustrate that even for one-off situations learnability may not be as important as usability.</span></div></div><div class="paper" id="cs130"><a href="#cs130" class="title">GroupAixplorer: An Interactive Mobile Guide for Small Groups</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span><div class="authors"><span class="author">Martin  Wermers</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Gero  Herkenrath</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Museum Audio guides often isolate visitors from each other with little regard for the social needs of a group. We developed a collaborative quest game for small groups on a mobile guide. A user study showed that communication and social interaction among visitors were encouraged instead of hindered and that even quests without much interaction on the device were still popular. It also demonstrated that our concept of having a group leader responsible to start and finish quests as well as organize group progress during the game does not impair the group experience per se, but that careful selection of the member fulfilling that part may be important.</span></div></div><div class="paper" id="cs172"><a href="#cs172" class="title">Art Loop Open: Designing for the intersection of Art and Technology in an Urban Public Exhibition</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979649&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anijo P Mathew</span> <span class="affiliation">Illinois Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this case study, we explore the design and implementation of Art Loop Open, a city-wide art exhibition with a cutting edge technologically mediated experience. The case study will enumerate the design process, the collaboration between different decision making entities, as well as the technology layer and the experience design of the exhibition.</span></div></div></td>
<td colspan="14" class="session_details" id="S1108_details"><div class="sessionChair"><strong>Session Chair: </strong>Gillian Hayes (<em>University of California, Irvine</em>)</div><div class="paper" id="paper1639"><a href="#paper1639" class="title">Matters of Life and Death: Locating the End of Life in Lifespan-Oriented HCI Research</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979090&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Massimi</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">William  Odom</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Richard  Banks</span> <span class="affiliation">Microsoft Research Cambridge</span>, <br />
<span class="author">David  Kirk</span> <span class="affiliation">University of Nottingham</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Examining developmental periods of the human lifespan has been a useful tradition for focusing HCI research (e.g., technologies for children or the elderly). In this paper, we identify the end of life as another period of the human lifespan that merits consideration by technology designers and researchers. This paper maps out current and future research in HCI at the end of life by first describing how this area raises questions concerning materiality and artifacts, social identities, temporality and methodologies. Having provided a description of the richness of this area, we then frame it against HCI traditions and practices in an orientation we term the lifespan-oriented approach. This paper maps early efforts in end of life research, structures and suggests areas for continued work, and situates the end of life among existing areas of HCI research.</span></div></div><div class="paper" id="paper575"><a href="#paper575" class="title">I Said Your Name in an Empty Room: Grieving and Continuing Bonds on Facebook</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979091&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Emily  Getty</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Jessica  Cobb</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Meryl  Gabeler</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Christine  Nelson</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Ellis  Weng</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Jeffrey  Hancock</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In response to the death of a close friend or relative, bereaved individuals can use technology as part of the grieving process. We present a study that analyzes the messages of the friends and family of the deceased to their Facebook profile before and after their passing.  Our analysis reveals that mourners use profiles as a way to maintain a continuing bond with the deceased, as well as a way to accomplish specific front stage bereavement communication, such as sharing memories, expressing sorrow and providing social support. These observations may improve the design of social networking technologies so that they remain useful, sensitive tools for the bereaved.</span></div></div><div class="paper" id="paper2071"><a href="#paper2071" class="title">Dealing with Death in Design: Developing Systems for the Bereaved</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979092&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Massimi</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Ronald M Baecker</span> <span class="affiliation">University of Toronto</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Increasingly, systems are being developed and used in ways that involve end of life issues such as death, dying, and bereavement. Yet design considerations and guidelines for technologists working in this sensitive area are not well-established. We therefore report on exploratory fieldwork consisting of focus groups, observations, and consultation with bereavement experts aimed at understanding how technology might be designed to support bereaved parents. From this fieldwork, we derive a set of considerations useful for researchers and designers developing systems that deal specifically with bereavement, and with the end of life more broadly. These considerations focus on interpersonal communication, new ways of being in the world, and materiality. We conclude with a distillation of these considerations into practical design guidelines for working in this area.</span></div></div></td>
<td colspan="14" class="session_details" id="S5002_details"><div class="paper" id="wp114"><a href="#wp114" class="title">Low Cost vs. High-End Eye Tracking for Usability Testing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979744&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sune Alstrup Johansen</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Javier  San Agustin</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Henrik  Skovsgaard</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">John Paulin Hansen</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Martin  Tall</span> <span class="affiliation">Duke University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Accuracy of an open source remote eye tracking system and a state-of-the-art commercial eye tracker was measured 4 times during a usability test. Results from 9 participants showed both devices to be fairly stable over time, but the commercial tracker was more accurate with a mean error of 31 pixels against 59 pixels using the low cost system. This suggests that low cost eye tracking can become a viable alternative, when usability studies need not to distinguish between, for instance, particular words or menu items that participants are looking at, but only between larger areas-of-interest they pay attention to.</span></div></div><div class="paper" id="wp118"><a href="#wp118" class="title">A Crowdsourcing Model for Receiving Design Critique</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979745&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anbang  Xu</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span>, <br />
<span class="author">Brian P. Bailey</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designers in many domains are increasingly turning to online communities to receive critiques of early design ideas. However, members of these communities may not contribute an effective critique due to limited skills, motivation, or time, and therefore many critiques may not go beyond &#8220;I (don&#8217;t) like it&#8221;. We propose a new approach for designers to receive online critique. Our approach is novel because it adopts a theoretical framework for effective critique and implements the framework on a popular crowdsourcing platform. Preliminary results show that our approach allows designers to acquire quality critiques in a timely manner that compare favorably with critiques produced from a well-known online community.</span></div></div><div class="paper" id="wp119"><a href="#wp119" class="title">Touch-Bookmark: A Lightweight Navigation and Bookmarking Technique for E-Books</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979746&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dongwook  Yoon</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Yongjun  Cho</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Kiwon  Yeom</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Ji-Hyung  Park</span> <span class="affiliation">Korea Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The navigation function of an e-book significantly influences its usability. In this paper, we introduce Touch-Bookmark (TB), a multitouch navigation technique for e-books. TB enables users to bookmark a page in a casual manner and return to it quickly when required. Moreover, the users can flip between two remote pages by using simple gestures. In a usability test conducted to evaluate our prototype, users found the technique easy to learn, natural to use, and useful for navigation. Analysis of the patterns of interaction gestures helped identify human factors that should be considered when designing touch interfaces for e-books. The factors include navigation strategies, patterns of interaction gestures, types of books, and motor memory.</span></div></div><div class="paper" id="wp127"><a href="#wp127" class="title">Understanding Email Communication of Persons with Aphasia</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979747&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abdullah  Al Mahmud</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Jean-Bernard  Martens</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An email program has been developed by the Aphasia Union Netherlands (AVN) to enhance communication between aphasics mutually and with their therapists. In this paper we report intermediate evaluation results of the AVN email program. We evaluated the email program in two ways: a. by analyzing the AVN email server logs and b. by collecting subjective responses through questionnaires. Our results indicate that both aphasics and therapists find the email program useful, despite the fact that they expressed several criticisms about its usability. Therefore, some changes are required to make the program better useable and more widely accessible for the target group.</span></div></div><div class="paper" id="wp133"><a href="#wp133" class="title">A Context-Sensitive Device to Help People with Autism Cope with Anxiety</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979748&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marziya  Mohammedali</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Dinh  Phung</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Brett  Adams</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Svetha  Venkatesh</span> <span class="affiliation">Curtin University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe a smartphone application that helps people with Autism Spectrum Disorder (ASD) cope with anxiety attacks. Our prototype provides a one-touch interface for indicating a panic level. The device&#8217;s response&#8212;to instruct, soothe, and/or contact carers&#8212;is sensitive to the user&#8217;s context, consisting of time, location, ambient noise, and nearby friends. Formative evaluation unearths a critical challenge to building assistive technologies for ASD sufferers: can regimented interfaces foster flexible behaviour? Our observations suggest that a delicate balance of design goals is required for a viable assistive technology.</span></div></div><div class="paper" id="wp147"><a href="#wp147" class="title">The Effects of Screen-Size and Communication Modality on Psychology of Mobile Device Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979749&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ki Joon  Kim</span> <span class="affiliation">SungKyunKwan University</span>, <br />
<span class="author">S. Shyam  Sundar</span> <span class="affiliation">Pennsylvania State University</span>, <br />
<span class="author">Eunil  Park</span> <span class="affiliation">SungKyunKwan University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Does screen-size matter in mobile devices? There appears to be a move toward larger screens, with recent launches of Apple&#8217;s iPad and Samsung&#8217;s Galaxy Tab, but do these devices undercut the perceived mobility and affect user attitudes toward the technology? To answer these and related questions, the present study examines the effects of screen-size and communication modality (text vs. video) on mobile device users&#8217; perception of mobility and content as well as attitudes toward technology acceptance. Preliminary data from a between-subjects experiment show that smaller screen-size elicited greater perceived mobility while larger screen-size was key to greater enjoyment. News story in video format played a crucial role in providing greater enjoyment and newsworthiness of the news story while news in text format was perceived to be easier to use on a mobile device. Design implications and limitations are discussed, as we prepare for a constructive replication.</span></div></div><div class="paper" id="wp150"><a href="#wp150" class="title">On the use of pervasive computing to support patients with obsessive compulsive disorder</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979750&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vassilis-Javed  Khan</span> <span class="affiliation">NHTV Breda University of Applied Sciences</span>, <br />
<span class="author">Panos  Markopoulos</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Nynke  Spijksma</span> <span class="affiliation">Marina de Wolf Hospital</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Obsessive-compulsive disorder (OCD) is a psychiatric disorder affecting 2% to 3% of world population. Patients having this disorder engage in repetitive and discomforting behaviors usually linked to controlling or cleaning. The potential of technical solutions trying to support both patients and therapists has been to a limited extent explored with some encouraging results. However, the use of a mobile phone application has not yet been explored. We present a study of a distributed application, partly running on mobile phone and partly on a website, with four patients suffering from OCD and their therapist. Our qualitative evaluation yields encouraging conclusions for practitioners and developers of such applications.</span></div></div><div class="paper" id="wp153"><a href="#wp153" class="title">Living with Pain, Staying in Touch: Exploring the Communication Needs of Older Adults with Chronic Pain</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979751&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jessica M David</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Alison  Benjamin</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Ronald M Baecker</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Diane J Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Jeremy P Birnholtz</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">For older adults with chronic pain, maintaining social ties can be difficult. Both chronic pain and social isolation compound each other and are associated with poor health outcomes. Our research explores how technology can be used to facilitate communication and support for older adults with chronic pain. We report on preliminary results of field research with 20 participants and deployment of a digital communicating picture frame prototype. We found that chronic pain introduces unique barriers to synchronous contact and that our prototype seemed to fit the needs of these individuals by supporting meaningful asynchronous communication with the possibility for adjustable reciprocity.</span></div></div><div class="paper" id="wp161"><a href="#wp161" class="title">Ambient Displays: Influencing Movement Patterns</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979752&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tasos  Varoudis</span> <span class="affiliation">arch+ech Architecture</span>, <br />
<span class="author">Sheep  Dalton</span> <span class="affiliation">Open University</span>, <br />
<span class="author">Katerina  Alexiou</span> <span class="affiliation">Open University</span>, <br />
<span class="author">Theodore  Zamenopoulos</span> <span class="affiliation">Open University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Ambient displays are gradually augmenting the principal static elements of architecture, such as walls, transforming space into a dynamic and ever-changing environment. Does the addition of such digital elements influence people&#8217;s perception and understanding of space around them? If so, do ambient displays lead to behavioral changes like people&#8217;s movement in such environments? In this particular study, a series of experiments were conducted to investigate public interior spaces with embedded ambient displays. The findings are then presented showing how the presence of an ambient display through its visual depth affects and changes movement patterns. This study discusses the ability of an ambient display to refine navigation paths and suggests that its visual depth can enhance its effectiveness.</span></div></div><div class="paper" id="wp162"><a href="#wp162" class="title">A Tactile Friend Sense for Keeping Groups Together</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979753&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Martin  Pielot</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Benjamin  Poppinga</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Wilko  Heuten</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Susanne  Boll</span> <span class="affiliation">University of Oldenburg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Visiting crowded places at night in a group of friends is a common leisure activity in many parts of the world. However, the chaotic nature of such place makes it difficult to keep the group together. Constantly watching out for the others or frequent use of technology (e.g. phone calls or Google Latitude) may be contradictory to the idea of having a jolly night out. We therefore designed FriendSense, a mobile application that acts as a pervasive anchor to one of the friends. Beyond existing solutions it allows to continuously sense the anchored friend&#8217;s location through vibro-tactile feedback. In a preliminary field study we investigated how this added sense affects a night out at an Oktoberfest-like festival. We found evidence that FriendSense users were more confident and less stressed with keeping the group together.</span></div></div><div class="paper" id="wp165"><a href="#wp165" class="title">Recompose: Direct and Gestural Interaction with an Actuated Surface</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979754&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Blackshaw</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Anthony  DeVincenzi</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">David  Lakatos</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Daniel  Leithinger</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present Recompose, a new system for manipulation of an actuated surface. By collectively utilizing the body as a tool for direct manipulation alongside gestural input for functional manipulation, we show how a user is afforded unprecedented control over an actuated surface. We describe a number of interaction techniques exploring the shared space of direct and gestural input, demonstrating how their combined use can greatly enhance creation and manipulation beyond unaided human capability.</span></div></div><div class="paper" id="wp169"><a href="#wp169" class="title">Make a Trip an Experience: Sharing In-Car Information with Passengers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979755&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ohad  Inbar</span> <span class="affiliation">Ben-Gurion University of the Negev</span>, <br />
<span class="author">Noam  Tractinsky</span> <span class="affiliation">Ben-Gurion University of the Negev</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Current in-vehicle information systems (IVIS) are designed for use by a single entity &#8211; the driver. In this paper we propose that the benefits of IVIS can increase if we also consider the needs of passengers and their potential contribution as additional information handlers who buffer the driver from information overload. The benefits these &#8220;incidental users&#8221; of IVIS can reap from having trip-related information shared with them include reduced boredom, increased trust and a sense of inclusion. Drivers&#8217; benefits include less distraction caused by questions previously aimed at them as the exclusive owners of the trip-related information, and reduced information load by allowing passengers to actively control selected in-car systems.</span></div></div><div class="paper" id="wp171"><a href="#wp171" class="title">Effects of Different Types of Artifacts on Interpretations of Artificial Subtle Expressions (ASEs)</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979756&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Takanori  Komatsu</span> <span class="affiliation">Shinshu University</span>, <br />
<span class="author">Seiji  Yamada</span> <span class="affiliation">National Institute of Informatics</span>, <br />
<span class="author">Kazuki  Kobayashi</span> <span class="affiliation">Shinshu University</span>, <br />
<span class="author">Kotaro  Funakoshi</span> <span class="affiliation">Honda Research Institute</span>, <br />
<span class="author">Mikio  Nakano</span> <span class="affiliation">Honda Research Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">So far, we already confirmed that the artificial subtle expressions (ASEs) from a robot could convey its internal states to participants accurately and intuitively. In this paper, we investigated whether the ASEs from an on-screen artifact could also convey the artifact&#8217;s internal states to participants in order to confirm whether the ASEs can be interpreted consistently for  various types of artifacts. The results clearly showed that the ASEs&#8217; interpretations from on-screen artifact were consistent with the ones from robotic agent.</span></div></div><div class="paper" id="wp174"><a href="#wp174" class="title">Adaptive Eye-Gaze-Guided Interfaces: Design &amp; Performance Evaluation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979757&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Oleg  Komogortsev</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Corey  Holland</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Jose  Camou</span> <span class="affiliation">Texas State University-San Marcos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper considers the effects of user interface adaptation based on regional eye tracker accuracy to improve user performance and satisfaction in an eye-gaze-guided application. We objectively and subjectively evaluated the differences between an adaptive interface, in which navigational elements were placed in regions of highest accuracy, and its inverted counterpart, in which navigational elements were placed in regions of lowest accuracy. The results indicate that by accounting for regional accuracy the adaptive interface was able to provide a significant improvement in user performance, though this effect had little bearing on user satisfaction.</span></div></div><div class="paper" id="wp183"><a href="#wp183" class="title">RegionalSliding: Enhancing Target Selection on Touchscreen-Based Mobile Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979758&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wenchang  Xu</span> <span class="affiliation">Tsinghua University</span>, <br />
<span class="author">Chun  Yu</span> <span class="affiliation">Tsinghua University</span>, <br />
<span class="author">Yuanchun  Shi</span> <span class="affiliation">Tsinghua University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Target selection on mobile devices with touchscreens usually gets users into trouble due to the occlusion of the target by the user&#8217;s finger and ambiguity about which part of the finger generates the result point. In this paper, we propose a novel technique to enhance target selection on touchscreen-based mobile devices, named RegionalSliding, which selectively renders the initially &#8220;selected&#8221; target as well as its &#8220;surrounding&#8221; targets in a non-occluded area when users press down on the screen and enables users to complete the selection with sliding gestures according to the visual feedback from the rendered area. A preliminary user study shows that RegionalSliding increases the selection accuracy and brings good user experience.</span></div></div><div class="paper" id="wp191"><a href="#wp191" class="title">Why not Use Mobile Phones? An Observational Study of Medical Work</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979759&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">So Young  Lee</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Sun Young  Park</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Yunan  Chen</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous studies suggest that mobile phones could prevent many communication and information breakdowns that commonly occur in a hospital environment. However, the actual benefits of mobile phones in medical work remain unexplored. We studied mobile phone usage among nurses in an Emergency Department (ED). Surprisingly, mobile phones were not favored by our study participants. We found that mobile phones do not support essential characteristics of nursing work in ED because they lack support for group awareness, informative interruption, and role-based calling. The findings suggest that the design of mobile devices should support nurses&#8217; share of work responsibilities and the need for information transparency.</span></div></div><div class="paper" id="wp209"><a href="#wp209" class="title">Enhancing Outdoor Navigation Systems through Vibrotactile Feedback</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979760&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominik  Bial</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Dagmar  Kern</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Florian  Alt</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Albrecht  Schmidt</span> <span class="affiliation">University of Stuttgart</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While driving many tasks compete for the attention of the user, mainly via the audio and visual channel. When designing systems depending upon providing feedback to users (e.g., navigation systems), it is a crucial prerequisite to minimize influence on and distraction <br /> from the driving task. This becomes even more important when designing systems for the use on motorbikes; space for output devices is scarce, as people are wearing helmets visual feedback is often difficult due to lighting conditions, and audio feedback is limited. <br /> In a first step we aimed at creating an understanding as to how information could be communicated in a meaningful way using vibrotactile signals. Therefore, we investigated suitable positions of actuators on the hand, appropriate length of the vibration stimulus, <br /> and different vibration patterns. We built a first prototype with 4 vibration actuators attached to the fingertips and asked 4 participants to test our prototype while driving. With this work we envision to lay the foundations for vibrotactile support in navigation systems.</span></div></div><div class="paper" id="wp210"><a href="#wp210" class="title">Us&#8217;em: Motivating Stroke Survivors to Use their Impaired Arm and Hand in Daily Life</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979761&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luuk  Beursgens</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Freek  Boesten</span> <span class="affiliation">Maastricht University</span>, <br />
<span class="author">Annick  Timmermans</span> <span class="affiliation">Adelante Rehabilitation Centre</span>, <br />
<span class="author">Henk  Seelen</span> <span class="affiliation">Adelante Rehabilitation Centre</span>, <br />
<span class="author">Panos  Markopoulos</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Stroke leaves the majority of its survivors with an impairment of the upper extremity that seriously reduces their quality of life and their ability to live independently. Rehabilitation research has shown that extensive usage of the impaired arm in everyday life can improve arm-hand performance, even in chronic stages after stroke. Such usage though is difficult for patients who need some help to be reminded and motivated for using the impaired arm. This paper presents the user centered design and initial evaluation of Us&#8217;em, a watch-like device that provides feedback to patients regarding the usage of their impaired arm-hand in relation to their non-affected upper extremity in order to motivate them to use their affected arm more.</span></div></div><div class="paper" id="wp217"><a href="#wp217" class="title">Duet for Solo Piano: MirrorFugue for Single User Playing with Recorded Performances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979762&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Xiao  Xiao</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">MirrorFugue is an interface that supports symmetric, real-time collaboration on the piano using spatial metaphors to communicate the hand gesture of collaborators. In this paper, we present an extension of MirrorFugue to support single-user interactions with recorded material and outline usage scenarios focusing on practicing and self-reflection. Based on interviews with expert musicians, we discuss how single-user interactions on MirrorFugue relate to larger themes in music learning and suggest directions for future research.</span></div></div><div class="paper" id="wp226"><a href="#wp226" class="title">OpenID-Enabled Browser: Towards Usable and Secure Web Single Sign-On</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979763&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">San-Tsai  Sun</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Eric  Pospisil</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Ildar  Muslukhov</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Nuray  Dindar</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">OpenID is an open and promising Web single sign-on solution; however, the interaction flows provided by OpenID are inconsistent, counter-intuitive, and vulnerable to phishing attacks. In this work, we investigated the challenges web users face when using OpenID for authentication, and designed a phishing-resistant, privacy-preserving browser add-on to provide a consistent and intuitive single sign-on user experience for the average web users.</span></div></div><div class="paper" id="wp237"><a href="#wp237" class="title">Children may Expect Drag-and-Drop Instead of Point-and-Click</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979764&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wolmet  Barendregt</span> <span class="affiliation">University of Gothenburg</span>, <br />
<span class="author">Mathilde M.  Bekker</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present evidence from a pilot study that children may have started to expect the drag-and-drop interaction style. This is in contrast with probably the most cited paper on this topic from 2001, stating that point-and-click is the most appropriate interaction style for children between 6 and 12 years old. Instead of providing children with information on the interaction style expected we developed two point-and-click interfaces and let children explore those interfaces themselves. Children consistently tried to apply the drag-and-drop interaction style both initially and after having discovered the point-and-click style, resulting in problems in interacting with the interfaces. This was especially clear for the type of action having a natural mapping to holding down the mouse-button, such as cutting or drawing lines. In summary, it appears that children have begun to expect the drag-and-drop interaction style and that deviating from this standard may result in serious usability problems.</span></div></div><div class="paper" id="wp243"><a href="#wp243" class="title">SoloFind: Chains of Interactions with a Mobile Retail Experience System</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979765&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alexander  Wiethoff</span> <span class="affiliation">Ludwig-Maximilians-Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Gregor  Broll</span> <span class="affiliation">DOCOMO Euro-Labs</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents SoloFind, a mobile retail experience system for large consumer electronic stores that helps users to retrieve product information. A tangible user interface (TUI) allows customers to collect product information via a simple, Near Field Communication (NFC) based interaction. This data can be customized, reviewed and compared at an interactive kiosk. The simple, touch-like interaction with NFC provides a seamless user experience for customers. This paper focuses on the design of SoloFind, its features and their preliminary evaluation with an experience prototype.</span></div></div><div class="paper" id="wp244"><a href="#wp244" class="title">Squeeze vs. Tilt: A Comparative Study Using Continuous Tactile Feedback</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979766&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eve  Hoggan</span> <span class="affiliation">University of Helsinki HIIT</span>, <br />
<span class="author">Dari  Trendafilov</span> <span class="affiliation">Nokia</span>, <br />
<span class="author">Teemu  Ahmaniemi</span> <span class="affiliation">Nokia</span>, <br />
<span class="author">Roope  Raisamo</span> <span class="affiliation">University of Tampere</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an investigation into the performance of squeezing as a manipulative interaction technique in comparison to tilting with an aim to answer two questions: is squeezing an effective input technique for mobile devices and can tactile feedback improve performance? The experiment results show that both input methods are viable but squeezing is significantly faster and more sustainable than tilting (with and without tactile feedback).</span></div></div><div class="paper" id="wp246"><a href="#wp246" class="title">Evaluating an Automatic Rotation Feature in Collaborative Tabletop Workspaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979767&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gianluca  Schiavo</span> <span class="affiliation">University of Padova</span>, <br />
<span class="author">Giulio  Jacucci</span> <span class="affiliation">University of Helsinki</span>, <br />
<span class="author">Tommi  Ilmonen</span> <span class="affiliation">Multitouch Ltd.</span>, <br />
<span class="author">Luciano  Gamberini</span> <span class="affiliation">University of Padova</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Tabletops are commonly used for collaboration but would benefit from features that help orient objects to individual users disposed around the display.  We propose an approach of automatic orientation based on fingers and hand detection as a proxy to determine the position of the user. To contribute to the discussion of the relevance of automatic rotation, we present a comparison study of pairs of participants engaged in both loosely and tightly coupled tasks. We collected performance measures, questionnaires and analyze interactions from video recordings. The results show that automatic rotation is more suitable when the collaboration is loosely coupled. Conversely, in tightly coupled tasks performance are worse and user ratings low when automatic rotations are enabled. We conclude that features such as automatic orientation on tabletop are important and promising but that they need to be critically assessed with respect to their effects on collaboration in both tightly and loosely coupled tasks.</span></div></div><div class="paper" id="wp250"><a href="#wp250" class="title">Participatory Sensing for Community Building</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979768&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Whitney</span> <span class="affiliation">University of North Carolina, Charlotte</span>, <br />
<span class="author">Heather  Richter Lipford</span> <span class="affiliation">University of North Carolina, Charlotte</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this research, we explore the viability of using participatory sensing as a means to enhance a sense of community. To accomplish this, we are developing and deploying a suite of participatory sensing applications, where users explicitly report on the state of their environment, such as the location of the bus. In doing so, community members become reliant on each other for valuable information about the community. By better understanding the relationship between participatory sensing and community, we inform the design and research of similar participatory sensing, or crowd-sourced sensing applications.</span></div></div><div class="paper" id="wp251"><a href="#wp251" class="title">Towards User-Centered Mashups: Exploring User Needs for Composite Web Services</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979769&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kaisa  V&#228;&#228;n&#228;nen-Vainio-Mattila</span> <span class="affiliation">Tampere University of Technology</span>, <br />
<span class="author">Minna  W&#228;ljas</span> <span class="affiliation">Tampere University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The Web contains a vast amount of services supporting users in various facets of life. In mashup or composite Web services, elements from various services are combined to create a service which suits users&#8217; needs. Our goal was to explore what kind of composite services users would need. We conducted semi-structured interviews with nine Web service users to investigate their experiences of service composition and expectations to future services. We also asked the participants to sketch their ideal composite service UI for both PC and mobile device. Our results indicate that service users do not yet have much experience of mashups but there is a need to merge functionality and data from different services to achieve the customized, integrated Web service. This work contributes to the development of future Web services and mashup tools.</span></div></div><div class="paper" id="wp254"><a href="#wp254" class="title">Five Strategies for Supporting Healthy Behavior Change</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979770&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yevgeniy  Medynskiy</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Svetlana  Yarosh</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Elizabeth  Mynatt</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There is an ongoing search for theoretical foundations and design principles for interactive systems that support healthy behavior change. In this work-in-progress, we present several behavior change strategies that are currently used in effective health self-management interventions. We then discuss how these strategies can be used in applications that support behavior change in the health/wellness domain.</span></div></div><div class="paper" id="wp264"><a href="#wp264" class="title">Interaction and Rendering Techniques for Handheld Phantograms</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979771&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Finn  Ericsson</span> <span class="affiliation">KTH</span>, <br />
<span class="author">Alex  Olwal</span> <span class="affiliation">KTH</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a number of rendering and interaction techniques that exploit the user's viewpoint for improved realism and immersion in 3D applications on handheld devices. <br />  <br /> Unlike 3D graphics on stationary screens, graphics on handheld devices are seldom regarded from a fixed perspective. This is particularly true for recent mobile platforms, where it is increasingly popular to use device orientation for interaction. We describe a set of techniques for improved perception of rendered 3D content. View-point correct anamorphosis and stereoscopy are discussed along with ways to approximate the spatial relationship between the user and the device. <br />  <br /> We present the design and implementation of a prototype phantogram viewer that was used to explore these methods for interaction with real-time photorealistic 3D models on commercially available mobile devices.</span></div></div><div class="paper" id="wp271"><a href="#wp271" class="title">Puchi Planet : A Tangible Interface Design for Hospitalized Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979772&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shinsuke  Akabane</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Johnson  Leu</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Hiromi  Iwadate</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Jae Won  Choi</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Chin Ching  Chang</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Saori  Nakayama</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Madoka  Terasaki</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Hala  Eldemellawy</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Masa  Inakage</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Susumu  Furukawa</span> <span class="affiliation">Keio University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes the concept, design and prototype of a tangible user interface (TUI) based toy set for the purpose to bring fun into the lives of hospitalized children. The objective is to encourage children to interact with others and satisfy their curiosity of the outside world. This prototype takes the form of a play set that provides the experience of taking a jet tour and seeing different scenes around the world.</span></div></div><div class="paper" id="wp278"><a href="#wp278" class="title">CapWidgets: Tangile Widgets versus Multi-Touch Controls on Mobile Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979773&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sven  Kratz</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Tilo  Westermann</span> <span class="affiliation">Deutsche Telekom Laboratories, TU Berlin</span>, <br />
<span class="author">Michael  Rohs</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Georg  Essl</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present CapWidgets, passive tangible controls for capacitive touch screens. CapWidgets bring back physical controls to off-the-shelf multi-touch surfaces as found in mobile phones and tablet computers. While the user touches the widget, the surface detects the capacitive marker on the widget&#8217;s underside. We study the relative performance of this tangible interaction with direct multi-touch interaction and our experimental results show that user performance and preferences are not automatically in favor of tangible widgets and careful design is necessary to validate their properties.</span></div></div><div class="paper" id="wp281"><a href="#wp281" class="title">Me Hates This: Exploring Different Levels of User Feedback for (Usability) Bug Reporting</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979774&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Florian  Heller</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Leonhard  Lichtschlag</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Moritz  Wittenhagen</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Thorsten  Karrer</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">User feedback for deployed software systems ranges from simple one-bit-feedback to full-blown bug reports. While detailed bug reports are very helpful for the developers to track down problems, the expertise and commitment required from the user is high. We analyzed existing user report systems and propose a flexible and independent hard- and software architecture to collect user feedback. We report our results from a preliminary two-week user study testing the system in the field and discuss challenges and solutions for the collection of multiple levels of user feedback through different modalities.</span></div></div><div class="paper" id="wp283"><a href="#wp283" class="title">TOK &#8211; a Tangible Interface for Storytelling</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979775&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cristina  Sylla</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Pedro  Branco</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Clara  Coutinho</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Eduarda  Coquet</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">David  &#352;karoupka</span> <span class="affiliation">Brno University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the design of the first prototype of TOK - a tangible interface for children to create their own stories. Based on data collected with two groups of five years old preschoolers we present our findings regarding the interaction design of the system. The picture cards have shown to generate ideas, acting as input for the creation of stories, promoting creativity while proposing a framework that supports and guides the construction of logical structures. This is a first step in an effort to build a toolkit of tangible interfaces allowing children and teachers to build their own digital enhanced learning activities.</span></div></div><div class="paper" id="wp289"><a href="#wp289" class="title">Collision Avoidance in Virtual Environments through Aural Spacial Awareness</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979776&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christian  Afonso</span> <span class="affiliation">University of Hamburg</span>, <br />
<span class="author">Steffi  Beckhaus</span> <span class="affiliation">University of Hamburg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe a new technique to make users aurally aware of walls surrounding them in a Virtual Environment (VE). This Collision Avoidance (CA) technique improves upon familiar Collision Notification (CN) feedback by constantly informing the user of his proximity to his surroundings through the playback of directional sounds. To render the aural CA feedback we use spatial sound played over surround loudspeakers, in addition to haptic feedback from a vibrating sound floor to signify collisions.</span></div></div><div class="paper" id="wp290"><a href="#wp290" class="title">Evaluating the Embodiment Benefits of a Paper-Based TUI for Educational Simulations</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979777&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tia  Shelley</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Leilah  Lyons</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Moira  Zellner</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Emily  Minor</span> <span class="affiliation">University of Illinois at Chicago</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many claims have been made regarding the potential benefits of Tangible User Interfaces (TUIs). Presented here is an experiment assessing the usability, problem solving, and collaboration benefits of a TUI for direct placement tasks in spatially-explicit simulations for environmental science education. To create a low-cost deployment for single-computer classrooms, the TUI uses a webcam and computer vision to recognize the placement of paper symbols on a map. An authentic green infrastructure urban planning problem was used as the task for a within-subjects with rotation experiment with 20 pairs of participants. Because no prior experimental study has isolated the influence of the embodied nature of the TUI on usability, problem solving, and collaboration, a control condition was designed to highlight the impact of embodiment. While this study did not establish the usability benefits suggested by prior research, certain problem solving and collaboration advantages were measured.</span></div></div><div class="paper" id="wp295"><a href="#wp295" class="title">The Life Frame: Responding to the Elderly People's Need of Remembering</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979778&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sabina  Giorgi</span> <span class="affiliation">Sapienza University of Rome</span>, <br />
<span class="author">Alessandra  Talamo</span> <span class="affiliation">Sapienza university of Rome</span>, <br />
<span class="author">Barbara  Mellini</span> <span class="affiliation">Sapienza University of Rome</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The paper describes the research project &#8220;The Life frame&#8221; which aims to investigate the added value of digitizing memories for elderly people. It reports the ethnographic research undertaken in order to develop a framework including both devices and services. Data were gathered on the use of mementos in the homes of 241 elderly people and on the technologies that they used, the purpose being to identify the different psychological functions that mementos perform in the homes of this specific target group and to understand the potential use of digital technologies. In the paper we discuss our findings and initial insights for the design of the Life Frame, a device integrated with services for enhancing elderly people&#8217;s personal memories.</span></div></div><div class="paper" id="wp300"><a href="#wp300" class="title">Framework for Measuring Social Affinity for CSCW Software</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979779&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael A Oren</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Stephen B Gilbert</span> <span class="affiliation">Iowa State Universtiy</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Using surveys as a means for assessing group common ground has the possibility of social desirability bias where the results may suggest a higher team affinity rating than may actually exist. To evaluate efforts to improve affinity within interdisciplinary design teams, we developed an empirical measurement of affinity based on behavior and conversation in order to compare affinity differences between workgroups more precisely. This methodology can be used for remote or co-located teams and offers HCI researchers a more powerful method of evaluating group affinity.</span></div></div><div class="paper" id="wp301"><a href="#wp301" class="title">Move-It: Interactive Sticky Notes Actuated by Shape Memory Alloys</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979780&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kathrin  Probst</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Thomas  Seifried</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Michael  Haller</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Kentaro  Yasu</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Maki  Sugimoto</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Masahiko  Inami</span> <span class="affiliation">Keio University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A lot of people still rely on pen and paper for taking short notes. Post-Its&#174; are still the most popular paper media for informal note taking. In this paper, we present the design and implementation of Move-It, a system that combines the affordances of note taking on paper with the capabilities of computer systems. Furthermore, we present how common Post-It&#174; notes can be actuated by shape memory alloys, thus become interactive sticky notes giving active physical feedback.</span></div></div><div class="paper" id="wp302"><a href="#wp302" class="title">Child-robot Interaction: Playing Alone or Together?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979781&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Suleman  Shahid</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span>, <br />
<span class="author">Emiel  Krahmer</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span>, <br />
<span class="author">Marc  Swerts</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we propose a new method to evaluate child-robot interaction, by asking whether playing a game with a state-of-the-art social robot is more similar to playing this game alone or with a friend. Subjective fun scores suggest that children have more fun playing with the robot than playing alone, but have more fun still when playing with a friend. A perception test of selected fragments indicates that children are more expressive when playing with the robot than they are when playing alone, but less expressive than when playing with a friend. Taken together these results show that playing a game together with a state-of-the-art social robot is more fun than playing alone, and approaches playing with a friend, although more work needs to be done to achieve the latter level.</span></div></div><div class="paper" id="wp307"><a href="#wp307" class="title">Topicality, Time, and Sentiment in Online News Comments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979782&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicholas  Diakopoulos</span> <span class="affiliation">Rutgers University</span>, <br />
<span class="author">Mor  Naaman</span> <span class="affiliation">Rutgers University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we examine the relationships between news comment topicality, temporality, sentiment, and quality in a dataset of 54,540 news comments. Initial observations indicate that comment sentiments, both positive and negative, can be useful indicators of discourse quality, and that aggregate temporal patterns in positive sentiment exist on comment threads.</span></div></div><div class="paper" id="wp308"><a href="#wp308" class="title">Children&#8217;s Drawing and Telling of Sustainability in the Home</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979783&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Audrey  Desjardins</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes a pilot study about children&#8217;s perspective on environmental sustainability in the home through the drawing-telling technique. We utilize the drawing-telling technique as described by Susan Wright [6] for interviewing children about issues related to sustainability. The participants (children from age 10 to 13) were asked to draw two houses (current and ideal) and then describe their drawings in terms of sustainable actions and features. This pilot study is an initial step to investigate if there are opportunities to develop eco-visualizations (EVs) with children in mind and shows that the drawing-telling technique is useful in researching sustainability and children.</span></div></div><div class="paper" id="wp310"><a href="#wp310" class="title">MusEEGk: A Brain Computer Musical Interface</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979784&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yee Chieh (Denise)  Chew</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Eric  Caspary</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a novel integration of a brain-computer interface (BCI) with a music step sequencer composition program. Previous BCIs that utilize EEG data to form music provide users little control over the final composition or do not provide enough feedback. Our interface allows a user to create and modify a melody in real time and provides continuous aural and visual feedback to the user, thus affording them a controllable means to achieve creative expression.</span></div></div><div class="paper" id="wp313"><a href="#wp313" class="title">TableCross: Exuding a Shared Space into Personal Spaces to Encourage Its Voluntary Maintenance</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979785&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kazushi  Nishimoto</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Akari  Ikenoue</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Koji  Shimizu</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Tomonori  Tajima</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Yuta  Tanaka</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Yutaka  Baba</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Xihong  Wang</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A shared space should be cooperatively maintained by all users. However, due to social loafing, often nobody maintains it and its condition worsens. We propose exudation of a shared space. Part of a shared space is exuded into personal workspaces so that office workers are forced to subjectively experience the atmosphere of the shared space, even while they remain at their personal workspaces. This paper illustrates the first prototype named &#8220;TableCross,&#8221; which reflects the degree of disorder of a table in a shared space to the desktop of each worker&#8217;s PC. We also report some results of our pilot user study.</span></div></div><div class="paper" id="wp318"><a href="#wp318" class="title">Interactivity Sketcher: Crafting and Experiencing Interactivity Qualities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979786&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jong-bum  Woo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Da-jung  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Suin  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Jaesung  Jo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we introduce the Interactivity Sketcher, which is an interactivity designing tool that can visualize and experience invisible interactivity in a tangible way by controlling Interactivity Attributes(IAs). The Interactivity Sketcher is composed of the IA application, input devices, output devices, and IA controllers. The Interactivity Sketcher can help to explore various qualities of interactivity by visualizing and manipulating the relationship between an input and an output through the IA controllers and the IA application. We expect that this tool will enable interaction designers to visualize their own thoughts of interactivity qualities so that they will be able to create their design as if they had &#8216;sketched&#8217; it.</span></div></div><div class="paper" id="wp323"><a href="#wp323" class="title">Predictive Error Behavior Model of On-screen Keyboard Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979787&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Siddharth  Jain</span> <span class="affiliation">IIT Guwahati</span>, <br />
<span class="author">Samit  Bhattacharya</span> <span class="affiliation">IIT Guwahati</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">On-screen keyboards are becoming ubiquitous with increasing use in mobile devices and touch-screens. In this work, we present a novel predictive error model which relates accuracy of an on-screen keyboard user to a given layout using the distance between keys. The model is developed from empirical data with the aim to predict the error rate of a user from the layout specification alone. Our proposed model can be combined with the existing quantitative design approaches for designing keyboards having high text-entry speed and accuracy.</span></div></div><div class="paper" id="wp338"><a href="#wp338" class="title">Weak Inter-Rater Reliability In Heuristic Evaluation Of Video Games</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979788&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gareth R White</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Pejman  Mirza-babaei</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Graham  McAllister</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Judith  Good</span> <span class="affiliation">The University of Sussex</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Heuristic evaluation promises to be a low-cost usability evaluation method, but is fraught with problems of subjective interpretation, and a proliferation of competing and contradictory heuristic lists. This is particularly true in the field of games research where no rigorous comparative validation has yet been published. In order to validate the available heuristics, a user test of a commercial game is conducted with 6 participants in which 88 issues are identified, against which 146 heuristics are rated for relevance by 3 evaluators. Weak inter-rater reliability is calculated with Krippendorff's Alpha of 0.343, refuting validation of any of the available heuristics. This weak reliability is due to the high complexity of video games, resulting in evaluators interpreting different reasonable causes and solutions for the issues, and hence the wide variance in their ratings of the heuristics.</span></div></div><div class="paper" id="wp339"><a href="#wp339" class="title">guitAR &#8211; Supporting Guitar Learning through Mobile Projection</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979789&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Markus  L&#246;chtefeld</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Sven  Gehring</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Ralf  Jung</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Antonio  Kr&#252;ger</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The guitar is one of the most widespread instruments amongst autodidacts, but even though a huge amount of learning material exists, it is still hard to learn especially without a guitar teacher. In this paper we propose an Augmented Reality application called guitAR that assists guitar students mastering their instrument using a projector phone. With the projector phone mounted at the headstock of the guitar, the fret board and the strings of the guitar are in the field of projection of the phone. By projecting instructions directly onto the strings of the guitar the user is easily able to realize where the fingers have to be placed on the fretboard (fingering) to play a certain chord or a tone sequence correctly.</span></div></div><div class="paper" id="wp343"><a href="#wp343" class="title">Emotion Faces: the Design and Evaluation of a Game for Preschool Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979790&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lynne  Humphries</span> <span class="affiliation">University of Sunderland</span>, <br />
<span class="author">Sharon  McDonald</span> <span class="affiliation">University of Sunderland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the design and initial evaluation of an interactive game that enables preschool children to practise a basic social skill: emotion recognition.  Users construct faces to represent 5 basic emotions through the manipulation of individual face parts.  An iterative user-centred design process was used to gather image and sound data for the game.  A field evaluation revealed that the children (7 boys and 4 girls) enjoyed playing the game and were able to match facial expression to emotions. Girls employed a different approach to game play than boys and achieved a higher success rate but made fewer overall attempts.  Affective and co-operative activity was evident with the children showing joint attention and mirroring of emotions during play.</span></div></div><div class="paper" id="wp345"><a href="#wp345" class="title">Exploring Trust in Group-to-Group Video-Conferencing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979791&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Petr  Slov&#225;k</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Peter  Nov&#225;k</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Pavel  Troubil</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Petr  Holub</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Erik C. Hofer</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous work has shown that supporting trust via computer-mediated communication can be a challenge, especially among strangers. In this paper, we report on an experiment comparing two group-to-group video-conferencing environments and face-to-face communication in their ability to support trust and mutual cooperation in a social dilemma task. There are pronounced differences in participant behaviour between the two video-conferencing designs, indicating higher mutual trust in one of the video-conferencing conditions. The decisive factor seems to be a discrepancy in the type of group identity that develops during the game. Moreover, our results suggest that a combination of personal displays and a unique video-stream of each participant present in the better video-conferencing condition contributed to this result.</span></div></div><div class="paper" id="wp349"><a href="#wp349" class="title">From dance to touch : movement qualities for interaction design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979792&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sarah  Fdili Alaoui</span> <span class="affiliation">LIMSI-CNRS and IRCAM-CNRS</span>, <br />
<span class="author">Baptiste  Caramiaux</span> <span class="affiliation">IRCAM-CNRS</span>, <br />
<span class="author">Marcos  Serrano</span> <span class="affiliation">ENSADLab/Drii</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we address the question of extending user experience in large scale tactile displays. Our contribution is a non task-oriented interaction technique based on modern dance for the creation of aesthetically pleasant large scale tactile interfaces. This approach is based on dance movement qualities applied to touch interaction allowing for natural gestures in large touch displays. We used specific movements from a choreographic glossary and developed a robust movement quality recognition process. To illustrate our approach, we propose a media installation called A light touch, where touch is used to control a light spot reacting to movement qualities.</span></div></div><div class="paper" id="wp350"><a href="#wp350" class="title">The Diversity Donut: Enabling Participant Control Over the Diversity of Recommended Responses</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979793&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Wong</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Siamak  Faridani</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Ephrat  Bitton</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Ken  Goldberg</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Most online discussion interfaces organize textual responses using linear lists.  Such lists do not scale to the number of responses and cannot convey the diversity of the participants who have contributed. The Opinion Space system is designed to address these issues. In this paper, we augment Opinion Space with two features. The first is a new user interface tool and recommendation system: the Diversity Donut (Figure 1). While the Diversity Donut did not establish a statistical advantage over other recommendation methods, participant self-reported data suggested that participants found the Diversity Donut to yield the most diverse set of comments. The second contribution is a new dimensionality reduction technique in Opinion Space: Canonical Correlation Analysis (CCA). Our analysis suggests that CCA is a better algorithm for opinion visualization than Principal Component Analysis (PCA).</span></div></div><div class="paper" id="wp351"><a href="#wp351" class="title">Beyond Pointing and Clicking: How do Newer Interaction Modalities Affect User Engagement?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979794&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S. Shyam  Sundar</span> <span class="affiliation">Penn State University, Sungkyunkwan University</span>, <br />
<span class="author">Qian  Xu</span> <span class="affiliation">Elon University</span>, <br />
<span class="author">Saraswathi  Bellur</span> <span class="affiliation">Penn State University</span>, <br />
<span class="author">Jeeyun  Oh</span> <span class="affiliation">Penn State University</span>, <br />
<span class="author">Haiyan  Jia</span> <span class="affiliation">Penn State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Modern interfaces offer users a wider range of interaction modalities beyond pointing and clicking, such as dragging, sliding, zooming, and flipping through images. But, do they offer any distinct psychological advantages? We address this question with an experiment (N = 128) testing the relative contributions made by six interaction modalities (zoom-in/out, drag, slide, mouse-over, cover-flow and click-to-download) to user engagement with identical content. Data suggest that slide is better at aiding memory than the other modalities, whereas cover-flow and mouse-over generate more user actions. Mouse-over, click-to-download, and zoom-in/out tend to foster more favorable attitudes among power users, whereas cover-flow and slide generate more positive attitudes among non-power users. Design implications are discussed.</span></div></div><div class="paper" id="wp352"><a href="#wp352" class="title">BiCEP: Bimanual Color Exploration Plugin</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979795&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Berto  Gonzalez</span> <span class="affiliation">UNC Charlotte</span>, <br />
<span class="author">Celine  Latulipe</span> <span class="affiliation">UNC Charlotte</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe a bimanual color exploration plugin (BiCEP) that allows a user to choose colors along three dimensions: hue, saturation, and brightness without mode switching between these dimensions. The plugin differs from other color selection tools by allowing users to simultaneously change all three dimensions utilizing a laptop trackpad with multi-touch tracking capabilities. We believe this methodology will improve the range of color exploration by allowing users to more easily explore a wider range of colors.</span></div></div><div class="paper" id="wp661"><a href="#wp661" class="title">MultiPress: Releasing Keys for MultiTap Segmentation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979796&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seunghwan  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Jaehyun  Han</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Geehyuk  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While MultiTap is one of the most popular text entry methods for mobile phones, it has a fundamental weakness known as MultiTap segmentation problem. Based on the observation that the thumb does not leave the keys between tapping actions, we designed a MultiTap segmentation method where the release action of the thumb is used to indicate input completion. A user study using a touch-sensing keypad prototype to explore the feasibility of the idea and a comparison test to access its benefit revealed promising results supporting the effectiveness of the proposed segmentation method.</span></div></div><div class="paper" id="wp670"><a href="#wp670" class="title">Arrange-A-Space: Tabletop Interfaces and Gender Collaboration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979797&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Richert</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Ammar  Halabi</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Anna  Eaglin</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Matthew  Edwards</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Collaborative technologies, such as shared tabletop interfaces, are becoming increasingly pervasive. Meanwhile, social dynamics have long been a major area of inquiry in HCI and CSCW. With a few notable exceptions, little has been done that addresses the roles gender identities play in shaping collaborative work. In this paper, we make the case for a deeper consideration of gender in our field through a study that investigates issues surrounding gendered collaboration around a tabletop interface. We report our findings and conclude with recommendations for future work in this area.</span></div></div><div class="paper" id="wp680"><a href="#wp680" class="title">Informed Consent and Users' Attitudes to Logging in Large Scale Trials</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979798&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alistair  Morrison</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Owain  Brown</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Donald  McMillan</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Matthew  Chalmers</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The HCI community has begun to use &#8216;app store&#8217;-style software repositories as a distribution channel for research applications. A number of ethical challenges present themselves in this setting, not least that of gaining informed consent from potential participants before logging data on their use of the software. We note that standard &#8216;terms and conditions&#8217; pages have proved unsuccessful in communicating relevant information to users, and explore further means of conveying researchers&#8217; intent and allowing opt-out mechanisms. We test the hypothesis that revealing collected information to users will affect their level of concern at being recorded and find that users are more concerned when presented with a personalised representation of recorded data, and consequently stop using the application sooner. Also described is a means of allowing between-groups experiments in such mass participation trials.</span></div></div><div class="paper" id="wp689"><a href="#wp689" class="title">Gathering Text Entry Metrics on Android Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979799&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Steven J. Castellucci</span> <span class="affiliation">York University</span>, <br />
<span class="author">I. Scott MacKenzie</span> <span class="affiliation">York University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We developed an application to gather text entry speed and accuracy metrics on Android devices. This paper details the features of the application and describes a pilot study to demonstrate its utility. We evaluated and compared three mobile text entry methods: QWERTY typing, handwriting recognition, and shape writing recognition. Handwriting was the slowest and least accurate technique. QWERTY was faster than shape writing, but we found no significant difference in accuracy between the two techniques.</span></div></div><div class="paper" id="wp695"><a href="#wp695" class="title">Mobile Phones and Information Capture in the Workplace</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979800&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amrita  Thakur</span> <span class="affiliation">Ricoh Innovations, Inc.  Stanford University</span>, <br />
<span class="author">Michael  Gormish</span> <span class="affiliation">Ricoh Innovations, Inc.</span>, <br />
<span class="author">Berna  Erol</span> <span class="affiliation">Ricoh Innovations, Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Smartphones (mobile phones with downloadable applications) are being used for far more than making calls and reading email. We investigated the use of phones for information capture for work purposes through interviews, multiple free response surveys, and two multiple choice surveys. While we expected and found taking pictures to be useful for work, we were surprised at the extent of audio, video, and note taking done on the phone, and the impact on other devices. Our work also suggests future mobile information capture for work will increase more due to cultural changes than technological improvements.</span></div></div><div class="paper" id="wp696"><a href="#wp696" class="title">Phone-Based Motion Control in VR - Analysis of degrees of freedom</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979801&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amal  Benzina</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Marcus  Toennis</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Gudrun  Klinker</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Ashry  Mohamed</span> <span class="affiliation">The German University in Cairo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce a one-handed travel technique for virtual environments (VE), we call Phone-Based Motion Control. The travel technique uses a mobile phone with integrated sensors as a 3D spatial input device. We benefit from the touch capability to change the viewpoint translation in the VE, while the orientation of the viewpoint in the VE is controlled by the built-in sensors. The travel interaction clearly distinguishes between translation (touch based translation control) and rotation (steer based rotation control), putting each set of degrees of freedom to a separate interaction technique. <br /> This work examines how many degrees of freedom are needed to perform the travel task as easy as possible. It also investigates different mapping functions between the user's actions and the viewpoint reactions in the VR. For that purpose, four metaphors are developed for the steer based rotation control technique. The results of the user study indicate the trend that 4 DOF metaphors perform best, and that the usage of a mobile roll to control the viewpoint is the desired mapping. <br /></span></div></div><div class="paper" id="wp700"><a href="#wp700" class="title">Crowdsourcing Suggestions to Programming Problems for Dynamic Web Development Languages</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979802&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dhawal  Mujumdar</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Manuel  Kallenbach</span> <span class="affiliation">RWTH Aachen</span>, <br />
<span class="author">Brandon  Liu</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Developers increasingly consult online examples and message boards to find solutions to common programming tasks. On the web, finding solutions to debugging problems is harder than searching for working code. Prior research introduced a social recommender system, HelpMeOut, that crowdsources debugging suggestions by presenting fixes to errors that peers have applied in the past. However, HelpMeOut only worked for statically typed, compiled programming languages like Java. We investigate how suggestions can be provided for dynamic, interpreted web development languages. Our primary insight is to instrument test-driven development to collect examples of bug fixes. We present Crowd::Debug, a tool for Ruby programmers that realizes these benefits.</span></div></div><div class="paper" id="wp701"><a href="#wp701" class="title">Video Summarization via Crowdsourcing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979803&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shao-Yu  Wu</span> <span class="affiliation">Academia Sinica</span>, <br />
<span class="author">Ruck  Thawonmas</span> <span class="affiliation">Ritsumeikan University</span>, <br />
<span class="author">Kuan-Ta  Chen</span> <span class="affiliation">Academia Sinica</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although video summarization has been studied extensively, existing schemes are neither lightweight nor generalizable to all types of video content. To generate accurate abstractions of all types of video, we propose a framework called Click2SMRY, which leverages the wisdom of the crowd to generate video summaries with a low workload for workers. The framework is lightweight because workers only need to click a dedicated key when they feel that the video being played is reaching a highlight. One unique feature of the framework is that it can generate different abstraction levels of video summaries according to viewers&#8217; preferences in real time. The results of experiments conducted to evaluate the framework demonstrate that it can generate satisfactory summaries for different types of video clips.</span></div></div><div class="paper" id="wp702"><a href="#wp702" class="title">&#8220;I Don&#8217;t Like Crumbs on My Keyboard&#8221;: Eating Behaviors of World of Warcraft Players</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979804&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Natalie  DeWitt</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">David  Lohrmann</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computer gamers are often categorized as being unhealthy due to lack of physical activity and poor eating habits. This mixed methods study revealed that computer gamers, specifically World of Warcraft players, are highly conscious of their food choices and eating decisions either because they value their health or because certain foods impede game play. In order to facilitate healthy behaviors in the game, researchers must consider the reasons why gamers choose certain foods to consume during game play.</span></div></div><div class="paper" id="wp704"><a href="#wp704" class="title">Investigating Phicon Feedback in Non-Visual Tangible User Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979805&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  McGookin</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We investigated ways that users could interact with Phicons in non-visual tabletop tangible user interfaces (TUIs). We carried out a brainstorming and rapid prototyping session with a blind usability expert, using two different non-visual TUI scenarios to quickly explore the design space. From this, we derived a basic set of guidelines and interactions that are common in both scenarios, and which we believe are common in most non-visual tabletop TUI applications.  Future work is focused on validating our findings in a fully functioning system.</span></div></div><div class="paper" id="wp705"><a href="#wp705" class="title">VisualWikiCurator: A Corporate Wiki Plugin</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979806&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicholas  Kong</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Gregorio  Convertino</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Benjamin  Hanrahan</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Ed  Chi</span> <span class="affiliation">Palo Alto Research Center (PARC)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Knowledge workers who maintain corporate wikis face high costs for organizing and updating content on wikis. This problem leads to low adoption rates and compromises the utility of such tools in organizations. We describe a system that seeks to reduce the interactions costs of updating and organizing wiki pages by combining human and machine intelligence. We then present preliminary results of an ongoing evaluation of the tool.</span></div></div><div class="paper" id="wp706"><a href="#wp706" class="title">Descriptive Analysis of Physical Activity Conversations on Twitter</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979807&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Logan  Kendall</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Andrea  Hartzler</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Predrag  Klasnja</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Wanda  Pratt</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores how people are using Twitter.com to manage and share information about health-promoting physical activity. We analyzed archived posts, called &#8220;tweets&#8221;, from Twitter.com to learn about the range, patterns, and captured metadata associated with muscle-strengthening, aerobic, and flexibility-enhancing physical activities. The content analysis describes how people are using Twitter to post about their health-related fitness activities. These findings can support the design of supportive tools and applications connected with the social media platform.</span></div></div><div class="paper" id="wp711"><a href="#wp711" class="title">Social Yoga Mats: Reinforcing Synergy between Physical and Social Activity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979808&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karl  Maybach</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Arun  Nagargoje</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Tomas  Sokoler</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper discusses our early research into the design space for digital technologies that extend the existing synergistic relationship between physical and social activity from fitness centers to the home. We focus on yoga activity for senior citizens and explore the concept of social yoga mats, which spread awareness of individuals&#8217; exercise activities within a peer group. We describe the concept, hardware sketches, exploratory co-design process and discuss our findings and early reflections into this design space. <br /></span></div></div><div class="paper" id="wp713"><a href="#wp713" class="title">Understanding and Designing Cool Technologies for Teenagers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979809&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janet  Read</span> <span class="affiliation">University of Central Lancashire</span>, <br />
<span class="author">Daniel  Fitton</span> <span class="affiliation">University of Central Lancashire</span>, <br />
<span class="author">Benjamin  Cowan</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Russell  Beale</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Yukang  Guo</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Matthew  Horton</span> <span class="affiliation">University of Central Lancashire</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes how initial principles for the designs of an interactive application were informed from a study of &#8216;coolness&#8217; with two different ages of teenagers.  The study used drawings to examine how teenagers might design their environments and these were then analysed by the research team based on a set of characteristics of cool that were drawn from the literature. Results from the teenagers&#8217; drawings demonstrate some change in emphasis between the younger and older age groups and between the genders.  A design space around innovation and rebellion is implicated in the findings.</span></div></div><div class="paper" id="wp717"><a href="#wp717" class="title">Automatically adapting web pages to heterogeneous devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979810&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chinmay Eishan Kulkarni</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott R Klemmer</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Smartphones and other handheld devices have become popular and powerful Internet access devices, yet the Web is still largely optimized for the desktop. We describe a system that automatically transforms desktop-optimized pages to ones better suited to the target device. The system leverages existing platform-customized sites as examples of good design, identifies consistent components across these sites, and renders the desktop page into these components.</span></div></div><div class="paper" id="wp721"><a href="#wp721" class="title">Leveraging Trust Relationships in Digital Backchannel Communications</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979811&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Syavash  Nobarany</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mona  Haraty</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney S Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Brian D Fisher</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Discussions during lecture can clarify lecture points for audience members and help them deepen their understanding. However, the fast-pace of lectures and the large number of attendees can make these discussions impossible. Although digital backchannels have been used to address this problem, they present some drawbacks such as increasing distractions and not providing valuable information. We suggest incorporating audience members&#8217; levels of trust in the knowledge of other members into the design of backchannel communication systems. Based on this approach, we present methods and design considerations to overcome the aforementioned drawbacks of the previous backchannel communication systems.</span></div></div><div class="paper" id="wp724"><a href="#wp724" class="title">Promoting A Physical Security Mental Model For Personal Firewall Warnings</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979812&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Fahimeh  Raja</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Steven  Hsu</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kai-Le  Wang</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We used an iterative process to design personal firewall warnings in which the functionality of a firewall is visualized based on a physical security mental model. We performed a study to determine the degree to which our proposed warnings are understandable for our participants, and the degree to which they convey the risks and encourage safe behavior as compared to warnings based on those from a popular personal firewall. Initial results show that our warnings facilitate the comprehension of warning information, better communicate risk, and increase the likelihood of safe behavior. Moreover, they provided participants with a better understanding of both the functionality of a personal firewall and the consequences of their actions.</span></div></div><div class="paper" id="wp725"><a href="#wp725" class="title">The Role of Commitment Devices and Self-shaping in Persuasive Technology</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979813&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Neema  Moraveji</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Ryo  Akasaka</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Roy  Pea</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">B.J.  Fogg</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We examine the role of self-shaping and commitment devices in persuasive systems. Self-shaping refers to the practice of taking purposeful action in modifying one&#8217;s environment in order to shape or influence one&#8217;s own future behavior. We present results from a survey of 23 users that assessed the role self-shaping plays in their use of persuasive technologies. A second survey elicited 65 self-shaping designs from 41 expert users, finding the Fogg Behavior Model describes how the designs were indeed persuasive. We then reviewed 85 tools based on this model to show the two dimensions that can be used to organize persuasive devices: (1) salience of a tool&#8217;s self-shaping features and (2) their intended flexibility. The resulting four categories of tools are useful for researchers and designers of persuasive systems.</span></div></div><div class="paper" id="wp726"><a href="#wp726" class="title">Trust-aware Privacy Control for Social Media</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979814&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Na  Li</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span>, <br />
<span class="author">Maryam  Najafian Razavi</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span>, <br />
<span class="author">Denis  Gillet</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Due to the huge exposure of personal information in social media, a challenge now is to design effective privacy mechanisms that protect against unauthorized access to social data. In this paper, a trust model for social media is first presented. Based on the trust model, a trust-aware privacy control protocol is proposed, that exploits the underlying inter-entity trust information. The objective is to design a fine-grained privacy scheme that ensures a user&#8217;s online information is disclosed only to sufficiently trustworthy parties.</span></div></div><div class="paper" id="wp727"><a href="#wp727" class="title">Four Factors of Change &#8211; Adaptations of Everyday Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979815&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Leah  Maestri</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper is a follow up study of a 2005-2006 study of everyday design. This follow-up study is an opportunity to gain insights into the social evolution of everyday design systems in the home. We report on changes to five systems and discuss how these changes occurred over the last four to five years. We identify four factors related to the changes 1) shared intent 2) mutual intelligibility, 3) materiality-substitutability, and 4) fit.</span></div></div><div class="paper" id="wp730"><a href="#wp730" class="title">Designing Flexible EMR Systems for Recording and Summarizing Doctor-Patient Interactions</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979816&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyle  Larkin</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Aisling  Kelliher</span> <span class="affiliation">Arizona State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Electronic Medical Records (EMR) are increasingly transitioning from desktop systems to mobile devices. This innovation presents challenges to medical practitioners in terms of doctor-patient interaction, patient record integrity and continuing reliance on paper-based annotation schemas. We describe findings from a pilot study of EMR use by physicians in a family medical clinic and propose guidelines for the design of mobile EMR systems. These guidelines seek to fuse the dynamic capabilities of digital systems with the immediacy and personal nature of paper-based records.</span></div></div><div class="paper" id="wp734"><a href="#wp734" class="title">intangibleCanvas: Free-Air Finger Painting on a Projected Canvas</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979817&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Nic  Lupfer</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Bill  Hamilton</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Haiqiao  Lin</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the advent of new sensing technologies, precision free-air interaction is becoming viable as a contender for the next generation of expressive, embodied interaction modalities. ZeroTouch, a novel multi-touch sensor that allows for free-air multi-finger, multi-object sensing, is one example of this next generation of free-air interfaces. We develop its use in a digitally-projected finger painting application, placing the see-through multitouch sensor in direct line-of-sight between an artist and a remote canvas. This allows the artist to reach through the sensor and paint on the intangibleCanvas as if it were directly in front of them. An iPad is employed as a multimodal workspace for color selection. We evaluate the system through an informal walk-up-and-play installation and comparative study, developing implications for interaction design using this type of precision free-air interface.  <br /></span></div></div><div class="paper" id="wp737"><a href="#wp737" class="title">Evaluating Software for Communities Using Social Affordances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979818&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ben  Hanrahan</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Sameer  Ahuja</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Manuel  Perez-Quinones</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Andrea  Kavanaugh</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we discuss the problems faced when building software for communities. In particular, we introduce the formative evaluation method that emerged while developing two social network sites (SNSs). We acknowledge that the success of software for communities is due, in part, to the network effect, which is difficult to predict. We also acknowl- edge that traditional usability (e.g., individual user perfor- mance) is required, but not sufficient, for the success of a social network. We hypothesize that a missing piece of cur- rent evaluations are the social affordances provided by the system and how well they encourage users into social action. In this paper we present the rationale behind our evaluation, two examples of the evaluation, and discuss the evaluation&#8217;s utility and future work.</span></div></div><div class="paper" id="wp738"><a href="#wp738" class="title">Pupillary Response Based Cognitive Workload Index under Luminance and Emotional Changes</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979819&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jie  Xu</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Yang  Wang</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Fang  Chen</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Ho  Choi</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Guanzhong  Li</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Siyuan  Chen</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Sazzad  Hussain</span> <span class="affiliation">National ICT Australia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pupillary response has been widely accepted as a physiological index of cognitive workload. It can be reliably measured with video-based eye trackers in a non-intrusive way. However, in practice commonly used measures such as pupil size or dilation might fail to evaluate cognitive workload due to various factors unrelated to workload, including luminance condition and emotional arousal. In this work, we investigate machine learning based feature extraction techniques that can both robustly index cognitive workload and adaptively handle changes of pupillary response caused by confounding factors unrelated to workload.</span></div></div><div class="paper" id="wp740"><a href="#wp740" class="title">Heuristics for Evaluating IT Security Management Tools</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979820&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pooya  Jaferian</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Andreas  Sotirakopoulos</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The usability of IT security management (ITSM) tools is hard to evaluate by regular methods, making heuristic evaluation attractive. However, ITSM occurs within a complex and collaborative context that involves diverse stakeholders; this makes standard usability heuristics difficult to apply. We propose a set of ITSM usability heuristics that are based on activity theory and supported by prior research. We performed a study to compare the use of the ITSM heuristics to Nielsen's heuristics for the evaluation of a commercial identity management system. Our preliminary results show that our new ITSM heuristics performed well in finding usability problems. However, we need to perform the study with more participants and perform more detailed analysis to precisely show the differences in applying the ITSM heuristics as compared to Nielsen&#8217;s heuristics.</span></div></div><div class="paper" id="wp742"><a href="#wp742" class="title">Who Needs Energy Management? Reducing Energy Consumption in Manufacturing Industries - Early Results of Research into Industrial Energy Management Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span><div class="authors"><span class="author">Daniela K.  Busse</span> <span class="affiliation">SAP Labs (Palo Alto)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this Work-in-Progress report, research into the potential target users for an Industrial Energy Management solution is being discussed with reference to both on-site and remote user interviews conducted in 2010 with Energy Managers of several US companies in high energy-intensity manufacturing industries.</span></div></div><div class="paper" id="wp743"><a href="#wp743" class="title">Supporting Visually Impaired Navigation:  A Needs-finding Study</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979822&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pablo-Alejandro  Quinones</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Tammy  Greene</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Rayoung  Yang</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Mark  Newman</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we investigate the requirements for designing systems to support wayfinding for visually impaired individuals. We report the results of an interview study with 20 individuals with visual impairments, asking about their way-finding tools, techniques, and obstacles. Our findings provide an account of the practices followed when navigating familiar, unfamiliar, and dynamic environments, and common breakdowns encountered during the wayfinding process. The findings from this study suggest ways of implementing a location-based system to assist in the recovery from various obstacles.</span></div></div><div class="paper" id="wp748"><a href="#wp748" class="title">Beyond Drunk Texting: Investigating Recorded Media Sharing at Parties</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979823&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gavin  Elster</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Lawrence  Gabriel</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Anton  Grobman</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We conducted field observations and interviews of college-aged users at parties to understand how they share recorded media. We collected 36 observations from seven private parties and conducted semi-structured follow-up interviews with six selected participants observed at the parties. Three different sharing themes emerged from our data which we term participatory, personal, and open sharing. The type of sharing used in a particular instance was strongly influenced by the context of the environment and the content of the media being shared.</span></div></div><div class="paper" id="wp750"><a href="#wp750" class="title">DARLS: Differencing and Merging Diagrams Using Dual View, Animation, Re-Layout, Layers and a Storyboard</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979824&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Loutfouz  Zaman</span> <span class="affiliation">York University</span>, <br />
<span class="author">Ashish  Kalra</span> <span class="affiliation">NIT Kurukshetra</span>, <br />
<span class="author">Wolfgang  Stuerzlinger</span> <span class="affiliation">York University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a new system for visualizing and merging differences in diagrams. It uses animation, dual views, a storyboard, relative re-layout, and layering to visualize differences. The system is also capable of differencing UML class diagrams. An evaluation produced positive results for animation and dual views with difference layer.</span></div></div><div class="paper" id="wp751"><a href="#wp751" class="title">Audience Visualization Influences Disclosures in Online Social Networks</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979825&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kelly  Caine</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Lorraine G. Kisselburgh</span> <span class="affiliation">Purdue University</span>, <br />
<span class="author">Louise  Lareau</span> <span class="affiliation">Purdue University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">One of the major concerns about online social networks (OSNs) is privacy. We introduce visualization and numeric audience information as potential interface solutions to the problem of privacy behaviors that are misaligned with privacy preferences. Findings from a large experiment with participants of all ages and from a broad range of backgrounds suggest that for both current and potential users, augmenting an interface with a visualization or numeric display of the audience helps people disclose in a way that is more in line with their own preferences. We conclude by proposing that audience visualization and quantification tools have the potential to assist users in achieving their privacy goals while using OSNs and have the potential to enhance privacy in other information systems as well.</span></div></div><div class="paper" id="wp754"><a href="#wp754" class="title">Shepherding the Crowd: Managing and Providing Feedback to Crowd Workers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979826&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Steven  Dow</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Anand  Kulkarni</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Brie  Bunge</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Truc  Nguyen</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott  Klemmer</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Micro-task platforms provide a marketplace for hiring people to do short-term work for small payments. Requesters often struggle to obtain high-quality results, especially on content-creation tasks, because work cannot be easily verified and workers can move to other tasks without consequence. Such platforms provide little opportunity for workers to reflect and improve their task performance. Timely and task-specific feedback can help crowd workers learn, persist, and produce better results. We analyze the design space for crowd feedback and introduce Shepherd, a prototype system for visualizing crowd work, providing feedback, and promoting workers into shepherding roles. This paper describes our current progress and our plans for system development and evaluation.</span></div></div><div class="paper" id="wp760"><a href="#wp760" class="title">Postcolonial Language and Culture Theory for HCI4D</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979827&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Samantha  Merritt</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As technology design spreads to less technologically developed countries, issues of cultural identity, language, and values manifest in the form of methodological and ethical challenges for HCI4D designers. We offer a new theoretical perspective, in the context of HCI4D design, to advance the HCI postcolonial critique and highlight fundamentally Western design practices. Application of Thiong&#8217;o&#8217;s language and culture theory provides a tool for designers and researchers to face assumptions, cultural communication, and the potential repercussions in cross-cultural design. Upon future development, this postcolonial orientation could be used to create responsible, successful designs and create awareness of inadvertent Western language culture embedded in HCI4D design.</span></div></div><div class="paper" id="wp762"><a href="#wp762" class="title">Better Brain Interfacing for the Masses: Progress in Event-Related Potential Detection using Commercial Brain Computer Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979828&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mick  Grierson</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Chris  Kiefer</span> <span class="affiliation">Goldsmiths, University of London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Event-Related Potential (ERP) techniques are commonly used by researchers from a range of disciplines including psychology and medicine to stimulate meaningful ERP signals from the brain and interpret them through Electroencephalography (EEG). ERP signals are in most cases able to reliably reflect cognitive processes, and are widely used in Brain Computer Interface (BCI) research. We present work in progress towards the application of these techniques to emerging consumer-grade BCI technology. Our approach has an impact on the reliability and usability of consumer Brain Computer Interfaces in commercial contexts, and is already being adopted by our industry partners in the games and entertainment sector. It could also significantly reduce the cost and complexity of certain types of large scale ERP research. This work is being undertaken by the Embodied AudioVisual Interaction (EAVI) group at Goldsmiths, University of London, and is supported by the Arts and Humanities Research Council.</span></div></div><div class="paper" id="wp770"><a href="#wp770" class="title">&#8220;Does It Know I&#8217;m Not Maintaining Good Posture?&#8221;: An In-Home Play Study of Wii Fit</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979829&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lindsay  Reynolds</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Steven  Ibara</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Victoria  Schwanda</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Dan  Cosley</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Persuasive technologies designed to improve the health and fitness of users are becoming increasingly popular. One example is Nintendo's Wii Fit, which has achieved commercial success. Despite this success, many people ultimately abandon this technology. Past work explored reasons for leaving, but retroactively. This study examines the reactions of first-time users of Wii Fit, through a one-time interview pilot study as well as an in-depth, month-long study in which participants used Wii Fit in their homes. We briefly present themes from the pilot study, as well as case studies from two month-long study participants, which shows how opinions and behaviors changed over time.</span></div></div><div class="paper" id="wp781"><a href="#wp781" class="title">The Role of Dynamic Digital Menu Boards in Consumer Decision Making</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979830&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anicia  Peters</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Brian  Mennecke</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Digital Signage has become a common-place feature in many public spaces and retail establishments; yet, only limited research has been reported to date on these technologies. For example, questions such as their effect on decision-making, cognitive load, and purchase behavior have yet to be examined. In an effort to attract more attention and increase effectiveness, venders of digital signage are rapidly enhancing features and capabilities for these displays. For example, displays are moving from simple 2d screens to 3d auto-stereoscopic screens, screens featuring multimodal forms of interaction are replacing static displays, and display-only screens are being replaced by displays capable of recognizing user characteristics. An important &#8220;new&#8221; type of display is the dynamic digital menu board, which combines digital signage with the power of video. Surprisingly, despite its increasingly common use in areas as diverse as education and retail, only limited academic research on digital signage has been conducted in areas such as marketing with little attention coming from the HCI field. Our research is focused on addressing this shortcoming by applying theories from HCI, marketing, and information systems to investigate the role of video and dynamic digital menu board display characteristics on consumer decision-making. We hypothesize that each consumer decision-making stage will be affected by the &#8220;vividness&#8221; of video in dynamic digital menu boards.</span></div></div><div class="paper" id="wp784"><a href="#wp784" class="title">CalmMeNow: Exploratory Research and Design of Stress Mitigating Mobile Interventions</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979831&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pablo  Paredes</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Matthew  Chan</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes design explorations for stress mitigation on mobile devices based on three types of interventions: haptic feedback, games and social networks. The paper offers a qualitative assessment of the usability of these three types of interventions together with an initial analysis of their potential efficacy. Social networking and games show great potential for stress relief. Lastly, the paper discusses key findings and considerations for long-term studies of stress mitigation in HCI, as well as a list of aspects to be considered when designing calming interventions.</span></div></div><div class="paper" id="wp787"><a href="#wp787" class="title">Using Gaze Patterns to Study and Predict Reading Struggles due to Distraction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979832&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vidhya  Navalpakkam</span> <span class="affiliation">Yahoo! Research</span>, <br />
<span class="author">Justin  Rao</span> <span class="affiliation">Yahoo! Research</span>, <br />
<span class="author">Malcolm  Slaney</span> <span class="affiliation">Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We analyze gaze patterns to study how users in online reading environments cope with visual distraction, and we report gaze markers that identify reading difficulties due to distraction. The amount of visual distraction is varied from none, medium to high by presenting irrelevant graphics beside the reading content in one of 3 conditions: no graphic, static or animated graphics. We find that under highly-distracting conditions, a struggling reader puts more effort into the text &#8212; she takes a longer time to comprehend the text, performs more fixations on the text and frequently revisits previously read content. Furthermore, she reports an unpleasant reading experience. Interestingly, we find that whether the user is distracted and struggles or not can be predicted from gaze patterns alone with up to 80% accuracy and up to 15% better than with non-gaze based features. This suggests that gaze patterns can be used to detect key events such as user struggle/frustration while reading.</span></div></div><div class="paper" id="wp789"><a href="#wp789" class="title">Facilitating Photographic Documentation of Accessibility in Street Scenes</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979833&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marynel  V&#225;zquez</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Aaron  Steinfeld</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present two interactive approaches for assisting users with visual impairments during photographic documentation of transit accessibility. We are working on an application for camera-enabled mobile devices that drives image composition towards highlighting visual information that is expected to be most relevant. In one interaction modality the user is guided trough small device motions that are expected to center the estimated region of interest in street photographs. In the other modality, the user captures the scene while pictures are processed, and the system alerts when enough data has been collected. The image that best aligns with our attention-getting composition model is then selected for documentation purposes. The specific design of these interactions is evolving to promote small motion behaviors by the user. Future work includes user studies.</span></div></div><div class="paper" id="wp793"><a href="#wp793" class="title">Places in Spaces: Common Ground in Virtual Worlds</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979834&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">N. Sadat  Shami</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Thomas  Erickson</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Wendy  Kellogg</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">David  Levine</span> <span class="affiliation">IBM Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Virtual worlds can allow conversational participants to achieve common ground in situations where the information volume and need for clarification is low. We argue in favor of this assertion through an examination of a semi-structured activity among hundreds of users held in a virtual world. Through the idea of 'implicit grounding', we argue that the affordances of contextualized space can allow users to achieve common ground in a low information volume, low clarification need activity. We use the success of the event to re-examine and extend Clark and Brennan's work on grounding in communication.</span></div></div><div class="paper" id="wp797"><a href="#wp797" class="title">Open Source Interface Politics: Identity, Acceptance, Trust, and Lobbying</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979835&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Roshanak  Zilouchian Moghaddam</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Michael  Twidale</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Kora  Bongen</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A study of the Drupal open source project shows the problematic status of usability designers with respect to the larger developer community. Issues of power, trust, and identity arise and affect the way that usability recommendations are acted on or ignored. Making a straightforward case for a particular interface design can be insufficient to convince developers. Instead various additional lobbying strategies may be employed to build up support for the design.</span></div></div><div class="paper" id="wp799"><a href="#wp799" class="title">Multi-Jump: Jump Roping Over Distances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979836&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lining  Yao</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Sayamindu  Dasgupta</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Nadia  Cheng</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Jason  Spingarn-Koff</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Ostap  Rudakevych</span> <span class="affiliation">Harvard University</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Jump roping, a game in which one or more people twirl a rope while others jump over the rope, promotes social interaction among children while developing their coordination skills and physical fitness. However, the traditional game requires that players be in the same physical location. Our &#8216;Multi-Jump&#8217; jump-roping game platform builds on the traditional game by allowing players to participate remotely by employing an augmented rope system. The game involves full-body motion in a shared game space and is enhanced with live video feeds, player rewards and music. Our work aims to expand exertion interface gaming, or games that deliberately require intense physical effort, with genuine tangible interfaces connected to real-time shared social gaming environments.</span></div></div><div class="paper" id="wp803"><a href="#wp803" class="title">Privacy in Domestic Environments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979837&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Peter J. Radics</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Denis  Gracanin</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While there is a growing body of research on privacy, most of the work puts the focus on information privacy. Physical and psychological privacy issues receive little to no attention. However, the introduction of technology into our lives can cause problems with regard to these aspects of privacy. This is especially true when it comes to our homes, both as nodes of our social life and places for relaxation. This paper presents the results of a study intended to capture a part of the phenomenology of privacy in domestic environments.</span></div></div><div class="paper" id="wp804"><a href="#wp804" class="title">Supporting Children's Creativity through Tangible User Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979838&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Allen  Bevans</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ying-Ting  Hsiao</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa  Antle</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We outline a preliminary research approach intended to explore the potential of tangible user interfaces (TUI&#8217;s) in supporting children&#8217;s creative problem solving activities, specifically those requiring the generation of divergent solutions. Our approach is grounded in theoretical notions taken from psychology, neuroscience, and developmental cognition. We detail a TUI currently in development called the Invention Workbench, and summarize how theoretical considerations have shaped the design of the interface.</span></div></div><div class="paper" id="wp808"><a href="#wp808" class="title">The Role of Modality in Virtual Manipulative Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979839&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seungoh  Paek</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Dan  Hoffman</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Antonios  Saravanos</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">John  Black</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Charles  Kinzer</span> <span class="affiliation">Teachers College, Columbia University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The current study examines aspects of multimedia design in virtual learning environments. It compares touch and mouse input methods in conjunction with audio and visual feedback in an effort to improve young children&#8217;s math learning. Fifty-nine (N=59) second grade students played Puzzle Blocks (PBs), a virtual manipulative designed to introduce students to the concept of multiplication through repetitive addition. All participants showed significant learning outcomes after playing PBs for five sessions. The results show that having auditory feedback is a more influential factor than input method. Implications are discussed.</span></div></div><div class="paper" id="wp812"><a href="#wp812" class="title">Line Following: A Path to Spatial Thinking Skills</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979840&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Megen E Brittell</span> <span class="affiliation">University of Oregon</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Encoding cursor position and directional information in synthesized audio feedback facilitates line following.  This technique will aid interpretation and spatial understanding of irregularly shaped line features (e.g. rivers, state boundaries) making maps more accessible to users who are blind or visually impaired.</span></div></div><div class="paper" id="wp813"><a href="#wp813" class="title">IDEAS: An Interface Design Experience for the Autistic Spectrum</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979841&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Laura  Benton</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Hilary  Johnson</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Mark  Brosnan</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Emma  Ashwin</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Beate  Grawemeyer</span> <span class="affiliation">University of Bath</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designing products and services to meet the specific requirements of children with Autism Spectrum Disorder (ASD) can be difficult due to their wide ranging and individual needs. Participatory Design (PD) is a design method that could be used to better meet these needs, by giving this population an opportunity to directly contribute to software designed for their use. Researchers have begun to involve children with ASD in the design process, but there is not yet a design method specifically adapted to support the potential difficulties this group may experience during PD sessions. This paper presents a new design method, IDEAS, which attempts to fulfill this need. The development of this method is described along with an initial pilot undertaken to determine the feasibility of using this method with an ASD population. The results indicate that the majority of children with ASD were able to produce a successful final design using this method, and have the potential to be involved in PD sessions as part of a design team.</span></div></div><div class="paper" id="wp814"><a href="#wp814" class="title">Enhancing Blog Readability for Non-native English Readers in the Enterprise</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979842&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chen-Hsiang  Yu</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Jennifer  Thom-Santelli</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">David  Millen</span> <span class="affiliation">IBM T.J. Watson Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Blogs are an important platform for people to access and share information, particularly in corporate settings where users rely on these systems for their work. However, because a global enterprise is multilingual, not all employees can understand the shared information in these systems easily if the content is written in a user&#8217;s non-native language. As a result, this research focuses on enhancing the readability of blogs in enterprise social software for this group of users. The pilot user study of Japanese and Chinese bloggers suggest there are two main challenges: finding an interesting blog post to read and encountering difficulties in reading blog posts as currently rendered. Based on these findings, we designed and implemented a Firefox extension, Clearly, which uses web customization techniques to improve these two levels of readability issues.</span></div></div><div class="paper" id="wp815"><a href="#wp815" class="title">Interactive Surface Technology for a Mobile Command Centre</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979843&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Victor  Cheung</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Nader  Cheaib</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Stacey D Scott</span> <span class="affiliation">University of Waterloo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, Contextual Inquiry is used to analyze the work inside a mobile command centre of a volunteer group, which provides specialized services and equipment to support events ranging from community-sponsored events to emergency incidents. The suitability and feasibility of utilizing interactive surface technology to support collaboration and coordination, using the mobile command centre as a hub for multiple agencies, are examined. Findings and lessons learned from this work can also inform the design of such technology for more general event organization and emergency response settings.</span></div></div><div class="paper" id="wp816"><a href="#wp816" class="title">Mobile SoundAR: Your phone on your head</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979844&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Syed  Naseh Hussaini</span> <span class="affiliation">Mobile Life @ II</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sound localization plays an important role in providing a believable sound based augmented reality. Human auditory system uses several cues for sound localization and thus it is important to render these cues in virtual environment as well. Though all cues complement each other, head motion is one cue that can work individually to help locate the direction of sound source. Affixing sensors on the head of the user have been used previously by researchers to reintroduce head motion in virtual soundscape and study it. Modern smart phones with motion detecting sensors are becoming highly pervasive in today's society. Such smart phones open up possibilities for early prototyping and testing of ideas, that previously required high fi gadgetry. Wearing the phone on head can track the head movement using gyroscope and accelerometer. This paper discusses development of prototypes to provide head tracking using iPhone4 to provide a believable sound augmentation.</span></div></div><div class="paper" id="wp817"><a href="#wp817" class="title">Enhancing Mobile Browsing and Reading</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979845&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chen-Hsiang  Yu</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Robert C. Miller</span> <span class="affiliation">MIT CSAIL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although the web browser has become a standard interface for information access on the Web, the mobile web browser on the smartphone does not hold the same interest to mobile users. A survey with 11 mobile users shows that only 18% of the participants like mobile web browsers, whereas 82% of them like other mobile applications. This research focuses on understanding mobile users&#8217; difficulties and proposes innovative ideas to enhance mobile web browsing. This research enhances mobile browsing and reading in three directions: (1) dynamically generating mobile web sites for browsing (2) using orientation sensor information to detect natural interactions and text-to-speech (TTS) to continue reading between different activities, and (3) providing a speech interface to ease web navigation and supporting dialog programming for repetitive tasks. The Read4Me Browser is a prototype system built to demonstrate the proposed ideas.</span></div></div><div class="paper" id="sr133"><a href="#sr133" class="title">Exploring Technological Opportunities for Cognitive Impairment Screening</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979512&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hyungsin  Kim</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, I present continuous research on developing a novel computerized screening tool for people with cognitive impairment. With the quickly growing aging population, more effectively accessible screening tools need to be developed. In order to gain an in-depth understanding of the possible technological opportunities, I conducted clinical practice observations, surveys, and interviews with older adults, as well as medical practitioners, such as neurologists and neuropsychologists. Based on the analysis results, I identify several issues in the current practice. I then present an ongoing progression of the development in order to solve the issues with future directions.</span></div></div><div class="paper" id="sr202"><a href="#sr202" class="title">How User Reviews Influence Older and Younger Adults&#8217; Credibility Judgments of Online Health Information</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979520&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vera  Liao</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A laboratory study was conducted to explore whether user reviews, a common Web 2.0 feature on healthcare website, would have differential influence on younger and older adults&#8217; judgment of information credibility. We found that when credibility cues in user reviews were consistent with those in Website contents, older adults benefited more from this supplementary information than younger adults, which allowed older adults to make better credibility judgments. When credibility cues in user reviews were inconsistent with those in Website contents, older adults were less influenced by the user reviews. Results have important implications on how user reviews may facilitate credibility judgment of online health information by older adults.</span></div></div><div class="paper" id="sr160"><a href="#sr160" class="title">Send Me Bubbles:  Multimodal Performance and Social Acceptability</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979513&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Julie Rico Williamson</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The use of performance as the focus of interaction provides the opportunity for exploratory and individual experiences but can also put users in an uncomfortable position. This paper presents an initial user study of a mobile remote awareness application in which users can control their own fish in a virtual fish tank using multimodal input from an external sensing device, where the input styles are created and performed by participants in an open ended sensing model. The study was designed in order to better understand the issues of performance when audience members are both casual passersby and familiar others watching remotely. Additionally, this study investigated the creation of performances and the effects of props when used in different social settings. The study involved pairs of participants interacting with the system in both public and private locations over repeated sessions. The results of this study show how users created and interpreted performances as well as how their consideration of passersby influenced their experiences.</span></div></div><div class="paper" id="sr166"><a href="#sr166" class="title">Frankenstein and Human Error: Device-Oriented Steps are More Problematic than Task-Oriented Ones</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979514&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Maartje  Ament</span> <span class="affiliation">University College London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Most errors in routine procedures are merely annoying, but they can have severe consequences in safety- critical systems such as medical devices. The current work investigates whether errors are more likely to occur on device-oriented steps (those concerned only with the operation of the device) than on task-oriented ones (those that help the user achieve their main task goal). Error rates were recorded on a routine toy task, with several carefully controlled device- and task- oriented steps. Results show that error rates are substantially higher on device-oriented steps, and step times are longer. The findings demonstrate that a step&#8217;s relevance to the task goal plays an important role in the occurrence of slip errors. They further highlight the problems associated with device-oriented steps, and make a strong case for avoiding them as much as possible in interface design.</span></div></div><div class="paper" id="sr173"><a href="#sr173" class="title">A Scalable and Tiling Multi-Monitor Aware Window Manager</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979515&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joona Antero Laukkanen</span> <span class="affiliation">University of Tampere</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The design of a prototypical scalable and tiling multi-monitor aware window manager is described that may overcome some of the layout management problems encountered with tiling window managers. The system also features a novel approach to monitor configuration in which monitors are treated as independent movable viewports to the large virtual desktop. This approach is expected to address a number of distal access and monitor configuration problems. In particular, it will enable many uses of multiple monitors that require dynamic or flexible monitor configurations.</span></div></div><div class="paper" id="sr175"><a href="#sr175" class="title">Sharing Stories "in the wild:" A Mobile Storytelling Case Study</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979516&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth  Bonsignore</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Today&#8217;s mobile devices are natively equipped with multimedia means for children to capture and share their daily experiences. However, designing authoring tools that effectively integrate the discrete media-capture components of mobile devices to enable rich expression remains a challenge. We report results of a study on the observed use of StoryKit, a mobile application that integrates multimodal media-capture tools to support the creation of multimedia stories on the iPhone/iPod Touch/iPad. The primary objectives of the study were to explore the ways in which StoryKit enables individuals to create and share personal stories; and to investigate how the created stories themselves might inform the design of mobile storytelling applications. Its results suggest that StoryKit&#8217;s relatively simple but well-integrated interface enables the creation of vibrant, varied narratives. Further, genre analysis of the types of stories created revealed a surprising volume and diversity of use in educational contexts.</span></div></div><div class="paper" id="sr195"><a href="#sr195" class="title">Trusting Experience Oriented Design</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979517&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aisling Ann O'Kane</span> <span class="affiliation">Mobile Life @ KTH Royal Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although trust and affective experiences have been linked in HCI research, a connection between traditional trust research for automation and experience design has not be made. This paper aims to start this discussion by showing the connection between experience-oriented HCI design and trust in automation through an experimental study of the Lega, a companion device for enriching experiences in museums. An experience-oriented HCI design approach was used to create this device and although it is not traditional automation, this study presents the links found between this approach and the bases of trust in automation, performance, process, and purpose, with regards to experience qualities of transparency, ambiguity, and usefulness, respectively.</span></div></div><div class="paper" id="sr197"><a href="#sr197" class="title">Code Gestalt: A Software Visualization Tool for Human Beings</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979518&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christopher  Kurtz</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Programmers are often faced with the necessity to visualize source code and grasp its structure. In a survey we studied how developers deal with this task. Based on our findings, we present the software visualization tool Code Gestalt, which assists programmers in quickly creating class diagrams. We evaluated and refined our concept using two prototypes. As a result, Code Gestalt introduces the tag overlay and thematic relations. These augmentations to class diagrams display similarities in the vocabulary used in the underlying source code. This simple, yet effective toolset empowers the user to explore and visualize software systems. The preliminary results of a user study investigating Code Gestalt indicate good usability.</span></div></div><div class="paper" id="sr198"><a href="#sr198" class="title">Cultural Difference in Image Searching</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979519&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wei  Dong</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous studies suggested that people from Eastern and Western cultural origins tagged digital images in different ways due to cultural difference in attentional patterns [2]. This study was conducted to examine whether Easterners and Westerners also exhibited dif-ferent behavioral patterns when searching for digital images. European Americans (EA) and Chinese were asked to general search keywords and to draw ideal target images for image searching tasks. Consistent with previous studies, results showed that Chinese were more likely to generate search keywords describing the overall properties of the target images than EA. When drawing ideal target images, EA assigned more space to the main objects than Chinese. The findings provided significant implications for designing cultural-sensitive tools to facilitate image search.</span></div></div><div class="paper" id="sr219"><a href="#sr219" class="title">The Influence of Grids on Spatial and Content Memory</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979522&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Svenja  Leifert</span> <span class="affiliation">University of Konstanz</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present an experiment that aims at understanding the influence that (visual) grid-based structuring of user interfaces can have on spatial and content memory. By the term grid we refer to two different aspects. On the one hand, this relates to the structured alignment, the layout of objects on a canvas. On the other hand, a grid can also be indicated visually by inserting lines that form an array which divides a canvas into smaller fields. In both cases we detected a strong positive influence on spatial memory. On content memory, however, grids have a less beneficial influence. Only if grid lines are visible, the structured alignment has a positive effect. On the other hand, the visibility of grid lines always leads to worse results in content memory performance, independent of the spatial arrangement.</span></div></div><div class="paper" id="sr215"><a href="#sr215" class="title">Digital Commemoration: Surveying the Social Media Revival of Historical Crises</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979521&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sophia B. Liu</span> <span class="affiliation">University of Colorado at Boulder</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social media has facilitated coordination efforts to help save lives, but are people using social media after the emergency phase? To answer this question, the author conducted a study surveying the social media revival of 111 crisis events that occurred over the past 50 years to examine if social media is being used to commemorate historical crises. Quantitative and qualitative social media metrics on each event were collected to determine their social media presence. The findings show that people are using social media to sustain the living record of past crises as an attempt to prevent disasters and strengthen resilience to future crises. Technological and social hazards that occurred before the social media age tended to exhibit a higher social media presence than natural hazards. Also, the revival of past crises typically occurred when they were linked to recent crises that exhibited similar causes, effects, and vulnerabilities. Issues in the construction and implementation of the survey inform the development of sociotechnical systems designed to collect, manage, and analyze historical events through the cyberinfrastructure.</span></div></div></td>
<td colspan="14" class="session_details" id="S1109_details"><div class="paper" id="sp104"><a href="#sp104" class="title">Lifetime Research Award: Filling in the H in HCI</a>&nbsp;-&nbsp;<span class="type">Special Events</span><div class="authors"><span class="author">Terry  Winograd</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Over the decades since the original framing of HCI as dealing with the "human information processor" we have seen an ongoing expansion of the field's perspective on the human side of the interaction. The human is physically embodied, non-rational, emotional, and social. An individual human's activity is part of collective and interactive groups. Every human is enmeshed in a specific economic and political environment as well as a global environment. Each time we broaden our view, we raise new challenges and opportunities for designing interactions with computers and information devices. <br />  <br /> I will reflect on the ways in which the field has introduced new dimensions of humanness over the years, and how that has shaped the research agenda and the kinds of designs we create. I will speculate on where this may go in the future, and how we might expect to see HCI evolving further.</span></div></div></td>
<td colspan="14" class="session_details" id="S1103_details"><div class="sessionChair"><strong>Session Chair: </strong>Loren Terveen (<em>University of Minnesota</em>)</div><div class="paper" id="paper523"><a href="#paper523" class="title">Enhancing Interactional Synchrony with an Ambient Display</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979070&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Madeline  Balaam</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Geraldine  Fitzpatrick</span> <span class="affiliation">Technical University of Vienna</span>, <br />
<span class="author">Judith  Good</span> <span class="affiliation">University of Sussex</span>, <br />
<span class="author">Eric  Harris</span> <span class="affiliation">University of Sussex</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Nonverbal communication is an essential part of face-to-face social interaction, conveying information about emotion and interpersonal relationships. The rigorous sensing capabilities of pervasive technologies and the subtle nature of ambient technologies make them ideal to support the production of nonverbal communication in social interactions. In this paper we present a study using an ambient technology that supports nonverbal communication, and specifically nonverbal behaviours associated with rapport. We show that an ambient display can influence a participant&#8217;s nonverbal behaviour, and that participants are not aware of this change in their behaviour. We discuss these findings in terms of the design and ethical issues that it raises, and define an agenda for future work.</span></div></div><div class="paper" id="paper2137"><a href="#paper2137" class="title">Issues in Evaluating Ambient Displays In the Wild: Two Case Studies</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979071&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">William R Hazlewood</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Erik  Stolterman</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Kay  Connelly</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we discus the complex task of evaluating ambient displays, concentrating on issues within in-situ deployments. We start by describing how these technologies have been evaluated in lab settings, where the focus has been primarily on issues of usability, and argue strongly for the necessity of in-situ evaluation. We then present two case studies involving in-situ evaluations, and from these derive issues that hindered the researchers from being able to delve more deeply into the overall impact of their implementations. We conclude with our own suggestions on possible alternatives to explore for evaluating ambient displays, which are based on the issues derived from our case studies.</span></div></div><div class="paper" id="paper536"><a href="#paper536" class="title">Does MoodyBoard Make Internet Use more Secure? Evaluating an Ambient Security Visualization Tool</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979072&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alexander  De Luca</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Bernhard  Frauendienst</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Max-Emanuel  Maurer</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Julian  Seifert</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Doris  Hausen</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Niels  Kammerer</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Heinrich  Hussmann</span> <span class="affiliation">University of Munich</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Internet users are targets for ever-advancing phishing- and other attacks. The risks are, for example, to disclose credit card information or passwords to unauthorized instances. One approach to help users with insecure situations is provided by MoodyBoard, which uses ambient information to highlight potential risks. In this paper, we present findings from an evaluation of this system. Two user studies were conducted in order to find out whether an ambient security tool can protect users during sensitive tasks. We designed a pilot study to find out whether users understand the warnings and a security study to see if it helps to protect users from phishing attacks. Results show that MoodyBoard users behaved significantly more secure.</span></div></div><div class="paper" id="paper339"><a href="#paper339" class="title">Peripheral Computing During Presentations:  Perspectives on Costs and Preferences</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979073&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shamsi T. Iqbal</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Jonathan  Grudin</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Eric  Horvitz</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Despite the common use of mobile computing devices to communicate and access information, the effects of peripheral computing tasks on people&#8217;s attention is not well understood. Studies that have identified consequences of multitasking in diverse domains have largely focused on influences on productivity. We have yet to understand perceptions and preferences regarding the use of computing devices for potentially extraneous tasks in settings such as presentations at seminars and colloquia. We explore costs and attitudes about the use of computing devices by people attending presentations. We find that audience members who use devices believe that they are missing content being presented and are concerned about social costs. Other attendees report being less offended by multitasking around them than the device users may realize.</span></div></div></td>
<td colspan="14" class="session_details" id="S1106_details"><div class="sessionChair"><strong>Session Chair: </strong>Ed Cutrell (<em>Microsoft Research</em>)</div><div class="paper" id="paper1651"><a href="#paper1651" class="title">Utilizing Multimedia Capabilities of Mobile Phones to  Support Teaching in Schools in Rural Panama</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979081&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elba del Carmen  Valderrama Bahamondez</span> <span class="affiliation">University Duisburg-Essen / University of Stuttgart</span>, <br />
<span class="author">Christian  Winkler</span> <span class="affiliation">University Duisburg-Essen</span>, <br />
<span class="author">Albrecht  Schmidt</span> <span class="affiliation">University of Stuttgart</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Providing good education is one of the major challenges for humanity. In many developing regions in the world improv-ing educational standards is seen as a central building block for improving socio-economic situation of society. Based on our research in Panama we report on how mobile phones can be used as educational tools. In contrast to personal computers mobile phones are widely available and in Panama over 80% of the children have access to phones. We report on four different studies building on one another. We conducted surveys, focus groups, and group interviews with several hundred teachers and pupils to assess opportunities, needs, and threads for using phones in teaching and learning. Based on the feedback received we created a set of use cases and finally evaluated these in a field study in a rural multigrade school in Panama. Our findings suggest that current phones with multimedia capabilities provide a valuable resource for teaching and learning across many subjects. In particular recording of audio and video, programs for drawing, and taking photos were used in very creative and constructive ways beyond the use cases envisioned by us and initial skepticism of parents turned into support.</span></div></div><div class="paper" id="paper1143"><a href="#paper1143" class="title">Infrastructures for low-cost laptop use in Mexican schools</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979082&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ruy  Cervantes</span> <span class="affiliation">Univerisity of California, Irvine</span>, <br />
<span class="author">Mark  Warschauer</span> <span class="affiliation">Univerisity of California, Irvine</span>, <br />
<span class="author">Bonnie  Nardi</span> <span class="affiliation">Univerisity of California, Irvine</span>, <br />
<span class="author">Nithya  Sambasivan</span> <span class="affiliation">Univerisity of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In recent years, a number of low-cost laptops have been created for children&#8217;s education, most notably the XO, developed by One Laptop per Child to embody principles of constructionist learning, and the ClassmatePC, designed by Intel to fit within and improve traditional education. We report on a series of field studies in Mexican elementary schools that deployed the XO or ClassmatePC. Although both devices are promoted as valuable for improving education in developing countries, our studies suggest that creating the social and technical infrastructures needed to sustain school laptop use is far more complex than what technology designers assume.</span></div></div><div class="paper" id="paper1653"><a href="#paper1653" class="title">Utilizing DVD Players as Low-Cost Offline Internet Browsers</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979083&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gaurav  Paruthi</span> <span class="affiliation">Microsoft Research India</span>, <br />
<span class="author">William  Thies</span> <span class="affiliation">Microsoft Research India</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In the developing world, computers and Internet access remain rare.  However, there are other devices that can be used to deliver information, including TVs and DVD players.  In this paper, we work to bridge this gap by delivering offline Internet content on DVD, for interactive playback on ordinary DVD players.  Using the remote control, users can accomplish all of the major functions available in a Web browser, including navigation, hyperlinks, and search. <br />  <br /> As our driving application, we map the entirety of schools-wikipedia.org -- encompassing 5,500 articles and 259,000 screens -- to a double-layer DVD.  We evaluate our system via a study of 20 low-income users in Bangalore, India.  Using our DVD as reference, participants are able to answer factual questions with over 90% success.  While most participants prefer to use a computer if one is available, for resource-poor environments the DVD platform could represent a viable and low-cost alternative.</span></div></div></td>
<td colspan="14" class="session_details" id="S1097_details"><div class="paper" id="pl106"><a href="#pl106" class="title">User Experience Management Post Mergers and Acquisitions</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979488&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janaki  Kumar</span> <span class="affiliation">SAP Labs, LLC</span>, <br />
<span class="author">Dan  Rosenberg</span> <span class="affiliation">SAP Labs, LLC</span>, <br />
<span class="author">Michael  Arent</span> <span class="affiliation">SAP Labs, LLC</span>, <br />
<span class="author">Anna  Wichansky</span> <span class="affiliation">Oracle</span>, <br />
<span class="author">Madhuri  Kolhatkar</span> <span class="affiliation">Oracle</span>, <br />
<span class="author">Esin  Kiris</span> <span class="affiliation">CA</span>, <br />
<span class="author">Russell  Wilson</span> <span class="affiliation">CA</span>, <br />
<span class="author">Arnold  Lund</span> <span class="affiliation">Microsoft Corporation</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This panel will discuss the prominent trend of business consolidations in the enterprise software industry and proffer best practice management techniques for user experience teams following a successfully achieved merger or acquisition.   <br /> Our panelists are UX managers who have experienced multiple mergers or acquisitions and will represent both the acquiring and acquired companies&#8217; perspectives.  <br /> This panel builds on the success of a SIG organized at CH 2010.  It will focus in on the UX management aspect post M&amp;A, since this was most interesting to our audience. <br /> We will discuss design and technical challenges such as multiple UI technologies and platforms, navigation paradigms and menu structures, interaction behaviors, visual designs, as well as cultural and organizational challenges such as different maturity levels of UX teams, User Centered Design practices, job titles, talent management, geographical distribution and other cultural differences.  <br /> Our goal is to explore best practice solutions that could help other UX managers facing similar challenges. <br /></span></div></div></td>
<td colspan="14" class="session_details" id="S1107_details"><div class="sessionChair"><strong>Session Chair: </strong>James Fogarty (<em>University of Washington</em>)</div><div class="paper" id="paper828"><a href="#paper828" class="title">Importance-Driven Compositing Window Management</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979085&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Manuela  Waldner</span> <span class="affiliation">Graz University of Technology</span>, <br />
<span class="author">Markus  Steinberger</span> <span class="affiliation">Graz University of Technology</span>, <br />
<span class="author">Raphael  Grasset</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Dieter  Schmalstieg</span> <span class="affiliation">Graz University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present importance-driven compositing window management, which considers windows not only as basic rectangular shapes but also integrates the importance of the windows' content using a bottom-up visual attention model. Based on this information, importance-driven compositing optimizes the spatial window layout for maximum visibility and interactivity of occluded content in combination with see-through windows. We employ this technique for emerging window manager functions to minimize information overlap caused by popping up windows or floating toolbars and to improve the access to occluded window content. An initial user study indicates that our technique provides a more effective and satisfactory access to occluded information than the well-adopted Alt+Tab window switching technique and see-through windows without optimized spatial layout.</span></div></div><div class="paper" id="paper1877"><a href="#paper1877" class="title">Content and Hierarchy in Pixel-Based Methods for Reverse Engineering Interface Structure</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979086&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Morgan  Dixon</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Daniel  Leventhal</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">James  Fogarty</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The rigidity and fragmentation of GUI toolkits are fundamentally limiting the progress and impact of interaction research. Pixel-based methods offer unique potential for addressing these challenges independent of the implementation of any particular interface or toolkit. This work builds upon Prefab, which enables the modification of existing interfaces. We present new methods for hierarchical models of complex widgets, real-time interpretation of interface content, and real-time interpretation of content and hierarchy throughout an entire interface. We validate our new methods through implementations of four applications: Stencils-based tutorials, ephemeral adaptation, interface translation, and end-user interface customization. We demonstrate these enhancements in complex existing applications created from different user interface toolkits running on different operating systems.</span></div></div><div class="paper" id="paper613"><a href="#paper613" class="title">Client TouchPoint Modeling: Understanding Client Interactions in the Context of Service Delivery</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979087&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aqueasha M Martin</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Yolanda A Rankin</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Joe  Bolinger</span> <span class="affiliation">The Ohio State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Service delivery organizations oftentimes overlook opportunities to cultivate client relationships due to a lack of awareness of the totality of touchpoints, or interactions, that occur between service delivery personnel and client personnel over time. To enable service delivery organizations to strategically manage their client relationships, we introduce the first phase of the Client TouchPoint Modeling (CTM) process in which service delivery teams create a touchpoint map of their collective interactions across a client account. Participatory design sessions with service delivery personnel informed the design of a CTM TouchPoint Map prototype.  Through these sessions, we also discovered a more collaborative approach to CTM, one in which service delivery team members work together to co-construct a unified account map in a way that promotes team transparency and sensemaking of the service experience.</span></div></div><div class="paper" id="paper1834"><a href="#paper1834" class="title">Using Predictive Human Performance Models to Inspire and Support UI Design Recommendations</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979088&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Bonnie E John</span> <span class="affiliation">IBM T. J. Watson Research Center / Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Predictive human performance modeling has traditionally been used to make quantitative comparisons between alternative designs (e.g., task execution time for skilled users) instead of identifying UI problems or making design recommendations. This note investigates how reliably novice modelers can extract design recommendations from their models. Many HCI evaluation methods have been plagued by the &#8220;evaluator effect&#8221; [3], i.e., different people using the same method find different UI problems. Our data and analyses show that predictive human performance modeling is no exception. Novice modelers using CogTool [5] display a 34% Any-Two Agreement in their design recommendations, a result in the upper quartile of evaluator effect studies. However, because these recommendations are grounded in models, they may have more reliable impact on measurable performance than recommendations arising from less formal methods.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">10:00<br />-<br />11:00</td>

<td class="session tbd" id="S1111">
<div class="session_box">
<span class="type"></span>
<a href="#S1111" class="title">Exhibit Hall Open</a>
<span class="location">Ballroom C/D</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S5008">
<div class="session_box">
<span class="type">Interactivity</span>
<a href="#S5008" class="title">Interactivity 2 Open</a>
<span class="location">202/203/204</span>
<strong></strong>

</div>
</td>

<td class="session " id="S5003">
<div class="session_box">
<span class="type">Student Research Competition &amp; Works In Progress</span>
<a href="#S5003" class="title">Poster Interactions: Group 1 Work-in-Progress (WIP100-299) and Student Research Competition</a>
<span class="location">Ballroom Foyer</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="3" class="session_details" id="S5008_details"><div class="paper" id="in122"><a href="#in122" class="title">Coco - The Therapy Robot</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979721&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katharina  Tran phuc</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Torsten  Racky</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Florian  Roth</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Iris  Wegmann</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Christoph  Busch</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Claudia  S&#246;ller-Eckert</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Mara  Pilz</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Katharina  Horst</span> <span class="affiliation">University of Applied Sciences Darmstadt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Coco is a therapeutic robot designed for elderly people in nursing homes or other care facilities. It is an electronic pet that represents a friend and helper who animates, reminds and motivates its owner.  He has 4 main functions: reading, singing, a calendar function and quiz games and can be operated by voice, remote control or base buttons. Pressure sensors in Coco's back react to touch. He interacts with its owner on its own initiative, suggesting to read, sing or play. Coco's memory and activity settings can be customised by carers or relatives. The prototype was implemented with Lego Mindstorms and successfully tested by a focus group. <br /></span></div></div><div class="paper" id="in129"><a href="#in129" class="title">Touch and Copy, Touch and Paste</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979714&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Suranga  Nanayakkara</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">SPARSH explores a novel interaction method to seamlessly transfer data between digital devices in a fun and intuitive way. The user touches whatever data item he or she wants to copy from a device. At that moment, the data item is conceptually saved in the user. Next, the user touches the other device he or she wants to paste/pass the saved content into. SPARSH uses touch-based interactions as indications for what to copy and where to pass it. Technically, the actual transfer of media happens via the information cloud.</span></div></div><div class="paper" id="in130"><a href="#in130" class="title">Mouseless - a Computer Mouse as Small as Invisible</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979715&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mouseless is a novel input device that provides the familiarity of interaction of a physical computer mouse without requiring a real hardware mouse. It consists of an IR laser beam and an IR camera, both of which are embedded in a computer. Mouseless proposes a number of novel additional gestural interactions while supporting all the conventional computer mouse interactions. We present the design and implementation of various Mouseless prototype systems.</span></div></div><div class="paper" id="in132"><a href="#in132" class="title">Obfuscating Authentication Through Haptics, Sound and Light</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979709&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrea  Bianchi</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span>, <br />
<span class="author">Dong-Soo  Kwon</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sensitive digital content associated with or owned by individuals now pervades everyday life. Mediating accessing to it in ways that are usable and secure is an ongoing challenge. We present a series of five PIN entry and transmission systems that address observation attacks in public spaces via shoulder surfing or camera recording. They do this through the use of novel modalities including audio cues, haptic cues and modulated visible light. Each prototype is introduced and motivated, and its strengths and weaknesses are considered.</span></div></div><div class="paper" id="in137"><a href="#in137" class="title">Blinky Blocks: A Physical Ensemble Programming Platform</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979712&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Brian T Kirby</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michael  Ashley-Rollman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Seth Copen Goldstein</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A major impediment to understanding programmable matter is the lack of an existing system with sufficiently many modules of sufficient capabilities. We present the requirements of physically distributed ensembles and discuss the use of the distributed programming language Meld to program ensembles of these units. We demonstrate a new <br /> system designed to meet these requirements called Blinky Blocks and discuss the hardware design we used to create 100 of these modules.</span></div></div><div class="paper" id="in145"><a href="#in145" class="title">humanaquarium: Exploring Audience, Participation, and Interaction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span><div class="authors"><span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Guy  Schofield</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Jayne  Wallace</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Pierre  Boulanger</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">humanaquarium is a movable performance space designed to explore the dialogical relationship between artist and audience. Two musicians perform inside the cube-shaped box, collaborating with participants to co-create an aesthetic audio-visual experience. The front wall of the humanaquarium is a touch-sensitive FTIR window. Max/MSP is used to translate the locations of touches on the window into control data, manipulating the tracking of software synthesizers and audio effects generated in Ableton Live, and influencing a Jitter visualization projected upon the rear wall of the cube.</span></div></div><div class="paper" id="in150"><a href="#in150" class="title">3D-Press - Tangible 3D Haptics on Touch Surfaces: Virtual Compliance</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979717&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Suitability of current haptic three-dimensional user interface (3D-UI) technologies is low for mobile interaction. 3D-Press in reviewed in this paper: a technique to create the haptic illusion that when pressing on a rigid surface is feels compliant. The fact that the illusion is intramodal (haptics only involved in creating it), and that the technology required is simple and with low energy demands, makes it ideal for mobile use. The parameters used in the implementation of 3D-Press influence the characteristics of the illusion.</span></div></div><div class="paper" id="in152"><a href="#in152" class="title">Graffito: Crowd-based Performative Interaction at Festivals</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979725&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Sheridan</span> <span class="affiliation">BigDog Interactive Ltd</span>, <br />
<span class="author">Nick  Bryan-Kinns</span> <span class="affiliation">Queen Mary University of London</span>, <br />
<span class="author">Stuart  Reeves</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Giles  Lane</span> <span class="affiliation">Proboscis</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crowd-based events are generating new forms of crowd-based performative interaction. Nightclubs and festivals are at the cutting edge of crowd-based interaction with ubiquitous computing. The social capital of crowd-based interaction is not well understood and is usually limited to one-off events. Our intention is to explore the possibility for generating a lifelong contextual footprint of crowd-based performative interaction.</span></div></div><div class="paper" id="in154"><a href="#in154" class="title">Galvanic Skin Response-Derived Bookmarking of an Audio Stream</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979716&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew K.X.J. Pan</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gordon Jih-Shiang  Chang</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gokhan H. Himmetoglu</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">AJung  Moon</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Thomas W. Hazelton</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Karon E. MacLean</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Elizabeth A. Croft</span> <span class="affiliation">The University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We demonstrate a novel interaction paradigm driven by implicit, low-attention user control, accomplished by monitoring a user&#8223;s physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. A listener&#8223;s galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our research prototype then automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted.</span></div></div><div class="paper" id="in158"><a href="#in158" class="title">MediaDiver: Viewing and Annotating Multi-View Video</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979711&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gregor  Miller</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Abir  Al Hajri</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Michael  Ilich</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Zoltan  Foley-Fisher</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Manuel  Fernandez</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Daesik  Jang</span> <span class="affiliation">Kunsan National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our novel rich media interface called MediaDiver demonstrates our new interaction techniques for viewing and annotating multiple view video. The demonstration allows attendees to experience novel moving target selection methods (called Hold and Chase), new multi-view selection techniques, automated quality of view analysis to switch viewpoints to follow targets, integrated annotation methods for viewing or authoring meta-content and advanced context sensitive transport and timeline functions. As users have become increasingly sophisticated when managing navigation and viewing of hyper-documents, they transfer their expectations to new media. We demonstrate the technology required to meet these expectations for video. Thus users will be able to directly click on objects in the video to link to more information or other video, easily change camera views and mark-up the video with their own content. The applications of this technology stretch from home video management to broadcast quality media production, which may be consumed on both desktop and mobile platforms.</span></div></div><div class="paper" id="in161"><a href="#in161" class="title">TagURIt: A Proximity-based Game of Tag Using Lumalive e-Textile Displays</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979707&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sylvia H Cheng</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an electronic game of tag that uses proximity sensing and Lumalive displays on garments.  In our game of tag, each player physically represents a location-tagged Universal Resource Indicator (URI). The URIs, one chaser and two target players, wear touch-sensitive Lumalive display shirts. The goal of the game is for the chaser to capture a token displayed on one of the Lumalive shirts, by pressing a touch sensor located on the shirt. When the chaser is in close proximity to the token player, the token jumps to the shirt of the second closest player, making this children&#8217;s game more challenging for adult players.  Our system demonstrates the use of interactive e-textile displays to remove the technological barrier between contact and proximity in the real world, and the seamless representation of gaming information from the virtual world in that real world.</span></div></div><div class="paper" id="in165"><a href="#in165" class="title">Frictional Widgets: Enhancing Touch Interfaces with Programmable Friction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979713&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vincent  Levesque</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Louise  Oram</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Karon  MacLean</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Nicholas  Marchuk</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Dan  Johnson</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">J. Edward  Colgate</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Michael  Peshkin</span> <span class="affiliation">Northwestern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch interactions occur through flat surfaces that lack the tactile richness of physical interfaces. We explore the design possibilities offered by augmenting touchscreens with programmable surface friction. Four exemplar applications &#8211; an alarm clock, a file manager, a game, and a text editor &#8211; demonstrate tactile effects that improve touch interactions by enhancing physicality, performance, and subjective satisfaction.</span></div></div><div class="paper" id="in168"><a href="#in168" class="title">SnowGlobe: A Spherical Fish-Tank VR Display</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979719&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">John  Bolton</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a spherical display with Fish-Tank VR as a means for interacting with three-dimensional objects. We implemented the spherical display by reflecting a projected image off a hemispherical mirror, allowing for a seamless curvilinear display surface. Diffuse illumination is used for detecting touch points on the sphere. The user&#8217;s head position and the position of the sphere are also tracked using a Vicon motion capture device. Users can perform multi-touch gestures to interact with 3D content on the spherical display. Our system relies on the metaphor of a snow globe. Users can walk around a display while maintaining motion parallax corrected viewpoints of the object on the display. They can interact with the 3D object using multitouch interaction techniques, allowing for rotating and scaling of the 3D model on the display.</span></div></div><div class="paper" id="in170"><a href="#in170" class="title">ZeroTouch: A Zero-Thickness Optical Multi-Touch Force Field</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979710&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Sashikanth  Damaraju</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present zero-thickness optical multi-touch sensing, a technique that simplifies sensor/display integration, and enables new forms of interaction not previously possible with other multi-touch sensing techniques. <br /> Using low-cost modulated infrared sensors to quickly determine the visual hull of an interactive area, we enable robust real-time sensing of fingers and hands, even in the presence of strong ambient lighting. Our technology allows for 20+ fingers to be detected, many more than through prior visual hull techniques, and our use of wide-angle optoelectonics allows for excellent touch resolution, even in the corners of the sensor. <br /> With the ability to track objects in free space, as well as its use as a traditional multi-touch sensor, ZeroTouch opens up a new world of interaction possibilities.</span></div></div><div class="paper" id="in207"><a href="#in207" class="title">Immersive VR: A Non-pharmacological Analgesic for Chronic Pain?</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979704&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diane  Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Meehae  Song</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ji-Dong  Yim</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Tyler  Fox</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Steven J Barnes</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mark  Nazemi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Chris  Shaw</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Pam  Squire, MD</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the research work being carried out by the Transforming Pain Research Group &#8211; the only group whose work is entirely focused on the use of immersive VR for chronic pain management. Unlike VR research for acute or short-term pain, which relies on pain "distraction," this research posits a new paradigm for the use of VR. In addition to providing an overview of our work, the present paper also describes one of our current works in detail: the Virtual Meditative Walk.</span></div></div></td>
<td colspan="3" class="session_details" id="S5003_details"><div class="paper" id="wp114"><a href="#wp114" class="title">Low Cost vs. High-End Eye Tracking for Usability Testing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979744&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sune Alstrup Johansen</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Javier  San Agustin</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Henrik  Skovsgaard</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">John Paulin Hansen</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Martin  Tall</span> <span class="affiliation">Duke University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Accuracy of an open source remote eye tracking system and a state-of-the-art commercial eye tracker was measured 4 times during a usability test. Results from 9 participants showed both devices to be fairly stable over time, but the commercial tracker was more accurate with a mean error of 31 pixels against 59 pixels using the low cost system. This suggests that low cost eye tracking can become a viable alternative, when usability studies need not to distinguish between, for instance, particular words or menu items that participants are looking at, but only between larger areas-of-interest they pay attention to.</span></div></div><div class="paper" id="wp118"><a href="#wp118" class="title">A Crowdsourcing Model for Receiving Design Critique</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979745&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anbang  Xu</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span>, <br />
<span class="author">Brian P. Bailey</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designers in many domains are increasingly turning to online communities to receive critiques of early design ideas. However, members of these communities may not contribute an effective critique due to limited skills, motivation, or time, and therefore many critiques may not go beyond &#8220;I (don&#8217;t) like it&#8221;. We propose a new approach for designers to receive online critique. Our approach is novel because it adopts a theoretical framework for effective critique and implements the framework on a popular crowdsourcing platform. Preliminary results show that our approach allows designers to acquire quality critiques in a timely manner that compare favorably with critiques produced from a well-known online community.</span></div></div><div class="paper" id="wp119"><a href="#wp119" class="title">Touch-Bookmark: A Lightweight Navigation and Bookmarking Technique for E-Books</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979746&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dongwook  Yoon</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Yongjun  Cho</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Kiwon  Yeom</span> <span class="affiliation">Korea Institute of Science and Technology</span>, <br />
<span class="author">Ji-Hyung  Park</span> <span class="affiliation">Korea Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The navigation function of an e-book significantly influences its usability. In this paper, we introduce Touch-Bookmark (TB), a multitouch navigation technique for e-books. TB enables users to bookmark a page in a casual manner and return to it quickly when required. Moreover, the users can flip between two remote pages by using simple gestures. In a usability test conducted to evaluate our prototype, users found the technique easy to learn, natural to use, and useful for navigation. Analysis of the patterns of interaction gestures helped identify human factors that should be considered when designing touch interfaces for e-books. The factors include navigation strategies, patterns of interaction gestures, types of books, and motor memory.</span></div></div><div class="paper" id="wp127"><a href="#wp127" class="title">Understanding Email Communication of Persons with Aphasia</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979747&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abdullah  Al Mahmud</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Jean-Bernard  Martens</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An email program has been developed by the Aphasia Union Netherlands (AVN) to enhance communication between aphasics mutually and with their therapists. In this paper we report intermediate evaluation results of the AVN email program. We evaluated the email program in two ways: a. by analyzing the AVN email server logs and b. by collecting subjective responses through questionnaires. Our results indicate that both aphasics and therapists find the email program useful, despite the fact that they expressed several criticisms about its usability. Therefore, some changes are required to make the program better useable and more widely accessible for the target group.</span></div></div><div class="paper" id="wp133"><a href="#wp133" class="title">A Context-Sensitive Device to Help People with Autism Cope with Anxiety</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979748&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marziya  Mohammedali</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Dinh  Phung</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Brett  Adams</span> <span class="affiliation">Curtin University</span>, <br />
<span class="author">Svetha  Venkatesh</span> <span class="affiliation">Curtin University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe a smartphone application that helps people with Autism Spectrum Disorder (ASD) cope with anxiety attacks. Our prototype provides a one-touch interface for indicating a panic level. The device&#8217;s response&#8212;to instruct, soothe, and/or contact carers&#8212;is sensitive to the user&#8217;s context, consisting of time, location, ambient noise, and nearby friends. Formative evaluation unearths a critical challenge to building assistive technologies for ASD sufferers: can regimented interfaces foster flexible behaviour? Our observations suggest that a delicate balance of design goals is required for a viable assistive technology.</span></div></div><div class="paper" id="wp147"><a href="#wp147" class="title">The Effects of Screen-Size and Communication Modality on Psychology of Mobile Device Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979749&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ki Joon  Kim</span> <span class="affiliation">SungKyunKwan University</span>, <br />
<span class="author">S. Shyam  Sundar</span> <span class="affiliation">Pennsylvania State University</span>, <br />
<span class="author">Eunil  Park</span> <span class="affiliation">SungKyunKwan University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Does screen-size matter in mobile devices? There appears to be a move toward larger screens, with recent launches of Apple&#8217;s iPad and Samsung&#8217;s Galaxy Tab, but do these devices undercut the perceived mobility and affect user attitudes toward the technology? To answer these and related questions, the present study examines the effects of screen-size and communication modality (text vs. video) on mobile device users&#8217; perception of mobility and content as well as attitudes toward technology acceptance. Preliminary data from a between-subjects experiment show that smaller screen-size elicited greater perceived mobility while larger screen-size was key to greater enjoyment. News story in video format played a crucial role in providing greater enjoyment and newsworthiness of the news story while news in text format was perceived to be easier to use on a mobile device. Design implications and limitations are discussed, as we prepare for a constructive replication.</span></div></div><div class="paper" id="wp150"><a href="#wp150" class="title">On the use of pervasive computing to support patients with obsessive compulsive disorder</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979750&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vassilis-Javed  Khan</span> <span class="affiliation">NHTV Breda University of Applied Sciences</span>, <br />
<span class="author">Panos  Markopoulos</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Nynke  Spijksma</span> <span class="affiliation">Marina de Wolf Hospital</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Obsessive-compulsive disorder (OCD) is a psychiatric disorder affecting 2% to 3% of world population. Patients having this disorder engage in repetitive and discomforting behaviors usually linked to controlling or cleaning. The potential of technical solutions trying to support both patients and therapists has been to a limited extent explored with some encouraging results. However, the use of a mobile phone application has not yet been explored. We present a study of a distributed application, partly running on mobile phone and partly on a website, with four patients suffering from OCD and their therapist. Our qualitative evaluation yields encouraging conclusions for practitioners and developers of such applications.</span></div></div><div class="paper" id="wp153"><a href="#wp153" class="title">Living with Pain, Staying in Touch: Exploring the Communication Needs of Older Adults with Chronic Pain</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979751&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jessica M David</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Alison  Benjamin</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Ronald M Baecker</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Diane J Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Jeremy P Birnholtz</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">For older adults with chronic pain, maintaining social ties can be difficult. Both chronic pain and social isolation compound each other and are associated with poor health outcomes. Our research explores how technology can be used to facilitate communication and support for older adults with chronic pain. We report on preliminary results of field research with 20 participants and deployment of a digital communicating picture frame prototype. We found that chronic pain introduces unique barriers to synchronous contact and that our prototype seemed to fit the needs of these individuals by supporting meaningful asynchronous communication with the possibility for adjustable reciprocity.</span></div></div><div class="paper" id="wp161"><a href="#wp161" class="title">Ambient Displays: Influencing Movement Patterns</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979752&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tasos  Varoudis</span> <span class="affiliation">arch+ech Architecture</span>, <br />
<span class="author">Sheep  Dalton</span> <span class="affiliation">Open University</span>, <br />
<span class="author">Katerina  Alexiou</span> <span class="affiliation">Open University</span>, <br />
<span class="author">Theodore  Zamenopoulos</span> <span class="affiliation">Open University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Ambient displays are gradually augmenting the principal static elements of architecture, such as walls, transforming space into a dynamic and ever-changing environment. Does the addition of such digital elements influence people&#8217;s perception and understanding of space around them? If so, do ambient displays lead to behavioral changes like people&#8217;s movement in such environments? In this particular study, a series of experiments were conducted to investigate public interior spaces with embedded ambient displays. The findings are then presented showing how the presence of an ambient display through its visual depth affects and changes movement patterns. This study discusses the ability of an ambient display to refine navigation paths and suggests that its visual depth can enhance its effectiveness.</span></div></div><div class="paper" id="wp162"><a href="#wp162" class="title">A Tactile Friend Sense for Keeping Groups Together</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979753&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Martin  Pielot</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Benjamin  Poppinga</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Wilko  Heuten</span> <span class="affiliation">OFFIS Institute for Information Technology</span>, <br />
<span class="author">Susanne  Boll</span> <span class="affiliation">University of Oldenburg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Visiting crowded places at night in a group of friends is a common leisure activity in many parts of the world. However, the chaotic nature of such place makes it difficult to keep the group together. Constantly watching out for the others or frequent use of technology (e.g. phone calls or Google Latitude) may be contradictory to the idea of having a jolly night out. We therefore designed FriendSense, a mobile application that acts as a pervasive anchor to one of the friends. Beyond existing solutions it allows to continuously sense the anchored friend&#8217;s location through vibro-tactile feedback. In a preliminary field study we investigated how this added sense affects a night out at an Oktoberfest-like festival. We found evidence that FriendSense users were more confident and less stressed with keeping the group together.</span></div></div><div class="paper" id="wp165"><a href="#wp165" class="title">Recompose: Direct and Gestural Interaction with an Actuated Surface</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979754&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Blackshaw</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Anthony  DeVincenzi</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">David  Lakatos</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Daniel  Leithinger</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present Recompose, a new system for manipulation of an actuated surface. By collectively utilizing the body as a tool for direct manipulation alongside gestural input for functional manipulation, we show how a user is afforded unprecedented control over an actuated surface. We describe a number of interaction techniques exploring the shared space of direct and gestural input, demonstrating how their combined use can greatly enhance creation and manipulation beyond unaided human capability.</span></div></div><div class="paper" id="wp169"><a href="#wp169" class="title">Make a Trip an Experience: Sharing In-Car Information with Passengers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979755&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ohad  Inbar</span> <span class="affiliation">Ben-Gurion University of the Negev</span>, <br />
<span class="author">Noam  Tractinsky</span> <span class="affiliation">Ben-Gurion University of the Negev</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Current in-vehicle information systems (IVIS) are designed for use by a single entity &#8211; the driver. In this paper we propose that the benefits of IVIS can increase if we also consider the needs of passengers and their potential contribution as additional information handlers who buffer the driver from information overload. The benefits these &#8220;incidental users&#8221; of IVIS can reap from having trip-related information shared with them include reduced boredom, increased trust and a sense of inclusion. Drivers&#8217; benefits include less distraction caused by questions previously aimed at them as the exclusive owners of the trip-related information, and reduced information load by allowing passengers to actively control selected in-car systems.</span></div></div><div class="paper" id="wp171"><a href="#wp171" class="title">Effects of Different Types of Artifacts on Interpretations of Artificial Subtle Expressions (ASEs)</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979756&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Takanori  Komatsu</span> <span class="affiliation">Shinshu University</span>, <br />
<span class="author">Seiji  Yamada</span> <span class="affiliation">National Institute of Informatics</span>, <br />
<span class="author">Kazuki  Kobayashi</span> <span class="affiliation">Shinshu University</span>, <br />
<span class="author">Kotaro  Funakoshi</span> <span class="affiliation">Honda Research Institute</span>, <br />
<span class="author">Mikio  Nakano</span> <span class="affiliation">Honda Research Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">So far, we already confirmed that the artificial subtle expressions (ASEs) from a robot could convey its internal states to participants accurately and intuitively. In this paper, we investigated whether the ASEs from an on-screen artifact could also convey the artifact&#8217;s internal states to participants in order to confirm whether the ASEs can be interpreted consistently for  various types of artifacts. The results clearly showed that the ASEs&#8217; interpretations from on-screen artifact were consistent with the ones from robotic agent.</span></div></div><div class="paper" id="wp174"><a href="#wp174" class="title">Adaptive Eye-Gaze-Guided Interfaces: Design &amp; Performance Evaluation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979757&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Oleg  Komogortsev</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Corey  Holland</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Jose  Camou</span> <span class="affiliation">Texas State University-San Marcos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper considers the effects of user interface adaptation based on regional eye tracker accuracy to improve user performance and satisfaction in an eye-gaze-guided application. We objectively and subjectively evaluated the differences between an adaptive interface, in which navigational elements were placed in regions of highest accuracy, and its inverted counterpart, in which navigational elements were placed in regions of lowest accuracy. The results indicate that by accounting for regional accuracy the adaptive interface was able to provide a significant improvement in user performance, though this effect had little bearing on user satisfaction.</span></div></div><div class="paper" id="wp183"><a href="#wp183" class="title">RegionalSliding: Enhancing Target Selection on Touchscreen-Based Mobile Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979758&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wenchang  Xu</span> <span class="affiliation">Tsinghua University</span>, <br />
<span class="author">Chun  Yu</span> <span class="affiliation">Tsinghua University</span>, <br />
<span class="author">Yuanchun  Shi</span> <span class="affiliation">Tsinghua University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Target selection on mobile devices with touchscreens usually gets users into trouble due to the occlusion of the target by the user&#8217;s finger and ambiguity about which part of the finger generates the result point. In this paper, we propose a novel technique to enhance target selection on touchscreen-based mobile devices, named RegionalSliding, which selectively renders the initially &#8220;selected&#8221; target as well as its &#8220;surrounding&#8221; targets in a non-occluded area when users press down on the screen and enables users to complete the selection with sliding gestures according to the visual feedback from the rendered area. A preliminary user study shows that RegionalSliding increases the selection accuracy and brings good user experience.</span></div></div><div class="paper" id="wp191"><a href="#wp191" class="title">Why not Use Mobile Phones? An Observational Study of Medical Work</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979759&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">So Young  Lee</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Sun Young  Park</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Yunan  Chen</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous studies suggest that mobile phones could prevent many communication and information breakdowns that commonly occur in a hospital environment. However, the actual benefits of mobile phones in medical work remain unexplored. We studied mobile phone usage among nurses in an Emergency Department (ED). Surprisingly, mobile phones were not favored by our study participants. We found that mobile phones do not support essential characteristics of nursing work in ED because they lack support for group awareness, informative interruption, and role-based calling. The findings suggest that the design of mobile devices should support nurses&#8217; share of work responsibilities and the need for information transparency.</span></div></div><div class="paper" id="wp209"><a href="#wp209" class="title">Enhancing Outdoor Navigation Systems through Vibrotactile Feedback</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979760&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominik  Bial</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Dagmar  Kern</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Florian  Alt</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">Albrecht  Schmidt</span> <span class="affiliation">University of Stuttgart</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While driving many tasks compete for the attention of the user, mainly via the audio and visual channel. When designing systems depending upon providing feedback to users (e.g., navigation systems), it is a crucial prerequisite to minimize influence on and distraction <br /> from the driving task. This becomes even more important when designing systems for the use on motorbikes; space for output devices is scarce, as people are wearing helmets visual feedback is often difficult due to lighting conditions, and audio feedback is limited. <br /> In a first step we aimed at creating an understanding as to how information could be communicated in a meaningful way using vibrotactile signals. Therefore, we investigated suitable positions of actuators on the hand, appropriate length of the vibration stimulus, <br /> and different vibration patterns. We built a first prototype with 4 vibration actuators attached to the fingertips and asked 4 participants to test our prototype while driving. With this work we envision to lay the foundations for vibrotactile support in navigation systems.</span></div></div><div class="paper" id="wp210"><a href="#wp210" class="title">Us&#8217;em: Motivating Stroke Survivors to Use their Impaired Arm and Hand in Daily Life</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979761&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luuk  Beursgens</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Freek  Boesten</span> <span class="affiliation">Maastricht University</span>, <br />
<span class="author">Annick  Timmermans</span> <span class="affiliation">Adelante Rehabilitation Centre</span>, <br />
<span class="author">Henk  Seelen</span> <span class="affiliation">Adelante Rehabilitation Centre</span>, <br />
<span class="author">Panos  Markopoulos</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Stroke leaves the majority of its survivors with an impairment of the upper extremity that seriously reduces their quality of life and their ability to live independently. Rehabilitation research has shown that extensive usage of the impaired arm in everyday life can improve arm-hand performance, even in chronic stages after stroke. Such usage though is difficult for patients who need some help to be reminded and motivated for using the impaired arm. This paper presents the user centered design and initial evaluation of Us&#8217;em, a watch-like device that provides feedback to patients regarding the usage of their impaired arm-hand in relation to their non-affected upper extremity in order to motivate them to use their affected arm more.</span></div></div><div class="paper" id="wp217"><a href="#wp217" class="title">Duet for Solo Piano: MirrorFugue for Single User Playing with Recorded Performances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979762&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Xiao  Xiao</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">MirrorFugue is an interface that supports symmetric, real-time collaboration on the piano using spatial metaphors to communicate the hand gesture of collaborators. In this paper, we present an extension of MirrorFugue to support single-user interactions with recorded material and outline usage scenarios focusing on practicing and self-reflection. Based on interviews with expert musicians, we discuss how single-user interactions on MirrorFugue relate to larger themes in music learning and suggest directions for future research.</span></div></div><div class="paper" id="wp226"><a href="#wp226" class="title">OpenID-Enabled Browser: Towards Usable and Secure Web Single Sign-On</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979763&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">San-Tsai  Sun</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Eric  Pospisil</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Ildar  Muslukhov</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Nuray  Dindar</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">OpenID is an open and promising Web single sign-on solution; however, the interaction flows provided by OpenID are inconsistent, counter-intuitive, and vulnerable to phishing attacks. In this work, we investigated the challenges web users face when using OpenID for authentication, and designed a phishing-resistant, privacy-preserving browser add-on to provide a consistent and intuitive single sign-on user experience for the average web users.</span></div></div><div class="paper" id="wp237"><a href="#wp237" class="title">Children may Expect Drag-and-Drop Instead of Point-and-Click</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979764&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wolmet  Barendregt</span> <span class="affiliation">University of Gothenburg</span>, <br />
<span class="author">Mathilde M.  Bekker</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present evidence from a pilot study that children may have started to expect the drag-and-drop interaction style. This is in contrast with probably the most cited paper on this topic from 2001, stating that point-and-click is the most appropriate interaction style for children between 6 and 12 years old. Instead of providing children with information on the interaction style expected we developed two point-and-click interfaces and let children explore those interfaces themselves. Children consistently tried to apply the drag-and-drop interaction style both initially and after having discovered the point-and-click style, resulting in problems in interacting with the interfaces. This was especially clear for the type of action having a natural mapping to holding down the mouse-button, such as cutting or drawing lines. In summary, it appears that children have begun to expect the drag-and-drop interaction style and that deviating from this standard may result in serious usability problems.</span></div></div><div class="paper" id="wp243"><a href="#wp243" class="title">SoloFind: Chains of Interactions with a Mobile Retail Experience System</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979765&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alexander  Wiethoff</span> <span class="affiliation">Ludwig-Maximilians-Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Gregor  Broll</span> <span class="affiliation">DOCOMO Euro-Labs</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents SoloFind, a mobile retail experience system for large consumer electronic stores that helps users to retrieve product information. A tangible user interface (TUI) allows customers to collect product information via a simple, Near Field Communication (NFC) based interaction. This data can be customized, reviewed and compared at an interactive kiosk. The simple, touch-like interaction with NFC provides a seamless user experience for customers. This paper focuses on the design of SoloFind, its features and their preliminary evaluation with an experience prototype.</span></div></div><div class="paper" id="wp244"><a href="#wp244" class="title">Squeeze vs. Tilt: A Comparative Study Using Continuous Tactile Feedback</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979766&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eve  Hoggan</span> <span class="affiliation">University of Helsinki HIIT</span>, <br />
<span class="author">Dari  Trendafilov</span> <span class="affiliation">Nokia</span>, <br />
<span class="author">Teemu  Ahmaniemi</span> <span class="affiliation">Nokia</span>, <br />
<span class="author">Roope  Raisamo</span> <span class="affiliation">University of Tampere</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an investigation into the performance of squeezing as a manipulative interaction technique in comparison to tilting with an aim to answer two questions: is squeezing an effective input technique for mobile devices and can tactile feedback improve performance? The experiment results show that both input methods are viable but squeezing is significantly faster and more sustainable than tilting (with and without tactile feedback).</span></div></div><div class="paper" id="wp246"><a href="#wp246" class="title">Evaluating an Automatic Rotation Feature in Collaborative Tabletop Workspaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979767&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gianluca  Schiavo</span> <span class="affiliation">University of Padova</span>, <br />
<span class="author">Giulio  Jacucci</span> <span class="affiliation">University of Helsinki</span>, <br />
<span class="author">Tommi  Ilmonen</span> <span class="affiliation">Multitouch Ltd.</span>, <br />
<span class="author">Luciano  Gamberini</span> <span class="affiliation">University of Padova</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Tabletops are commonly used for collaboration but would benefit from features that help orient objects to individual users disposed around the display.  We propose an approach of automatic orientation based on fingers and hand detection as a proxy to determine the position of the user. To contribute to the discussion of the relevance of automatic rotation, we present a comparison study of pairs of participants engaged in both loosely and tightly coupled tasks. We collected performance measures, questionnaires and analyze interactions from video recordings. The results show that automatic rotation is more suitable when the collaboration is loosely coupled. Conversely, in tightly coupled tasks performance are worse and user ratings low when automatic rotations are enabled. We conclude that features such as automatic orientation on tabletop are important and promising but that they need to be critically assessed with respect to their effects on collaboration in both tightly and loosely coupled tasks.</span></div></div><div class="paper" id="wp250"><a href="#wp250" class="title">Participatory Sensing for Community Building</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979768&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Whitney</span> <span class="affiliation">University of North Carolina, Charlotte</span>, <br />
<span class="author">Heather  Richter Lipford</span> <span class="affiliation">University of North Carolina, Charlotte</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this research, we explore the viability of using participatory sensing as a means to enhance a sense of community. To accomplish this, we are developing and deploying a suite of participatory sensing applications, where users explicitly report on the state of their environment, such as the location of the bus. In doing so, community members become reliant on each other for valuable information about the community. By better understanding the relationship between participatory sensing and community, we inform the design and research of similar participatory sensing, or crowd-sourced sensing applications.</span></div></div><div class="paper" id="wp251"><a href="#wp251" class="title">Towards User-Centered Mashups: Exploring User Needs for Composite Web Services</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979769&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kaisa  V&#228;&#228;n&#228;nen-Vainio-Mattila</span> <span class="affiliation">Tampere University of Technology</span>, <br />
<span class="author">Minna  W&#228;ljas</span> <span class="affiliation">Tampere University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The Web contains a vast amount of services supporting users in various facets of life. In mashup or composite Web services, elements from various services are combined to create a service which suits users&#8217; needs. Our goal was to explore what kind of composite services users would need. We conducted semi-structured interviews with nine Web service users to investigate their experiences of service composition and expectations to future services. We also asked the participants to sketch their ideal composite service UI for both PC and mobile device. Our results indicate that service users do not yet have much experience of mashups but there is a need to merge functionality and data from different services to achieve the customized, integrated Web service. This work contributes to the development of future Web services and mashup tools.</span></div></div><div class="paper" id="wp254"><a href="#wp254" class="title">Five Strategies for Supporting Healthy Behavior Change</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979770&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yevgeniy  Medynskiy</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Svetlana  Yarosh</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Elizabeth  Mynatt</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There is an ongoing search for theoretical foundations and design principles for interactive systems that support healthy behavior change. In this work-in-progress, we present several behavior change strategies that are currently used in effective health self-management interventions. We then discuss how these strategies can be used in applications that support behavior change in the health/wellness domain.</span></div></div><div class="paper" id="wp264"><a href="#wp264" class="title">Interaction and Rendering Techniques for Handheld Phantograms</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979771&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Finn  Ericsson</span> <span class="affiliation">KTH</span>, <br />
<span class="author">Alex  Olwal</span> <span class="affiliation">KTH</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a number of rendering and interaction techniques that exploit the user's viewpoint for improved realism and immersion in 3D applications on handheld devices. <br />  <br /> Unlike 3D graphics on stationary screens, graphics on handheld devices are seldom regarded from a fixed perspective. This is particularly true for recent mobile platforms, where it is increasingly popular to use device orientation for interaction. We describe a set of techniques for improved perception of rendered 3D content. View-point correct anamorphosis and stereoscopy are discussed along with ways to approximate the spatial relationship between the user and the device. <br />  <br /> We present the design and implementation of a prototype phantogram viewer that was used to explore these methods for interaction with real-time photorealistic 3D models on commercially available mobile devices.</span></div></div><div class="paper" id="wp271"><a href="#wp271" class="title">Puchi Planet : A Tangible Interface Design for Hospitalized Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979772&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shinsuke  Akabane</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Johnson  Leu</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Hiromi  Iwadate</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Jae Won  Choi</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Chin Ching  Chang</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Saori  Nakayama</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Madoka  Terasaki</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Hala  Eldemellawy</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Masa  Inakage</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Susumu  Furukawa</span> <span class="affiliation">Keio University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes the concept, design and prototype of a tangible user interface (TUI) based toy set for the purpose to bring fun into the lives of hospitalized children. The objective is to encourage children to interact with others and satisfy their curiosity of the outside world. This prototype takes the form of a play set that provides the experience of taking a jet tour and seeing different scenes around the world.</span></div></div><div class="paper" id="wp278"><a href="#wp278" class="title">CapWidgets: Tangile Widgets versus Multi-Touch Controls on Mobile Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979773&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sven  Kratz</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Tilo  Westermann</span> <span class="affiliation">Deutsche Telekom Laboratories, TU Berlin</span>, <br />
<span class="author">Michael  Rohs</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Georg  Essl</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present CapWidgets, passive tangible controls for capacitive touch screens. CapWidgets bring back physical controls to off-the-shelf multi-touch surfaces as found in mobile phones and tablet computers. While the user touches the widget, the surface detects the capacitive marker on the widget&#8217;s underside. We study the relative performance of this tangible interaction with direct multi-touch interaction and our experimental results show that user performance and preferences are not automatically in favor of tangible widgets and careful design is necessary to validate their properties.</span></div></div><div class="paper" id="wp281"><a href="#wp281" class="title">Me Hates This: Exploring Different Levels of User Feedback for (Usability) Bug Reporting</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979774&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Florian  Heller</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Leonhard  Lichtschlag</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Moritz  Wittenhagen</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Thorsten  Karrer</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">User feedback for deployed software systems ranges from simple one-bit-feedback to full-blown bug reports. While detailed bug reports are very helpful for the developers to track down problems, the expertise and commitment required from the user is high. We analyzed existing user report systems and propose a flexible and independent hard- and software architecture to collect user feedback. We report our results from a preliminary two-week user study testing the system in the field and discuss challenges and solutions for the collection of multiple levels of user feedback through different modalities.</span></div></div><div class="paper" id="wp283"><a href="#wp283" class="title">TOK &#8211; a Tangible Interface for Storytelling</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979775&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cristina  Sylla</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Pedro  Branco</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Clara  Coutinho</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Eduarda  Coquet</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">David  &#352;karoupka</span> <span class="affiliation">Brno University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the design of the first prototype of TOK - a tangible interface for children to create their own stories. Based on data collected with two groups of five years old preschoolers we present our findings regarding the interaction design of the system. The picture cards have shown to generate ideas, acting as input for the creation of stories, promoting creativity while proposing a framework that supports and guides the construction of logical structures. This is a first step in an effort to build a toolkit of tangible interfaces allowing children and teachers to build their own digital enhanced learning activities.</span></div></div><div class="paper" id="wp289"><a href="#wp289" class="title">Collision Avoidance in Virtual Environments through Aural Spacial Awareness</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979776&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christian  Afonso</span> <span class="affiliation">University of Hamburg</span>, <br />
<span class="author">Steffi  Beckhaus</span> <span class="affiliation">University of Hamburg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe a new technique to make users aurally aware of walls surrounding them in a Virtual Environment (VE). This Collision Avoidance (CA) technique improves upon familiar Collision Notification (CN) feedback by constantly informing the user of his proximity to his surroundings through the playback of directional sounds. To render the aural CA feedback we use spatial sound played over surround loudspeakers, in addition to haptic feedback from a vibrating sound floor to signify collisions.</span></div></div><div class="paper" id="wp290"><a href="#wp290" class="title">Evaluating the Embodiment Benefits of a Paper-Based TUI for Educational Simulations</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979777&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tia  Shelley</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Leilah  Lyons</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Moira  Zellner</span> <span class="affiliation">University of Illinois at Chicago</span>, <br />
<span class="author">Emily  Minor</span> <span class="affiliation">University of Illinois at Chicago</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many claims have been made regarding the potential benefits of Tangible User Interfaces (TUIs). Presented here is an experiment assessing the usability, problem solving, and collaboration benefits of a TUI for direct placement tasks in spatially-explicit simulations for environmental science education. To create a low-cost deployment for single-computer classrooms, the TUI uses a webcam and computer vision to recognize the placement of paper symbols on a map. An authentic green infrastructure urban planning problem was used as the task for a within-subjects with rotation experiment with 20 pairs of participants. Because no prior experimental study has isolated the influence of the embodied nature of the TUI on usability, problem solving, and collaboration, a control condition was designed to highlight the impact of embodiment. While this study did not establish the usability benefits suggested by prior research, certain problem solving and collaboration advantages were measured.</span></div></div><div class="paper" id="wp295"><a href="#wp295" class="title">The Life Frame: Responding to the Elderly People's Need of Remembering</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979778&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sabina  Giorgi</span> <span class="affiliation">Sapienza University of Rome</span>, <br />
<span class="author">Alessandra  Talamo</span> <span class="affiliation">Sapienza university of Rome</span>, <br />
<span class="author">Barbara  Mellini</span> <span class="affiliation">Sapienza University of Rome</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The paper describes the research project &#8220;The Life frame&#8221; which aims to investigate the added value of digitizing memories for elderly people. It reports the ethnographic research undertaken in order to develop a framework including both devices and services. Data were gathered on the use of mementos in the homes of 241 elderly people and on the technologies that they used, the purpose being to identify the different psychological functions that mementos perform in the homes of this specific target group and to understand the potential use of digital technologies. In the paper we discuss our findings and initial insights for the design of the Life Frame, a device integrated with services for enhancing elderly people&#8217;s personal memories.</span></div></div><div class="paper" id="wp300"><a href="#wp300" class="title">Framework for Measuring Social Affinity for CSCW Software</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979779&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael A Oren</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Stephen B Gilbert</span> <span class="affiliation">Iowa State Universtiy</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Using surveys as a means for assessing group common ground has the possibility of social desirability bias where the results may suggest a higher team affinity rating than may actually exist. To evaluate efforts to improve affinity within interdisciplinary design teams, we developed an empirical measurement of affinity based on behavior and conversation in order to compare affinity differences between workgroups more precisely. This methodology can be used for remote or co-located teams and offers HCI researchers a more powerful method of evaluating group affinity.</span></div></div><div class="paper" id="wp301"><a href="#wp301" class="title">Move-It: Interactive Sticky Notes Actuated by Shape Memory Alloys</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979780&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kathrin  Probst</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Thomas  Seifried</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Michael  Haller</span> <span class="affiliation">Upper Austria University of Applied Sciences</span>, <br />
<span class="author">Kentaro  Yasu</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Maki  Sugimoto</span> <span class="affiliation">Keio University</span>, <br />
<span class="author">Masahiko  Inami</span> <span class="affiliation">Keio University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A lot of people still rely on pen and paper for taking short notes. Post-Its&#174; are still the most popular paper media for informal note taking. In this paper, we present the design and implementation of Move-It, a system that combines the affordances of note taking on paper with the capabilities of computer systems. Furthermore, we present how common Post-It&#174; notes can be actuated by shape memory alloys, thus become interactive sticky notes giving active physical feedback.</span></div></div><div class="paper" id="wp302"><a href="#wp302" class="title">Child-robot Interaction: Playing Alone or Together?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979781&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Suleman  Shahid</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span>, <br />
<span class="author">Emiel  Krahmer</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span>, <br />
<span class="author">Marc  Swerts</span> <span class="affiliation">Tilburg center for Cognition and Communication, Tilburg University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we propose a new method to evaluate child-robot interaction, by asking whether playing a game with a state-of-the-art social robot is more similar to playing this game alone or with a friend. Subjective fun scores suggest that children have more fun playing with the robot than playing alone, but have more fun still when playing with a friend. A perception test of selected fragments indicates that children are more expressive when playing with the robot than they are when playing alone, but less expressive than when playing with a friend. Taken together these results show that playing a game together with a state-of-the-art social robot is more fun than playing alone, and approaches playing with a friend, although more work needs to be done to achieve the latter level.</span></div></div><div class="paper" id="wp307"><a href="#wp307" class="title">Topicality, Time, and Sentiment in Online News Comments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979782&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicholas  Diakopoulos</span> <span class="affiliation">Rutgers University</span>, <br />
<span class="author">Mor  Naaman</span> <span class="affiliation">Rutgers University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we examine the relationships between news comment topicality, temporality, sentiment, and quality in a dataset of 54,540 news comments. Initial observations indicate that comment sentiments, both positive and negative, can be useful indicators of discourse quality, and that aggregate temporal patterns in positive sentiment exist on comment threads.</span></div></div><div class="paper" id="wp308"><a href="#wp308" class="title">Children&#8217;s Drawing and Telling of Sustainability in the Home</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979783&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Audrey  Desjardins</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes a pilot study about children&#8217;s perspective on environmental sustainability in the home through the drawing-telling technique. We utilize the drawing-telling technique as described by Susan Wright [6] for interviewing children about issues related to sustainability. The participants (children from age 10 to 13) were asked to draw two houses (current and ideal) and then describe their drawings in terms of sustainable actions and features. This pilot study is an initial step to investigate if there are opportunities to develop eco-visualizations (EVs) with children in mind and shows that the drawing-telling technique is useful in researching sustainability and children.</span></div></div><div class="paper" id="wp310"><a href="#wp310" class="title">MusEEGk: A Brain Computer Musical Interface</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979784&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yee Chieh (Denise)  Chew</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Eric  Caspary</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a novel integration of a brain-computer interface (BCI) with a music step sequencer composition program. Previous BCIs that utilize EEG data to form music provide users little control over the final composition or do not provide enough feedback. Our interface allows a user to create and modify a melody in real time and provides continuous aural and visual feedback to the user, thus affording them a controllable means to achieve creative expression.</span></div></div><div class="paper" id="wp313"><a href="#wp313" class="title">TableCross: Exuding a Shared Space into Personal Spaces to Encourage Its Voluntary Maintenance</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979785&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kazushi  Nishimoto</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Akari  Ikenoue</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Koji  Shimizu</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Tomonori  Tajima</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Yuta  Tanaka</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Yutaka  Baba</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span>, <br />
<span class="author">Xihong  Wang</span> <span class="affiliation">Japan Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A shared space should be cooperatively maintained by all users. However, due to social loafing, often nobody maintains it and its condition worsens. We propose exudation of a shared space. Part of a shared space is exuded into personal workspaces so that office workers are forced to subjectively experience the atmosphere of the shared space, even while they remain at their personal workspaces. This paper illustrates the first prototype named &#8220;TableCross,&#8221; which reflects the degree of disorder of a table in a shared space to the desktop of each worker&#8217;s PC. We also report some results of our pilot user study.</span></div></div><div class="paper" id="wp318"><a href="#wp318" class="title">Interactivity Sketcher: Crafting and Experiencing Interactivity Qualities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979786&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jong-bum  Woo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Da-jung  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Suin  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Jaesung  Jo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we introduce the Interactivity Sketcher, which is an interactivity designing tool that can visualize and experience invisible interactivity in a tangible way by controlling Interactivity Attributes(IAs). The Interactivity Sketcher is composed of the IA application, input devices, output devices, and IA controllers. The Interactivity Sketcher can help to explore various qualities of interactivity by visualizing and manipulating the relationship between an input and an output through the IA controllers and the IA application. We expect that this tool will enable interaction designers to visualize their own thoughts of interactivity qualities so that they will be able to create their design as if they had &#8216;sketched&#8217; it.</span></div></div><div class="paper" id="wp323"><a href="#wp323" class="title">Predictive Error Behavior Model of On-screen Keyboard Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979787&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Siddharth  Jain</span> <span class="affiliation">IIT Guwahati</span>, <br />
<span class="author">Samit  Bhattacharya</span> <span class="affiliation">IIT Guwahati</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">On-screen keyboards are becoming ubiquitous with increasing use in mobile devices and touch-screens. In this work, we present a novel predictive error model which relates accuracy of an on-screen keyboard user to a given layout using the distance between keys. The model is developed from empirical data with the aim to predict the error rate of a user from the layout specification alone. Our proposed model can be combined with the existing quantitative design approaches for designing keyboards having high text-entry speed and accuracy.</span></div></div><div class="paper" id="wp338"><a href="#wp338" class="title">Weak Inter-Rater Reliability In Heuristic Evaluation Of Video Games</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979788&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gareth R White</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Pejman  Mirza-babaei</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Graham  McAllister</span> <span class="affiliation">The University of Sussex</span>, <br />
<span class="author">Judith  Good</span> <span class="affiliation">The University of Sussex</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Heuristic evaluation promises to be a low-cost usability evaluation method, but is fraught with problems of subjective interpretation, and a proliferation of competing and contradictory heuristic lists. This is particularly true in the field of games research where no rigorous comparative validation has yet been published. In order to validate the available heuristics, a user test of a commercial game is conducted with 6 participants in which 88 issues are identified, against which 146 heuristics are rated for relevance by 3 evaluators. Weak inter-rater reliability is calculated with Krippendorff's Alpha of 0.343, refuting validation of any of the available heuristics. This weak reliability is due to the high complexity of video games, resulting in evaluators interpreting different reasonable causes and solutions for the issues, and hence the wide variance in their ratings of the heuristics.</span></div></div><div class="paper" id="wp339"><a href="#wp339" class="title">guitAR &#8211; Supporting Guitar Learning through Mobile Projection</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979789&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Markus  L&#246;chtefeld</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Sven  Gehring</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Ralf  Jung</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Antonio  Kr&#252;ger</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The guitar is one of the most widespread instruments amongst autodidacts, but even though a huge amount of learning material exists, it is still hard to learn especially without a guitar teacher. In this paper we propose an Augmented Reality application called guitAR that assists guitar students mastering their instrument using a projector phone. With the projector phone mounted at the headstock of the guitar, the fret board and the strings of the guitar are in the field of projection of the phone. By projecting instructions directly onto the strings of the guitar the user is easily able to realize where the fingers have to be placed on the fretboard (fingering) to play a certain chord or a tone sequence correctly.</span></div></div><div class="paper" id="wp343"><a href="#wp343" class="title">Emotion Faces: the Design and Evaluation of a Game for Preschool Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979790&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lynne  Humphries</span> <span class="affiliation">University of Sunderland</span>, <br />
<span class="author">Sharon  McDonald</span> <span class="affiliation">University of Sunderland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the design and initial evaluation of an interactive game that enables preschool children to practise a basic social skill: emotion recognition.  Users construct faces to represent 5 basic emotions through the manipulation of individual face parts.  An iterative user-centred design process was used to gather image and sound data for the game.  A field evaluation revealed that the children (7 boys and 4 girls) enjoyed playing the game and were able to match facial expression to emotions. Girls employed a different approach to game play than boys and achieved a higher success rate but made fewer overall attempts.  Affective and co-operative activity was evident with the children showing joint attention and mirroring of emotions during play.</span></div></div><div class="paper" id="wp345"><a href="#wp345" class="title">Exploring Trust in Group-to-Group Video-Conferencing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979791&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Petr  Slov&#225;k</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Peter  Nov&#225;k</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Pavel  Troubil</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Petr  Holub</span> <span class="affiliation">Masaryk university</span>, <br />
<span class="author">Erik C. Hofer</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous work has shown that supporting trust via computer-mediated communication can be a challenge, especially among strangers. In this paper, we report on an experiment comparing two group-to-group video-conferencing environments and face-to-face communication in their ability to support trust and mutual cooperation in a social dilemma task. There are pronounced differences in participant behaviour between the two video-conferencing designs, indicating higher mutual trust in one of the video-conferencing conditions. The decisive factor seems to be a discrepancy in the type of group identity that develops during the game. Moreover, our results suggest that a combination of personal displays and a unique video-stream of each participant present in the better video-conferencing condition contributed to this result.</span></div></div><div class="paper" id="wp349"><a href="#wp349" class="title">From dance to touch : movement qualities for interaction design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979792&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sarah  Fdili Alaoui</span> <span class="affiliation">LIMSI-CNRS and IRCAM-CNRS</span>, <br />
<span class="author">Baptiste  Caramiaux</span> <span class="affiliation">IRCAM-CNRS</span>, <br />
<span class="author">Marcos  Serrano</span> <span class="affiliation">ENSADLab/Drii</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we address the question of extending user experience in large scale tactile displays. Our contribution is a non task-oriented interaction technique based on modern dance for the creation of aesthetically pleasant large scale tactile interfaces. This approach is based on dance movement qualities applied to touch interaction allowing for natural gestures in large touch displays. We used specific movements from a choreographic glossary and developed a robust movement quality recognition process. To illustrate our approach, we propose a media installation called A light touch, where touch is used to control a light spot reacting to movement qualities.</span></div></div><div class="paper" id="wp350"><a href="#wp350" class="title">The Diversity Donut: Enabling Participant Control Over the Diversity of Recommended Responses</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979793&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Wong</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Siamak  Faridani</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Ephrat  Bitton</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Ken  Goldberg</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Most online discussion interfaces organize textual responses using linear lists.  Such lists do not scale to the number of responses and cannot convey the diversity of the participants who have contributed. The Opinion Space system is designed to address these issues. In this paper, we augment Opinion Space with two features. The first is a new user interface tool and recommendation system: the Diversity Donut (Figure 1). While the Diversity Donut did not establish a statistical advantage over other recommendation methods, participant self-reported data suggested that participants found the Diversity Donut to yield the most diverse set of comments. The second contribution is a new dimensionality reduction technique in Opinion Space: Canonical Correlation Analysis (CCA). Our analysis suggests that CCA is a better algorithm for opinion visualization than Principal Component Analysis (PCA).</span></div></div><div class="paper" id="wp351"><a href="#wp351" class="title">Beyond Pointing and Clicking: How do Newer Interaction Modalities Affect User Engagement?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979794&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S. Shyam  Sundar</span> <span class="affiliation">Penn State University, Sungkyunkwan University</span>, <br />
<span class="author">Qian  Xu</span> <span class="affiliation">Elon University</span>, <br />
<span class="author">Saraswathi  Bellur</span> <span class="affiliation">Penn State University</span>, <br />
<span class="author">Jeeyun  Oh</span> <span class="affiliation">Penn State University</span>, <br />
<span class="author">Haiyan  Jia</span> <span class="affiliation">Penn State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Modern interfaces offer users a wider range of interaction modalities beyond pointing and clicking, such as dragging, sliding, zooming, and flipping through images. But, do they offer any distinct psychological advantages? We address this question with an experiment (N = 128) testing the relative contributions made by six interaction modalities (zoom-in/out, drag, slide, mouse-over, cover-flow and click-to-download) to user engagement with identical content. Data suggest that slide is better at aiding memory than the other modalities, whereas cover-flow and mouse-over generate more user actions. Mouse-over, click-to-download, and zoom-in/out tend to foster more favorable attitudes among power users, whereas cover-flow and slide generate more positive attitudes among non-power users. Design implications are discussed.</span></div></div><div class="paper" id="wp352"><a href="#wp352" class="title">BiCEP: Bimanual Color Exploration Plugin</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979795&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Berto  Gonzalez</span> <span class="affiliation">UNC Charlotte</span>, <br />
<span class="author">Celine  Latulipe</span> <span class="affiliation">UNC Charlotte</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe a bimanual color exploration plugin (BiCEP) that allows a user to choose colors along three dimensions: hue, saturation, and brightness without mode switching between these dimensions. The plugin differs from other color selection tools by allowing users to simultaneously change all three dimensions utilizing a laptop trackpad with multi-touch tracking capabilities. We believe this methodology will improve the range of color exploration by allowing users to more easily explore a wider range of colors.</span></div></div><div class="paper" id="wp661"><a href="#wp661" class="title">MultiPress: Releasing Keys for MultiTap Segmentation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979796&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seunghwan  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Jaehyun  Han</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Geehyuk  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While MultiTap is one of the most popular text entry methods for mobile phones, it has a fundamental weakness known as MultiTap segmentation problem. Based on the observation that the thumb does not leave the keys between tapping actions, we designed a MultiTap segmentation method where the release action of the thumb is used to indicate input completion. A user study using a touch-sensing keypad prototype to explore the feasibility of the idea and a comparison test to access its benefit revealed promising results supporting the effectiveness of the proposed segmentation method.</span></div></div><div class="paper" id="wp670"><a href="#wp670" class="title">Arrange-A-Space: Tabletop Interfaces and Gender Collaboration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979797&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Richert</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Ammar  Halabi</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Anna  Eaglin</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Matthew  Edwards</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Collaborative technologies, such as shared tabletop interfaces, are becoming increasingly pervasive. Meanwhile, social dynamics have long been a major area of inquiry in HCI and CSCW. With a few notable exceptions, little has been done that addresses the roles gender identities play in shaping collaborative work. In this paper, we make the case for a deeper consideration of gender in our field through a study that investigates issues surrounding gendered collaboration around a tabletop interface. We report our findings and conclude with recommendations for future work in this area.</span></div></div><div class="paper" id="wp680"><a href="#wp680" class="title">Informed Consent and Users' Attitudes to Logging in Large Scale Trials</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979798&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alistair  Morrison</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Owain  Brown</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Donald  McMillan</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Matthew  Chalmers</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The HCI community has begun to use &#8216;app store&#8217;-style software repositories as a distribution channel for research applications. A number of ethical challenges present themselves in this setting, not least that of gaining informed consent from potential participants before logging data on their use of the software. We note that standard &#8216;terms and conditions&#8217; pages have proved unsuccessful in communicating relevant information to users, and explore further means of conveying researchers&#8217; intent and allowing opt-out mechanisms. We test the hypothesis that revealing collected information to users will affect their level of concern at being recorded and find that users are more concerned when presented with a personalised representation of recorded data, and consequently stop using the application sooner. Also described is a means of allowing between-groups experiments in such mass participation trials.</span></div></div><div class="paper" id="wp689"><a href="#wp689" class="title">Gathering Text Entry Metrics on Android Devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979799&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Steven J. Castellucci</span> <span class="affiliation">York University</span>, <br />
<span class="author">I. Scott MacKenzie</span> <span class="affiliation">York University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We developed an application to gather text entry speed and accuracy metrics on Android devices. This paper details the features of the application and describes a pilot study to demonstrate its utility. We evaluated and compared three mobile text entry methods: QWERTY typing, handwriting recognition, and shape writing recognition. Handwriting was the slowest and least accurate technique. QWERTY was faster than shape writing, but we found no significant difference in accuracy between the two techniques.</span></div></div><div class="paper" id="wp695"><a href="#wp695" class="title">Mobile Phones and Information Capture in the Workplace</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979800&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amrita  Thakur</span> <span class="affiliation">Ricoh Innovations, Inc.  Stanford University</span>, <br />
<span class="author">Michael  Gormish</span> <span class="affiliation">Ricoh Innovations, Inc.</span>, <br />
<span class="author">Berna  Erol</span> <span class="affiliation">Ricoh Innovations, Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Smartphones (mobile phones with downloadable applications) are being used for far more than making calls and reading email. We investigated the use of phones for information capture for work purposes through interviews, multiple free response surveys, and two multiple choice surveys. While we expected and found taking pictures to be useful for work, we were surprised at the extent of audio, video, and note taking done on the phone, and the impact on other devices. Our work also suggests future mobile information capture for work will increase more due to cultural changes than technological improvements.</span></div></div><div class="paper" id="wp696"><a href="#wp696" class="title">Phone-Based Motion Control in VR - Analysis of degrees of freedom</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979801&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amal  Benzina</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Marcus  Toennis</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Gudrun  Klinker</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Ashry  Mohamed</span> <span class="affiliation">The German University in Cairo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce a one-handed travel technique for virtual environments (VE), we call Phone-Based Motion Control. The travel technique uses a mobile phone with integrated sensors as a 3D spatial input device. We benefit from the touch capability to change the viewpoint translation in the VE, while the orientation of the viewpoint in the VE is controlled by the built-in sensors. The travel interaction clearly distinguishes between translation (touch based translation control) and rotation (steer based rotation control), putting each set of degrees of freedom to a separate interaction technique. <br /> This work examines how many degrees of freedom are needed to perform the travel task as easy as possible. It also investigates different mapping functions between the user's actions and the viewpoint reactions in the VR. For that purpose, four metaphors are developed for the steer based rotation control technique. The results of the user study indicate the trend that 4 DOF metaphors perform best, and that the usage of a mobile roll to control the viewpoint is the desired mapping. <br /></span></div></div><div class="paper" id="wp700"><a href="#wp700" class="title">Crowdsourcing Suggestions to Programming Problems for Dynamic Web Development Languages</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979802&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dhawal  Mujumdar</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Manuel  Kallenbach</span> <span class="affiliation">RWTH Aachen</span>, <br />
<span class="author">Brandon  Liu</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Developers increasingly consult online examples and message boards to find solutions to common programming tasks. On the web, finding solutions to debugging problems is harder than searching for working code. Prior research introduced a social recommender system, HelpMeOut, that crowdsources debugging suggestions by presenting fixes to errors that peers have applied in the past. However, HelpMeOut only worked for statically typed, compiled programming languages like Java. We investigate how suggestions can be provided for dynamic, interpreted web development languages. Our primary insight is to instrument test-driven development to collect examples of bug fixes. We present Crowd::Debug, a tool for Ruby programmers that realizes these benefits.</span></div></div><div class="paper" id="wp701"><a href="#wp701" class="title">Video Summarization via Crowdsourcing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979803&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shao-Yu  Wu</span> <span class="affiliation">Academia Sinica</span>, <br />
<span class="author">Ruck  Thawonmas</span> <span class="affiliation">Ritsumeikan University</span>, <br />
<span class="author">Kuan-Ta  Chen</span> <span class="affiliation">Academia Sinica</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although video summarization has been studied extensively, existing schemes are neither lightweight nor generalizable to all types of video content. To generate accurate abstractions of all types of video, we propose a framework called Click2SMRY, which leverages the wisdom of the crowd to generate video summaries with a low workload for workers. The framework is lightweight because workers only need to click a dedicated key when they feel that the video being played is reaching a highlight. One unique feature of the framework is that it can generate different abstraction levels of video summaries according to viewers&#8217; preferences in real time. The results of experiments conducted to evaluate the framework demonstrate that it can generate satisfactory summaries for different types of video clips.</span></div></div><div class="paper" id="wp702"><a href="#wp702" class="title">&#8220;I Don&#8217;t Like Crumbs on My Keyboard&#8221;: Eating Behaviors of World of Warcraft Players</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979804&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Natalie  DeWitt</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">David  Lohrmann</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computer gamers are often categorized as being unhealthy due to lack of physical activity and poor eating habits. This mixed methods study revealed that computer gamers, specifically World of Warcraft players, are highly conscious of their food choices and eating decisions either because they value their health or because certain foods impede game play. In order to facilitate healthy behaviors in the game, researchers must consider the reasons why gamers choose certain foods to consume during game play.</span></div></div><div class="paper" id="wp704"><a href="#wp704" class="title">Investigating Phicon Feedback in Non-Visual Tangible User Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979805&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  McGookin</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We investigated ways that users could interact with Phicons in non-visual tabletop tangible user interfaces (TUIs). We carried out a brainstorming and rapid prototyping session with a blind usability expert, using two different non-visual TUI scenarios to quickly explore the design space. From this, we derived a basic set of guidelines and interactions that are common in both scenarios, and which we believe are common in most non-visual tabletop TUI applications.  Future work is focused on validating our findings in a fully functioning system.</span></div></div><div class="paper" id="wp705"><a href="#wp705" class="title">VisualWikiCurator: A Corporate Wiki Plugin</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979806&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicholas  Kong</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Gregorio  Convertino</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Benjamin  Hanrahan</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Ed  Chi</span> <span class="affiliation">Palo Alto Research Center (PARC)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Knowledge workers who maintain corporate wikis face high costs for organizing and updating content on wikis. This problem leads to low adoption rates and compromises the utility of such tools in organizations. We describe a system that seeks to reduce the interactions costs of updating and organizing wiki pages by combining human and machine intelligence. We then present preliminary results of an ongoing evaluation of the tool.</span></div></div><div class="paper" id="wp706"><a href="#wp706" class="title">Descriptive Analysis of Physical Activity Conversations on Twitter</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979807&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Logan  Kendall</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Andrea  Hartzler</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Predrag  Klasnja</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Wanda  Pratt</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores how people are using Twitter.com to manage and share information about health-promoting physical activity. We analyzed archived posts, called &#8220;tweets&#8221;, from Twitter.com to learn about the range, patterns, and captured metadata associated with muscle-strengthening, aerobic, and flexibility-enhancing physical activities. The content analysis describes how people are using Twitter to post about their health-related fitness activities. These findings can support the design of supportive tools and applications connected with the social media platform.</span></div></div><div class="paper" id="wp711"><a href="#wp711" class="title">Social Yoga Mats: Reinforcing Synergy between Physical and Social Activity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979808&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karl  Maybach</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Arun  Nagargoje</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Tomas  Sokoler</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper discusses our early research into the design space for digital technologies that extend the existing synergistic relationship between physical and social activity from fitness centers to the home. We focus on yoga activity for senior citizens and explore the concept of social yoga mats, which spread awareness of individuals&#8217; exercise activities within a peer group. We describe the concept, hardware sketches, exploratory co-design process and discuss our findings and early reflections into this design space. <br /></span></div></div><div class="paper" id="wp713"><a href="#wp713" class="title">Understanding and Designing Cool Technologies for Teenagers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979809&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janet  Read</span> <span class="affiliation">University of Central Lancashire</span>, <br />
<span class="author">Daniel  Fitton</span> <span class="affiliation">University of Central Lancashire</span>, <br />
<span class="author">Benjamin  Cowan</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Russell  Beale</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Yukang  Guo</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Matthew  Horton</span> <span class="affiliation">University of Central Lancashire</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes how initial principles for the designs of an interactive application were informed from a study of &#8216;coolness&#8217; with two different ages of teenagers.  The study used drawings to examine how teenagers might design their environments and these were then analysed by the research team based on a set of characteristics of cool that were drawn from the literature. Results from the teenagers&#8217; drawings demonstrate some change in emphasis between the younger and older age groups and between the genders.  A design space around innovation and rebellion is implicated in the findings.</span></div></div><div class="paper" id="wp717"><a href="#wp717" class="title">Automatically adapting web pages to heterogeneous devices</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979810&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chinmay Eishan Kulkarni</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott R Klemmer</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Smartphones and other handheld devices have become popular and powerful Internet access devices, yet the Web is still largely optimized for the desktop. We describe a system that automatically transforms desktop-optimized pages to ones better suited to the target device. The system leverages existing platform-customized sites as examples of good design, identifies consistent components across these sites, and renders the desktop page into these components.</span></div></div><div class="paper" id="wp721"><a href="#wp721" class="title">Leveraging Trust Relationships in Digital Backchannel Communications</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979811&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Syavash  Nobarany</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mona  Haraty</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney S Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Brian D Fisher</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Discussions during lecture can clarify lecture points for audience members and help them deepen their understanding. However, the fast-pace of lectures and the large number of attendees can make these discussions impossible. Although digital backchannels have been used to address this problem, they present some drawbacks such as increasing distractions and not providing valuable information. We suggest incorporating audience members&#8217; levels of trust in the knowledge of other members into the design of backchannel communication systems. Based on this approach, we present methods and design considerations to overcome the aforementioned drawbacks of the previous backchannel communication systems.</span></div></div><div class="paper" id="wp724"><a href="#wp724" class="title">Promoting A Physical Security Mental Model For Personal Firewall Warnings</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979812&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Fahimeh  Raja</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Steven  Hsu</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kai-Le  Wang</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We used an iterative process to design personal firewall warnings in which the functionality of a firewall is visualized based on a physical security mental model. We performed a study to determine the degree to which our proposed warnings are understandable for our participants, and the degree to which they convey the risks and encourage safe behavior as compared to warnings based on those from a popular personal firewall. Initial results show that our warnings facilitate the comprehension of warning information, better communicate risk, and increase the likelihood of safe behavior. Moreover, they provided participants with a better understanding of both the functionality of a personal firewall and the consequences of their actions.</span></div></div><div class="paper" id="wp725"><a href="#wp725" class="title">The Role of Commitment Devices and Self-shaping in Persuasive Technology</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979813&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Neema  Moraveji</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Ryo  Akasaka</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Roy  Pea</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">B.J.  Fogg</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We examine the role of self-shaping and commitment devices in persuasive systems. Self-shaping refers to the practice of taking purposeful action in modifying one&#8217;s environment in order to shape or influence one&#8217;s own future behavior. We present results from a survey of 23 users that assessed the role self-shaping plays in their use of persuasive technologies. A second survey elicited 65 self-shaping designs from 41 expert users, finding the Fogg Behavior Model describes how the designs were indeed persuasive. We then reviewed 85 tools based on this model to show the two dimensions that can be used to organize persuasive devices: (1) salience of a tool&#8217;s self-shaping features and (2) their intended flexibility. The resulting four categories of tools are useful for researchers and designers of persuasive systems.</span></div></div><div class="paper" id="wp726"><a href="#wp726" class="title">Trust-aware Privacy Control for Social Media</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979814&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Na  Li</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span>, <br />
<span class="author">Maryam  Najafian Razavi</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span>, <br />
<span class="author">Denis  Gillet</span> <span class="affiliation">Ecole Polytechnique F&#233;d&#233;rale de Lausanne</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Due to the huge exposure of personal information in social media, a challenge now is to design effective privacy mechanisms that protect against unauthorized access to social data. In this paper, a trust model for social media is first presented. Based on the trust model, a trust-aware privacy control protocol is proposed, that exploits the underlying inter-entity trust information. The objective is to design a fine-grained privacy scheme that ensures a user&#8217;s online information is disclosed only to sufficiently trustworthy parties.</span></div></div><div class="paper" id="wp727"><a href="#wp727" class="title">Four Factors of Change &#8211; Adaptations of Everyday Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979815&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Leah  Maestri</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper is a follow up study of a 2005-2006 study of everyday design. This follow-up study is an opportunity to gain insights into the social evolution of everyday design systems in the home. We report on changes to five systems and discuss how these changes occurred over the last four to five years. We identify four factors related to the changes 1) shared intent 2) mutual intelligibility, 3) materiality-substitutability, and 4) fit.</span></div></div><div class="paper" id="wp730"><a href="#wp730" class="title">Designing Flexible EMR Systems for Recording and Summarizing Doctor-Patient Interactions</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979816&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyle  Larkin</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Aisling  Kelliher</span> <span class="affiliation">Arizona State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Electronic Medical Records (EMR) are increasingly transitioning from desktop systems to mobile devices. This innovation presents challenges to medical practitioners in terms of doctor-patient interaction, patient record integrity and continuing reliance on paper-based annotation schemas. We describe findings from a pilot study of EMR use by physicians in a family medical clinic and propose guidelines for the design of mobile EMR systems. These guidelines seek to fuse the dynamic capabilities of digital systems with the immediacy and personal nature of paper-based records.</span></div></div><div class="paper" id="wp734"><a href="#wp734" class="title">intangibleCanvas: Free-Air Finger Painting on a Projected Canvas</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979817&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Nic  Lupfer</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Bill  Hamilton</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Haiqiao  Lin</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the advent of new sensing technologies, precision free-air interaction is becoming viable as a contender for the next generation of expressive, embodied interaction modalities. ZeroTouch, a novel multi-touch sensor that allows for free-air multi-finger, multi-object sensing, is one example of this next generation of free-air interfaces. We develop its use in a digitally-projected finger painting application, placing the see-through multitouch sensor in direct line-of-sight between an artist and a remote canvas. This allows the artist to reach through the sensor and paint on the intangibleCanvas as if it were directly in front of them. An iPad is employed as a multimodal workspace for color selection. We evaluate the system through an informal walk-up-and-play installation and comparative study, developing implications for interaction design using this type of precision free-air interface.  <br /></span></div></div><div class="paper" id="wp737"><a href="#wp737" class="title">Evaluating Software for Communities Using Social Affordances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979818&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ben  Hanrahan</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Sameer  Ahuja</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Manuel  Perez-Quinones</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Andrea  Kavanaugh</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we discuss the problems faced when building software for communities. In particular, we introduce the formative evaluation method that emerged while developing two social network sites (SNSs). We acknowledge that the success of software for communities is due, in part, to the network effect, which is difficult to predict. We also acknowl- edge that traditional usability (e.g., individual user perfor- mance) is required, but not sufficient, for the success of a social network. We hypothesize that a missing piece of cur- rent evaluations are the social affordances provided by the system and how well they encourage users into social action. In this paper we present the rationale behind our evaluation, two examples of the evaluation, and discuss the evaluation&#8217;s utility and future work.</span></div></div><div class="paper" id="wp738"><a href="#wp738" class="title">Pupillary Response Based Cognitive Workload Index under Luminance and Emotional Changes</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979819&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jie  Xu</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Yang  Wang</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Fang  Chen</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Ho  Choi</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Guanzhong  Li</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Siyuan  Chen</span> <span class="affiliation">National ICT Australia</span>, <br />
<span class="author">Sazzad  Hussain</span> <span class="affiliation">National ICT Australia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pupillary response has been widely accepted as a physiological index of cognitive workload. It can be reliably measured with video-based eye trackers in a non-intrusive way. However, in practice commonly used measures such as pupil size or dilation might fail to evaluate cognitive workload due to various factors unrelated to workload, including luminance condition and emotional arousal. In this work, we investigate machine learning based feature extraction techniques that can both robustly index cognitive workload and adaptively handle changes of pupillary response caused by confounding factors unrelated to workload.</span></div></div><div class="paper" id="wp740"><a href="#wp740" class="title">Heuristics for Evaluating IT Security Management Tools</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979820&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pooya  Jaferian</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kirstie  Hawkey</span> <span class="affiliation">Dalhousie University</span>, <br />
<span class="author">Andreas  Sotirakopoulos</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Konstantin  Beznosov</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The usability of IT security management (ITSM) tools is hard to evaluate by regular methods, making heuristic evaluation attractive. However, ITSM occurs within a complex and collaborative context that involves diverse stakeholders; this makes standard usability heuristics difficult to apply. We propose a set of ITSM usability heuristics that are based on activity theory and supported by prior research. We performed a study to compare the use of the ITSM heuristics to Nielsen's heuristics for the evaluation of a commercial identity management system. Our preliminary results show that our new ITSM heuristics performed well in finding usability problems. However, we need to perform the study with more participants and perform more detailed analysis to precisely show the differences in applying the ITSM heuristics as compared to Nielsen&#8217;s heuristics.</span></div></div><div class="paper" id="wp742"><a href="#wp742" class="title">Who Needs Energy Management? Reducing Energy Consumption in Manufacturing Industries - Early Results of Research into Industrial Energy Management Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span><div class="authors"><span class="author">Daniela K.  Busse</span> <span class="affiliation">SAP Labs (Palo Alto)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this Work-in-Progress report, research into the potential target users for an Industrial Energy Management solution is being discussed with reference to both on-site and remote user interviews conducted in 2010 with Energy Managers of several US companies in high energy-intensity manufacturing industries.</span></div></div><div class="paper" id="wp743"><a href="#wp743" class="title">Supporting Visually Impaired Navigation:  A Needs-finding Study</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979822&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pablo-Alejandro  Quinones</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Tammy  Greene</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Rayoung  Yang</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Mark  Newman</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we investigate the requirements for designing systems to support wayfinding for visually impaired individuals. We report the results of an interview study with 20 individuals with visual impairments, asking about their way-finding tools, techniques, and obstacles. Our findings provide an account of the practices followed when navigating familiar, unfamiliar, and dynamic environments, and common breakdowns encountered during the wayfinding process. The findings from this study suggest ways of implementing a location-based system to assist in the recovery from various obstacles.</span></div></div><div class="paper" id="wp748"><a href="#wp748" class="title">Beyond Drunk Texting: Investigating Recorded Media Sharing at Parties</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979823&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gavin  Elster</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Lawrence  Gabriel</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Anton  Grobman</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We conducted field observations and interviews of college-aged users at parties to understand how they share recorded media. We collected 36 observations from seven private parties and conducted semi-structured follow-up interviews with six selected participants observed at the parties. Three different sharing themes emerged from our data which we term participatory, personal, and open sharing. The type of sharing used in a particular instance was strongly influenced by the context of the environment and the content of the media being shared.</span></div></div><div class="paper" id="wp750"><a href="#wp750" class="title">DARLS: Differencing and Merging Diagrams Using Dual View, Animation, Re-Layout, Layers and a Storyboard</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979824&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Loutfouz  Zaman</span> <span class="affiliation">York University</span>, <br />
<span class="author">Ashish  Kalra</span> <span class="affiliation">NIT Kurukshetra</span>, <br />
<span class="author">Wolfgang  Stuerzlinger</span> <span class="affiliation">York University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a new system for visualizing and merging differences in diagrams. It uses animation, dual views, a storyboard, relative re-layout, and layering to visualize differences. The system is also capable of differencing UML class diagrams. An evaluation produced positive results for animation and dual views with difference layer.</span></div></div><div class="paper" id="wp751"><a href="#wp751" class="title">Audience Visualization Influences Disclosures in Online Social Networks</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979825&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kelly  Caine</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Lorraine G. Kisselburgh</span> <span class="affiliation">Purdue University</span>, <br />
<span class="author">Louise  Lareau</span> <span class="affiliation">Purdue University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">One of the major concerns about online social networks (OSNs) is privacy. We introduce visualization and numeric audience information as potential interface solutions to the problem of privacy behaviors that are misaligned with privacy preferences. Findings from a large experiment with participants of all ages and from a broad range of backgrounds suggest that for both current and potential users, augmenting an interface with a visualization or numeric display of the audience helps people disclose in a way that is more in line with their own preferences. We conclude by proposing that audience visualization and quantification tools have the potential to assist users in achieving their privacy goals while using OSNs and have the potential to enhance privacy in other information systems as well.</span></div></div><div class="paper" id="wp754"><a href="#wp754" class="title">Shepherding the Crowd: Managing and Providing Feedback to Crowd Workers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979826&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Steven  Dow</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Anand  Kulkarni</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Brie  Bunge</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Truc  Nguyen</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott  Klemmer</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Micro-task platforms provide a marketplace for hiring people to do short-term work for small payments. Requesters often struggle to obtain high-quality results, especially on content-creation tasks, because work cannot be easily verified and workers can move to other tasks without consequence. Such platforms provide little opportunity for workers to reflect and improve their task performance. Timely and task-specific feedback can help crowd workers learn, persist, and produce better results. We analyze the design space for crowd feedback and introduce Shepherd, a prototype system for visualizing crowd work, providing feedback, and promoting workers into shepherding roles. This paper describes our current progress and our plans for system development and evaluation.</span></div></div><div class="paper" id="wp760"><a href="#wp760" class="title">Postcolonial Language and Culture Theory for HCI4D</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979827&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Samantha  Merritt</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As technology design spreads to less technologically developed countries, issues of cultural identity, language, and values manifest in the form of methodological and ethical challenges for HCI4D designers. We offer a new theoretical perspective, in the context of HCI4D design, to advance the HCI postcolonial critique and highlight fundamentally Western design practices. Application of Thiong&#8217;o&#8217;s language and culture theory provides a tool for designers and researchers to face assumptions, cultural communication, and the potential repercussions in cross-cultural design. Upon future development, this postcolonial orientation could be used to create responsible, successful designs and create awareness of inadvertent Western language culture embedded in HCI4D design.</span></div></div><div class="paper" id="wp762"><a href="#wp762" class="title">Better Brain Interfacing for the Masses: Progress in Event-Related Potential Detection using Commercial Brain Computer Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979828&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mick  Grierson</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Chris  Kiefer</span> <span class="affiliation">Goldsmiths, University of London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Event-Related Potential (ERP) techniques are commonly used by researchers from a range of disciplines including psychology and medicine to stimulate meaningful ERP signals from the brain and interpret them through Electroencephalography (EEG). ERP signals are in most cases able to reliably reflect cognitive processes, and are widely used in Brain Computer Interface (BCI) research. We present work in progress towards the application of these techniques to emerging consumer-grade BCI technology. Our approach has an impact on the reliability and usability of consumer Brain Computer Interfaces in commercial contexts, and is already being adopted by our industry partners in the games and entertainment sector. It could also significantly reduce the cost and complexity of certain types of large scale ERP research. This work is being undertaken by the Embodied AudioVisual Interaction (EAVI) group at Goldsmiths, University of London, and is supported by the Arts and Humanities Research Council.</span></div></div><div class="paper" id="wp770"><a href="#wp770" class="title">&#8220;Does It Know I&#8217;m Not Maintaining Good Posture?&#8221;: An In-Home Play Study of Wii Fit</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979829&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lindsay  Reynolds</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Steven  Ibara</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Victoria  Schwanda</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Dan  Cosley</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Persuasive technologies designed to improve the health and fitness of users are becoming increasingly popular. One example is Nintendo's Wii Fit, which has achieved commercial success. Despite this success, many people ultimately abandon this technology. Past work explored reasons for leaving, but retroactively. This study examines the reactions of first-time users of Wii Fit, through a one-time interview pilot study as well as an in-depth, month-long study in which participants used Wii Fit in their homes. We briefly present themes from the pilot study, as well as case studies from two month-long study participants, which shows how opinions and behaviors changed over time.</span></div></div><div class="paper" id="wp781"><a href="#wp781" class="title">The Role of Dynamic Digital Menu Boards in Consumer Decision Making</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979830&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anicia  Peters</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Brian  Mennecke</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Digital Signage has become a common-place feature in many public spaces and retail establishments; yet, only limited research has been reported to date on these technologies. For example, questions such as their effect on decision-making, cognitive load, and purchase behavior have yet to be examined. In an effort to attract more attention and increase effectiveness, venders of digital signage are rapidly enhancing features and capabilities for these displays. For example, displays are moving from simple 2d screens to 3d auto-stereoscopic screens, screens featuring multimodal forms of interaction are replacing static displays, and display-only screens are being replaced by displays capable of recognizing user characteristics. An important &#8220;new&#8221; type of display is the dynamic digital menu board, which combines digital signage with the power of video. Surprisingly, despite its increasingly common use in areas as diverse as education and retail, only limited academic research on digital signage has been conducted in areas such as marketing with little attention coming from the HCI field. Our research is focused on addressing this shortcoming by applying theories from HCI, marketing, and information systems to investigate the role of video and dynamic digital menu board display characteristics on consumer decision-making. We hypothesize that each consumer decision-making stage will be affected by the &#8220;vividness&#8221; of video in dynamic digital menu boards.</span></div></div><div class="paper" id="wp784"><a href="#wp784" class="title">CalmMeNow: Exploratory Research and Design of Stress Mitigating Mobile Interventions</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979831&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pablo  Paredes</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Matthew  Chan</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes design explorations for stress mitigation on mobile devices based on three types of interventions: haptic feedback, games and social networks. The paper offers a qualitative assessment of the usability of these three types of interventions together with an initial analysis of their potential efficacy. Social networking and games show great potential for stress relief. Lastly, the paper discusses key findings and considerations for long-term studies of stress mitigation in HCI, as well as a list of aspects to be considered when designing calming interventions.</span></div></div><div class="paper" id="wp787"><a href="#wp787" class="title">Using Gaze Patterns to Study and Predict Reading Struggles due to Distraction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979832&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vidhya  Navalpakkam</span> <span class="affiliation">Yahoo! Research</span>, <br />
<span class="author">Justin  Rao</span> <span class="affiliation">Yahoo! Research</span>, <br />
<span class="author">Malcolm  Slaney</span> <span class="affiliation">Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We analyze gaze patterns to study how users in online reading environments cope with visual distraction, and we report gaze markers that identify reading difficulties due to distraction. The amount of visual distraction is varied from none, medium to high by presenting irrelevant graphics beside the reading content in one of 3 conditions: no graphic, static or animated graphics. We find that under highly-distracting conditions, a struggling reader puts more effort into the text &#8212; she takes a longer time to comprehend the text, performs more fixations on the text and frequently revisits previously read content. Furthermore, she reports an unpleasant reading experience. Interestingly, we find that whether the user is distracted and struggles or not can be predicted from gaze patterns alone with up to 80% accuracy and up to 15% better than with non-gaze based features. This suggests that gaze patterns can be used to detect key events such as user struggle/frustration while reading.</span></div></div><div class="paper" id="wp789"><a href="#wp789" class="title">Facilitating Photographic Documentation of Accessibility in Street Scenes</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979833&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marynel  V&#225;zquez</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Aaron  Steinfeld</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present two interactive approaches for assisting users with visual impairments during photographic documentation of transit accessibility. We are working on an application for camera-enabled mobile devices that drives image composition towards highlighting visual information that is expected to be most relevant. In one interaction modality the user is guided trough small device motions that are expected to center the estimated region of interest in street photographs. In the other modality, the user captures the scene while pictures are processed, and the system alerts when enough data has been collected. The image that best aligns with our attention-getting composition model is then selected for documentation purposes. The specific design of these interactions is evolving to promote small motion behaviors by the user. Future work includes user studies.</span></div></div><div class="paper" id="wp793"><a href="#wp793" class="title">Places in Spaces: Common Ground in Virtual Worlds</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979834&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">N. Sadat  Shami</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Thomas  Erickson</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Wendy  Kellogg</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">David  Levine</span> <span class="affiliation">IBM Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Virtual worlds can allow conversational participants to achieve common ground in situations where the information volume and need for clarification is low. We argue in favor of this assertion through an examination of a semi-structured activity among hundreds of users held in a virtual world. Through the idea of 'implicit grounding', we argue that the affordances of contextualized space can allow users to achieve common ground in a low information volume, low clarification need activity. We use the success of the event to re-examine and extend Clark and Brennan's work on grounding in communication.</span></div></div><div class="paper" id="wp797"><a href="#wp797" class="title">Open Source Interface Politics: Identity, Acceptance, Trust, and Lobbying</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979835&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Roshanak  Zilouchian Moghaddam</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Michael  Twidale</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Kora  Bongen</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A study of the Drupal open source project shows the problematic status of usability designers with respect to the larger developer community. Issues of power, trust, and identity arise and affect the way that usability recommendations are acted on or ignored. Making a straightforward case for a particular interface design can be insufficient to convince developers. Instead various additional lobbying strategies may be employed to build up support for the design.</span></div></div><div class="paper" id="wp799"><a href="#wp799" class="title">Multi-Jump: Jump Roping Over Distances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979836&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lining  Yao</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Sayamindu  Dasgupta</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Nadia  Cheng</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Jason  Spingarn-Koff</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Ostap  Rudakevych</span> <span class="affiliation">Harvard University</span>, <br />
<span class="author">Hiroshi  Ishii</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Jump roping, a game in which one or more people twirl a rope while others jump over the rope, promotes social interaction among children while developing their coordination skills and physical fitness. However, the traditional game requires that players be in the same physical location. Our &#8216;Multi-Jump&#8217; jump-roping game platform builds on the traditional game by allowing players to participate remotely by employing an augmented rope system. The game involves full-body motion in a shared game space and is enhanced with live video feeds, player rewards and music. Our work aims to expand exertion interface gaming, or games that deliberately require intense physical effort, with genuine tangible interfaces connected to real-time shared social gaming environments.</span></div></div><div class="paper" id="wp803"><a href="#wp803" class="title">Privacy in Domestic Environments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979837&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Peter J. Radics</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Denis  Gracanin</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While there is a growing body of research on privacy, most of the work puts the focus on information privacy. Physical and psychological privacy issues receive little to no attention. However, the introduction of technology into our lives can cause problems with regard to these aspects of privacy. This is especially true when it comes to our homes, both as nodes of our social life and places for relaxation. This paper presents the results of a study intended to capture a part of the phenomenology of privacy in domestic environments.</span></div></div><div class="paper" id="wp804"><a href="#wp804" class="title">Supporting Children's Creativity through Tangible User Interfaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979838&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Allen  Bevans</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ying-Ting  Hsiao</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa  Antle</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We outline a preliminary research approach intended to explore the potential of tangible user interfaces (TUI&#8217;s) in supporting children&#8217;s creative problem solving activities, specifically those requiring the generation of divergent solutions. Our approach is grounded in theoretical notions taken from psychology, neuroscience, and developmental cognition. We detail a TUI currently in development called the Invention Workbench, and summarize how theoretical considerations have shaped the design of the interface.</span></div></div><div class="paper" id="wp808"><a href="#wp808" class="title">The Role of Modality in Virtual Manipulative Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979839&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seungoh  Paek</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Dan  Hoffman</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Antonios  Saravanos</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">John  Black</span> <span class="affiliation">Teachers College, Columbia University</span>, <br />
<span class="author">Charles  Kinzer</span> <span class="affiliation">Teachers College, Columbia University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The current study examines aspects of multimedia design in virtual learning environments. It compares touch and mouse input methods in conjunction with audio and visual feedback in an effort to improve young children&#8217;s math learning. Fifty-nine (N=59) second grade students played Puzzle Blocks (PBs), a virtual manipulative designed to introduce students to the concept of multiplication through repetitive addition. All participants showed significant learning outcomes after playing PBs for five sessions. The results show that having auditory feedback is a more influential factor than input method. Implications are discussed.</span></div></div><div class="paper" id="wp812"><a href="#wp812" class="title">Line Following: A Path to Spatial Thinking Skills</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979840&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Megen E Brittell</span> <span class="affiliation">University of Oregon</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Encoding cursor position and directional information in synthesized audio feedback facilitates line following.  This technique will aid interpretation and spatial understanding of irregularly shaped line features (e.g. rivers, state boundaries) making maps more accessible to users who are blind or visually impaired.</span></div></div><div class="paper" id="wp813"><a href="#wp813" class="title">IDEAS: An Interface Design Experience for the Autistic Spectrum</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979841&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Laura  Benton</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Hilary  Johnson</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Mark  Brosnan</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Emma  Ashwin</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Beate  Grawemeyer</span> <span class="affiliation">University of Bath</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designing products and services to meet the specific requirements of children with Autism Spectrum Disorder (ASD) can be difficult due to their wide ranging and individual needs. Participatory Design (PD) is a design method that could be used to better meet these needs, by giving this population an opportunity to directly contribute to software designed for their use. Researchers have begun to involve children with ASD in the design process, but there is not yet a design method specifically adapted to support the potential difficulties this group may experience during PD sessions. This paper presents a new design method, IDEAS, which attempts to fulfill this need. The development of this method is described along with an initial pilot undertaken to determine the feasibility of using this method with an ASD population. The results indicate that the majority of children with ASD were able to produce a successful final design using this method, and have the potential to be involved in PD sessions as part of a design team.</span></div></div><div class="paper" id="wp814"><a href="#wp814" class="title">Enhancing Blog Readability for Non-native English Readers in the Enterprise</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979842&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chen-Hsiang  Yu</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Jennifer  Thom-Santelli</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">David  Millen</span> <span class="affiliation">IBM T.J. Watson Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Blogs are an important platform for people to access and share information, particularly in corporate settings where users rely on these systems for their work. However, because a global enterprise is multilingual, not all employees can understand the shared information in these systems easily if the content is written in a user&#8217;s non-native language. As a result, this research focuses on enhancing the readability of blogs in enterprise social software for this group of users. The pilot user study of Japanese and Chinese bloggers suggest there are two main challenges: finding an interesting blog post to read and encountering difficulties in reading blog posts as currently rendered. Based on these findings, we designed and implemented a Firefox extension, Clearly, which uses web customization techniques to improve these two levels of readability issues.</span></div></div><div class="paper" id="wp815"><a href="#wp815" class="title">Interactive Surface Technology for a Mobile Command Centre</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979843&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Victor  Cheung</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Nader  Cheaib</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Stacey D Scott</span> <span class="affiliation">University of Waterloo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, Contextual Inquiry is used to analyze the work inside a mobile command centre of a volunteer group, which provides specialized services and equipment to support events ranging from community-sponsored events to emergency incidents. The suitability and feasibility of utilizing interactive surface technology to support collaboration and coordination, using the mobile command centre as a hub for multiple agencies, are examined. Findings and lessons learned from this work can also inform the design of such technology for more general event organization and emergency response settings.</span></div></div><div class="paper" id="wp816"><a href="#wp816" class="title">Mobile SoundAR: Your phone on your head</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979844&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Syed  Naseh Hussaini</span> <span class="affiliation">Mobile Life @ II</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sound localization plays an important role in providing a believable sound based augmented reality. Human auditory system uses several cues for sound localization and thus it is important to render these cues in virtual environment as well. Though all cues complement each other, head motion is one cue that can work individually to help locate the direction of sound source. Affixing sensors on the head of the user have been used previously by researchers to reintroduce head motion in virtual soundscape and study it. Modern smart phones with motion detecting sensors are becoming highly pervasive in today's society. Such smart phones open up possibilities for early prototyping and testing of ideas, that previously required high fi gadgetry. Wearing the phone on head can track the head movement using gyroscope and accelerometer. This paper discusses development of prototypes to provide head tracking using iPhone4 to provide a believable sound augmentation.</span></div></div><div class="paper" id="wp817"><a href="#wp817" class="title">Enhancing Mobile Browsing and Reading</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979845&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chen-Hsiang  Yu</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Robert C. Miller</span> <span class="affiliation">MIT CSAIL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although the web browser has become a standard interface for information access on the Web, the mobile web browser on the smartphone does not hold the same interest to mobile users. A survey with 11 mobile users shows that only 18% of the participants like mobile web browsers, whereas 82% of them like other mobile applications. This research focuses on understanding mobile users&#8217; difficulties and proposes innovative ideas to enhance mobile web browsing. This research enhances mobile browsing and reading in three directions: (1) dynamically generating mobile web sites for browsing (2) using orientation sensor information to detect natural interactions and text-to-speech (TTS) to continue reading between different activities, and (3) providing a speech interface to ease web navigation and supporting dialog programming for repetitive tasks. The Read4Me Browser is a prototype system built to demonstrate the proposed ideas.</span></div></div><div class="paper" id="sr133"><a href="#sr133" class="title">Exploring Technological Opportunities for Cognitive Impairment Screening</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979512&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hyungsin  Kim</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, I present continuous research on developing a novel computerized screening tool for people with cognitive impairment. With the quickly growing aging population, more effectively accessible screening tools need to be developed. In order to gain an in-depth understanding of the possible technological opportunities, I conducted clinical practice observations, surveys, and interviews with older adults, as well as medical practitioners, such as neurologists and neuropsychologists. Based on the analysis results, I identify several issues in the current practice. I then present an ongoing progression of the development in order to solve the issues with future directions.</span></div></div><div class="paper" id="sr202"><a href="#sr202" class="title">How User Reviews Influence Older and Younger Adults&#8217; Credibility Judgments of Online Health Information</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979520&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vera  Liao</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A laboratory study was conducted to explore whether user reviews, a common Web 2.0 feature on healthcare website, would have differential influence on younger and older adults&#8217; judgment of information credibility. We found that when credibility cues in user reviews were consistent with those in Website contents, older adults benefited more from this supplementary information than younger adults, which allowed older adults to make better credibility judgments. When credibility cues in user reviews were inconsistent with those in Website contents, older adults were less influenced by the user reviews. Results have important implications on how user reviews may facilitate credibility judgment of online health information by older adults.</span></div></div><div class="paper" id="sr160"><a href="#sr160" class="title">Send Me Bubbles:  Multimodal Performance and Social Acceptability</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979513&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Julie Rico Williamson</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The use of performance as the focus of interaction provides the opportunity for exploratory and individual experiences but can also put users in an uncomfortable position. This paper presents an initial user study of a mobile remote awareness application in which users can control their own fish in a virtual fish tank using multimodal input from an external sensing device, where the input styles are created and performed by participants in an open ended sensing model. The study was designed in order to better understand the issues of performance when audience members are both casual passersby and familiar others watching remotely. Additionally, this study investigated the creation of performances and the effects of props when used in different social settings. The study involved pairs of participants interacting with the system in both public and private locations over repeated sessions. The results of this study show how users created and interpreted performances as well as how their consideration of passersby influenced their experiences.</span></div></div><div class="paper" id="sr166"><a href="#sr166" class="title">Frankenstein and Human Error: Device-Oriented Steps are More Problematic than Task-Oriented Ones</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979514&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Maartje  Ament</span> <span class="affiliation">University College London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Most errors in routine procedures are merely annoying, but they can have severe consequences in safety- critical systems such as medical devices. The current work investigates whether errors are more likely to occur on device-oriented steps (those concerned only with the operation of the device) than on task-oriented ones (those that help the user achieve their main task goal). Error rates were recorded on a routine toy task, with several carefully controlled device- and task- oriented steps. Results show that error rates are substantially higher on device-oriented steps, and step times are longer. The findings demonstrate that a step&#8217;s relevance to the task goal plays an important role in the occurrence of slip errors. They further highlight the problems associated with device-oriented steps, and make a strong case for avoiding them as much as possible in interface design.</span></div></div><div class="paper" id="sr173"><a href="#sr173" class="title">A Scalable and Tiling Multi-Monitor Aware Window Manager</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979515&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joona Antero Laukkanen</span> <span class="affiliation">University of Tampere</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The design of a prototypical scalable and tiling multi-monitor aware window manager is described that may overcome some of the layout management problems encountered with tiling window managers. The system also features a novel approach to monitor configuration in which monitors are treated as independent movable viewports to the large virtual desktop. This approach is expected to address a number of distal access and monitor configuration problems. In particular, it will enable many uses of multiple monitors that require dynamic or flexible monitor configurations.</span></div></div><div class="paper" id="sr175"><a href="#sr175" class="title">Sharing Stories "in the wild:" A Mobile Storytelling Case Study</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979516&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth  Bonsignore</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Today&#8217;s mobile devices are natively equipped with multimedia means for children to capture and share their daily experiences. However, designing authoring tools that effectively integrate the discrete media-capture components of mobile devices to enable rich expression remains a challenge. We report results of a study on the observed use of StoryKit, a mobile application that integrates multimodal media-capture tools to support the creation of multimedia stories on the iPhone/iPod Touch/iPad. The primary objectives of the study were to explore the ways in which StoryKit enables individuals to create and share personal stories; and to investigate how the created stories themselves might inform the design of mobile storytelling applications. Its results suggest that StoryKit&#8217;s relatively simple but well-integrated interface enables the creation of vibrant, varied narratives. Further, genre analysis of the types of stories created revealed a surprising volume and diversity of use in educational contexts.</span></div></div><div class="paper" id="sr195"><a href="#sr195" class="title">Trusting Experience Oriented Design</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979517&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aisling Ann O'Kane</span> <span class="affiliation">Mobile Life @ KTH Royal Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although trust and affective experiences have been linked in HCI research, a connection between traditional trust research for automation and experience design has not be made. This paper aims to start this discussion by showing the connection between experience-oriented HCI design and trust in automation through an experimental study of the Lega, a companion device for enriching experiences in museums. An experience-oriented HCI design approach was used to create this device and although it is not traditional automation, this study presents the links found between this approach and the bases of trust in automation, performance, process, and purpose, with regards to experience qualities of transparency, ambiguity, and usefulness, respectively.</span></div></div><div class="paper" id="sr197"><a href="#sr197" class="title">Code Gestalt: A Software Visualization Tool for Human Beings</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979518&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christopher  Kurtz</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Programmers are often faced with the necessity to visualize source code and grasp its structure. In a survey we studied how developers deal with this task. Based on our findings, we present the software visualization tool Code Gestalt, which assists programmers in quickly creating class diagrams. We evaluated and refined our concept using two prototypes. As a result, Code Gestalt introduces the tag overlay and thematic relations. These augmentations to class diagrams display similarities in the vocabulary used in the underlying source code. This simple, yet effective toolset empowers the user to explore and visualize software systems. The preliminary results of a user study investigating Code Gestalt indicate good usability.</span></div></div><div class="paper" id="sr198"><a href="#sr198" class="title">Cultural Difference in Image Searching</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979519&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wei  Dong</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous studies suggested that people from Eastern and Western cultural origins tagged digital images in different ways due to cultural difference in attentional patterns [2]. This study was conducted to examine whether Easterners and Westerners also exhibited dif-ferent behavioral patterns when searching for digital images. European Americans (EA) and Chinese were asked to general search keywords and to draw ideal target images for image searching tasks. Consistent with previous studies, results showed that Chinese were more likely to generate search keywords describing the overall properties of the target images than EA. When drawing ideal target images, EA assigned more space to the main objects than Chinese. The findings provided significant implications for designing cultural-sensitive tools to facilitate image search.</span></div></div><div class="paper" id="sr219"><a href="#sr219" class="title">The Influence of Grids on Spatial and Content Memory</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979522&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Svenja  Leifert</span> <span class="affiliation">University of Konstanz</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present an experiment that aims at understanding the influence that (visual) grid-based structuring of user interfaces can have on spatial and content memory. By the term grid we refer to two different aspects. On the one hand, this relates to the structured alignment, the layout of objects on a canvas. On the other hand, a grid can also be indicated visually by inserting lines that form an array which divides a canvas into smaller fields. In both cases we detected a strong positive influence on spatial memory. On content memory, however, grids have a less beneficial influence. Only if grid lines are visible, the structured alignment has a positive effect. On the other hand, the visibility of grid lines always leads to worse results in content memory performance, independent of the spatial arrangement.</span></div></div><div class="paper" id="sr215"><a href="#sr215" class="title">Digital Commemoration: Surveying the Social Media Revival of Historical Crises</a>&nbsp;-&nbsp;<span class="type">Student Research Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979521&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sophia B. Liu</span> <span class="affiliation">University of Colorado at Boulder</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social media has facilitated coordination efforts to help save lives, but are people using social media after the emergency phase? To answer this question, the author conducted a study surveying the social media revival of 111 crisis events that occurred over the past 50 years to examine if social media is being used to commemorate historical crises. Quantitative and qualitative social media metrics on each event were collected to determine their social media presence. The findings show that people are using social media to sustain the living record of past crises as an attempt to prevent disasters and strengthen resilience to future crises. Technological and social hazards that occurred before the social media age tended to exhibit a higher social media presence than natural hazards. Also, the revival of past crises typically occurred when they were linked to recent crises that exhibited similar causes, effects, and vulnerabilities. Issues in the construction and implementation of the survey inform the development of sociotechnical systems designed to collect, manage, and analyze historical events through the cyberinfrastructure.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">11:00<br />-<br />12:20</td>

<td class="session " id="S1113">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1113" class="title">Facebook for Health: Opportunities and Challenges for Driving Behavior Change</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1112">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1112" class="title">Games and Entertainment Community: Towards Forming a Robust and Ongoing Community</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1122">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1122" class="title">Microblogging Behavior</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1127">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1127" class="title">Expression &amp; Perception</a>
<span class="location">223/224</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1121">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1121" class="title">Design Theory</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1125">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1125" class="title">Families</a>
<span class="location">217/218/219</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1126">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1126" class="title">Search &amp; Information Seeking</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1120">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1120" class="title">Non-flat Displays</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1123">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1123" class="title">Inter-cultural Interaction</a>
<span class="location">212/213/214</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1114">
<div class="session_box">
<span class="type">Special Events</span>
<a href="#S1114" class="title">Invited Panel</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1124">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1124" class="title">Eye Tracking</a>
<span class="location">215/216</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>
</tr>
<tr class="details_row"><td colspan="11" class="session_details" id="S1113_details"><div class="paper" id="pl114"><a href="#pl114" class="title">Facebook for Health: Opportunities and Challenges for Driving Behavior Change</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979489&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Margaret E Morris</span> <span class="affiliation">Intel</span>, <br />
<span class="author">Sunny  Consolvo</span> <span class="affiliation">Intel</span>, <br />
<span class="author">Sean  Munson</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Kevin  Patrick</span> <span class="affiliation">UC San Diego</span>, <br />
<span class="author">Janice  Tsai</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Adam D.I. Kramer</span> <span class="affiliation">Facebook</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Obesity, mood, and associated behaviors spread within social networks [1]. Facebook, the primary representation of these networks, shapes our perceptions of social norms and the expectations we set for ourselves. As such, Facebook holds potential to influence health behaviors of individuals and improve public health. This panel explores that potential from a variety of perspectives including psychology, public health, privacy, and design innovation. Panelists include: Margie Morris and Sunny Consolvo, researchers at Intel who have created novel mobile health and Facebook applications; Sean Munson, a social computing researcher at University of Michigan; Kevin Patrick, of UCSD, who is investigating social media for preventing and reducing weight gain in young adults; and Janice Tsai, from Microsoft, who focuses on privacy implications of Facebook. This panel will identify opportunities for health interventions on Facebook to have a broad social impact, challenges to implementing effective interventions on this dynamic platform, appropriate research methods, and considerations related to privacy and ethics.</span></div></div></td>
<td colspan="11" class="session_details" id="S1112_details"><div class="paper" id="si115"><a href="#si115" class="title">Games and Entertainment Community: Towards Forming a Robust and Ongoing Community</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979531&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Regina  Bernhaupt</span> <span class="affiliation">IRIT</span>, <br />
<span class="author">Katherine  Isbister</span> <span class="affiliation">NYU Polytechnic Institute, USA</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The community of games and entertainment includes researchers and practitioners focusing on player-centered development and evaluation of all forms of games and applications that focus on entertainment. Games and entertainment have been represented in all CHI venues including workshops, tutorials, papers, and notes; in fact this community at CHI is already present, but as yet only loosely connected and defined as such. This year Games and Entertainment was selected as a Special Community at CHI&#8212;this SIG is meant to explore how we can build a robust and ongoing community around this topic at CHI.</span></div></div></td>
<td colspan="11" class="session_details" id="S1122_details"><div class="sessionChair"><strong>Session Chair: </strong>Mor Naaman (<em>Rutgers University</em>)</div><div class="paper" id="paper1776"><a href="#paper1776" class="title">"Voluntweeters": Self-Organizing by Digital Volunteers in Times of Crisis</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979102&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kate  Starbird</span> <span class="affiliation">University of Colorado, Boulder</span>, <br />
<span class="author">Leysia  Palen</span> <span class="affiliation">University of Colorado, Boulder</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This empirical study of &#8220;digital volunteers&#8221; in the aftermath of the January 12, 2010 Haiti earthquake describes their behaviors and mechanisms of self-organizing in the information space of a microblogging environment, where collaborators were newly found and distributed across continents. The paper explores the motivations, resources, activities and products of digital volunteers. It describes how seemingly small features of the technical environment offered structure for self-organizing, while considering how the social-technical milieu enabled individual capacities and collective action. Using social theory about self-organizing, the research offers insight about features of coordination within a setting of massive interaction.</span></div></div><div class="paper" id="paper1850"><a href="#paper1850" class="title">Social Media Ownership: Using Twitter as a Window onto Current Attitudes and Beliefs</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979103&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Catherine C.  Marshall</span> <span class="affiliation">Microsoft Research, Silicon Valley</span>, <br />
<span class="author">Frank  Shipman</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social media, by its very nature, introduces questions about ownership. Ownership comes into play most crucially when we investigate how social media is saved or archived; how it is reused; and whether it can be removed or deleted. We investigate these social media ownership issues using a Mechanical Turk survey of Twitter users; the survey uses open-ended questions and statements of belief about realistic Twitter-based scenarios to give us a window onto current attitudes and beliefs. Our findings reveal that respondents take a liberal attitude toward saving and storing the tweets that they encounter. More caution is exercised with republishing the material, and still more with sharing the material among friends and associates. Respondents approach removal of this type of lightweight social media most cautiously. The material&#8217;s provenance and the respondents&#8217; relationship to the material (whether they are the author or subject) has considerable bearing on what they feel they can do with it.</span></div></div><div class="paper" id="paper1956"><a href="#paper1956" class="title">Fragile Online Relationship: A First Look at Unfollow Dynamics in Twitter</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979104&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Haewoon  Kwak</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Hyunwoo  Chun</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Sue  Moon</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We analyze the dynamics of the behavior known as &#8216;unfollow&#8217; in Twitter. We collected daily snapshots of the online relationships of 1.2 million Korean-speaking users for 51 days as well as all of their tweets. We found that Twitter users frequently unfollow. We then discover the major factors, including the reciprocity of the relationships, the duration of a relationship, the followees&#8217; informativeness, and the overlap of the relationships, which affect the decision to unfollow. We conduct interview with 22 Korean respondents to supplement the quantitative results. They unfollowed those who left many tweets within a short time, created tweets about uninteresting topics, or tweeted about the mundane details of their lives. To the best of our knowledge, this work is the first systematic study of the unfollow <br /> behavior in Twitter.</span></div></div><div class="paper" id="paper1091"><a href="#paper1091" class="title">The Impact of Network Structure on Breaking Ties in Online Social Networks: Unfollowing on Twitter</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979105&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Funda  Kivran-Swaine</span> <span class="affiliation">Rutgers University</span>, <br />
<span class="author">Priya  Govindan</span> <span class="affiliation">Rutgers University</span>, <br />
<span class="author">Mor  Naaman</span> <span class="affiliation">Rutgers University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We investigate the breaking of ties between individuals in the online social network of Twitter, a hugely popular social media service. Building on sociology concepts such as strength of ties, embeddedness, and status, we explore how network structure alone influences tie breaks &#8211; the common phenomena of an individual ceasing to &#8220;follow&#8221; another in Twitter&#8217;s directed social network. We examine these relationships using a dataset of 245,586 Twitter "follow" edges, and the persistence of these edges after nine months. We show that structural properties of individuals and dyads at Time 1 have a significant effect on the existence of edges at Time 2, and connect these findings to the social theories that motivated the study.</span></div></div><div class="paper" id="paper608"><a href="#paper608" class="title">Computing Political Preference among Twitter Followers</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979106&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Golbeck</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Derek  Hansen</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There is great interest in understanding media bias and political information seeking preferences. As many media outlets create online personas, we seek to automatically estimate the political preferences of their audience, rather than of the outlet itself. In this paper, we present a novel method for computing preference among an organization&#8217;s Twitter followers. We present an application of this technique to estimate political preference of the audiences of U.S. media outlets. We also discuss how these results may be used and extended.</span></div></div></td>
<td colspan="11" class="session_details" id="S1127_details"><div class="sessionChair"><strong>Session Chair: </strong>Justine Cassell (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper1083"><a href="#paper1083" class="title">Using Fast Interaction to Create Intense Experiences</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979129&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Steve  Benford</span> <span class="affiliation">University of Nottingham</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Several emerging strands of HCI involve connecting physical exercise activity with digital interactive systems to create intense combined experiences, for example pervasive games, GPS based exercise games and &#8216;exertion interfaces&#8217;. Many of these systems are mobile, used outside in public, whilst moving quickly through the environment. In this paper, we argue that the combination of moving fast and interacting with a digital system allows us to create a powerfully intense experience for participants, and that key to this is careful attention to the way in which movement is combined with digital content.  <br />  <br /> We study an interactive art experience in which a person runs whilst listening to poetry. Based on this study and other HCI research, we present a framework for mixing physical and interactive content, based on 3 dimensions, which describe ways that a movement activity may itself create intense experiences, followed by a set of tactics for combining intense movement and interactive content. <br /></span></div></div><div class="paper" id="paper658"><a href="#paper658" class="title">A VJ Centered Exploration of Expressive Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979130&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jonathan  Hook</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">David  Green</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  McCarthy</span> <span class="affiliation">University College Cork</span>, <br />
<span class="author">Stuart  Taylor</span> <span class="affiliation">Microsoft Research Cambridge</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper identifies key themes of expressive interaction for VJs. VJs are visual artists who use digital media to express themselves to an audience during a live audio-visual performance. Those designing for the expressive use of technology can gain insight from an articulation of expressive interaction from the perspective of VJ practice. This is developed using a novel qualitative methodology designed to be sensitive to the subtle and tacit nature of expression. We detail our methodology, present the results of its application to a group of VJs and conclude with a discussion of the implications our findings may have for those wishing to design for VJs, or those in related domains that involve expressive interaction with technology.</span></div></div><div class="paper" id="paper1153"><a href="#paper1153" class="title">Placing a Value on Aesthetics in Online Casual Games</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979131&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Erik  Andersen</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Yun-En  Liu</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Rich  Snider</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Roy  Szeto</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Zoran  Popovi&#263;</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Game designers frequently invest in aesthetic improvements such as music, sound effects, and animations. However, their exact value for attracting and retaining players remains unclear. Seeking to estimate this value in two popular Flash games, we conducted a series of large-scale A/B tests in which we selectively removed aesthetic improvements and examined the effect of each component on play time, progress, and return rate. We found that music and sound effects had little or no effect on player retention in either game, while animations caused users to play more. We also found, counterintuitively, that optional rewards caused players to play less in both games. In one game, this gameplay modification affected play time three times as much as the largest aesthetic variation. Our methodology provides a way to determine where resources may be best spent during the game design and development process.</span></div></div><div class="paper" id="paper999"><a href="#paper999" class="title">Kinetic Tiles</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979132&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hyunjung  Kim</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span>, <br />
<span class="author">Woohun  Lee</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We propose and demonstrate Kinetic Tiles, modular construction units for kinetic animations. Three different design methods are explored and evaluated for kinetic animation with the Kinetic Tiles using preset movements, design via animation toolkit, and design via direct input. It is expected that the Kinetic Tiles, as a new design and architecture material, will assist designers to introduce kinetic expressions to the surfaces of everyday objects and spaces.</span></div></div><div class="paper" id="paper329"><a href="#paper329" class="title">SandCanvas: A Multi-touch Art Medium Inspired by Sand Animation</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979133&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rubaiat Habib  Kazi</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Kien Chuan  Chua</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Shengdong  Zhao</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Richard  Davis</span> <span class="affiliation">Singapore Management University</span>, <br />
<span class="author">Kok-Lim  Low</span> <span class="affiliation">National University of Singapore</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sand animation is a performance art technique in which an artist tells stories by creating animated images with sand. Inspired by this medium, we have developed a new multi-touch digital artistic medium named SandCanvas that simplifies the creation of sand animations. SandCanvas also goes beyond traditional sand animation with tools for mixing sand animation with video and replicating recorded free-form hand gestures. In this paper, we analyze common sand animation hand gestures, present SandCanvas&#8217;s intuitive UI, and describe implementation challenges we encountered. We also present an evaluation with professional and novice artists that shows the importance and unique affordances of this new medium.</span></div></div></td>
<td colspan="11" class="session_details" id="S1121_details"><div class="sessionChair"><strong>Session Chair: </strong>Steven Dow (<em>Stanford University</em>)</div><div class="paper" id="paper524"><a href="#paper524" class="title">The New Good: Exploring the Potential of Philosophy of Technology to Contribute to Human-Computer Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979099&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Fallman</span> <span class="affiliation">Interactive Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As a result of the increased interest in issues such as engagement, affection, and meaning, contemporary human-computer interaction (HCI) has increasingly come to examine the nature of interactions between artifacts, humans, and environments through concepts such as user experience and meaning. In the transition from usability metrics to user experience, what appears lacking is a more explicit characterization of what it is HCI now strives for as a discipline&#8212;i.e. what constitutes a &#8216;good&#8217; user experience? Through a detailed look at two contemporary philosophies of technology&#8212;Albert Borgmann&#8217;s notion of the device paradigm and Don Ihde&#8217;s non-neutrality of technology- mediated experience&#8212;this paper seeks to explore the potential of the philosophy of technology to contribute new insights and provide well-grounded conceptual tools for coming to terms with what may become HCI&#8217;s &#8216;new good&#8217;.</span></div></div><div class="paper" id="paper1801"><a href="#paper1801" class="title">Understanding Interaction Design Practices</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979100&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth  Goodman</span> <span class="affiliation">University of California</span>, <br />
<span class="author">Erik  Stolterman</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There is an undesirable gap between HCI research aimed at influencing interaction design practice and the practitioners in question. To close this gap, we advocate a theoretical and methodological focus on the day-to-day, lived experience of designers. To date, this type of theory-generative, experientially oriented research has focused on the users of technologies, not the designers. In contrast, we propose that HCI researchers turn their attention to producing theories of interaction design practice that resonate with practitioners themselves. In part one of this paper, we describe the mismatch between HCI research and interaction design practices. Then we present vignettes from an observational study of commercial design practice to illustrate the issues at hand. In part two, we discuss methodological and theoretical changes in research practice that might support the goal of integrating HCI research with interaction design practices. We then discuss current research methods and theories to identify changes that might enlarge our view on practice. In part three, we elaborate on our theoretically minded agenda and a kind of ideal-type theory.</span></div></div><div class="paper" id="to103"><a href="#to103" class="title">Complex Interaction</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Lars-Erik  Janlert</span> <span class="affiliation">Ume&#229; University</span>, <br />
<span class="author">Erik  Stolterman</span> <span class="affiliation">Indiana University, Bloomington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An almost explosive growth of complexity puts pressure on people in their everyday doings. Digital artifacts and systems are at the core of this development. How should we handle complexity aspects when designing new interactive devices and systems? In this article we begin an analysis of interaction complexity. We portray different views of complexity; we explore not only negative aspects of complexity, but also positive, making a case for the existence of benign complexity. We argue that complex interaction is not necessarily bad, but designers need a deeper understanding of interaction complexity and need to treat it in a more intentional and thoughtful way. We examine interaction complexity as it relates to different loci of complexity: internal, external, and mediated complexity. Our purpose with these analytical exercises is to pave the way for design that is informed by a more focused and precise understanding of interaction complexity.</span></div></div><div class="paper" id="to106"><a href="#to106" class="title">Indexicality: understanding mobile human-computer interaction in context</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Jesper  Kjeldskov</span> <span class="affiliation">Aalborg University</span>, <br />
<span class="author">Jeni  Paay</span> <span class="affiliation">Aalborg University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A lot of research has been done within the area of mobile computing and context-awareness over the last 15 years, and the idea of systems adapting to their context has produced promising results for overcoming some of the challenges of user interaction with mobile devices within various specialised domains. However, today it is still the case that only a limited body of theoretically grounded knowledge exists that can explain the relationship between users, mobile system user interfaces, and their context. Lack of such knowledge limits our ability to elevate learning from the mobile systems we develop and study from a concrete to an abstract level. Consequently, the research field is impeded in its ability to leap forward and is limited to incremental steps from one design to the next. Addressing the problem of this void, this article contributes to the body of knowledge about mobile interaction design by promoting a theoretical approach for describing and understanding the relationship between user interface representations and user context. Specifically, we promote the concept of indexicality derived from semiotics as an analytical concept that can be used to describe and understand a design. We illustrate the value of the indexicality concept through an analysis of empirical data from evaluations of three prototype systems in use. Based on our analytical and empirical work we promote the view that users interpret information in a mobile computer user interface through creation of meaningful indexical signs based on the ensemble of context and system.As urban environments become increasingly hybridhybridized, mixing the social, built and digital in compelling ways,  physical and digital spaces, designing for computing in the city presents new challenges &#8211; how do we understand such hybridization, and then respond to it as designers? Here we synthesize requires researchers and interaction designers to explore the intersections between physical and social context, and pervasive computing technologies. This article combinearlier work in es ideas from human-computer interaction (HCI), sociology and architecture in order to deliberately influence the design of digital systems with an understanding of their built and social context of use. We propose, illustrate and evaluate a to investigate physical and social context of an urban environment, and to use this understanding in interaction design of a pervasive computing system for that environment. The major contribution of this research is the demonstration of a multi-disciplinary approach combining rapid ethnography, architectural analysis, design sketching and paper prototyping to drive interaction design. Following the approach we are able to The multi-disciplinary approach is described in detail, and outcomes are presented in the form of conceptual framewprovide orks, which provide empirically grounded representations of the socio-physical context of use, in this case s of ppeople socializing in urban spaces. We then use . It is then demonstrated how this understanding these frameworks can be used to influence the design of a context aware system to be used whilst &#8216;out on the town&#8217;. We believe that the approach is of value more generally, particularly when achieving powerfully situated interactions is the design ambition.</span></div></div></td>
<td colspan="11" class="session_details" id="S1125_details"><div class="sessionChair"><strong>Session Chair: </strong>Shaowen Bardzell (<em>Indiana University</em>)</div><div class="paper" id="paper1284"><a href="#paper1284" class="title">Learning Patterns of Pick-ups and Drop-offs to Support Busy Family Coordination</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979119&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Scott  Davidoff</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Brian D. Ziebart</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">John  Zimmerman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Anind K. Dey</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Part of being a parent is taking responsibility for arranging and supplying transportation of children between various events. Dual-income parents frequently develop routines to help manage transportation with a minimal amount of attention. On days when families deviate from their routines, effective logistics can often depend on knowledge of the routine location, availability and intentions of other family members. Since most families rarely document their routine activities, making that needed information unavailable, coordination breakdowns are much more likely to occur. To address this problem we demonstrate the feasibility of learning family routines using mobile phone GPS. We describe how we (1) detect pick-ups and drop-offs; (2) predict which parent will perform a future pick-up or drop-off; and (3) infer if a child will be left at an activity. We discuss how these routine models give digital calendars, reminder and location systems new capabilities to help prevent breakdowns, and improve family life.</span></div></div><div class="paper" id="paper1105"><a href="#paper1105" class="title">Mediated Parent-Child Contact in Work-Separated Families</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979120&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Svetlana  Yarosh</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Gregory D Abowd</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Parents and children in families living with regular separation due to work develop strategies to manage being apart. We interviewed 14 pairs of parents and children (ages 7 &#8211; 13) from work-separated families to understand their experiences and the strategies that they use to keep their family together. Parents focus on combining scheduled synchronous and spontaneous asynchronous communication to maintain a constant presence in the life of the child. Children, on the other hand, focus on other sources of support, on other activities, and on the eventual reunion. Both the remote parent and the child rely heavily on a collocated adult to maintain awareness and contact. We compare work-separated families with other types of separation and highlight opportunities for new designs.</span></div></div><div class="paper" id="paper343"><a href="#paper343" class="title">Hello, is Grandma there? Let&#8217;s Read! StoryVisit: Family Video Chat and Connected E-Books</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979121&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hayes  Raffle</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Glenda  Revelle</span> <span class="affiliation">University of Arkansas</span>, <br />
<span class="author">Koichi  Mori</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Rafael  Ballagas</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Kyle  Buza</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Hiroshi  Horii</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Joseph 'Jofish'  Kaye</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Kristin  Cook</span> <span class="affiliation">Sesame Workshop</span>, <br />
<span class="author">Natalie  Freed</span> <span class="affiliation">Nokia Research Center, MIT Media Lab</span>, <br />
<span class="author">Janet  Go</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Mirjana  Spasojevic</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">StoryVisit allows children and long-distance adults to experience a sense of togetherness by reading children&#8217;s story books together over a distance. StoryVisit combines video conferencing and connected books: remote grown-up and child readers can see and hear each other, and can also see and control the same e-book. We report on research with 61 families &#8211; over 200 users including parents, children and long-distance readers &#8211; who used StoryVisit in their homes with a long-distance reader for at least one reading session. In addition, we report qualitative findings regarding nineteen of the families who participated in telephone interviews and four families who were monitored and interviewed by researchers at home. Results show that connected e-book video chat sessions last about five times as long as the typical video chats reported in previous research on families with young children. Moreover, the addition of an animated character increased session lengths by another 50%. StoryVisit usage peaked for families with three year olds, showing that sustained distance interactions with very young children are possible if communication technologies incorporate joint activities that engage children and adults.  <br /></span></div></div><div class="paper" id="paper557"><a href="#paper557" class="title">Family Portals: Connecting Families Through A Multifamily Media Space</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979122&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tejinder K.  Judge</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Carman  Neustaedter</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Steve  Harrison</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Andrew  Blose</span> <span class="affiliation">Kodak Research Laboratories</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Video conferencing allows distance-separated family members to interact somewhat akin to being together at the same place and time. Yet most video conferencing systems are designed for phone-like calls between only two locations. Using such systems for long interactions or social gatherings with multiple families is cumbersome, if not impossible. For this reason, we wanted to explore how families would make use of a video system that permitted sharing everyday life over extended periods of time between multiple locations. We designed a media space called Family Portals that provides shared video between three locations and deployed it within the homes of six families. Results show that the media space increased feelings of connectedness and the focus on a triad, in contrast to a dyad, caused new styles of interaction to emerge. Despite this, families experienced new privacy challenges and non-adoption by some family members, not previously seen in dyadic family media spaces.</span></div></div></td>
<td colspan="11" class="session_details" id="S1126_details"><div class="sessionChair"><strong>Session Chair: </strong>Jaime Teevan (<em>Microsoft Research</em>)</div><div class="paper" id="paper2186"><a href="#paper2186" class="title">The Information Flaneur: A Fresh Look at Information Seeking</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979124&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marian  Doerk</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">Sheelagh  Carpendale</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">Carey  Williamson</span> <span class="affiliation">University of Calgary</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce the information flaneur as a new human-centred view on information seeking that is grounded in interdisciplinary research. We use the metaphor of the urban flaneur making sense of a city as an inspiring lens that brings together diverse perspectives. These perspectives shift information seeking towards a more optimistic outlook: the information flaneur represents curious, creative, and critical information seeking. The resulting information-seeking model conceptualizes the interrelated nature between information activities and experiences as a continuum between horizontal exploration and vertical immersion. Motivated by enabling technological trends and inspired by the information flaneur, we present explorability as a new guiding principle for design and raise research challenges regarding the representation of information abstractions and details.</span></div></div><div class="paper" id="paper2015"><a href="#paper2015" class="title">No Clicks, No Problem: Using Cursor Movements to Understand and Improve Search</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979125&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jeff  Huang</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Ryen W. White</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Susan  Dumais</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Understanding how people interact with search engines is important in improving search quality. Web search engines typically analyze queries and clicked results, but these actions provide limited signals regarding search interaction. Laboratory studies often use richer methods such as gaze tracking, but this is impractical at Web scale. In this paper, we examine mouse cursor behavior on search engine results pages (SERPs), including not only clicks but also cursor movements and hovers over different page regions. We: (i) report an eye-tracking study showing that cursor position is closely related to eye gaze, especially on SERPs; (ii) present a scalable approach to capture cursor movements, and an analysis of search result examination behavior evident in these large-scale cursor data; and (iii) describe two applications (estimating search result relevance and distinguishing good from bad abandonment) that demonstrate the value of capturing cursor data. Our findings help us better understand how searchers use cursors on SERPs and can help design more effective search systems. Our scalable cursor tracking method may also be useful in non-search settings.</span></div></div><div class="paper" id="paper2257"><a href="#paper2257" class="title">Enhancing Credibility Judgment of Web Search Results</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979126&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yusuke  Yamamoto</span> <span class="affiliation">Kyoto University</span>, <br />
<span class="author">Katsumi  Tanaka</span> <span class="affiliation">Kyoto University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we propose a system for helping users to judge the credibility of Web search results and to search for credible Web pages. Conventional Web search engines present only titles, snippets, and URLs for users, which give few clues to judge the credibility of Web search results. Moreover, ranking algorithms of the conventional Web search engines are often based on relevance and popularity of Web pages. Towards credibility-oriented Web search, our proposed system provides users with the following three functions: (1) calculation and visualization of several scores of Web search results on the main credibility aspects, (2) prediction of user's credibility judgment model through user's credibility feedback for Web search results, and (3) re-ranking of Web search results based on user's predicted credibility model. Experimental results suggest that our system enables users - in particular, users with knowledge about search topics - to find credible Web pages from a list of Web search results more efficiently than conventional Web search interfaces.</span></div></div><div class="paper" id="paper480"><a href="#paper480" class="title">Augmenting Web Pages and Search Results to Support Credibility Assessment</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979127&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Julia  Schwarz</span> <span class="affiliation">Carnegie Mellon University, Microsoft Research</span>, <br />
<span class="author">Meredith  Morris</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The presence (and, sometimes, prominence) of incorrect and misleading content on the Web can have serious consequences for people who increasingly rely on the internet as their information source for topics such as health, politics, and financial advice. In this paper, we identify and collect several page features (such as popularity among specialized user groups) that are currently difficult or impossible for end users to assess, yet provide valuable signals regarding credibility. We then present visualizations designed to augment search results and Web pages with the most promising of these features. Our lab evaluation finds that our augmented search results are particularly effective at increasing the accuracy of users&#8217; credibility assessments, highlighting the potential of data aggregation and simple interventions to help people make more informed decisions as they search for information online.</span></div></div></td>
<td colspan="11" class="session_details" id="S1120_details"><div class="sessionChair"><strong>Session Chair: </strong>Xiang Cao (<em>Microsoft Research</em>)</div><div class="paper" id="paper1698"><a href="#paper1698" class="title">Touch Input on Curved Surfaces</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979094&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anne  Roudaut</span> <span class="affiliation">Hasso Plattner Institute</span>, <br />
<span class="author">Henning  Pohl</span> <span class="affiliation">Hasso Plattner Institute</span>, <br />
<span class="author">Patrick  Baudisch</span> <span class="affiliation">Hasso Plattner Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Advances in sensing technology are currently bringing touch input to non-planar surfaces, ranging from spherical touch screens to prototypes the size and shape of a ping-pong ball. To help interface designers create usable interfaces on such devices, we determine how touch surface curvature affects targeting. We present a user study in which participants acquired targets on surfaces of different curvature and at locations of different slope. We find that surface convexity increases pointing accuracy, and in particular reduces the offset between the input point perceived by users and the input point sensed by the device. Concave surfaces, in contrast, are subject to larger error offsets. This is likely caused by how concave surfaces hug the user&#8217;s finger, thus resulting in a larger contact area. The effect of slope on targeting, in contrast, is unexpected at first sight. Some targets located downhill from the user&#8217;s perspective are subject to error offsets in the opposite direction from all others. This appears to be caused by participants acquiring these targets using a different finger posture that lets them monitor the position of their fingers more effectively.</span></div></div><div class="paper" id="paper558"><a href="#paper558" class="title">Audience Behavior around Large Interactive Cylindrical Screens</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979095&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gilbert  Beyer</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Florian  Alt</span> <span class="affiliation">University of Duisburg-Essen</span>, <br />
<span class="author">J&#246;rg  M&#252;ller</span> <span class="affiliation">Deutsche Telekom Laboratories, TU Berlin</span>, <br />
<span class="author">Albrecht  Schmidt</span> <span class="affiliation">University of Stuttgart</span>, <br />
<span class="author">Karsten  Isakovic</span> <span class="affiliation">Fraunhofer FIRST</span>, <br />
<span class="author">Stefan  Klose</span> <span class="affiliation">Fraunhofer FIRST</span>, <br />
<span class="author">Manuel  Schiewe</span> <span class="affiliation">Fraunhofer FIRST</span>, <br />
<span class="author">Ivo  Haulsen</span> <span class="affiliation">Fraunhofer FIRST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Non-planar screens, such as columns, have been a popular means for displaying information for a long time. In contrast to traditional displays their digital counterparts are mainly flat and rectangular due to current technological constraints. However, we envision bendable displays to be available in the future, which will allow for creating new forms of displays with new properties. In this paper we explore cylindrical displays as a possible form of such novel public displays. We present a prototype and report on a user study, comparing the influence of the display shape on user behavior and user experience between flat and cylindrical displays. The results indicate that people move more in the vicinity of cylindrical displays and that there is no longer a default position when it comes to interaction. As a result, such displays are especially suitable to keep people in motion and to support gesture-like interaction.</span></div></div><div class="paper" id="paper1177"><a href="#paper1177" class="title">MotionBeam: A Metaphor for Character Interaction with Handheld Projectors</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979096&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karl D.D. Willis</span> <span class="affiliation">Carnegie Mellon University, Disney Research</span>, <br />
<span class="author">Ivan  Poupyrev</span> <span class="affiliation">Disney Research</span>, <br />
<span class="author">Takaaki  Shiratori</span> <span class="affiliation">Disney Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the MotionBeam metaphor for character interaction with handheld projectors. Our work draws from the tradition of pre-cinema handheld projectors that use direct physical manipulation to control projected imagery. With our prototype system, users interact and control projected characters by moving and gesturing with the handheld projector itself. This creates a unified interaction style where input and output are tied together within a single device. We introduce a set of interaction principles and present prototype applications that provide clear examples of the MotionBeam metaphor in use. Finally we describe observations and insights from a preliminary user study with our system.</span></div></div><div class="paper" id="paper1458"><a href="#paper1458" class="title">3D Projection on Physical Objects:  Design Insights from Five Real Life Cases</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979097&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Peter  Dalsgaard</span> <span class="affiliation">Aarhus University</span>, <br />
<span class="author">Kim  Halskov</span> <span class="affiliation">Aarhus University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">3D projection on physical objects is a particular kind of Augmented Reality that augments a physical object by projecting digital content directly onto it, rather than by using a mediating device, such as a mobile phone or a head-mounted display. In this paper, we present five cases in which we have developed installations that employ 3D projection on physical objects. The installations have been developed in collaboration with external partners and have been put into use in real-life settings such as museums, exhibitions and interaction design laboratories. On the basis of these cases, we present and discuss three central design insights concerning new potentials for well-known 3D effects, dynamics between digital world and physical world, and relations between object, content and context.</span></div></div></td>
<td colspan="11" class="session_details" id="S1123_details"><div class="sessionChair"><strong>Session Chair: </strong>Susan Fussell (<em>Cornell University</em>)</div><div class="paper" id="paper1977"><a href="#paper1977" class="title">Online Contribution Practices in Countries that Engage in Internet Blocking and Censorship</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979108&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Irina  Shklovski</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Nalini  Kotamraju</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this article we describe people&#8217;s online contribution practices in contexts in which the government actively blocks access to or censors the Internet. We argue that people experience blocking as confusing, as a motivation for self-censorship online, as a cause of impoverishment of available content and as a real threat of personal persecution. Challenging ideas of blocking as a monolithic, abstract policy, we discuss five strategies with which Internet users navigate blocking: self-censorship, cultivating technical savvy, reliance on social ties to relay blocked content, use of already blocked sites for content production as a form of protection and practiced transparency. We also discuss strategies that forum owners and blogging platform providers employ to deal with and to avoid blocking. We conclude by advocating for more research that acknowledges the complexity of the contexts in which all Internet users contribute to the Internet and social media.</span></div></div><div class="paper" id="paper421"><a href="#paper421" class="title">Real-time Collaborative Editing Behavior in U.S. and Japanese Distributed Teams</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979109&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lauren  Scissors</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">N. Sadat  Shami</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Tatsuya  Ishihara</span> <span class="affiliation">IBM Tokyo Research Laboratory</span>, <br />
<span class="author">Steven  Rohall</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Shin  Saito</span> <span class="affiliation">IBM Tokyo Research Laboratory</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While there are tools that allow distributed teams to collaboratively edit in real time, little work examines this practice among real teams doing real work. Even less is known about how teams from different countries make use of real-time collaborative editing tools. The current work highlights results from a qualitative user study of real-world Japanese and U.S. distributed work teams who used LiveDeck, a real-time slide editing and whiteboarding tool. Through the implementation of various novel features used as probes, differences in behavior and attitudes between team members were uncovered. Differences in the use of slide navigation options, anonymity features, and pop-up &#8216;emotes&#8217; representing nonverbal gestures are discussed.</span></div></div><div class="paper" id="paper1774"><a href="#paper1774" class="title">Cultural Differences on Visual Self-Presentation through Social Networking Site Profile Images</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979110&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chen  Zhao</span> <span class="affiliation">Microsoft Research Asia</span>, <br />
<span class="author">Gonglue  Jiang</span> <span class="affiliation">Harvard Universtiy</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A profile image is one of the most important personal attributes on social networking sites (SNSs). The current study examines whether self-presentation on SNSs is related to national culture and how forms of self-presentation differ between American and Chinese users. We accomplish this by analyzing profile images on two social networking sites, Facebook in the US and Renren in China. Our findings indicate that self-presentation is sensitive to national culture: Chinese users are more likely to customize their profile images than Americans. Our study suggests that there is a need to design social networking website features that better support profile construction for international users.</span></div></div><div class="paper" id="paper2255"><a href="#paper2255" class="title">MonoTrans2: A New Human Computation System to Support Monolingual Translation</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979111&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chang  Hu</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Benjamin B Bederson</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Philip  Resnik</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Yakov  Kronrod</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we present MonoTrans2, a new user interface to support monolingual translation; that is, translation by people who speak only the source or target language, but not both. Compared to previous systems, MonoTrans2 supports multiple edits in parallel, and shorter tasks with less translation context. In an experiment translating children's books, we show that MonoTrans2 is able to substantially close the gap between machine translation and human bilingual translations. The percentage of sentences rated 5 out of 5 for fluency and adequacy by both bilingual evaluators in our study increased from 10% for Google Translate output to 68% for MonoTrans2.</span></div></div><div class="paper" id="paper375"><a href="#paper375" class="title">Culture or Fluency? Unpacking Interactions Between Culture and Communication Medium</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979112&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Leslie  Setlock</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Susan  Fussell</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe two studies intended to replicate earlier work comparing American and Chinese communication in a negotiation task using several different media. In the earlier studies, the participants all spoke in English, raising the question of whether differences in fluency rather than differences in cultural background explained the results. We replicated the earlier studies using materials translated into Chinese, a native Chinese-speaking experimenter, and native Chinese participants. Counts of Chinese characters in each media show nearly the identical pattern found in the earlier studies, suggesting that cultural differences in communication styles, rather than fluency, account for the earlier findings. We describe implications of this work for tools to support intercultural communication.</span></div></div></td>
<td colspan="11" class="session_details" id="S1114_details"><div class="paper" id="sp112"><a href="#sp112" class="title">Festschrift Panel in Honor of Stuart K. Card</a>&nbsp;-&nbsp;<span class="type">Special Events</span><div class="authors"><span class="author">Ed  Chi</span> <span class="affiliation">Google</span>, <br />
<span class="author">Peter  Pirolli</span> <span class="affiliation">PARC</span>, <br />
<span class="author">Bonnie  John</span> <span class="affiliation">CMU</span>, <br />
<span class="author">Judith S Olson</span> <span class="affiliation">UC Irvine</span>, <br />
<span class="author">Dan  Russell</span> <span class="affiliation">Google</span>, <br />
<span class="author">Tom  Moran</span> <span class="affiliation">IBM</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This panel will recognize and celebrate the lifetime work of Stuart K. Card, who retired from PARC in 2010.  As one of the fathers of the HCI field, Stu's work greatly influences the field in a deep and profound way.  Using a model-driven approach, his work on Fitts' law, the mouse, GOMS theory, Model Human Processor, Information Visualization, and Information Foraging have impacted how we do HCI research today.  For his contributions to the field, in 2000 he was awarded the CHI Lifetime Achievement Award from SIGCHI, and became an ACM Fellow. In 2001 he was elected to the CHI Academy. In 2007, he was elected to the National Academy of Engineering, and was awarded The Franklin Institute's Bower Award and Prize for Achievement in Science.  <br />  <br /> At this panel, which will function like a shortened Festschrift, panelists will discuss how Stu's work have influenced the field, toast his accomplishments, and discuss the future of HCI. <br /></span></div></div></td>
<td colspan="11" class="session_details" id="S1124_details"><div class="sessionChair"><strong>Session Chair: </strong>Melanie Fitzgerald (<em>Google</em>)</div><div class="paper" id="paper1065"><a href="#paper1065" class="title">Skim Reading by Satisficing: Evidence from Eye Tracking</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979114&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Geoffrey B Duggan</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Stephen J Payne</span> <span class="affiliation">University of Bath</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Readers on the Web often skim through text to cope with the volume of available information. In a previous study, Duggan and Payne [11] tracked readers&#8217; eye movements as they skimmed through expository text under time pressure. This article presents novel analyses of these eye-movement data. Results indicated that readers were able to explicitly direct attention to the most important information in the text and that this improved performance on a subsequent test of memory for the meaning of text. We suggest readers achieve this by satisficing &#8211; reading through text until the rate of information gain drops below threshold and then skipping to the next section of text. Further analyses of gaze patterns for paragraphs and pages supported this explanation. Combining satisficing with some form of scanning or sampling behaviour could explain patterns of reading found on the Web. A greater understanding of the way that text is read on the Web would assist many producers of online content.</span></div></div><div class="paper" id="paper1114"><a href="#paper1114" class="title">Older Web Users' Eye Movements: Experience Counts</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979115&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Robin L Hill</span> <span class="affiliation">University of Edinburgh</span>, <br />
<span class="author">Anna  Dickinson</span> <span class="affiliation">University of Dundee</span>, <br />
<span class="author">John L Arnott</span> <span class="affiliation">University of Dundee</span>, <br />
<span class="author">Peter  Gregor</span> <span class="affiliation">University of Dundee</span>, <br />
<span class="author">Louise  McIver</span> <span class="affiliation">University of Dundee</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Eye-tracking is a valuable tool for usability research. Studies into the effect of age on eye-movement behavior tend to indicate a propensity for slower viewing and longer times spent examining information. This pattern is usually attributed to the general physiological and cognitive slow-down associated with normal aging. In this paper, however, across three different tasks based on computer and internet use (free-viewing, visual search, and browser interaction), we show that among older adults (n=18, age range: 70-93) computer experience appears to be a highly important factor in eye-movement behavior. We argue that as a consequence of the experimental environment used in modern eye-tracking studies, characteristics such as familiarity and experience with computers should be taken into account before conclusions are drawn about the raw effects of age.</span></div></div><div class="paper" id="paper974"><a href="#paper974" class="title">Retrospective Think-Aloud Method: Using Eye Movements as an Extra Cue for Participants&#8217; Verbalizations</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979116&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sanne  Elling</span> <span class="affiliation">Utrecht University</span>, <br />
<span class="author">Leo  Lentz</span> <span class="affiliation">Utrecht University</span>, <br />
<span class="author">Menno  de Jong</span> <span class="affiliation">University of Twente</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The retrospective think-aloud method, in which participants work in silence and verbalize their thoughts afterwards while watching a recording of their performance, is often used for the evaluation of websites. However, participants may not always be able to recall what they thought, when they only see few visual cues that help them remembering their task execution process. In our study we complemented the recording of the performance with a gaze trail of the participants&#8217; eye movements, in order to elicit more verbalizations. A comparison was made between the traditional retrospective think-aloud protocols and the variant with eye movements. Contrary to our expectations, no differences were found between the two conditions on numbers of problems, the ways these problems were detected, and types of problems. Two possible explanations for this result are that eye movements might be rather confronting and distracting for participants, and the rather generic way of probing we used. The added value might be stronger when specific questions are asked, based on the observed eye movements. Implications for usability practitioners are discussed in the conclusions of this paper.</span></div></div><div class="paper" id="paper1421"><a href="#paper1421" class="title">Triggered Think-Aloud Protocol: Using Eye Tracking to Improve Usability Test Moderation</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979117&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Beverly  Freeman</span> <span class="affiliation">PayPal</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Usability practitioners often rely on research participants' verbal reports to better understand the user experience.  These reports can be collected either during or after task execution, with each approach entailing unique benefits and limitations.  This note presents a framework for using eye tracking data to "trigger" when and how moderators probe participants for verbal comments during task execution to supplement or elaborate participant-initiated comments.  A preliminary case study suggests that this approach affords a level of efficiency and effectiveness difficult to achieve with retrospective verbalization or without the use of eye tracking.  The hope is that practitioners will be encouraged to use and refine this method for the benefit of the field.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">14:00<br />-<br />15:20</td>

<td class="session " id="S1128">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1128" class="title">Geographic Human-Computer Interaction</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1137">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1137" class="title">Crowdsourcing</a>
<span class="location">211</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1142">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1142" class="title">Design Materiality</a>
<span class="location">223/224</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1136">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1136" class="title">3D Interaction</a>
<span class="location">208/209</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1140">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1140" class="title">Digital Content &amp; Collections</a>
<span class="location">217/218/219</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1141">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1141" class="title">Search &amp; Stuff</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1135">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1135" class="title">Flexible Grips &amp; Gestures</a>
<span class="location">205/206/207</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1138">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1138" class="title">User Studies/Ethnography in Developing Regions</a>
<span class="location">212/213/214</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1129">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1129" class="title">Re-engineering Health Care with Information Technology</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1139">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1139" class="title">Visualization &amp; Perception</a>
<span class="location">215/216</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="10" class="session_details" id="S1128_details"><div class="paper" id="si130"><a href="#si130" class="title">Geographic Human-Computer Interaction</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979532&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Brent  Hecht</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Johannes  Sch&#246;ning</span> <span class="affiliation">German Research Center for Artificial Intelligence (DFKI)</span>, <br />
<span class="author">Thomas  Erickson</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Reid  Priedhorsky</span> <span class="affiliation">IBM T.J. Watson Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Researchers and practitioners in human-computer interaction are increasingly taking geographic approaches to their work. Whether designing novel location-based systems, developing natural user interfaces for maps, or exploring online interactions over space and time, HCI is discovering that geographic questions, methods, and use cases are becoming integral to our field. Unfortunately, to our knowledge, there have been no direct efforts to unite members of the community exploring geographic HCI. The goal of this forum is to bring together researchers from a variety of areas to provide a summary of what has been done thus far and to discuss options for developing a more formal geographic HCI community. We will also highlight the troublesome lack of communication between scholars in geography and HCI and the opportunities that will result from increased collaboration between the two fields.</span></div></div></td>
<td colspan="10" class="session_details" id="S1137_details"><div class="sessionChair"><strong>Session Chair: </strong>Niki Kittur (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper1983"><a href="#paper1983" class="title">Guess Who? Enriching the Social Graph through a Crowdsourcing Game</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979145&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ido  Guy</span> <span class="affiliation">IBM Research Haifa</span>, <br />
<span class="author">Adam  Perer</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Tal  Daniel</span> <span class="affiliation">IBM Research Haifa</span>, <br />
<span class="author">Ohad  Greenshpan</span> <span class="affiliation">Tel Aviv University</span>, <br />
<span class="author">Itai  Turbahn</span> <span class="affiliation">MIT</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Despite the tremendous popularity of social network sites both on the web and within enterprises, the relationship information they contain may be often incomplete or outdated. We suggest a novel crowdsourcing approach that uses a game to help enrich and expand the social network topology. The game prompts players to provide the names of people who have a relationship with individuals they know. The game was deployed for a one-month period within a large global organization. We provide an analysis of the data collected through this deployment, in comparison with the data from the organization&#8217;s social network site. Our results indicate that the game rapidly collects large volumes of valid information that can be used to enrich and reinforce an existing social network site&#8217;s data. We point out other aspects and benefits of using a crowdsourcing game to harvest social network information.</span></div></div><div class="paper" id="paper2248"><a href="#paper2248" class="title">PhotoCity: Training Experts at Large-scale Image Acquisition Through a Competitive Game</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979146&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kathleen  Tuite</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Noah  Snavely</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Dun-yu  Hsiao</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Nadine  Tabing</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Zoran  Popovi&#263;</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Large-scale, ground-level urban imagery has recently developed as an important element of online mapping tools such as Google's Street View.  Such imagery is extremely valuable in a number of potential applications, ranging from augmented reality to 3D modeling, and from urban planning to monitoring city infrastructure. While such imagery is already available from many sources, including Street View and tourist photos on photo-sharing sites, these collections have drawbacks related to high cost, incompleteness, and accuracy. A potential solution is to leverage the community of photographers around the world to collaboratively acquire large-scale image collections.  This work explores this approach through PhotoCity, an online game that trains its players to become ``experts'' at taking photos at targeted locations and in great density, for the purposes of creating 3D building models. To evaluate our approach, we ran a competition between two universities that resulted in the submission of over 100,000 photos, many of which were highly relevant for the 3D modeling task at hand. Although the number of players was small, we found that this was compensated for by incentives that drove players to become experts at photo collection, often capturing thousands of useful photos each. <br /></span></div></div><div class="paper" id="paper1240"><a href="#paper1240" class="title">Cooks or Cobblers? Crowd Creativity through Combination</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979147&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lixiu  Yu</span> <span class="affiliation">Stevens Institute of Technology</span>, <br />
<span class="author">Jeffrey V. Nickerson</span> <span class="affiliation">Stevens Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A sketch combination system is introduced and tested: a crowd of 1047 participated in an iterative process of design, evaluation and combination. Specifically, participants in a crowdsourcing marketplace sketched chairs for children. One crowd created a first generation of chairs, and then successive crowds created new generations by combining the chairs made by previous crowds. Other participants evaluated the chairs. The crowd judged the chairs from the third generation more creative than those from the first generation. An analysis of the design evolution shows that participants inherited and modified presented features, and also added new features. These findings suggest that crowd based design processes may be effective, and point the way toward computer-human interactions that might further encourage crowd creativity.</span></div></div><div class="paper" id="paper2258"><a href="#paper2258" class="title">Human Computation: A Survey and Taxonomy of a Growing Field</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979148&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alexander J Quinn</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Benjamin B Bederson</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The rapid growth of human computation within research and industry has produced many novel ideas aimed at organizing web users to do great things. However, the growth is not adequately supported by a framework with which to understand each new system in the context of the old. We classify human computation systems to help identify parallels between different systems and reveal &#8220;holes&#8221; in the existing work as opportunities for new research. Since human computation is often confused with &#8220;crowdsourcing&#8221; and other terms, we explore the position of human computation with respect to these related topics.</span></div></div></td>
<td colspan="10" class="session_details" id="S1142_details"><div class="sessionChair"><strong>Session Chair: </strong>Scott McCrickard (<em>Virginia Polytechnic Institute &amp; State University</em>)</div><div class="paper" id="paper1224"><a href="#paper1224" class="title">Making Spaces: How Design Workbooks Work</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979169&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">William  Gaver</span> <span class="affiliation">Goldsmiths, University of London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, I discuss design workbooks, collections of design proposals and related materials, both as a method for design and as a design methodology. In considering them as a method, I describe a number of examples of design workbooks we have developed in our studio and describe some of the practical techniques we have used in developing them. More fundamentally, I discuss design workbooks as embodiments of a methodological approach which recognises that ideas may emerge slowly over time, that important issues and perspectives may emerge from multiple concrete ideas, potentially generated by multiple members of a team, rather than being theory-driven, and that maintaining the provisionality and vagueness of early proposals can be useful in supporting a quasi-participatory design approach that allows participants to interpret, react to and elaborate upon the ideas they present.</span></div></div><div class="paper" id="to101"><a href="#to101" class="title">Sketching Interactive Systems with Sketchify</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">&#381;eljko  Obrenovi&#263;</span> <span class="affiliation">Einhdoven University of Technology</span>, <br />
<span class="author">Jean-Bernard  Martens</span> <span class="affiliation">Einhdoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent discussions in the interaction design community have called attention to sketching as an omnipresent element of any disciplined activity of design, and have pointed out that sketching should be extended beyond the creation of a pencil trace on paper. More specifically the need to deal with all attributes of a user experience, especially the timing, phrasing, and feel of the interaction, has been identified. We propose extending the concept of sketching with a pencil on paper to the more generic concept of fluent exploration with interactive materials. We have implemented the proposed concept within Sketchify, a tool for sketching user interfaces. Sketchify gives designers the freedom to manipulate interactive materials by combining elements of traditional freehand sketching with functional extensions and end-user programming tools, such as spreadsheets and scripting. We have evaluated Sketchify in the education of interaction designers, identifying both successful aspects and aspects that need further improvements.</span></div></div><div class="paper" id="paper306"><a href="#paper306" class="title">Inspirational Bits - Towards a Shared Understanding of the Digital Material</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979170&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Petra  Sundstr&#246;m</span> <span class="affiliation">Mobile Life @ SICS</span>, <br />
<span class="author">Alex  S. Taylor</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Katja  Grufberg</span> <span class="affiliation">Mobile Life @ SICS</span>, <br />
<span class="author">Niklas  Wirstr&#246;m</span> <span class="affiliation">SICS</span>, <br />
<span class="author">Jordi  S. Belenguer</span> <span class="affiliation">Wireless @ KTH</span>, <br />
<span class="author">Marcus  Lund&#233;n</span> <span class="affiliation">SICS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In any design process, a medium&#8217;s properties need to be considered. This is nothing new in design. Still we find that in HCI and interactive systems design the properties of a technology are often glossed over. That is, technologies are black-boxed without much thought given to how their distinctive properties open up design possibilities. In this paper we describe what we call inspirational bits as a way to become more familiar with the design material in HCI, the digital material. We describe inspirational bits as quick and dirty but fully working systems in both hardware and software built with the aim of exposing one or several of the dynamic properties of a digital material. We also show how they provide a means of sharing design knowledge across the members of a multi-disciplined design team.</span></div></div><div class="paper" id="paper702"><a href="#paper702" class="title">Don't Drop It!  Pick It Up and Storyboard</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979171&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shahtab  Wahid</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">D. Scott McCrickard</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Joseph  DeGol</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">Nina  Elias</span> <span class="affiliation">Michigan State University</span>, <br />
<span class="author">Steve  Harrison</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Storyboards offer designers a way to illustrate a narrative. Their creation can be enabled by tools supporting sketching or widget collections. As designers often incorporate previous ideas, we contribute the notion of blending the reappropriation of artifacts and their design tradeoffs with storyboarding. We present PIC-UP, a storyboarding tool supporting reappropriation, and report on two studies&#8212;a long-term investigation with novices and interviews with experts. We discuss how it may support design thinking, tailor to different expertise levels, facilitate reappropriation during storyboarding, and assist with communication.</span></div></div></td>
<td colspan="10" class="session_details" id="S1136_details"><div class="sessionChair"><strong>Session Chair: </strong>Stephen Voida (<em>University of California, Irvine</em>)</div><div class="paper" id="paper225"><a href="#paper225" class="title">WYSIWYF: Exploring and Annotating Volume Data with a Tangible Handheld Device</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979140&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Peng  Song</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Wooi Boon  Goh</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Chi-Wing  Fu</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Qiang  Meng</span> <span class="affiliation">The Chinese University of Hong Kong</span>, <br />
<span class="author">Pheng-Ann  Heng</span> <span class="affiliation">The Chinese University of Hong Kong</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Visual exploration of volume data often requires the user to manipulate the orientation and position of a slicing plane in order to observe, annotate or measure its internal structures. Such operations, with its many degrees of freedom in 3D space, map poorly into interaction modalities afforded by mouse-keyboard interfaces or flat multi-touch displays alone. We addressed this problem using a what-you-see-is-what-you-feel (WYSIWYF) approach, which integrates the natural user interface of a multi-touch wall display with the untethered physical dexterity provided by a handheld device with multi-touch and 3D-tilt sensing capabilities. A slicing plane can be directly and intuitively manipulated at any desired position within the displayed volume data using a commonly available mobile device such as the iPod touch. 2D image slices can be transferred wirelessly to this small touch screen device, where a novel fast fat finger annotation technique (F3AT) is proposed to perform accurate and speedy contour drawings. Our user studies support the efficacy of our proposed visual exploration and annotation interaction designs.</span></div></div><div class="paper" id="paper598"><a href="#paper598" class="title">Eden: A Professional Multitouch Tool for Constructing Virtual Organic Environments</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979141&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kenrick  Kin</span> <span class="affiliation">Pixar Animation Studios / University of California, Berkeley</span>, <br />
<span class="author">Tom  Miller</span> <span class="affiliation">Pixar Animation Studios</span>, <br />
<span class="author">Bj&#246;rn  Bollensdorff</span> <span class="affiliation">Technische Universit&#228;t Berlin</span>, <br />
<span class="author">Tony  DeRose</span> <span class="affiliation">Pixar Animation Studios</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Maneesh  Agrawala</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Set construction is the process of selecting and positioning virtual geometric objects to create a virtual environment used in a computer-animated film. Set construction artists often have a clear mental image of the set composition, but find it tedious to build their intended sets with current mouse and keyboard interfaces. We investigate whether multitouch input can ease the process of set construction. Working with a professional set construction artist at Pixar Animation Studios, we designed and developed Eden, a fully functional multitouch set construction application. In this paper, we describe our design process and how we balanced the advantages and disadvantages of multitouch input to develop usable gestures for set construction. Based on our design process and the user experiences of two set construction artists, we present a general set of lessons we learned regarding the design of a multitouch interface.</span></div></div><div class="paper" id="paper1526"><a href="#paper1526" class="title">2D Touching of 3D Stereoscopic Objects</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979142&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dimitar  Valkov</span> <span class="affiliation">University of M&#252;nster</span>, <br />
<span class="author">Frank  Steinicke</span> <span class="affiliation">University of M&#252;nster</span>, <br />
<span class="author">Gerd  Bruder</span> <span class="affiliation">University of M&#252;nster</span>, <br />
<span class="author">Klaus  Hinrichs</span> <span class="affiliation">University of M&#252;nster</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent developments in the area of touch and display technologies have suggested to combine multi-touch systems and stereoscopic visualization. <br /> Stereoscopic perception requires each eye to see a slightly different perspective of the same scene, which results in two distinct projections on the display. <br />  <br /> Thus, if the user wants to select a 3D stereoscopic object in such a setup, the question arises where she would touch the 2D surface to indicate the selection. <br /> A user may apply different strategies, for instance touching the midpoint between the two projections, or touching one of them. <br />  <br /> In this paper we analyze the relation between the 3D positions of stereoscopically rendered objects and the <br />emph{on-surface touch points}, where users touch the surface.  <br /> We performed an experiment in which we determined the positions of the users' touches for objects, which were displayed with positive, negative or zero parallaxes. <br /> We found that users tend to touch between the projections for the two eyes with an offset towards the projection for the dominant eye. <br /> Our results give implications for the development of future touch-enabled interfaces, which support 3D stereoscopic visualization.</span></div></div><div class="paper" id="paper1205"><a href="#paper1205" class="title">TZee: Exploiting the Lighting Properties of Multi-touch Tabletops for Tangible 3D Interactions</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979143&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cary  Williams</span> <span class="affiliation">University of Manitoba</span>, <br />
<span class="author">Xing Dong  Yang</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Grant  Partridge</span> <span class="affiliation">University of Manitoba</span>, <br />
<span class="author">Josh  Millar-Usiskin</span> <span class="affiliation">University of Manitoba</span>, <br />
<span class="author">Arkady  Major</span> <span class="affiliation">University of Manitoba</span>, <br />
<span class="author">Pourang  Irani</span> <span class="affiliation">University of Manitoba</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Manipulating 3D objects on a tabletop is inherently problematic. Tabletops lack a third degree of freedom and thus require novel solutions to support even the simplest 3D manipulations. Our solution is TZee &#8211; a passive tangible widget that enables natural interactions with 3D objects by exploiting the lighting properties of diffuse illumination (DI) multi-touch tabletops. TZee is assembled from stacked layers of acrylic glass to extend the tabletop&#8217;s infrared light slightly above the surface without supplemental power. With TZee, users can intuitively scale, translate and rotate objects in all three dimensions, and also perform more sophisticated gestures, like &#8220;slicing&#8221; a volumetric object, that have not been possible with existing tabletop interaction schemes. TZee is built with affordable and accessible materials, and one tabletop surface can easily support multiple TZees. Moreover, since TZee is transparent, there are numerous possibilities to augment interactions with feedback, helpful hints, or other visual enhancements. We discuss several important design considerations and demonstrate the value of TZee with several applications.</span></div></div></td>
<td colspan="10" class="session_details" id="S1140_details"><div class="sessionChair"><strong>Session Chair: </strong>Dan Cosley (<em>Cornell University</em>)</div><div class="paper" id="to104"><a href="#to104" class="title">On Human Remains: Values and Practice in the Home Archiving of Cherished Objects</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">David  Kirk</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Abigail  Sellen</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Creating digital archives of personal and family artifacts is an area of growing interest, but which seemingly is often not supported by a thorough understanding of current home archiving practice. In this article we seek to excavate the home archive, exploring those things that people choose to keep rather than simply accumulate. Based on extensive field research in family homes we present an investigation of the kinds of sentimental objects, both physical and digital, to be found in homes, and through in-depth interviews with family members we explore the values behind archiving practices, explaining why and how sentimental artefacts are kept. In doing this we wish to highlight the polysemous nature of things and to argue that archiving practice in the home is not solely concerned with the invocation of memory. In support of this we show how sentimental artifacts are also used to connect with others, to define the self and the family, to fulfill obligations and, quite conversely to efforts of remembering, to safely forget. Such values are fundamental to family life where archiving takes place and consequently we explore how home archiving is achieved as a familial practice in the negotiated spaces of the home. From this grounded understanding of existing practices and values, in context, we derive requirements and implications for the design of future forms of domestic archiving technology. <br /></span></div></div><div class="paper" id="paper1965"><a href="#paper1965" class="title">Freed: a System for Creating Multiple Views of a Digital Collection during the Design Process</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979160&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Philip  Mendels</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Joep  Frens</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Kees  Overbeeke</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper Freed is presented, a system that enables design students to spatially organize their digital collection, define relations between collection content and reflect on it. The system features a force-based layout that allows to explore spatial organizations, and hence to gain new insights. Its main advantage over existing software, is that it empowers the students to create different views of their digital collection. A view is a spatial organization of a selection of the collection content and its relations. It can e.g. be used for a specific design activity or project phase, for organizing work around a specific topic, or for explaining the perspective of a given student or stakeholder. Feedback of design students working with Freed during their design projects, and results from a workshop as measured by a questionnaire, show positive prospects for adoption of the system during the design process.</span></div></div><div class="paper" id="paper1134"><a href="#paper1134" class="title">Teenagers and Their Virtual Possessions: Design Opportunities and Issues</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979161&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">William  Odom</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">John  Zimmerman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jodi  Forlizzi</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Over the past several years, people have increasingly acquired virtual possessions. We consider these things to include artifacts that are increasingly becoming immaterial (e.g. books, photos, music, movies) and things that have never traditionally had a lasting material form (e.g. SMS archives, social networking profiles, personal behavior logs). To date, little research exists about how people value and form attachments to virtual possessions. To investigate, we conducted a study with 21 teenagers exploring the perceived value of their virtual possessions, and the comparative similarities and differences with their material things. Findings are interpreted to detail design and research opportunities and issues in this emerging space.</span></div></div><div class="paper" id="paper2023"><a href="#paper2023" class="title">Life Editing: Third-Party Perspectives on Lifelog Content</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979162&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daragh  Byrne</span> <span class="affiliation">School of Computing, Dublin City University</span>, <br />
<span class="author">Aisling  Kelliher</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Gareth J.F. Jones</span> <span class="affiliation">School of Computing, Dublin City University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Lifelog collections digitally capture and preserve personal experiences and can be mined to reveal insights and understandings of individual significance. These rich data sources also offer opportunities for learning and discovery by motivated third parties. We employ a custom-designed storytelling application in constructing meaningful lifelog summaries from third-party perspectives. This storytelling initiative was implemented as a core component in a university media-editing course. We present promising results from a preliminary study conducted to evaluate the utility and potential of our approach in creatively interpreting a unique experiential dataset.</span></div></div></td>
<td colspan="10" class="session_details" id="S1141_details"><div class="sessionChair"><strong>Session Chair: </strong>Susan Dumais (<em>Microsoft Research</em>)</div><div class="paper" id="paper2069"><a href="#paper2069" class="title">Metrics for the Evaluation of News Site Content Layout in Large-Screen Contexts</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979164&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Nebeling</span> <span class="affiliation">ETH Zurich</span>, <br />
<span class="author">Fabrice  Matulic</span> <span class="affiliation">ETH Zurich</span>, <br />
<span class="author">Moira C. Norrie</span> <span class="affiliation">ETH Zurich</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Despite the fact that screen sizes and average screen resolutions have dramatically increased over the past few years, little attention has been paid to the design of web sites for large, high-resolution displays that are now becoming increasingly used both in enterprise and consumer spaces. We present a study of how the visual area of the browser window is currently utilised by news web sites at different widescreen resolutions. The analysis includes measurements of space taken up by the article content, embedded ads and the remaining components as they appear in the viewport of the web browser. The results show that the spatial distribution of page elements does not scale well with larger viewing sizes, which leads to an increasing amount of unused screen real estate and unnecessary scrolling. We derive a number of device-sensitive metrics to measure the quality of web page layout in different viewing contexts, which can guide the design of flexible layout templates that scale effectively on large screens.</span></div></div><div class="paper" id="paper879"><a href="#paper879" class="title">YouPivot: Improving Recall with Contextual Search</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979165&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joshua  Hailpern</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Nicholas  Jitkoff</span> <span class="affiliation">Google</span>, <br />
<span class="author">Andrew  Warr</span> <span class="affiliation">Google</span>, <br />
<span class="author">Karrie  Karahalios</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Robert  Sesek</span> <span class="affiliation">Boston University</span>, <br />
<span class="author">Nik  Shkrob</span> <span class="affiliation">University of Waterloo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">According to cognitive science literature, human memory is predicated on contextual cues (e.g., room, music) in the environment. During recall tasks, we associate information/activities/objects with contextual cues. However, computer systems do not leverage our natural process of using contextual cues to facilitate recall. We present a new interaction technique, Pivoting, that allows users to search for contextually related activities and find a target piece of information (often not semantically related). A sample motivation for contextual search would be, &#8220;what was that website I was looking at when Yesterday by The Beatles was last playing?&#8221; Our interaction technique is grounded in the cognitive science literature, and is demonstrated in our system YouPivot. In addition, we present a new personal annotation method, called TimeMarks, to further support contextual recall and the pivoting process. In a pilot study, participants were quicker to identify websites, and preferred using YouPivot, compared to current tools. YouPivot demonstrates how principles of human memory can be applied to enhance the search of digital information.</span></div></div><div class="paper" id="paper2025"><a href="#paper2025" class="title">An Examination of Two Delivery Modes for Interactive Search System Experiments: Remote and Laboratory</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979166&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diane  Kelly</span> <span class="affiliation">University of North Carolina, Chapel Hill</span>, <br />
<span class="author">Karl  Gyllstrom</span> <span class="affiliation">Katholieke Universiteit Leuven</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We compare two delivery modes for interactive search system (ISS) experiments:  remote and laboratory.  Our study was completed by two groups of subjects from the same population.  The first group completed the study remotely and the second group completed the study in the laboratory. We compare differences in participants, participation behaviors, search behaviors and evaluation behaviors. Overall, for most measures no significant differences were found, but there were some notable differences. Greater variance was observed in time taken and number of documents opened and saved by remote subjects. Lab subjects provided more favorable responses to exit questionnaire items and reported significantly higher satisfaction. Lab subjects also provided significantly longer responses to open questions, while remote subjects provided more null responses. These results suggest that many behaviors do not change significantly according to study mode and that results from remote ISS experiments are similar to those from laboratory experiments.</span></div></div><div class="paper" id="paper1860"><a href="#paper1860" class="title">Review Spotlight: A User Interface for Summarizing User-generated Reviews Using Adjective-Noun Word Pairs</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979167&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Koji  Yatani</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Michael  Novati</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Andrew  Trusty</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Khai N. Truong</span> <span class="affiliation">University of Toronto</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many people read online reviews written by other users to <br /> learn more about a product or venue. However, the <br /> overwhelming amount of user-generated reviews and <br /> variance in length, detail and quality across the reviews <br /> make it difficult to glean useful information. In this paper, <br /> we present the iterative design of our system, called Review <br /> Spotlight. It provides a brief overview of reviews using <br /> adjective-noun word pairs, and allows the user to quickly <br /> explore the reviews in greater detail. Through a laboratory <br /> user study which required participants to perform decision <br /> making tasks, we showed that participants could form <br /> detailed impressions about restaurants and decide between <br /> two options significantly faster with Review Spotlight than <br /> with traditional review webpages.</span></div></div></td>
<td colspan="10" class="session_details" id="S1135_details"><div class="sessionChair"><strong>Session Chair: </strong>Hiroshi Ishii (<em>Massachusetts Institute of Technology</em>)</div><div class="paper" id="paper840"><a href="#paper840" class="title">Evaluating Effects of Structural Holds on Pointing and Dragging Performance with Flexible Displays</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979135&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rob  Dijkstra</span> <span class="affiliation">Human Media Lab, Queen's University</span>, <br />
<span class="author">Christopher  Perez</span> <span class="affiliation">Human Media Lab, Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Human Media Lab, Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we present a study of the effects of structural holds and rigidity of a flexible display on touch pointing and dragging performance. We discuss an observational study in which we collected common holds used when pointing on a mockup paper display. We also measured the force patterns each hold generated within the display surface. We analyzed this data to produce 3 force zones in the display for each of the four most frequently observed holds: the grip zone, rigid zone, and the flexible zone. We report on an empirical evaluation in which we compared the efficiency of pointing and dragging operations between holds, and between structural zones within holds, using a real flexible Lumalive display. Results suggest that structural force distributions in a flexible display affect the Index of Performance of both pointing and dragging tasks, irrespective of hold, with rigid parts of the display yielding a 12% average performance gain over flexible areas.</span></div></div><div class="paper" id="paper649"><a href="#paper649" class="title">PaperPhone: Understanding the Use of Bend Gestures in Mobile Devices with Flexible Electronic Paper Displays</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979136&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Byron  Lahey</span> <span class="affiliation">Human Media Lab, Queen's University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Human Media Lab, Queen's University</span>, <br />
<span class="author">Winslow  Burleson</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Human Media Lab, Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Flexible displays potentially allow for interaction styles that resemble those used in paper documents. Bending the display, e.g., to page forward, shows particular promise as an interaction technique. In this paper, we present an evaluation of the effectiveness of various bend gestures in executing a set of tasks with a flexible display. We discuss a study in which users designed bend gestures for common computing actions deployed on a smartphone-inspired flexible E Ink prototype called PaperPhone. We collected a total of 87 bend gesture pairs from ten participants and their appropriateness over twenty actions in five applications. We identi- fied six most frequently used bend gesture pairs out of 24 unique pairs. Results show users preferred bend gestures and bend gesture pairs that were conceptually simpler, e.g., along one axis, and less physically demanding. There was a strong agreement among participants to use the same three pairs in applications: (1) side of display, up/down (2) top corner, up/down (3) bottom corner, up/down. For actions with a strong directional cue, we found strong consensus on the polarity of the bend gestures (e.g., navigating left is performed with an upwards bend gesture, navigating right, downwards). This implies that bend gestures that take directional cues into account are likely more natural to users.</span></div></div><div class="paper" id="paper1990"><a href="#paper1990" class="title">Pinstripe: Eyes-free Continuous Input on Interactive Clothing</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979137&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Thorsten  Karrer</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Moritz  Wittenhagen</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Leonhard  Lichtschlag</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Florian  Heller</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present Pinstripe, a textile user interface element for eyes-free, continuous value input on smart garments that uses pinching and rolling a piece of cloth between your fin- gers. The input granularity can be controlled in a natural way by varying the amount of cloth pinched. Pinstripe input elements physically consist of fields of parallel conductive lines sewn onto the fabric. This way, they can be invisi- ble, and can be included across large areas of a garment. Pinstripe also addresses several problems previously identi- fied in the placement and operation of textile UI elements on smart clothing. Two user studies evaluate ideal placement and orientation of Pinstripe elements on the users&#8217; garments as well as acceptance and perceived ease of use of this novel textile input technique.</span></div></div><div class="paper" id="paper941"><a href="#paper941" class="title">Grips and Gestures on a Multi-Touch Pen</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979138&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hyunyoung  Song</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Francois  Guimbretiere</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Shahram  Izadi</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Xiang  Cao</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Ken  Hinckley</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the interactive possibilities enabled when the barrel of a digital pen is augmented with a multi-touch sensor. We present a novel multi-touch pen (MTPen) prototype and discuss its alternate uses beyond those of a standard stylus, such as allowing new touch gestures to be performed using the index finger or thumb and detecting how users grip the device as a mechanism for mode switching. We also discuss the hardware and software implementation challenges in realizing our prototype, and showcase how one can combine different grips (tripod, relaxed tripod, sketch, wrap) and gestures (swipe and double tap) to enable new interaction techniques with the MTPen in a prototype drawing application. One specific aim is the elimination of some of the comfort problems associated with existing auxiliary controls on digital pens, such as barrel buttons and barrel scroll wheels; such mechanical controls work best in only a few specific hand grips and pen rotations. Comparatively, our gestures can be successfully and comfortably performed regardless of the rotation of the pen or how the user grips it, offering greater flexibility in use. We describe a formal evaluation comparing MTPen gestures against the use of a barrel button for mode switching. This study shows that both swipe and double tap gestures are comparable in performance to commonly employed barrel buttons without its disadvantages.</span></div></div></td>
<td colspan="10" class="session_details" id="S1138_details"><div class="sessionChair"><strong>Session Chair: </strong>John Thomas (<em>IBM Research</em>)</div><div class="paper" id="to100"><a href="#to100" class="title">Designing Mobile Interfaces for Novice and Low-Literacy Users</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Indrani  Medhi</span> <span class="affiliation">Microsoft Research India</span>, <br />
<span class="author">Somani  Patnaik</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Emma  Brunskill</span> <span class="affiliation">University of California Berkeley</span>, <br />
<span class="author">S. N. Gautama  Nagasena</span> <span class="affiliation">Microsoft Research India</span>, <br />
<span class="author">William  Thies</span> <span class="affiliation">Microsoft Research India</span>, <br />
<span class="author">Kentaro  Toyama</span> <span class="affiliation">University of California Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While mobile phones have found broad application in bringing health, financial, and other services to the developing world, usability remains a major hurdle for novice and low-literacy populations. In this paper, we offer an ethnographic study of the usability barriers facing 90 low-literacy subjects in India, Kenya, the Philippines and South Africa. Then, via two studies involving over 70 subjects in India, we quantitatively compare the usability of different points in the mobile design space, including electronic forms, SMS, a spoken dialogue system, a graphical interface, and a live operator. We synthesize our findings into a set of design recommendations.</span></div></div><div class="paper" id="paper205"><a href="#paper205" class="title">The Times They Are A-Changin&#8217;: Mobile Payments in India</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979150&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Deepti  Kumar</span> <span class="affiliation">IIT Madras</span>, <br />
<span class="author">David  Martin</span> <span class="affiliation">Xerox Research Centre Europe</span>, <br />
<span class="author">Jacki  O'Neill</span> <span class="affiliation">Xerox Research Centre Europe</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We report on an ethnographic study of payment and banking practices in India. Currently a mobile payment mechanism is being developed in India and we were interested to see how it would fit with various current payment systems for various types of users. Therefore we studied a variety of current payment situations and gained an understanding of the banking and payment practices and needs of a diverse community. Our aim was to inform the development of interface elements, applications and services that would support the needs we uncovered. We describe our findings and the design ideas they provoked.</span></div></div><div class="paper" id="paper1825"><a href="#paper1825" class="title">Folk Music Goes Digital in India</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979151&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Neha  Kumar</span> <span class="affiliation">U. C. Berkeley</span>, <br />
<span class="author">Gopal  Chouhan</span> <span class="affiliation">Self-Employed</span>, <br />
<span class="author">Tapan  Parikh</span> <span class="affiliation">U. C. Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Folk music forms in India are rich and diverse, varying from region to region across the Indian landscape. The recent explosion of new media technologies (e.g. DVDs, CDs, mobile phones) in both rural and urban India is changing how oral folk music is being performed, produced, distributed, and shared. To further understand this impact, we conducted an extended field study across four field sites in India that are rich in folk music tradition and activity. Through a process of interviews, participant observation, focus group discussion, and content analysis with a varied group of stakeholders &#8211; including folk musicians, listeners, retailers, and radio show producers &#8211; we found that 1) there are a diverse set of motivations for performing and listening to folk music, 2) new media technologies are helping folk musicians become more popular, while reducing some streams of revenue, particularly for businesses engaged only in music production and distribution, and 3) as expected, piracy is widely tolerated by musicians, both out of apathy, and an interest in reaching new audiences with their message, while increasing their own fame and associated patronage. Based on these findings, we propose some implications for the design of an appropriate folk music sharing and distribution service that addresses these various motivations of the musicians and listeners.</span></div></div><div class="paper" id="paper996"><a href="#paper996" class="title">Designing for Emerging Rural Users: Experiences from China</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979152&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elisa  Oreglia</span> <span class="affiliation">UC Berkeley School of Information</span>, <br />
<span class="author">Ying  Liu</span> <span class="affiliation">IBM Research China</span>, <br />
<span class="author">Wei  Zhao</span> <span class="affiliation">IBM Research China</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As part of IBM&#8217;s Smarter Planet initiative, we studied information-sharing practices in rural Northern China to understand if and how ICT can help rural residents improve their lives. Interviews and participant observation in two villages showed a profusion of ICT devices, as well as an abundance of face-to-face information exchanges, but a shortage of localized and easily accessible information, and a deep dependence of many rural residents on &#8216;information brokers&#8217; such as agricultural extension workers and shop owners. Can ICT support existing practices of information sharing among rural residents, when these practices are largely based on face-to-face encounters and passive reception of information? We argue that in such an environment, ICT should build on existing social habits even if less than ideal, rather than trying to transform them, and we outline a possible way to do so.</span></div></div><div class="paper" id="paper1833"><a href="#paper1833" class="title">Adapting Usability Testing for Oral, Rural Users</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979153&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Trina  Gorman</span> <span class="affiliation">Literacy Bridge</span>, <br />
<span class="author">Emma  Rose</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Judith  Yaaqoubi</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Andrew  Bayor</span> <span class="affiliation">Literacy Bridge</span>, <br />
<span class="author">Beth  Kolko</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Traditional usability methods are of limited use when evaluating systems designed for distant, diverse populations. In this paper, we describe a study conducted in two Ghanaian villages that evaluated an audio computer designed for people living in oral cultures. Informed by ICTD and orality-grounded HCID, we modified existing usability testing practices and we reflect on the utility of these adaptations. We found that conducting a culturally appropriate study often meant forgoing more traditional approaches in favor of flexible, opportunistic methods. We acknowledge the challenges of adapting traditional usability methods for oral, rural users. However, we found that by implementing strategic modifications led by local staff, our study produced valuable, actionable results.</span></div></div></td>
<td colspan="10" class="session_details" id="S1129_details"><div class="paper" id="pl108"><a href="#pl108" class="title">Re-engineering Health Care with Information Technology</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979490&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Keith  Butler</span> <span class="affiliation">Univ of Washington</span>, <br />
<span class="author">Thomas  Payne</span> <span class="affiliation">Univ of Washington</span>, <br />
<span class="author">Ben  Shneiderman</span> <span class="affiliation">Univ of Maryland</span>, <br />
<span class="author">Patricia  Brennan</span> <span class="affiliation">Univ of Wisconsin</span>, <br />
<span class="author">Jiajie  Zhang</span> <span class="affiliation">Univ of Texas</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There is critical, nation-wide need to improve health care and its cost. Health information technology has great promise that is yet to be realized. In this panel four noted experts will discuss key issues that should drive health IT, and the challenges for the CHI community to play a leading role.</span></div></div></td>
<td colspan="10" class="session_details" id="S1139_details"><div class="sessionChair"><strong>Session Chair: </strong>Mary Czerwinski (<em>Microsoft Research</em>)</div><div class="paper" id="paper1305"><a href="#paper1305" class="title">Evaluating Video Visualizations of Human Behavior</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979155&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mario  Romero</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Alice  Vialard</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">John  Peponis</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">John  Stasko</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Gregory  Abowd</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previously, we presented Viz-A-Vis, a VIsualiZation of Activity through computer VISion. Viz-A-Vis visualizes behavior as aggregate motion over observation space. In this paper, we present two complementary user studies of Viz-A-Vis measuring its performance and discovery affordances. First, we present a controlled user study aimed at comparatively measuring behavioral analysis preference and performance for observational and search tasks. Second, we describe a study with architects measuring discovery affordances and potential impacts on their work practices. We conclude: 1) Viz-A-Vis significantly reduced search time; and 2) it increased the number and quality of insightful discoveries.</span></div></div><div class="paper" id="paper1925"><a href="#paper1925" class="title">Sizing Up Visualizations: Effects of Display Size in Focus+Context, Overview+Detail, and Zooming Interfaces</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979156&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mikkel  R&#248;nne Jakobsen</span> <span class="affiliation">University of Copenhagen</span>, <br />
<span class="author">Kasper  Hornb&#230;k</span> <span class="affiliation">University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Whereas the literature is clear on the benefits of large displays and visualizations, little is known about their combination, that is, how display size affect the usability of visualizations. We describe a controlled experiment where 19 participants used focus+context, overview+detail, and zooming techniques with varying display sizes (13.8, 1.5, and 0.17 megapixels). Participants navigated geographical maps to find specific locations, compare items, and follow routes. Results show that for multi-scale navigation, classic interactive visualization techniques did not benefit from being scaled to a large display: In contrast to the literature we find similar performance on medium and large displays. Across display sizes, overview+detail works the best, in particular for comparing items. Focus+context is relatively more difficult to use at a small display size. We explain these findings and discuss the design of interactive visualization techniques for large displays.</span></div></div><div class="paper" id="paper736"><a href="#paper736" class="title">The Impact of Social Information on Visual Judgments</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979157&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jessica  Hullman</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Eytan  Adar</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Priti  Shah</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social visualization systems have emerged to support collective intelligence-driven analysis of a growing influx of open data. As with many other online systems, social signals (e.g., forums, polls) are commonly integrated to drive use. Unfortunately, the same social features that can provide rapid, high-accuracy analysis are coupled with the pitfalls of any social system. Through an experiment involving over 300 subjects, we address how social information signals (social proof) affect quantitative judgments in the context of graphical perception. We identify how unbiased social signals lead to fewer errors over non-social settings and conversely, how biased signals lead to more errors. We further reflect on how systematic bias nullifies certain collective intelligence benefits, and we provide evidence of the formation of information cascades. We describe how these findings can be applied to collaborative visualization systems to produce more accurate individual interpretations in social contexts.</span></div></div><div class="paper" id="paper948"><a href="#paper948" class="title">Directing Attention and Influencing Memory with Visual Saliency Modulation</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979158&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eduardo E Veas</span> <span class="affiliation">Graz University of Technology</span>, <br />
<span class="author">Erick  Mendez</span> <span class="affiliation">Graz University of Technology</span>, <br />
<span class="author">Steven K Feiner</span> <span class="affiliation">Columbia University</span>, <br />
<span class="author">Dieter  Schmalstieg</span> <span class="affiliation">Graz University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In augmented reality, it is often necessary to draw the user&#8217;s attention to particular objects of the real world without distracting her from her task. We explore the effectiveness of directing a user&#8217;s attention by imperceptibly modifying existing features of a video. We present three user studies of the effects of applying a saliency modulation technique to video; evaluating modulation awareness, attention and memory. Our results validate the saliency modulation technique as an alternative means to convey information to the user, suggesting attention shifts and influencing recall of selected regions without perceptible changes to visual input.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">15:20<br />-<br />16:00</td>

<td class="session " id="S5014">
<div class="session_box">
<span class="type">Interactivity</span>
<a href="#S5014" class="title">Interactivity 1 Open</a>
<span class="location">Ballroom C/D</span>
<strong></strong>

</div>
</td>

<td class="session " id="S5012">
<div class="session_box">
<span class="type">Interactivity</span>
<a href="#S5012" class="title">Interactivity 2 Open</a>
<span class="location">202/203/204</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="2" class="session_details" id="S5014_details"><div class="paper" id="in135"><a href="#in135" class="title">ChronoViz: A System for Supporting Navigation of Time-coded Data</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979706&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Adam  Fouse</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">Nadir  Weibel</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">Edwin  Hutchins</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">James D Hollan</span> <span class="affiliation">University of California, San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present ChronoViz, a system to aid annotation, visualization, navigation, and analysis of multimodal time-coded data. Exploiting interactive paper technology, ChronoViz also integrates researcher's paper notes into the composite data set. Researchers can navigate data in multiple ways, taking advantage of synchronized visualizations and annotations. The goal is to decrease the time and effort required to analyze multimodal data by providing direct indexing and flexible mechanisms to control data exploration.</span></div></div><div class="paper" id="in143"><a href="#in143" class="title">i*Chameleon: A Scalable and Extensible Framework for Multimodal Interaction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979703&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wai Wa  Tang</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Kenneth W.K.  Lo</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Alvin T.S.  Chan</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Stephen  Chan</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Hong Va  Leong</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Grace  Ngai</span> <span class="affiliation">The Hong Kong Polytechnic University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">i*Chameleon is a multimodal interaction framework that enables programmers to readily prototype and test new interactive devices or interaction modes. It allows users to customize their own desktop environment for interaction beyond the usual KVM devices, which would be particularly useful for users with difficulty using the keyboard and mouse, or for systems deployed in specialized environments. This is made possible with the engineering of an interaction framework that distills the complexity of control processing to a set of semantically-rich modal controls that are discoverable, composable and adaptable. The framework can also be used for developing new applications with multimodal interactions, for example, distributed applications in collaborative environments or robot control.</span></div></div><div class="paper" id="in147"><a href="#in147" class="title">INVISQUE: Intuitive Information Exploration through Interactive Visualization</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979720&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">B L William  Wong</span> <span class="affiliation">Middlesex University</span>, <br />
<span class="author">Raymond  Chen</span> <span class="affiliation">Middlesex University</span>, <br />
<span class="author">Neesha  Kodagoda</span> <span class="affiliation">Middlesex University</span>, <br />
<span class="author">Chris  Rooney</span> <span class="affiliation">Middlesex University</span>, <br />
<span class="author">Kai  Xu</span> <span class="affiliation">Middlesex University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present INVISQUE, a novel system designed for interactive information exploration. Instead of a conventional list-style arrangement, in INVISQUE information is represented by a two-dimensional spatial canvas, with each dimension representing user-defined semantics.  Search results are presented as index cards, ordered in both dimensions. Intuitive interactions are used to perform tasks such as keyword searching, results browsing, categorizing, and linking to online resources such as Google and Twitter. The interaction-based query style also naturally lends the system to different types of user input such as multi-touch gestures. As a result, INVISQUE gives users a much more intuitive and smooth experience of exploring large information spaces.</span></div></div><div class="paper" id="in148"><a href="#in148" class="title">Tactile Display for the Visually Impaired Using TeslaTouch</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979705&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cheng  Xu</span> <span class="affiliation">Disney Research Pittsburgh &amp; Carnegie Mellon University</span>, <br />
<span class="author">Ali  Israr</span> <span class="affiliation">Disney Research Pittsburgh</span>, <br />
<span class="author">Ivan  Poupyrev</span> <span class="affiliation">Disney Research Pittsburgh</span>, <br />
<span class="author">Olivier  Bau</span> <span class="affiliation">Disney Research Pittsburgh</span>, <br />
<span class="author">Chris  Harrison</span> <span class="affiliation">Disney Research Pittsburgh &amp; Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">TeslaTouch is a technology that provides tactile sensation to moving fingers on touch screens. Based on TeslaTouch, we have developed applications for the visually impaired to interpret and create 2D tactile information. We demonstrate these applications, present observations from the interaction, and discuss TeslaTouch&#8217;s potential in supporting communication among visually impaired individuals.</span></div></div><div class="paper" id="in151"><a href="#in151" class="title">MudPad: Tactile Feedback for Touch Surfaces</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979702&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yvonne  Jansen</span> <span class="affiliation">INRIA / RWTH Aachen University</span>, <br />
<span class="author">Thorsten  Karrer</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">MudPad is a system enriching touch surfaces with localized active haptic feedback. A soft and flexible overlay containing magnetorheological fluid is actuated by an array of electromagnets to create a variety of tactile sensations. As each magnet can be controlled individually, we are able to produce feedback in realtime locally at arbitrary points of interaction.</span></div></div><div class="paper" id="in162"><a href="#in162" class="title">Snaplet: Using Body Shape to Inform Function in Mobile Flexible Display Devices</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979701&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aneesh P Tarun</span> <span class="affiliation">Human Media Lab, Queen's University</span>, <br />
<span class="author">Byron  Lahey</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Human Media Lab, Queen's University</span>, <br />
<span class="author">Winslow  Burleson</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Human Media Lab, Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With recent advances in flexible displays, computer displays are no longer restricted to flat, rigid form factors. We propose that the physical form of a flexible display, depending on the way it is held or worn, can help shape its current functionality. We propose Snaplet, a wearable flexible E Ink display augmented with sensors that allow the shape of the display to be detected. Snaplet is a paper computer in the form of a bracelet. When in a convex shape on the wrist, Snaplet functions as a watch and media player. When held flat in the hand it is a PDA with notepad functionality. When held in a concave shape Snaplet functions as a phone. Calls are dropped by returning its shape to a flat or convex shape.</span></div></div><div class="paper" id="in171"><a href="#in171" class="title">Ubiquitous Voice Synthesis: Interactive Manipulation of Speech and Singing on Mobile Distributed Platforms</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979700&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicolas  d'Alessandro</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Robert  Pritchard</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Johnty  Wang</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Vocal production is one of the most ubiquitous and expressive activities of people, yet understanding its production and synthesis remains elusive. When vocal synthesis is elevated to include new forms of singing and sound production, fundamental changes to culture and musical expression emerge. Nowadays, Text-To-Speech (TTS) synthesis seems unable to suggest innovative solutions for new computing trends, such as mobility, interactivity, ubiquitous computing or expressive manipulation. <br />  <br /> We describe our pioneering work in developing interactive voice synthesis beyond the TTS paradigm. We present DiVA and HandSketch as our two current voice-based digital musical instruments. We then discuss the evolution of this performance practice into a new ubiquitous model applied to voice synthesis, and we describe our first prototype using a mobile phone and wireless embodied devices in order to allow a group of users to collaboratively produce voice synthesis in real-time.</span></div></div><div class="paper" id="in173"><a href="#in173" class="title">RayMatic: Ambient meter display with facial expression and gesture</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979718&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ray  Yun</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Mark D Gross</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an experimental thermostat display that moves beyond a conventional, number-based interface. It explores an approach to engaging and emotional human-computer interaction through facial expression and gesture. Using sensors and touch technology, an ordinary picture frame becomes an interactive meter and conveys environmental information as an ambient display.</span></div></div></td>
<td colspan="2" class="session_details" id="S5012_details"><div class="paper" id="in122"><a href="#in122" class="title">Coco - The Therapy Robot</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979721&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katharina  Tran phuc</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Torsten  Racky</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Florian  Roth</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Iris  Wegmann</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Christoph  Busch</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Claudia  S&#246;ller-Eckert</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Mara  Pilz</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Katharina  Horst</span> <span class="affiliation">University of Applied Sciences Darmstadt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Coco is a therapeutic robot designed for elderly people in nursing homes or other care facilities. It is an electronic pet that represents a friend and helper who animates, reminds and motivates its owner.  He has 4 main functions: reading, singing, a calendar function and quiz games and can be operated by voice, remote control or base buttons. Pressure sensors in Coco's back react to touch. He interacts with its owner on its own initiative, suggesting to read, sing or play. Coco's memory and activity settings can be customised by carers or relatives. The prototype was implemented with Lego Mindstorms and successfully tested by a focus group. <br /></span></div></div><div class="paper" id="in129"><a href="#in129" class="title">Touch and Copy, Touch and Paste</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979714&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Suranga  Nanayakkara</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">SPARSH explores a novel interaction method to seamlessly transfer data between digital devices in a fun and intuitive way. The user touches whatever data item he or she wants to copy from a device. At that moment, the data item is conceptually saved in the user. Next, the user touches the other device he or she wants to paste/pass the saved content into. SPARSH uses touch-based interactions as indications for what to copy and where to pass it. Technically, the actual transfer of media happens via the information cloud.</span></div></div><div class="paper" id="in130"><a href="#in130" class="title">Mouseless - a Computer Mouse as Small as Invisible</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979715&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mouseless is a novel input device that provides the familiarity of interaction of a physical computer mouse without requiring a real hardware mouse. It consists of an IR laser beam and an IR camera, both of which are embedded in a computer. Mouseless proposes a number of novel additional gestural interactions while supporting all the conventional computer mouse interactions. We present the design and implementation of various Mouseless prototype systems.</span></div></div><div class="paper" id="in132"><a href="#in132" class="title">Obfuscating Authentication Through Haptics, Sound and Light</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979709&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrea  Bianchi</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span>, <br />
<span class="author">Dong-Soo  Kwon</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sensitive digital content associated with or owned by individuals now pervades everyday life. Mediating accessing to it in ways that are usable and secure is an ongoing challenge. We present a series of five PIN entry and transmission systems that address observation attacks in public spaces via shoulder surfing or camera recording. They do this through the use of novel modalities including audio cues, haptic cues and modulated visible light. Each prototype is introduced and motivated, and its strengths and weaknesses are considered.</span></div></div><div class="paper" id="in137"><a href="#in137" class="title">Blinky Blocks: A Physical Ensemble Programming Platform</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979712&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Brian T Kirby</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michael  Ashley-Rollman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Seth Copen Goldstein</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A major impediment to understanding programmable matter is the lack of an existing system with sufficiently many modules of sufficient capabilities. We present the requirements of physically distributed ensembles and discuss the use of the distributed programming language Meld to program ensembles of these units. We demonstrate a new <br /> system designed to meet these requirements called Blinky Blocks and discuss the hardware design we used to create 100 of these modules.</span></div></div><div class="paper" id="in145"><a href="#in145" class="title">humanaquarium: Exploring Audience, Participation, and Interaction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span><div class="authors"><span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Guy  Schofield</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Jayne  Wallace</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Pierre  Boulanger</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">humanaquarium is a movable performance space designed to explore the dialogical relationship between artist and audience. Two musicians perform inside the cube-shaped box, collaborating with participants to co-create an aesthetic audio-visual experience. The front wall of the humanaquarium is a touch-sensitive FTIR window. Max/MSP is used to translate the locations of touches on the window into control data, manipulating the tracking of software synthesizers and audio effects generated in Ableton Live, and influencing a Jitter visualization projected upon the rear wall of the cube.</span></div></div><div class="paper" id="in150"><a href="#in150" class="title">3D-Press - Tangible 3D Haptics on Touch Surfaces: Virtual Compliance</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979717&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Suitability of current haptic three-dimensional user interface (3D-UI) technologies is low for mobile interaction. 3D-Press in reviewed in this paper: a technique to create the haptic illusion that when pressing on a rigid surface is feels compliant. The fact that the illusion is intramodal (haptics only involved in creating it), and that the technology required is simple and with low energy demands, makes it ideal for mobile use. The parameters used in the implementation of 3D-Press influence the characteristics of the illusion.</span></div></div><div class="paper" id="in152"><a href="#in152" class="title">Graffito: Crowd-based Performative Interaction at Festivals</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979725&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Sheridan</span> <span class="affiliation">BigDog Interactive Ltd</span>, <br />
<span class="author">Nick  Bryan-Kinns</span> <span class="affiliation">Queen Mary University of London</span>, <br />
<span class="author">Stuart  Reeves</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Giles  Lane</span> <span class="affiliation">Proboscis</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crowd-based events are generating new forms of crowd-based performative interaction. Nightclubs and festivals are at the cutting edge of crowd-based interaction with ubiquitous computing. The social capital of crowd-based interaction is not well understood and is usually limited to one-off events. Our intention is to explore the possibility for generating a lifelong contextual footprint of crowd-based performative interaction.</span></div></div><div class="paper" id="in154"><a href="#in154" class="title">Galvanic Skin Response-Derived Bookmarking of an Audio Stream</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979716&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew K.X.J. Pan</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gordon Jih-Shiang  Chang</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gokhan H. Himmetoglu</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">AJung  Moon</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Thomas W. Hazelton</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Karon E. MacLean</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Elizabeth A. Croft</span> <span class="affiliation">The University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We demonstrate a novel interaction paradigm driven by implicit, low-attention user control, accomplished by monitoring a user&#8223;s physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. A listener&#8223;s galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our research prototype then automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted.</span></div></div><div class="paper" id="in158"><a href="#in158" class="title">MediaDiver: Viewing and Annotating Multi-View Video</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979711&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gregor  Miller</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Abir  Al Hajri</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Michael  Ilich</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Zoltan  Foley-Fisher</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Manuel  Fernandez</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Daesik  Jang</span> <span class="affiliation">Kunsan National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our novel rich media interface called MediaDiver demonstrates our new interaction techniques for viewing and annotating multiple view video. The demonstration allows attendees to experience novel moving target selection methods (called Hold and Chase), new multi-view selection techniques, automated quality of view analysis to switch viewpoints to follow targets, integrated annotation methods for viewing or authoring meta-content and advanced context sensitive transport and timeline functions. As users have become increasingly sophisticated when managing navigation and viewing of hyper-documents, they transfer their expectations to new media. We demonstrate the technology required to meet these expectations for video. Thus users will be able to directly click on objects in the video to link to more information or other video, easily change camera views and mark-up the video with their own content. The applications of this technology stretch from home video management to broadcast quality media production, which may be consumed on both desktop and mobile platforms.</span></div></div><div class="paper" id="in161"><a href="#in161" class="title">TagURIt: A Proximity-based Game of Tag Using Lumalive e-Textile Displays</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979707&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sylvia H Cheng</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an electronic game of tag that uses proximity sensing and Lumalive displays on garments.  In our game of tag, each player physically represents a location-tagged Universal Resource Indicator (URI). The URIs, one chaser and two target players, wear touch-sensitive Lumalive display shirts. The goal of the game is for the chaser to capture a token displayed on one of the Lumalive shirts, by pressing a touch sensor located on the shirt. When the chaser is in close proximity to the token player, the token jumps to the shirt of the second closest player, making this children&#8217;s game more challenging for adult players.  Our system demonstrates the use of interactive e-textile displays to remove the technological barrier between contact and proximity in the real world, and the seamless representation of gaming information from the virtual world in that real world.</span></div></div><div class="paper" id="in165"><a href="#in165" class="title">Frictional Widgets: Enhancing Touch Interfaces with Programmable Friction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979713&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vincent  Levesque</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Louise  Oram</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Karon  MacLean</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Nicholas  Marchuk</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Dan  Johnson</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">J. Edward  Colgate</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Michael  Peshkin</span> <span class="affiliation">Northwestern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch interactions occur through flat surfaces that lack the tactile richness of physical interfaces. We explore the design possibilities offered by augmenting touchscreens with programmable surface friction. Four exemplar applications &#8211; an alarm clock, a file manager, a game, and a text editor &#8211; demonstrate tactile effects that improve touch interactions by enhancing physicality, performance, and subjective satisfaction.</span></div></div><div class="paper" id="in168"><a href="#in168" class="title">SnowGlobe: A Spherical Fish-Tank VR Display</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979719&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">John  Bolton</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a spherical display with Fish-Tank VR as a means for interacting with three-dimensional objects. We implemented the spherical display by reflecting a projected image off a hemispherical mirror, allowing for a seamless curvilinear display surface. Diffuse illumination is used for detecting touch points on the sphere. The user&#8217;s head position and the position of the sphere are also tracked using a Vicon motion capture device. Users can perform multi-touch gestures to interact with 3D content on the spherical display. Our system relies on the metaphor of a snow globe. Users can walk around a display while maintaining motion parallax corrected viewpoints of the object on the display. They can interact with the 3D object using multitouch interaction techniques, allowing for rotating and scaling of the 3D model on the display.</span></div></div><div class="paper" id="in170"><a href="#in170" class="title">ZeroTouch: A Zero-Thickness Optical Multi-Touch Force Field</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979710&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Sashikanth  Damaraju</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present zero-thickness optical multi-touch sensing, a technique that simplifies sensor/display integration, and enables new forms of interaction not previously possible with other multi-touch sensing techniques. <br /> Using low-cost modulated infrared sensors to quickly determine the visual hull of an interactive area, we enable robust real-time sensing of fingers and hands, even in the presence of strong ambient lighting. Our technology allows for 20+ fingers to be detected, many more than through prior visual hull techniques, and our use of wide-angle optoelectonics allows for excellent touch resolution, even in the corners of the sensor. <br /> With the ability to track objects in free space, as well as its use as a traditional multi-touch sensor, ZeroTouch opens up a new world of interaction possibilities.</span></div></div><div class="paper" id="in207"><a href="#in207" class="title">Immersive VR: A Non-pharmacological Analgesic for Chronic Pain?</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979704&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diane  Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Meehae  Song</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ji-Dong  Yim</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Tyler  Fox</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Steven J Barnes</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mark  Nazemi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Chris  Shaw</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Pam  Squire, MD</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the research work being carried out by the Transforming Pain Research Group &#8211; the only group whose work is entirely focused on the use of immersive VR for chronic pain management. Unlike VR research for acute or short-term pain, which relies on pain "distraction," this research posits a new paradigm for the use of VR. In addition to providing an overview of our work, the present paper also describes one of our current works in detail: the Virtual Meditative Walk.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">16:00<br />-<br />17:20</td>

<td class="session " id="S1144">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1144" class="title">Applying the NSF Broader Impacts Criteria to HCI Research</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1143">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1143" class="title">Design Community: What does Design Mean for CHI</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1153">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1153" class="title">Evaluation and/or Design Based on Many Users</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1158">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1158" class="title">Performing Arts</a>
<span class="location">223/224</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1152">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1152" class="title">Pointing 2: Fitts Law</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1156">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1156" class="title">Photo Sharing</a>
<span class="location">217/218/219</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1157">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1157" class="title">Web Search &amp; Usability</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1151">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1151" class="title">Multi-touch</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1154">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1154" class="title">Homeless Users</a>
<span class="location">212/213/214</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1145">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1145" class="title">RepliCHI - Should CHI be Replicating and Validating Research Results More?</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1155">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1155" class="title">Visual Analytics</a>
<span class="location">215/216</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="11" class="session_details" id="S1144_details"><div class="paper" id="si131"><a href="#si131" class="title">Applying the NSF Broader Impacts Criteria to HCI Research</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979534&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Juan E. Gilbert</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Margaret  Burnett</span> <span class="affiliation">Oregon State University</span>, <br />
<span class="author">Richard E. Ladner</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Mary Beth  Rosson</span> <span class="affiliation">Pennsylvania State University</span>, <br />
<span class="author">Janet  Davis</span> <span class="affiliation">Grinnell College</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Broader impacts emerged as a major concern in a recent evaluation of the Division of Computer and Network Systems (CNS) at the U.S. National Science Foundation (NSF).  Evaluators found that the intellectual merit contributions from the CNS investigators were strong, but broader impacts could  (and should) be improved [10]. As a result, a summit was held in Washington, D.C., to clarify and strengthen the broader impacts criteria for computing research [4]. In this SIG meeting, we will discuss the outcomes of this summit, with particular attention to broader impacts in human-computer interaction research. <br /></span></div></div></td>
<td colspan="11" class="session_details" id="S1143_details"><div class="paper" id="si154"><a href="#si154" class="title">Design Community: What does Design Mean for CHI</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span><div class="authors"><span class="author">Scott G Pobiner</span> <span class="affiliation">Parsons the New School for Design</span>, <br />
<span class="author">Carla  Diana</span> <span class="affiliation">Smart Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Each year scholars and practitioners from institutions, organizations, and corporations around the world gather for one week to discuss their work and see the work of others from across the wide range of practices that compose the SIGCHI community. The scale and diversity of this gathering offers an opportunity that is special and only available during the short, intense week. During the conference there is a session dedicated to the discussion of priorities for us as members of a community, and for the community itself as a part of the fabric of SIGCHI. For the Design Community this is a rather complex endeavor because our constituents are and our fellow communities understand the pursuit of design in a variety of ways. But this embodies the valuable asset that our community has become as one part of SIGCHI. So let&#8217;s discuss these topics.</span></div></div></td>
<td colspan="11" class="session_details" id="S1153_details"><div class="sessionChair"><strong>Session Chair: </strong>Manfred Tscheligi (<em>University of Salzburg</em>)</div><div class="paper" id="paper841"><a href="#paper841" class="title">Into the wild: Challenges and opportunities for field trial methods</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979185&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Barry  Brown</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">Stuart  Reeves</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Scott  Sherwood</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Field trials of experimental systems &#8216;in the wild&#8217; have developed into a standard method within HCI - testing new systems with groups of users in relatively unconstrained settings outside of the laboratory. In this paper we discuss methodological challenges in running user trials. Using a &#8216;trial of trials&#8217; we examined the practices of investigators and participants - documenting &#8216;demand characteristics&#8217;, where users adjust their behaviour to fit the expectations of those running the trial, the interdependence of how trials are run and the result they produce, and how trial results can be dependent on the insights of a subset of trial participants. We develop three strategies that researchers can use to leverage these challenges to run better trials. <br /></span></div></div><div class="paper" id="cs139"><a href="#cs139" class="title">Why Context Is Important When Gathering Design Feedback: An E-commerce Case Study</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979651&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Katz</span> <span class="affiliation">eBay, Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sellers on eBay today can use a variety of web page designs to distinguish their items from similar merchandise sold by other sellers. While such inconsistency in information display may lead certain items to be more memorable than others, it was also hypothesized to make it more difficult for buyers to compare items when making a purchase decision.  <br />  <br /> To investigate this hypothesis, eBay gathered user feedback on a more consistent page design using two survey approaches that yielded markedly different results. The first approach involved presenting the new design in isolation, while the second approach involved presenting the new design in the context of a larger task flow. Respondents in the first approach tended to focus on specific design aspects and the inconvenience they might face in acclimating to a new design, whereas respondents in the second approach were better able to appreciate the benefits to overall shopping efficiency.   <br />  <br /> This case study underscores the importance of context when gathering user feedback about designs, especially when such designs are intended to provide more holistic real-world benefits.</span></div></div><div class="paper" id="paper1503"><a href="#paper1503" class="title">When a Little Knowledge isn&#8217;t a Dangerous Thing</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979186&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jacki  O'neill</span> <span class="affiliation">Xerox Research Centre Europe</span>, <br />
<span class="author">David  Martin</span> <span class="affiliation">Xerox Research Centre Europe</span>, <br />
<span class="author">Tommaso  Colombino</span> <span class="affiliation">Xerox Research Centre Europe</span>, <br />
<span class="author">Antonietta  Grasso</span> <span class="affiliation">Xerox Research Centre Europe</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we compare two departments of a public administration body carrying out similar work. In one department two sections, telephony and processing, are collocated whereas in the other they are not. We demonstrate the costs of distribution, in particular how the strictly enforced division of labour and limited visibility onto the workflow of the other section causes problems when dealing with normal, natural exceptions. The setting is one of seemingly routine bureaucratic work rather than high-skilled cooperative work, thus the impact of distribution might be considered rather surprising. We argue that a key requirement for any solution is to enable practitioners on the &#8216;shop floor&#8217; the freedom to find elegant solutions to problems.</span></div></div><div class="paper" id="paper1749"><a href="#paper1749" class="title">Field Trial of Tiramisu: Crowd-Sourcing Bus Arrival Times to Spur Co-Design</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979187&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">John  Zimmerman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Anthony  Tomasic</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Charles  Garrod</span> <span class="affiliation">Swarthmore</span>, <br />
<span class="author">Daisy  Yoo</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Chaya  Hiruncharoenvate</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Rafae  Aziz</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Nikhil  Thirunevgadam</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Yun  Huang</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Aaron  Steinfeld</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crowd-sourcing social computing systems represent a new material for HCI designers. However, these systems are difficult to work with and to prototype, because they require a critical mass of participants to investigate social behavior. Service design is an emerging research area that focuses on how customers co-produce the services that they use, and thus it appears to be a great domain to apply this new material. To investigate this relationship, we developed Tiramisu, a transit information system where commuters share GPS traces and submit problem reports. Tiramisu processes incoming traces and generates real-time arrival time predictions for buses. We conducted a field trial with 28 participants. In this paper we report on the results and reflect on the use of field trials to evaluate crowd-sourcing prototypes and on how crowd sourcing can generate co-production between citizens and public services.</span></div></div></td>
<td colspan="11" class="session_details" id="S1158_details"><div class="sessionChair"><strong>Session Chair: </strong>Erik Stolterman (<em>Indiana University</em>)</div><div class="paper" id="paper914"><a href="#paper914" class="title">Evaluating Longitudinal Projects Combining Technology with Temporal Arts</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979209&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Celine  Latulipe</span> <span class="affiliation">University of North Carolina, Charlotte</span>, <br />
<span class="author">Erin A Carroll</span> <span class="affiliation">University of North Carolina, Charlotte</span>, <br />
<span class="author">Danielle  Lottridge</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The integration of interactive technology with temporal art such as dance is an exciting, emerging area. The design space for such collaborations is immense, with variations in sensors, visualizations, and how these interact with dancers and choreography.  This paper presents the evaluation methodology and results of Dance.Draw, a longitudinal project spanning two years and three productions, which aimed to develop a deep, interdisciplinary understanding of this space.  Given that this is pioneering work, there is little guidance on how to evaluate such collaborations. We describe the significant confounds in doing evaluation in this area, and we present our evolving mixed-methods approach, which includes two unique methods to address the multiple stakeholders in a holistic manner: dancer focus groups and repeated presentations. Our approach has generated insights, such as differing perspectives of audience members and the responses of dancers to technological variables. We conclude by discussing the challenges and successes of our evaluation approach.</span></div></div><div class="paper" id="paper741"><a href="#paper741" class="title">Love, Hate, Arousal and Engagement: Exploring Audience Responses to Performing Arts</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979210&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Celine  Latulipe</span> <span class="affiliation">University of North Carolina, Charlotte</span>, <br />
<span class="author">Erin A Carroll</span> <span class="affiliation">University of North Carolina, Charlotte</span>, <br />
<span class="author">Danielle  Lottridge</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Understanding audience responses to art and performance is a challenge. New sensors are promising for measurement of implicit and explicit audience engagement. However, the meaning of biometric data, and its relationship to engagement, is unclear. We conceptually explore the audience engagement domain to uncover opportunities and challenges in the assessment and interpretation of audience engagement data. We developed a display that linked performance videos with audience biometric data and presented it to 7 performing arts experts, to explore the measurement, interpretation and application of biometric data. Experts were intrigued by the response data and reflective in interpreting it. We deepened our inquiry with an empirical study with 49 participants who watched a video of a dance performance. We related temporal galvanic skin response (GSR) data to two self-report scales, which provided insights on interpreting this measure. Our findings, which include strong correlations, support the interpretation of GSR as a valid representation of audience engagement.</span></div></div><div class="paper" id="paper1063"><a href="#paper1063" class="title">Designing from within: humanaquarium</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979211&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Guy  Schofield</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Jayne  Wallace</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Pierre  Boulanger</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an experience-based approach to designing a collaborative interactive performance, humanaquarium. Our research explores public interaction with digital technology through the practice-based inquiry of an inter-disciplinary team of interaction designers and musicians. We present a method of designing experience from within, literally situating ourselves within the performance/use space and assuming the roles both of performers and of designers as we develop and refine the humanaquarium project over the course of a year&#8217;s worth of public performances.</span></div></div></td>
<td colspan="11" class="session_details" id="S1152_details"><div class="sessionChair"><strong>Session Chair: </strong>Shumin Zhai (<em>IBM Research</em>)</div><div class="paper" id="paper262"><a href="#paper262" class="title">Fitts&#8217; Law as an Explicit Time/Error Trade-Off</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979179&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yves  Guiard</span> <span class="affiliation">LTCI CNRS  - Telecom ParisTech</span>, <br />
<span class="author">Halla B Olafsdottir</span> <span class="affiliation">LTCI CNRS  - Telecom ParisTech</span>, <br />
<span class="author">Simon T Perrault</span> <span class="affiliation">LTCI CNRS  - Telecom ParisTech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The widely-held view that Fitts' law expresses a speed/accuracy trade-off is presumably correct, but it is vague. We outline a simple resource-allocation theory of Fitts&#8217; law in which movement time and error trade for each other. The theory accounts quite accurately for the data of Fitts&#8217; (1954) seminal study, as well as some fresh data of our own. In both data sets we found the time/error trade-off to obey a power law. Our data, which we could analyze more thoroughly than Fitts&#8217;, are consistent with a square-root function with a single adjustable constant. We suggest that the resource-allocation framework should help combine information and energy considerations to allow a more complete account of Fitts' law.</span></div></div><div class="paper" id="paper596"><a href="#paper596" class="title">Benchmarking Pointing Techniques with Distractors: Adding a Density Factor to Fitts' Pointing Paradigm</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979180&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Renaud  Blanch</span> <span class="affiliation">UJF-Grenoble 1</span>, <br />
<span class="author">Michael  Ortega</span> <span class="affiliation">CNRS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Fitts' pointing paradigm is widely used to conduct controlled experiments and to evaluate new interaction techniques enhancing target acquisition. <br /> Many of them change the behavior of the cursor according to various inputs, most notably the positions of potential targets. <br /> We propose to extend Fitts' paradigm in order to challenge those techniques with distractors (i.e., potential targets which are not the goal of the user) in a controlled manner. <br /> To reduce variability, we add a single new factor to the paradigm, the distractor density. <br /> We specify a distractors distribution, fully determined by this factor together with those of Fitts' task, aimed at reducing bias toward a specific technique. <br /> We also propose a preliminary extension of Fitts' law to take account of the sensitivity to the density of distractors as well as of the task difficulty. <br /> In an experiment, we compare five existing pointing techniques, and show that this extended protocol enables contrasted comparisons between them.</span></div></div><div class="paper" id="paper430"><a href="#paper430" class="title">The Effects of Task Dimensionality, Endpoint Deviation, Throughput Calculation, and Experiment Design on Pointing Measures and Models</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979181&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Kristen  Shinohara</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alex  Jansen</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Fitts&#8217; law (1954) characterizes pointing speed-accuracy performance as throughput, whose invariance to target distances (A) and sizes (W) is known. However, it is unknown whether throughput and Fitts&#8217; law models in general are invariant to task dimensionality (1-D vs. 2-D), whether univariate (SDx) or bivariate (SDx,y) endpoint deviation is used, whether throughput is calculated using the mean-of-means approach or the slope-inverse approach, or whether Guiard&#8217;s (2009) Form &#215; Scale experiment design is used instead of fully crossed A&#215;W factors. We empirically investigate the confluence of these issues, finding that Fitts&#8217; law is largely invariant across 1-D and 2-D, provided that univariate endpoint deviation (SDx) is used in both, but that for 2-D pointing data, bivariate endpoint deviation (SDx,y) results in better Fitts&#8217; law models. Also, the mean-of-means throughput calculation exhibits lower variance across subjects and dimensionalities than the slope-inverse calculation. In light of these and other findings, we offer recommendations for pointing evaluations, especially in 2-D. We also offer an evaluation tool called FittsStudy to facilitate comparisons.</span></div></div><div class="paper" id="paper257"><a href="#paper257" class="title">The Effects of Intended Use on Target Acquisition</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979182&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Regan L Mandryk</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Calvin  Lough</span> <span class="affiliation">University of Saskatchewan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Fitts&#8217;s Law has been used extensively in HCI to describe 2D targeting; however, the controlled tasks generally used neglect aspects of real-world pointing, including how the intended use of a target affects its acquisition. We studied aiming to a target in four tasks requiring varying precision after acquisition. Our results present the first evidence that the intended use of a target affects its acquisition in terms of movement time and motion kinematics for computer aiming. Important for researchers who model 2D targeting, our results also have particular impact for HCI research that uses motion kinematics.</span></div></div><div class="paper" id="paper509"><a href="#paper509" class="title">Modeling and Predicting Pointing Errors in Two Dimensions</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979183&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alex  Jansen</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Kristen  Shinohara</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recently, Wobbrock et al. (2008) derived a predictive model of pointing accuracy to complement Fitts&#8217; law&#8217;s predictive model of pointing speed. However, their model was based on one-dimensional (1-D) horizontal movement, while applications of such a model require two dimensions (2-D). In this paper, the pointing error model is investigated for 2-D pointing in a study of 21 participants performing a time-matching task on the ISO 9241-9 ring-of-circles layout. Results show that the pointing error model holds well in 2-D. If univariate endpoint deviation (SDx) is used, regressing on N=72 observed vs. predicted error rate points yields R^2=.953. If bivariate endpoint deviation (SDx,y) is used, regression yields R^2=.936. For both univariate and bivariate models, the magnitudes of observed and predicted error rates are comparable.</span></div></div></td>
<td colspan="11" class="session_details" id="S1156_details"><div class="sessionChair"><strong>Session Chair: </strong>Si&#802;n Lindley (<em>Microsoft Research</em>)</div><div class="paper" id="paper1213"><a href="#paper1213" class="title">The Photostroller: Supporting Diverse Care Home Residents in Engaging with the World</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979198&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">William  Gaver</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Andy  Boucher</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">John  Bowers</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Mark  Blythe</span> <span class="affiliation">Northumbria University</span>, <br />
<span class="author">Nadine  Jarvis</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">David  Cameron</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Tobie  Kerridge</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Alex  Wilkie</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Robert  Phillips</span> <span class="affiliation">Goldsmiths, University of London</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The Photostroller is a device designed for use by residents of a care home for older people. It shows a continuous slideshow of photographs retrieved from the Flickr&#8482; image website using a set of six predefined categories modified by a tuneable degree of &#8216;semantic drift&#8217;. In this paper, we describe the design process that led to the Photostroller, and summarise observations made during a deployment in the care home that has lasted over two months at the time of writing. We suggest that the Photostroller balances constraint with openness, and control with drift, to provide an effective resource for the ludic engagement of a diverse group of older people with each other and the world outside their home.</span></div></div><div class="paper" id="paper1728"><a href="#paper1728" class="title">Automics: souvenir generating photoware for theme parks</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979199&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abigail  Durrant</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Duncan  Rowland</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">David S Kirk</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Steve  Benford</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Joel E Fischer</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Derek  McAuley</span> <span class="affiliation">University of Nottingham</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Automics is a photo-souvenir service which utilises mobile devices to support the capture, sharing and annotation of digital images amongst groups of visitors to theme parks. The prototype service mixes individual and group photo-capture with existing in-park, on-ride photo services, to allow users to create printed photo-stories. Herein we discuss initial fieldwork in theme parks that grounded the design of Automics, our development of the service prototype, and its real-world evaluation with theme park visitors. We relate our findings on user experience of the service to a literature on mobile photoware, finding implications for the design of souvenir services.</span></div></div><div class="paper" id="paper301"><a href="#paper301" class="title">Contextual Dynamics of Group-Based Sharing Decisions</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979200&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Simon  Jones</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Eamonn  O'Neill</span> <span class="affiliation">University of Bath</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we investigate how decisions made while using a granular access control mechanism for sharing photographs are influenced by contextual factors and properties relating to the identities of contacts. We develop analytical models using logistic regression to understand relationships between variables that affect sharing decisions. We also investigate how predefined, static groups for privacy control cope with the challenge of sharing large amounts of content associated with numerous different contexts, and test whether they need to be adjusted to suit particular contexts.</span></div></div><div class="paper" id="paper776"><a href="#paper776" class="title">Pass-Them-Around: Collaborative Use of Mobile Phones for Photo Sharing</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979201&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andr&#233;s  Lucero</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Jussi  Holopainen</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Tero  Jokela</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we explore shared collocated interactions with mobile phones. We introduce a phone-based application that allows a small group of collocated people to share photos using the metaphor of passing paper photos around. The prototype encourages people to share their devices and use them interchangeably while discussing photos face-to-face. The prototype supports ad-hoc photo sharing in different contexts by taking into account the spatial arrangement of users around a table, measured with sensors embedded in their mobile phones. Our evaluations show that people are willing to share and connect their mobile phones to engage in collaborative interactions. Participants were able to easily share their collections of photos using our proposed interaction techniques.</span></div></div></td>
<td colspan="11" class="session_details" id="S1157_details"><div class="sessionChair"><strong>Session Chair: </strong>Mira Dontcheva (<em>Advanced Technologies Lab Adobe Systems</em>)</div><div class="paper" id="paper265"><a href="#paper265" class="title">ClassSearch: Facilitating the Development of Web Search Skills through Social Learning</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979203&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Neema  Moraveji</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Meredith  Morris</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Daniel  Morris</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Mary  Czerwinski</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Nathalie  Henry Riche</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We explore the use of social learning &#8211; improving knowledge skills by observing peer behavior &#8211; in the do- main of Web search skill acquisition, focusing specifically on co-located classroom scenarios. Through a series of in- terviews, pilot studies, and classroom deployments, we conclude that a peripheral display of Web search activity within a classroom facilitates both social learning and teacher-led discourse. We present the ClassSearch system for shared awareness of Web search activity, which embod- ies principles gleaned from our iterative design process, and show results from a ClassSearch deployment in twelve middle-school classroom sessions. Finally, we highlight design suggestions and opportunities for future work while taxonomizing the space of co-located search pedagogies.</span></div></div><div class="paper" id="paper1878"><a href="#paper1878" class="title">Role of Available and Provided Resources in Sensemaking</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979204&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nikhil  Sharma</span> <span class="affiliation">University of Pittsburgh</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Making sense of a topic often involves appropriating information and organizing themes from various existing resources. We studied how sensemakers appropriated from available online resources as well as artifacts provided by another person directly. We found that both available and provided resources affect sensemaking activities. Sensemakers added more structure in their work when online resources were easily available, but added less structure and information when they were provided relevant sensemaking artifacts from another person. We also studied how early and mature artifacts provided by another person were appropriated differently and found that mature artifacts were rated better and used more but resulted in lesser structure and information being added by the recipient. These findings have implications for the support of sensemaking activities using resources available online as well as artifacts provided by others including co-workers and friends.</span></div></div><div class="paper" id="paper1058"><a href="#paper1058" class="title">Characterizing the Usability of Interactive Applications Through Query Log Analysis</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979205&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Adam  Fourney</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Richard  Mann</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Michael  Terry</span> <span class="affiliation">University of Waterloo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">People routinely rely on Internet search engines to support their use of interactive systems: they issue queries to learn how to accomplish tasks, troubleshoot problems, and otherwise educate themselves on products. Given this common behavior, we argue that search query logs can usefully augment traditional usability methods by revealing the primary tasks and needs of a product's user population. We term this use of search query logs CUTS -- characterizing usability through search. In this paper, we introduce CUTS and describe an automated process for harvesting, ordering, labeling, filtering, and grouping search queries related to a given product. Importantly, this data set can be assembled in minutes, is timely, has a high degree of ecological validity, and is arguably less prone to self-selection bias than data gathered via traditional usability methods. We demonstrate the utility of this approach by applying it to a number of popular software and hardware systems.</span></div></div><div class="paper" id="paper2117"><a href="#paper2117" class="title">Determining Relevancy: How Software Developers Determine Relevant Information in Feeds</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979206&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Thomas  Fritz</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Gail C. Murphy</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Finding relevant information within the vast amount of information exchanged via feeds is difficult. Previous research into this problem has largely focused on recommending relevant information based on topicality. By not considering individual and situational factors these approaches fall short. Through a formative, interview-based study, we explored how five software developers determined relevancy of items in two kinds of project news feeds. We identified four factors that the developers used to help determine relevancy and found that placement of items in source code and team contexts can ease the determination of relevancy. <br /></span></div></div><div class="paper" id="paper326"><a href="#paper326" class="title">Measuring Web Page Revisitation in Tabbed Browsing</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979207&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Haimo  Zhang</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Shengdong  Zhao</span> <span class="affiliation">National University of Singapore</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Browsing the web has been shown to be a highly recurrent activity. Aimed to optimize the browsing experience, extensive previous research has been carried out on users&#8217; revisitation behavior. However, the conventional definition for revisitation, which only considers page loading activities by monitoring http requests initiated by the browser, largely underestimates users&#8217; intended revisitation activities with tabbed browsers. Thus, we introduce a goal-oriented definition and a refined revisitation measurement based on page viewings in tabbed browsers. An empirical analysis of statistics taken from a client-side log study showed that although the overall revisitation rate remained relatively constant, tabbed browsing has introduced new behaviors warrant future investigations. <br /></span></div></div></td>
<td colspan="11" class="session_details" id="S1151_details"><div class="sessionChair"><strong>Session Chair: </strong>Tomer Moscovich (<em>INRIA</em>)</div><div class="paper" id="paper590"><a href="#paper590" class="title">Rock &amp; Rails: Extending Multi-touch Interactions with Shape Gestures to Enable Precise Spatial Manipulations</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979173&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Wigdor</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">John  Pella</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Jarrod  Lombardo</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Sarah  Williams</span> <span class="affiliation">Microsoft</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Direct touch manipulations enable the user to interact with the on-screen content in a direct and easy manner closely mimicking the spatial manipulations in the physical world. However, they also suffer from well-known issues of precision, occlusion and an inability to isolate different degrees of freedom in spatial manipulations. We present a set of interactions, called Rock &amp; Rails, that augment existing direct touch manipulations with shape-based gestures, thus providing on-demand gain control, occlusion avoidance, and separation of constraints in 2D manipulation tasks. Using shape gestures in combination with direct-manipulations allows us to do this without ambiguity in detection and without resorting to manipulation handles, which break the direct manipulation paradigm. Our set of interactions were evaluated by 8 expert graphic designers and were found to be easy to learn and master, as well as effective in accomplishing a precise graphical layout task.</span></div></div><div class="paper" id="paper414"><a href="#paper414" class="title">Multi-touch Document Folding:  Gesture Models, Fold Directions and Symmetries</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979174&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Patrick  Chiu</span> <span class="affiliation">FX Palo Alto Laboratory</span>, <br />
<span class="author">Chunyuan  Liao</span> <span class="affiliation">FX Palo Alto Laboratory</span>, <br />
<span class="author">Francine  Chen</span> <span class="affiliation">FX Palo Alto Laboratory</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">For document visualization, folding techniques provide a focus-plus-context approach with fairly high legibility on flat sections.  To enable richer interaction, we explore the design space of multi-touch document folding.  We discuss several design considerations for simple modeless gesturing and compatibility with standard Drag and Pinch gestures. We categorize gesture models along the characteristics of Symmetric/Asymmetric and Serial/Parallel, which yields three gesture models.  We built a prototype document workspace application that integrates folding and standard gestures, and a system for testing the gesture models.  A user study was conducted to compare the three models and to analyze the factors of fold direction, target symmetry, and target tolerance in user performance when folding a document to a specific shape.  Our results indicate that all three factors were significant for task times, and parallelism was greater for symmetric targets.</span></div></div><div class="paper" id="paper401"><a href="#paper401" class="title">FingerGlass: Ef&#64257;cient Multiscale Interaction on Multitouch Screens</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979175&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominik P. K&#228;ser</span> <span class="affiliation">University of California, Berkeley / ETH Z&#252;rich / Pixar Animation Studios</span>, <br />
<span class="author">Maneesh  Agrawala</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Mark  Pauly</span> <span class="affiliation">EPFL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many tasks in graphical user interfaces require users to interact with elements at various levels of precision. We present FingerGlass, a bimanual technique designed to improve the precision of graphical tasks on multitouch screens. It enables users to quickly navigate to different locations and across multiple scales of a scene using a single hand. The other hand can simultaneously interact with objects in the scene. Unlike traditional pan-zoom interfaces, FingerGlass retains contextual information during the interaction. We evaluated our technique in the context of precise object selection and translation and found that FingerGlass significantly outperforms three state-of-the-art baseline techniques in both objective and subjective measurements: users acquired and translated targets more than 50% faster than with the second-best technique in our experiment.</span></div></div><div class="paper" id="paper497"><a href="#paper497" class="title">An Interactive Multi-touch Sketching Interface for Diffusion Curves</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979176&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Qian  Sun</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Chi-Wing  Fu</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Ying  He</span> <span class="affiliation">Nanyang Technological University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Diffusion curves are effective 2D vector-graphics primitives, for creating smoothly-shaded drawings with rich colors and unique styles. Conventional drawing systems for diffusion curves often require users to successively layout curve geometry and then specify colors, which is rather tedious for complex drawings. This paper proposes a novel multi-touch sketching interface for efficient design of 2D vector graphics with diffusion curves. In sharp contrast to previous interfaces, we develop a family of multi-touch gestures, allowing users to simultaneously sketch multiple diffusion curves and also to interactively edit and tune curve geometry and colors. Our experiments show that this not only brings novel painting experience to users but also provides a practical and effective tool for vector graphics design, useful for styles like silk painting, Disney cartoon, art poster, and photo-realistic effects. Lastly, we conduct a user study to explore the interface's intuitive and efficient drawing capability with both professional 2D artists and novice users.</span></div></div><div class="paper" id="paper854"><a href="#paper854" class="title">Grids &amp; Guides: Multi-Touch Layout and Alignment Tools</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979177&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathias  Frisch</span> <span class="affiliation">Otto-von-Guericke University Magdeburg</span>, <br />
<span class="author">Sebastian  Kleinau</span> <span class="affiliation">Otto-von-Guericke University Magdeburg</span>, <br />
<span class="author">Ricardo  Langner</span> <span class="affiliation">Otto-von-Guericke University Magdeburg</span>, <br />
<span class="author">Raimund  Dachselt</span> <span class="affiliation">Otto-von-Guericke University Magdeburg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Precise alignment of graphical objects and the creation of accurate layouts are crucial activities in many applications, such as graphics design tools, presentation software or graph editors. Surface computing is very promising for these application domains but not fully explored yet. In this paper we contribute two tools which support layout tasks on interactive displays: interactive grids and multi-touch alignment guides. Both tools allow the precise positioning of graphical objects in a flexible and fluent way by multi-touch input. Direct bimanual interaction and physical metaphors are applied to arrange objects along straight lines and curves. A formative user evaluation showed promising results with regard to a productive and easy use of the tools.</span></div></div></td>
<td colspan="11" class="session_details" id="S1154_details"><div class="sessionChair"><strong>Session Chair: </strong>Phoebe Sengers (<em>Cornell University</em>)</div><div class="paper" id="paper1142"><a href="#paper1142" class="title">Publics in Practice: Ubiquitous Computing at a Shelter for Homeless Mothers</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979189&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christopher A. Le Dantec</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Robert G. Farrell</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Jim E. Christensen</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Mark  Bailey</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Jason B. Ellis</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Wendy A. Kellogg</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">W. Keith Edwards</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Today, commodity technologies like mobile phones&#8212;once symbols of status and wealth&#8212;have become deeply woven into social and economic participation in Western society. Despite the pervasiveness of these technologies, there re- main groups who may not have extensive access to them but who are nonetheless deeply affected by their presence in everyday life. In light of this, we designed, built, and de- ployed a ubiquitous computing system for one such over- looked group: the staff and residents at a shelter for homeless mothers. Our system connects mobile phones, a shared display, and a Web application to help staff and resi- dents stay connected. We report on the adoption and use of this system over the course of a 30 week deployment, dis- cussing the substantial impact our system had on shelter life and the broader implications for such socio-technical sys- tems that sit at the juncture of social action and organiza- tional coordination.</span></div></div><div class="paper" id="paper392"><a href="#paper392" class="title">Homeless Young People and Living with Personal Digital Artifacts</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979190&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jill P. Woelfer</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">David G. Hendry</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports on an investigation of how homeless young people hold themselves in relation to personal digital artifacts. Twelve participants, aged 19-29, took part in semi-structured interviews. Participants answered questions about the acquisition and disposition of personal artifacts, digital and non-digital, including mobile phones, music players, and wallets. The analysis of the interview transcripts reveals that young people often part with their digital artifacts in order to meet immediate needs, including the need to create and reciprocate goodwill. This contingent holding of personal artifacts illuminates both the ordinary and extraordinary circumstances of homelessness. The paper concludes with a discussion of constraints and implications for the design of information systems for improving the welfare of homeless young people.</span></div></div><div class="paper" id="paper393"><a href="#paper393" class="title">Improving the Safety of Homeless Young People with Mobile Phones: Values, Form and Function</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979191&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jill P. Woelfer</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Amy  Iverson</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">David G. Hendry</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Batya  Friedman</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Brian T. Gill</span> <span class="affiliation">Seattle Pacific University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">By their pervasiveness and by being worn on our bodies, mobile phones seem to have become intrinsic to safety. To examine this proposition, 43 participants, from four stakeholder groups (homeless young people, service providers, police officers, and community members), were asked to consider how homeless young people could use mobile phones to keep safe. Participants were asked to express their knowledge for place-based safety and to envision how mobile phones might be used to improve safety. Detailed analysis of the resulting data, which included value sketches, written value scenarios, and semi-structured discussion, led to specific design opportunities, related to values (e.g., supporting trust and desire to help others), function (e.g., documenting harms for future purposes), and form (e.g., leveraging social expectations for how mobile phones can be used to influence behavior). Together, these findings bound a design space for how mobile phones can be used to manage unsafe situations.</span></div></div></td>
<td colspan="11" class="session_details" id="S1145_details"><div class="paper" id="pl104"><a href="#pl104" class="title">RepliCHI - Should CHI be Replicating and Validating Research Results More?</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979491&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Max L. Wilson</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Wendy  Mackay</span> <span class="affiliation">INRIA and Stanford University</span>, <br />
<span class="author">Ed  Chi</span> <span class="affiliation">Palo Alto Research Center</span>, <br />
<span class="author">Michael  Bernstein</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Dan  Russell</span> <span class="affiliation">Google</span>, <br />
<span class="author">Harold  Thimbleby</span> <span class="affiliation">Swansea University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The replication of research findings is a cornerstone of good science. Replication confirms results, strengthens research, and makes sure progress is based on solid foundations. CHI, however, rewards novelty and is focused on new results. As a community, therefore, we do not value, facilitate, or reward replication in research, and often take the significant results of a single user study on 20 users to be true. This panel will address the issues surrounding replication in our community, and discuss: a) how much of our broad diverse discipline is &#8216;science&#8217;, b) how, if at all, we currently see replication of research in our community, c) whether we should place more emphasis on replication in some form, and d) how that should look in our community. The aim of the panel is to make a proposal to future CHI organizers (2 are on the panel) for how we should facilitate replication in the future.</span></div></div></td>
<td colspan="11" class="session_details" id="S1155_details"><div class="sessionChair"><strong>Session Chair: </strong>Jeffrey Heer (<em>Stanford University</em>)</div><div class="paper" id="paper1257"><a href="#paper1257" class="title">Playable Data: Characterizing the Design Space of Game-y Infographics</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979193&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicholas  Diakopoulos</span> <span class="affiliation">Rutgers University</span>, <br />
<span class="author">Funda  Kivran-Swaine</span> <span class="affiliation">Rutgers University</span>, <br />
<span class="author">Mor  Naaman</span> <span class="affiliation">Rutgers University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This work explores the intersection between infographics and games by examining how to embed meaningful visual analytic interactions into game mechanics that in turn impact user behavior around a data-driven graphic. In contrast to other methods of narrative visualization, games provide an alternate method for structuring a story, not bound by a linear arrangement but still providing structure via rules, goals, and mechanics of play. We designed two different versions of a game-y infographic, Salubrious Nation, and compared them to a non-game-y version in an online experiment. We assessed the relative merits of the game-y approach of presentation in terms of exploration of the visualization, insights and learning, and enjoyment of the experience. Based on our results, we discuss some of the benefits and drawbacks of our designs. More generally, we identify challenges and opportunities for further exploration of this new design space.</span></div></div><div class="paper" id="paper506"><a href="#paper506" class="title">Cardiogram: Visual Analytics for Automotive Engineers</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979194&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Sedlmair</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Petra  Isenberg</span> <span class="affiliation">INRIA</span>, <br />
<span class="author">Dominikus  Baur</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Michael  Mauerer</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Christian  Pigorsch</span> <span class="affiliation">BMW Group</span>, <br />
<span class="author">Andreas  Butz</span> <span class="affiliation">University of Munich</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present Cardiogram, a visual analytics system that supports automotive engineers in debugging masses of traces each consisting of millions of recorded messages from in-car communication networks. With their increasing complexity, ensuring these safety-critical networks to be error-free has become a major task and challenge for automotive engineers. To overcome shortcomings of current analysis tools, Cardiogram combines visualization techniques with a data preprocessing approach to automatically reduce complexity based on engineers' domain knowledge.   <br /> In this paper, we provide the findings from an exploratory, three-year field study within a large automotive company, studying current practices of engineers, the challenges they meet and the characteristics for integrating novel visual analytics tools into their work practices.  <br /> We then introduce Cardiogram, discuss how our field analysis influenced our design decisions, and present a qualitative, long-term, in-depth evaluation. Results of this study showed that our participants successfully used Cardiogram to increase the amount of analyzable information, to externalize domain knowledge, and to provide new insights into trace data. Our design approach finally led to the adoption of Cardiogram into engineers' daily practices.</span></div></div><div class="paper" id="paper1679"><a href="#paper1679" class="title">KronoMiner: Using Multi-Foci Navigation for the Visual Exploration of Time-Series Data</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979195&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jian  Zhao</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Fanny  Chevalier</span> <span class="affiliation">Ontario College of Art &amp; Design University</span>, <br />
<span class="author">Ravin  Balakrishnan</span> <span class="affiliation">University of Toronto</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The need for pattern discovery in long time-series data led researchers to develop interactive visualization tools and analytical algorithms for gaining insight into the data. Most of the literature on time-series data visualization either focus on a small number of tasks or a specific domain. We propose KronoMiner, a tool that embeds new interaction and visualization techniques as well as analytical capabilities for the visual exploration of time-series data. The interface's design has been iteratively refined based on feedback from expert users. Qualitative evaluation with an expert user not involved in the design process indicates that our prototype is promising for further research.</span></div></div><div class="paper" id="paper428"><a href="#paper428" class="title">LifeFlow: Visualizing an Overview of Event Sequences</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979196&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Krist  Wongsuphasawat</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">John Alexis  Guerra G&#243;mez</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Catherine  Plaisant</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Taowei David Wang</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Meirav  Taieb-Maimon</span> <span class="affiliation">Ben-Gurion University of the Negev</span>, <br />
<span class="author">Ben  Shneiderman</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Event sequence analysis is an important task in many domains: medical researchers may study the patterns of transfers within the hospital for quality control; transportation experts may study accident response logs to identify best practices. In many cases they deal with thousands of records. While previous research has focused on searching and browsing, overview tasks are often overlooked.  We introduce a novel interactive visual overview of event sequences called LifeFlow.  LifeFlow is scalable, can summarize all possible sequences, and represents the temporal spacing of the events within sequences. Two case studies with healthcare and transportation domain experts are presented to illustrate the usefulness of LifeFlow.  A user study with ten participants confirmed that after 15 minutes of training  novice users were <br /> able to rapidly answer questions about the prevalence and temporal characteristics <br /> of sequences, find anomalies, and gain significant insight from the data.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">17:30<br />-<br />18:30</td>

<td class="session tbd" id="S1159">
<div class="session_box">
<span class="type"></span>
<a href="#S1159" class="title">Job Fair</a>
<span class="location">Ballroom C/D</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1160">
<div class="session_box">
<span class="type">Interactivity &amp; Videos</span>
<a href="#S1160" class="title">Video Night</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S5013">
<div class="session_box">
<span class="type">Interactivity</span>
<a href="#S5013" class="title">Interactivity 2 Open</a>
<span class="location">202/203/204</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="3" class="session_details" id="S1160_details"><div class="paper" id="in139"><a href="#in139" class="title">What Does A Body Know?</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979724&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Bob  Pritchard</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sid  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Nicolas  d'Alessandro</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Marguerite  Witvoet</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Johnty  Wang</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Cameron  Hassall</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Helene  Day-Fraser</span> <span class="affiliation">Emily Carr University of Art and Design</span>, <br />
<span class="author">Meryn  Cadell</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">What Does A Body Know? is a concert work for Digital Ventriloquized Actor (DiVA) and sound clips. A DiVA is a real time gesture-controlled formant-based speech synthesizer using a Cyberglove&#174;, touchglove, and Polhemus Tracker&#174; as the main interfaces. When used in conjunction with the performer&#8217;s own voice solos and &#8220;duets&#8221; can be performed in real time.</span></div></div><div class="paper" id="vi115"><a href="#vi115" class="title">SandCanvas: New Possibilities in Sand Animation</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979562&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rubaiat Habib  Kazi</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Kien Chuan  Chua</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Shengdong  Zhao</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Richard  Davis</span> <span class="affiliation">Singapore Management University</span>, <br />
<span class="author">Kok-Lim  LOW</span> <span class="affiliation">National University of Singapore</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sand animation is a performance art technique in which an artist tells stories by creating animated images with sand. Inspired by this medium, we have developed a new multi-touch digital artistic medium named SandCanvas that simplifies the creation of sand animations. <br /> The elegance of sand animation lies in the seamless flow of expressive hand gestures that cause images to fluidly evolve, surprising and delighting audiences. While physical sand animation already possesses these properties, SandCanvas enhances them. SandCanvas&#8217;s color and texture features enable faster, more dramatic transitions, while its mixed media and gesture recording features make it possible to create entirely new experiences. Session recording and frame capture complement these capabilities by simplifying post-production of sand animation performances. <br /></span></div></div><div class="paper" id="vi119"><a href="#vi119" class="title">Six-Forty by Four-Eighty: An Interactive Lighting Installation</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979564&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jamie  Zigelbaum</span> <span class="affiliation">Zigelbaum + Coelho</span>, <br />
<span class="author">Marcelo  Coelho</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Six-Forty by Four-Eighty is an interactive lighting installation composed of an array of magnetic, physical pixels. Individually, pixel-tiles change their color in response to touch and communicate their state to each other by using a person's body as the conduit for information. When grouped together, the pixel-tiles create patterns and animations that can serve as a tool for customizing our physical spaces.</span></div></div><div class="paper" id="vi126"><a href="#vi126" class="title">Cube-U: Exploring The Combination Of The Internet Of Things And ELearning</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979551&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Muriel  Garreta-Domingo</span> <span class="affiliation">UOC (Open University of Catalonia)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Cube-U is an initial prototype that explores the combination of the Internet of Things (IOT) and eLearning. Following a user-centered design process, the powerful possibilities opened by the Internet of Things (IOT) are being included to eLearning in order to <br /> enhance the learning experience. IOT is a new field based on the connection of common objects to the internet. So far, it has mainly been applied in industrial environments. Introducing IOT in eLearning will allow for the expansion of the virtual learning experience, <br /> currently mostly centered around a computer and paper.  <br /></span></div></div><div class="paper" id="vi117"><a href="#vi117" class="title">Layered Elaboration</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979556&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Greg  Walsh</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Allison  Druin</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Mona Leigh  Guha</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Elizabeth  Foss</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Evan  Golub</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Leshell  Hatley</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Elizabeth  Bonsignore</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Sonia  Franckel</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this video we describe Layered Elaboration techniques and their use in the cooperative inquiry method.</span></div></div><div class="paper" id="vi104"><a href="#vi104" class="title">PeR: designing for perceptive qualities</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979559&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eva  Deckers</span> <span class="affiliation">Eindhoven University of Technology, Department of Industrial Design</span>, <br />
<span class="author">Stephan  Wensveen</span> <span class="affiliation">Eindhoven University of Technology, Department of Industrial Design</span>, <br />
<span class="author">Kees  Overbeeke</span> <span class="affiliation">Eindhoven University of Technology, Department of Industrial Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this video we show PeR, short for &#8216;Perception Rug&#8217;. The design is created as part of our research on how to design for perceptive qualities in objects. This research is conducted around the educational and research theme &#8216;Wearable Senses&#8217; and has a theoretical departure in the &#8216;phenomenology of perception&#8217; and &#8216;ecological psychology&#8217;. The integration of conductive and optic fibers, respectively enable PeR to sense the touch of a person and to let a body of light behave within the surface of the rug. The design can be used as a platform for the exploration of perceptive behavior. Different design characteristics, like the size of the light body, the speed by which the body moves, its shape, focus and direction, can be adjusted in order to design behavior.</span></div></div><div class="paper" id="vi106"><a href="#vi106" class="title">Reactive Wall (RWal)</a>&nbsp;-&nbsp;<span class="type">Videos</span><div class="authors"><span class="author">Nivedhitha  Giri</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Anthony  Threatt</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Ian D. Walker</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Keith Evan Green</span> <span class="affiliation">Clemson University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This video features a scaled prototype of RWal (Reactive Wall) that was built based upon the floor plan of Hilton San Francisco Union Sq. Continental Ballroom. The RWal is a continuum surface intelligent system that is commissioned in a conference area. It can sense occupancy in different session areas and change its shape dynamically so that it provides more space for a session that is crowded at the expense of reducing the room space for a session that is sparsely populated. Temperature sensors are used to monitor occupancy and the walls are manipulated by tendons driven by servo motors and controlled by an Arduino ATMega328 microcontroller. The wall is actuated (actively and passively) at different points and is designed in such a way that it encloses a constant volume space. The key idea is to manage the available floor area to prevent congestion.  This will be a practical option in any conference where there are typically boring as well as interesting speakers and an unavoidable movement of attendees from one session to another.</span></div></div><div class="paper" id="vi111"><a href="#vi111" class="title">Why Buttons Go Bad</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979565&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Philipp  Hund</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Lucy  Hughes</span> <span class="affiliation">University College London</span>, <br />
<span class="author">alistair  wood</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Jesper  Garde</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Tianbo  Xu</span> <span class="affiliation">University College London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This video explains in 100 seconds the importance of studying how humans interact with technology. The idea revolves around the evolution of the button and proposes that the design of modern buttons can go wrong when user-centered design is neglected. This was a winning video developed by five MSc students at the UCL Interaction Centre (UCLIC). It was produced as part of a public engagement challenge: to make a digital story that explains what HCI is to young adults. The roles within the video are intentionally caricatured to simplify its message. The video has been used to promote HCI to a wider audience and mark World Usability Day 2010.</span></div></div><div class="paper" id="vi105"><a href="#vi105" class="title">Microwave Racing</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979558&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominic  Furniss</span> <span class="affiliation">University College London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This video engages a broad audience through the theme of 'Microwave Racing' - a title aimed to intrigue. The film is a fun take on a usability testing scenario where four users/riders have to use a microwave for a simple task, and they race against each other. However, there is a serious point which challenges the audience: if we struggle to design for simple everyday things then what about more serious things like medical devices. We think this could challenge a CHI audience and might sit nicely between videos on the latest entertainment and interaction techniques - for juxtaposition. It is a reminder that there is important work to be done in the healthcare domain and that safety-critical HCI can save lives.</span></div></div><div class="paper" id="vi107"><a href="#vi107" class="title">EasyPointer:  What You Pointing at is What You Get</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979553&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gang  Pan</span> <span class="affiliation">Zhejiang University</span>, <br />
<span class="author">Haoyi  Ren</span> <span class="affiliation">Zhejiang University</span>, <br />
<span class="author">Weidong  Hua</span> <span class="affiliation">Zhejiang University</span>, <br />
<span class="author">Qian  Zheng</span> <span class="affiliation">Zhejiang University</span>, <br />
<span class="author">Shijian  Li</span> <span class="affiliation">Zhejiang University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This extended abstract presents a natural pointing system using gyroscope MEMS, which could achieve what you pointing at is what you get. It enables screen interaction via physical pointing. The system only needs a phone with built-in gyroscope, camera, and wireless communication, e.g. Wi-Fi and Bluetooth, without any other hardware. To achieve sensing of the screen position where user is physically pointing, we also develop easy calibration methods. The prototype system, called EasyPointer, is built upon iPhone 4/iPod 4. It can serve as a laser pointer, a presentation controller, a game controller, and a drawing pen.</span></div></div><div class="paper" id="vi130"><a href="#vi130" class="title">Interactive Snow Sculpture Painting</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979555&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">J&#252;rgen  Scheible</span> <span class="affiliation">Aalto University, School of Art and Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This video shows the live-painting of snow sculptures with dabs of digital paint, deploying a mobile phone (virtual spray can) with accelerometer, a PC and a video projector - creating 100% recyclable art. The technology used is called MobiSpray, which has been reported by the author at SIGGRAPH 2009 in the Art papers track. Using a mobile phone in this context allows the painter to roam freely (walk, stand, lie) around the target object, far or near in real physical space, while looking directly at its surface to see how the painting appears in real time. The phone&#8217;s keyboard keys are used for controlling the drawing tools such as spraying colors or spraying intensity.</span></div></div><div class="paper" id="vi124"><a href="#vi124" class="title">Scenario-Based Persona: Introducing Personas Through Their Main Contexts</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979563&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alicia  Valls-Saez</span> <span class="affiliation">UOC (Open University of Catalonia).</span>, <br />
<span class="author">Muriel  Garreta-Domingo</span> <span class="affiliation">UOC (Open University of Catalonia).</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The present work introduces a new way of conveying the results of a user analysis study. Personas are a well established user-centered design methodology; however they are not always well-understood or used by non-experts. By explaining our personas based on their main contexts we wanted to 1) reduce the bias that a face can generate by representing silhouettes instead; 2) combine the concepts of personas and scenarios; 3) foster understanding of our users by showing their main contexts (which are becoming more important with the increase of mobile devices); and 4) create a playful and more permanent artefact to hold all this information.</span></div></div><div class="paper" id="vi114"><a href="#vi114" class="title">LifeFlow: Visualizing an Overview of Event Sequences (Video Preview)</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979557&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Krist  Wongsuphasawat</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">John Alexis  Guerra G&#243;mez</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Catherine  Plaisant</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Taowei  Wang</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Meirav  Taieb-Maimon</span> <span class="affiliation">Ben-Gurion University of the Negev</span>, <br />
<span class="author">Ben  Shneiderman</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Event sequence analysis is an important task in many domains: medical researchers may study the patterns of transfers within the hospital for quality control; transportation experts may study accident response logs to identify best practices. In many cases they deal with thousands of records. While previous research has focused on searching and browsing, overview tasks are often overlooked. We introduce a novel interactive visual overview of event sequences called LifeFlow.  LifeFlow is scalable, can summarize all possible sequences, and represents the temporal spacing of the events within sequences. In this video, we show an example of patient transfer data and briefly demonstrate how to analyze them with LifeFlow. Please see our presentation on Tues 1600-1720 in the Visual Analytics session and http://www.cs.umd.edu/hcil/lifeflow for more detail.</span></div></div><div class="paper" id="vi132"><a href="#vi132" class="title">SAMM: Driving Asistance System for the Senior Citizen</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979561&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">V&#237;ctor M Gonz&#225;lez</span> <span class="affiliation">ITAM</span>, <br />
<span class="author">Roberto  Lapuente Romo</span> <span class="affiliation">ITAM</span>, <br />
<span class="author">Luis Eduardo  P&#233;rez Estrada</span> <span class="affiliation">ITAM</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Within a frame of possible ubiquitous urban applications this research explores ways to support the mobility of senior citizens in vehicles by finding efficient routes to reach their destination and managing their time. Our solution is called SAMM and operates following a context-aware and crowdsourcing model where data used by the system to optimize routes is both, taken from user&#8217;s agenda and received from other users in real time. This allows older adults to optimize their trips by doing several things without leaving a main route, and to be aware of traffic jams long before other media report it. It is expected that a ubiquitous urban application like SAMM will be of great benefit for elderly people by increasing trip efficiency and avoiding the problems associated with spending excessive time sitting in a vehicle as well as encouraging them to take an active and independent role in society.</span></div></div><div class="paper" id="vi118"><a href="#vi118" class="title">Don't Touch: Social Appropriateness of Touch Sensor Placement on Interactive Lumalive E-Textime Shirts</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979552&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sylvia  Cheng</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Connor  Dickie</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Andreas  Hanewich-Hollatz</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Justin  Lee</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this video, we discuss the design of an e-textile shirt with an interactive Lumalive display featuring a touch- controlled image browser. To determine where to place touch sensors, we investigated which areas of the Lumalive shirt users would be comfortable touching or being touched based on how often participants would opt out of touches. For both touchers and touchees, opt-outs occurred mostly in the upper chest. On the front, the upper chest and lower abdominal zones were the least comfortable. Findings suggest participants were less comfortable with touches on the upper chest, the lower abdomen, and the lower back. We conclude that the most appropriate areas for touch sensors on a shirt are on the arms, shoulders, and upper back.</span></div></div><div class="paper" id="vi129"><a href="#vi129" class="title">Energy House</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979554&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Greg  Walsh</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Allison  Druin</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Elizabeth  Foss</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Evan  Golub</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Mona Leigh  Guha</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Leshell  Hatley</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Elizabeth  Bonsignore</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this video we describe Energy House. Energy House is a game designed with the Cooperative Inquiry Method through the Layered Elaboration technique. Children power items in a virtual house by jumping up and down.</span></div></div><div class="paper" id="vi109"><a href="#vi109" class="title">BiebBeep: An interactive screen for supporting public Library 2.0 information and social services</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979550&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marije  Kanis</span> <span class="affiliation">Amsterdam University of Applied Sciences</span>, <br />
<span class="author">Wouter  Meys</span> <span class="affiliation">Amsterdam University of Applied Sciences</span>, <br />
<span class="author">Mettina  Veenstra</span> <span class="affiliation">Amsterdam University of Applied Sciences</span>, <br />
<span class="author">Maarten  Groen</span> <span class="affiliation">Amsterdam University of Applied Sciences, Novay</span>, <br />
<span class="author">Wout  Slakhorst</span> <span class="affiliation">Novay</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This video presents BiebBeep, an interactive <br /> touchscreen system that has been developed with the <br /> aim to support information and social services for the <br /> New Library in Almere, The Netherlands. The constantly <br /> updated information displayed on the interactive screen <br /> concerns not only the library itself, but also features <br /> happenings in the local area. The system's distinctive <br /> feature is that people can add information to the screen <br /> themselves, such as tweets, photos, local and cultural <br /> news announcements, so that the library and its <br /> visitors can inform and connect with each other. Over <br /> the course of almost one year, several studies were <br /> conducted, including focus group, interview- and <br /> observation-based studies that have motivated the <br /> functionality, and particularly the user-generated and <br /> localized content the system supports. Consequently, <br /> the services and functionality the system offers are <br /> aimed towards supporting Library 2.0, the next <br /> generation library.</span></div></div><div class="paper" id="vi120"><a href="#vi120" class="title">Accessible Voting: One Machine, One Vote for Everyone</a>&nbsp;-&nbsp;<span class="type">Videos</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979549&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Juan E. Gilbert</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Joshua I. Ekandem</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Shelby S. Darnell</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Hanan  Alnizami</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Aqueasha M. Martin</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Wanda  Johnson</span> <span class="affiliation">Clemson University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The video for Accessible Voting shows a novel technology that allows private and secure voting to people with disabilities who have previously not had the same access to voting equipment as the common voter. Since the inception of elections and election technologies, all segments of the voting population have never been granted equal access, privacy and security when voting. Voting technology today has not addressed the issues that disabled voters are confronted with at the polls. Because approximately 17% of the voting population is disabled, their issues should be handled with a solution geared towards their needs. Disabled voters need to be able to cast their vote without the assistance of others. The Prime III multimodal voting system addresses these issues. The video illustrates the use of the Prime III system and how it allows disabled voters to use the same system as those without disabilities.</span></div></div></td>
<td colspan="3" class="session_details" id="S5013_details"><div class="paper" id="in122"><a href="#in122" class="title">Coco - The Therapy Robot</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979721&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katharina  Tran phuc</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Torsten  Racky</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Florian  Roth</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Iris  Wegmann</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Christoph  Busch</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Claudia  S&#246;ller-Eckert</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Mara  Pilz</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Katharina  Horst</span> <span class="affiliation">University of Applied Sciences Darmstadt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Coco is a therapeutic robot designed for elderly people in nursing homes or other care facilities. It is an electronic pet that represents a friend and helper who animates, reminds and motivates its owner.  He has 4 main functions: reading, singing, a calendar function and quiz games and can be operated by voice, remote control or base buttons. Pressure sensors in Coco's back react to touch. He interacts with its owner on its own initiative, suggesting to read, sing or play. Coco's memory and activity settings can be customised by carers or relatives. The prototype was implemented with Lego Mindstorms and successfully tested by a focus group. <br /></span></div></div><div class="paper" id="in129"><a href="#in129" class="title">Touch and Copy, Touch and Paste</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979714&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Suranga  Nanayakkara</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">SPARSH explores a novel interaction method to seamlessly transfer data between digital devices in a fun and intuitive way. The user touches whatever data item he or she wants to copy from a device. At that moment, the data item is conceptually saved in the user. Next, the user touches the other device he or she wants to paste/pass the saved content into. SPARSH uses touch-based interactions as indications for what to copy and where to pass it. Technically, the actual transfer of media happens via the information cloud.</span></div></div><div class="paper" id="in130"><a href="#in130" class="title">Mouseless - a Computer Mouse as Small as Invisible</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979715&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mouseless is a novel input device that provides the familiarity of interaction of a physical computer mouse without requiring a real hardware mouse. It consists of an IR laser beam and an IR camera, both of which are embedded in a computer. Mouseless proposes a number of novel additional gestural interactions while supporting all the conventional computer mouse interactions. We present the design and implementation of various Mouseless prototype systems.</span></div></div><div class="paper" id="in132"><a href="#in132" class="title">Obfuscating Authentication Through Haptics, Sound and Light</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979709&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrea  Bianchi</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span>, <br />
<span class="author">Dong-Soo  Kwon</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sensitive digital content associated with or owned by individuals now pervades everyday life. Mediating accessing to it in ways that are usable and secure is an ongoing challenge. We present a series of five PIN entry and transmission systems that address observation attacks in public spaces via shoulder surfing or camera recording. They do this through the use of novel modalities including audio cues, haptic cues and modulated visible light. Each prototype is introduced and motivated, and its strengths and weaknesses are considered.</span></div></div><div class="paper" id="in137"><a href="#in137" class="title">Blinky Blocks: A Physical Ensemble Programming Platform</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979712&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Brian T Kirby</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michael  Ashley-Rollman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Seth Copen Goldstein</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A major impediment to understanding programmable matter is the lack of an existing system with sufficiently many modules of sufficient capabilities. We present the requirements of physically distributed ensembles and discuss the use of the distributed programming language Meld to program ensembles of these units. We demonstrate a new <br /> system designed to meet these requirements called Blinky Blocks and discuss the hardware design we used to create 100 of these modules.</span></div></div><div class="paper" id="in145"><a href="#in145" class="title">humanaquarium: Exploring Audience, Participation, and Interaction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span><div class="authors"><span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Guy  Schofield</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Jayne  Wallace</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Pierre  Boulanger</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">humanaquarium is a movable performance space designed to explore the dialogical relationship between artist and audience. Two musicians perform inside the cube-shaped box, collaborating with participants to co-create an aesthetic audio-visual experience. The front wall of the humanaquarium is a touch-sensitive FTIR window. Max/MSP is used to translate the locations of touches on the window into control data, manipulating the tracking of software synthesizers and audio effects generated in Ableton Live, and influencing a Jitter visualization projected upon the rear wall of the cube.</span></div></div><div class="paper" id="in150"><a href="#in150" class="title">3D-Press - Tangible 3D Haptics on Touch Surfaces: Virtual Compliance</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979717&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Suitability of current haptic three-dimensional user interface (3D-UI) technologies is low for mobile interaction. 3D-Press in reviewed in this paper: a technique to create the haptic illusion that when pressing on a rigid surface is feels compliant. The fact that the illusion is intramodal (haptics only involved in creating it), and that the technology required is simple and with low energy demands, makes it ideal for mobile use. The parameters used in the implementation of 3D-Press influence the characteristics of the illusion.</span></div></div><div class="paper" id="in152"><a href="#in152" class="title">Graffito: Crowd-based Performative Interaction at Festivals</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979725&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Sheridan</span> <span class="affiliation">BigDog Interactive Ltd</span>, <br />
<span class="author">Nick  Bryan-Kinns</span> <span class="affiliation">Queen Mary University of London</span>, <br />
<span class="author">Stuart  Reeves</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Giles  Lane</span> <span class="affiliation">Proboscis</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crowd-based events are generating new forms of crowd-based performative interaction. Nightclubs and festivals are at the cutting edge of crowd-based interaction with ubiquitous computing. The social capital of crowd-based interaction is not well understood and is usually limited to one-off events. Our intention is to explore the possibility for generating a lifelong contextual footprint of crowd-based performative interaction.</span></div></div><div class="paper" id="in154"><a href="#in154" class="title">Galvanic Skin Response-Derived Bookmarking of an Audio Stream</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979716&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew K.X.J. Pan</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gordon Jih-Shiang  Chang</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gokhan H. Himmetoglu</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">AJung  Moon</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Thomas W. Hazelton</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Karon E. MacLean</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Elizabeth A. Croft</span> <span class="affiliation">The University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We demonstrate a novel interaction paradigm driven by implicit, low-attention user control, accomplished by monitoring a user&#8223;s physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. A listener&#8223;s galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our research prototype then automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted.</span></div></div><div class="paper" id="in158"><a href="#in158" class="title">MediaDiver: Viewing and Annotating Multi-View Video</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979711&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gregor  Miller</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Abir  Al Hajri</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Michael  Ilich</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Zoltan  Foley-Fisher</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Manuel  Fernandez</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Daesik  Jang</span> <span class="affiliation">Kunsan National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our novel rich media interface called MediaDiver demonstrates our new interaction techniques for viewing and annotating multiple view video. The demonstration allows attendees to experience novel moving target selection methods (called Hold and Chase), new multi-view selection techniques, automated quality of view analysis to switch viewpoints to follow targets, integrated annotation methods for viewing or authoring meta-content and advanced context sensitive transport and timeline functions. As users have become increasingly sophisticated when managing navigation and viewing of hyper-documents, they transfer their expectations to new media. We demonstrate the technology required to meet these expectations for video. Thus users will be able to directly click on objects in the video to link to more information or other video, easily change camera views and mark-up the video with their own content. The applications of this technology stretch from home video management to broadcast quality media production, which may be consumed on both desktop and mobile platforms.</span></div></div><div class="paper" id="in161"><a href="#in161" class="title">TagURIt: A Proximity-based Game of Tag Using Lumalive e-Textile Displays</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979707&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sylvia H Cheng</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an electronic game of tag that uses proximity sensing and Lumalive displays on garments.  In our game of tag, each player physically represents a location-tagged Universal Resource Indicator (URI). The URIs, one chaser and two target players, wear touch-sensitive Lumalive display shirts. The goal of the game is for the chaser to capture a token displayed on one of the Lumalive shirts, by pressing a touch sensor located on the shirt. When the chaser is in close proximity to the token player, the token jumps to the shirt of the second closest player, making this children&#8217;s game more challenging for adult players.  Our system demonstrates the use of interactive e-textile displays to remove the technological barrier between contact and proximity in the real world, and the seamless representation of gaming information from the virtual world in that real world.</span></div></div><div class="paper" id="in165"><a href="#in165" class="title">Frictional Widgets: Enhancing Touch Interfaces with Programmable Friction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979713&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vincent  Levesque</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Louise  Oram</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Karon  MacLean</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Nicholas  Marchuk</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Dan  Johnson</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">J. Edward  Colgate</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Michael  Peshkin</span> <span class="affiliation">Northwestern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch interactions occur through flat surfaces that lack the tactile richness of physical interfaces. We explore the design possibilities offered by augmenting touchscreens with programmable surface friction. Four exemplar applications &#8211; an alarm clock, a file manager, a game, and a text editor &#8211; demonstrate tactile effects that improve touch interactions by enhancing physicality, performance, and subjective satisfaction.</span></div></div><div class="paper" id="in168"><a href="#in168" class="title">SnowGlobe: A Spherical Fish-Tank VR Display</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979719&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">John  Bolton</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a spherical display with Fish-Tank VR as a means for interacting with three-dimensional objects. We implemented the spherical display by reflecting a projected image off a hemispherical mirror, allowing for a seamless curvilinear display surface. Diffuse illumination is used for detecting touch points on the sphere. The user&#8217;s head position and the position of the sphere are also tracked using a Vicon motion capture device. Users can perform multi-touch gestures to interact with 3D content on the spherical display. Our system relies on the metaphor of a snow globe. Users can walk around a display while maintaining motion parallax corrected viewpoints of the object on the display. They can interact with the 3D object using multitouch interaction techniques, allowing for rotating and scaling of the 3D model on the display.</span></div></div><div class="paper" id="in170"><a href="#in170" class="title">ZeroTouch: A Zero-Thickness Optical Multi-Touch Force Field</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979710&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Sashikanth  Damaraju</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present zero-thickness optical multi-touch sensing, a technique that simplifies sensor/display integration, and enables new forms of interaction not previously possible with other multi-touch sensing techniques. <br /> Using low-cost modulated infrared sensors to quickly determine the visual hull of an interactive area, we enable robust real-time sensing of fingers and hands, even in the presence of strong ambient lighting. Our technology allows for 20+ fingers to be detected, many more than through prior visual hull techniques, and our use of wide-angle optoelectonics allows for excellent touch resolution, even in the corners of the sensor. <br /> With the ability to track objects in free space, as well as its use as a traditional multi-touch sensor, ZeroTouch opens up a new world of interaction possibilities.</span></div></div><div class="paper" id="in207"><a href="#in207" class="title">Immersive VR: A Non-pharmacological Analgesic for Chronic Pain?</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979704&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diane  Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Meehae  Song</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ji-Dong  Yim</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Tyler  Fox</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Steven J Barnes</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mark  Nazemi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Chris  Shaw</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Pam  Squire, MD</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the research work being carried out by the Transforming Pain Research Group &#8211; the only group whose work is entirely focused on the use of immersive VR for chronic pain management. Unlike VR research for acute or short-term pain, which relies on pain "distraction," this research posits a new paradigm for the use of VR. In addition to providing an overview of our work, the present paper also describes one of our current works in detail: the Virtual Meditative Walk.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">18:00<br />-<br />20:00</td>

<td class="session tbd" id="S5030">
<div class="session_box">
<span class="type"></span>
<a href="#S5030" class="title">Buxton Collection Open</a>
<span class="location">201</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
</table>
</div>

<div class="day" id="day5"><h1>Wednesday, May 11, 2011</h1><table cellspacing="0" class="program" id="day_5">
<tr class="timeslot">
<td class="time">08:00<br />-<br />8:45</td>

<td class="session tbd" id="S1161">
<div class="session_box">
<span class="type"></span>
<a href="#S1161" class="title">Madness</a>
<span class="location">Ballroom A/B</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session tbd" id="S1162">
<div class="session_box">
<span class="type"></span>
<a href="#S1162" class="title">Registration Open</a>
<span class="location">Ballroom Foyer</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">09:00<br />-<br />10:00</td>

<td class="session " id="S1164">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1164" class="title">Interactions magazine</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1163">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1163" class="title">Interactive Technologies for Health Special Interest Group</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1173">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1173" class="title">Storytelling &amp; Perceptual Crossing</a>
<span class="location">211</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1178">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1178" class="title">Time/Animations</a>
<span class="location">223/224</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1172">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1172" class="title">Wireless Networks</a>
<span class="location">208/209</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1176">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1176" class="title">Learning</a>
<span class="location">217/218/219</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S5005">
<div class="session_box">
<span class="type">Student Design Competition &amp; Works In Progress</span>
<a href="#S5005" class="title">Poster Group 2 Displayed</a>
<span class="location">Ballroom Foyer</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1177">
<div class="session_box">
<span class="type">Special Events</span>
<a href="#S1177" class="title">SIGCHI Lifetime Practice Award</a>
<span class="location">220/221/222</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1171">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1171" class="title">Collaboration &amp; Creativity</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1174">
<div class="session_box">
<span class="type">alt.chi</span>
<a href="#S1174" class="title">alt.chi: Look! Up in the sky!</a>
<span class="location">212/213/214</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1165">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1165" class="title">Managing Global User Experience Teams</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1175">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1175" class="title">Emergency Response &amp; Scheduling</a>
<span class="location">215/216</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="12" class="session_details" id="S1164_details"><div class="paper" id="si144"><a href="#si144" class="title">Interactions magazine</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979536&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ron  Wakkary</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Erik  Stolterman</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this SIG paper we invite members of CHI to join us for a meeting to discuss interactions magazine. We describe the vision of the new editorial team for interactions and describe new features. We also introduce the forums, forum editors and other regular contributors to the magazine.</span></div></div></td>
<td colspan="12" class="session_details" id="S1163_details"><div class="paper" id="si125"><a href="#si125" class="title">Interactive Technologies for Health Special Interest Group</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979535&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Helena M. Mentis</span> <span class="affiliation">Microsoft Research Cambridge</span>, <br />
<span class="author">Harold  Thimbleby</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Julie A. Kientz</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Gillian R. Hayes</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Madhu  Reddy</span> <span class="affiliation">The Pennsylvania State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Health and how to support it with interactive computer systems, networks, and devices is a global and, for many countries, an explicit national priority. Significant interest in issues related to interactive systems for health has been demonstrated repeatedly within SIGCHI. A community focused on health started in 2010, fostering collaboration and dissemination of research findings as well as bridging with practitioners. As part of this community&#8217;s on-going efforts, we will hold a special interest group session during ACM CHI 2011 to discuss, prioritize, and promote some of these most pressing issues facing the community.</span></div></div></td>
<td colspan="12" class="session_details" id="S1173_details"><div class="sessionChair"><strong>Session Chair: </strong>Kristina H&#806;&#806;k (<em>Stockholm University</em>)</div><div class="paper" id="paper221"><a href="#paper221" class="title">ShadowStory: Creative and Collaborative Digital Storytelling Inspired by Cultural Heritage</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979221&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Fei  Lu</span> <span class="affiliation">Chinese Academy of Sciences</span>, <br />
<span class="author">Feng  Tian</span> <span class="affiliation">Chinese Academy of Sciences</span>, <br />
<span class="author">Yingying  Jiang</span> <span class="affiliation">Chinese Academy of Sciences</span>, <br />
<span class="author">Xiang  Cao</span> <span class="affiliation">Microsoft Research Cambridge</span>, <br />
<span class="author">Wencan  Luo</span> <span class="affiliation">Chinese Academy of Sciences</span>, <br />
<span class="author">Guang  Li</span> <span class="affiliation">Chinese Academy of Sciences</span>, <br />
<span class="author">Xiaolong  Zhang</span> <span class="affiliation">Pennsylvania State University</span>, <br />
<span class="author">Guozhong  Dai</span> <span class="affiliation">Chinese Academy of Sciences</span>, <br />
<span class="author">Hongan  Wang</span> <span class="affiliation">Chinese Academy of Sciences</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the fast economic growth and urbanization of many developing countries come concerns that their children now have fewer opportunities to express creativity and develop collaboration skills, or to experience their local cultural heritage. We propose to address these concerns by creating technologies inspired by traditional arts, and allowing children to create and collaborate through playing with them. ShadowStory is our first attempt in this direction, a digital storytelling system inspired by traditional Chinese shadow puppetry. We present the design and implementation of ShadowStory and a 7-day field trial in a primary school. Findings illustrated that ShadowStory promoted creativity, collaboration, and intimacy with traditional culture among children, as well as interleaved children&#8217;s digital and physical playing experience.</span></div></div><div class="paper" id="paper539"><a href="#paper539" class="title">Designing For Perceptual Crossing to Improve User Involvement</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979222&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eva  Deckers</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Stephan  Wensveen</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Rene  Ahn</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Kees  Overbeeke</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe our research on how to design for perceptive activity in artifacts in order for perceptual crossing between subject and artifact to happen. We base our research on the phenomenology of perception [19] and on ecological psychology [10]. Perceptual crossing is believed to be essential to share perception and thereby to feel involved in the situation [5,15]. We propose a theoretical model in which perceptive connections between user, artifact and event are presented. We designed an artifact to function as physical hypotheses [9] and show the design relevance of the model. In an experiment we investigate how the user&#8217;s feeling of involvement is influenced in relation to differentiations of the proposed theoretical model. The results of our experiment show that indeed perceptual crossing between user and artifact influences the user&#8217;s feeling of involvement with the artifact in their common space. We conclude with describing several design notions important for designing for perceptive activity in artifacts.</span></div></div><div class="paper" id="paper312"><a href="#paper312" class="title">Limits of Rereadability in Procedural Interactive Stories</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979223&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Mitchell</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Kevin  McGee</span> <span class="affiliation">National University of Singapore</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The paper investigates the limits of what authors can vary procedurally to encourage and reward rereadability in procedural hypertext fiction. Exploring these issues raises a methodological challenge: how do we study re-reading in the context of stories that change? We have developed an adapted form of the Piagetan clinical interview to do this. Using this approach, we have determined that readers, surprisingly, do not want to experience endless variation when rereading interactive stories. Instead, they are looking for some form of closure, either in terms of &#8220;understanding the story&#8221;, reaching the &#8220;best ending&#8221; for the characters in the story, or finding the &#8220;most interesting&#8221; version of the story. This has implications for the design/authoring of interactive stories and interactive art and entertainment.</span></div></div></td>
<td colspan="12" class="session_details" id="S1178_details"><div class="sessionChair"><strong>Session Chair: </strong>Scott Hudson (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper162"><a href="#paper162" class="title">Kineticons: Using Iconographic Motion in Graphical User Interface Design</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979232&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chris  Harrison</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Gary  Hsieh</span> <span class="affiliation">Michigan State University</span>, <br />
<span class="author">Karl D. D. Willis</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jodi  Forlizzi</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Scott E. Hudson</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Icons in graphical user interfaces convey information in a mostly universal fashion that allows users to immediately interact with new applications, systems and devices. In this paper, we define Kineticons - an iconographic scheme based on motion. By motion, we mean geometric manipulations  applied to a graphical element over time (e.g., scale, rotation, deformation). In contrast to static graphical icons and icons with animated graphics, kineticons do not alter the visual content or &#8220;pixel-space&#8221; of an element. Although kineticons are not new &#8211; indeed, they are seen in several popular systems &#8211; we formalize their scope and utility. One powerful quality is their ability to be applied to GUI elements of varying size and shape &#8211; from a something as small as a close button, to something as large as dialog box or even the entire desktop. This allows a suite of system-wide kinetic behaviors to be reused for a variety of uses. Part of our contribution is an initial kineticon vocabulary, which we evaluated in a 200 participant study. We conclude with discussion of our results and design recommendations. <br /></span></div></div><div class="paper" id="paper1893"><a href="#paper1893" class="title">Temporal Distortion for Animated Transitions</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979233&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pierre  Dragicevic</span> <span class="affiliation">INRIA</span>, <br />
<span class="author">Anastasia  Bezerianos</span> <span class="affiliation">Ecole Centrale Paris</span>, <br />
<span class="author">Waqas  Javed</span> <span class="affiliation">Purdue University</span>, <br />
<span class="author">Niklas  Elmqvist</span> <span class="affiliation">Purdue University</span>, <br />
<span class="author">Jean-Daniel  Fekete</span> <span class="affiliation">INRIA</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Animated transitions are popular in many visual applications but they can be difficult to follow, especially when many objects move at the same time. One informal design guideline for creating effective animated transitions has long been the use of slow-in/slow-out pacing, but no empirical data exist to support this practice. We remedy this by studying object tracking performance under different conditions of temporal distortion, i.e., constant speed transitions, slow-in/slow-out, fast-in/fast-out, and an adaptive technique that slows down the visually complex parts of the animation. Slow-in/slow-out outperformed other techniques, but we saw technique differences depending on the type of visual transition.</span></div></div><div class="paper" id="cs120"><a href="#cs120" class="title">Interactive Sparklines: A Dynamic Display of Quantitative Information</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979655&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Leo D Frishberg</span> <span class="affiliation">Tektronix,Inc</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Initially proposed by Edward Tufte, &#8220;sparklines&#8221; present hundreds of data points in the space of a word or two. Tufte originally designed sparklines to be embedded in a sentence. Today they have moved off the printed page into websites, online applications, smart phone screens and interactive documents. <br /> Sparklines display hundreds of data points over time: stock prices or sports statistics for the prior year, for example. But how well do they perform with millions of data points acquired in microseconds? What if users capture these data every couple of minutes? How well do sparklines, primarily designed for static display of historical data, fare in the context of an interactive application? <br /> In this case study, the author describes interactive sparklines his team designed and developed to assist electronic engineers debugging their electronic circuits. The case study presents an iterative user-centered design process from the initial proposal of sparklines through to their refinement after several releases. The study concludes with reflections about future improvements to interactive sparklines. <br /></span></div></div></td>
<td colspan="12" class="session_details" id="S1172_details"><div class="sessionChair"><strong>Session Chair: </strong>Elizabeth Churchill (<em>Yahoo! Research</em>)</div><div class="paper" id="paper236"><a href="#paper236" class="title">Why is My Internet Slow?: Making Network Speeds Visible</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979217&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marshini  Chetty</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">David  Haslem</span> <span class="affiliation">Orange Sparkle Ball</span>, <br />
<span class="author">Andrew  Baird</span> <span class="affiliation">Amazon.com</span>, <br />
<span class="author">Ugochi  Ofoha</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Bethany  Sumner</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Rebecca  Grinter</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With widespread broadband adoption, more households report experiencing sub-optimal speeds. Not only are slow speeds frustrating, they may indicate consumers are not receiving the services they are paying for from their internet service providers. Yet, determining the speed and source of slow-downs is hard because few tools exist for broadband management. We report on results of a field trial with 10 households using a visual network probe designed to address these problems. We describe the results of the study and provide design implications for future tools. More importantly, we argue that tools like this can educate and empower consumers by making broadband speeds and sources of slow-downs more visible.</span></div></div><div class="paper" id="paper202"><a href="#paper202" class="title">GridOrbit &#8211; An Awareness System Supporting the Adoption of a Volunteer Computing Infrastructure</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979218&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Juan David  Hincapi&#233; Ramos</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Aur&#233;lien  Tabard</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Jakob E. Bardram</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The success of a volunteer computing infrastructure depends on the contributions of its users. An example of such an infrastructure is the Mini-Grid, a local peer-to-peer system used for computational analysis of DNA. The speed of analysis increases as more users join the Mini-Grid. However, the invisible nature of such an infrastructure hinders adoption, as it is difficult for users to participate in an infrastructure they are not aware of. This paper introduces GridOrbit, a system designed to increase user awareness, fostering contributions to this infrastructure. We designed GridOrbit using a participatory design process with biologists, and subsequently deployed it for use in a biology laboratory. Our results indicate that the number of contributors to the Mini-Grid increased with the use of awareness technologies. In addition, our analysis presents their motives and behaviors. Finally, a characterization of user interaction with GridOrbit emerged, which enabled us to understand how awareness systems can be better designed. We see GridOrbit as an example of a broader class of technologies designed to create &#8216;Infrastructure Awareness&#8217; as a means to increase the contributions to technological infrastructures.</span></div></div><div class="paper" id="paper884"><a href="#paper884" class="title">How Users Associate Wireless Devices</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979219&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ming Ki  Chong</span> <span class="affiliation">Lancaster University</span>, <br />
<span class="author">Hans  Gellersen</span> <span class="affiliation">Lancaster University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In a wireless world, users can establish connections between devices spontaneously, and unhampered by cables. However, in the absence of cables, what is the natural interaction to connect one device with another? A wide range of device association techniques have been demonstrated, but it has remained an open question what actions users would spontaneously choose for device association. We contribute a study eliciting device association actions from non-technical users without premeditation. Over 700 user-defined actions were collected for 37 different device combinations. We present a classification of user-defined actions, and observations of the users' rationale. Our findings indicate that there is no single most spontaneous action; instead five prominent categories of user-defined actions were found.</span></div></div></td>
<td colspan="12" class="session_details" id="S1176_details"><div class="sessionChair"><strong>Session Chair: </strong>Maria Francesca Costabile (<em>University of Bari</em>)</div><div class="paper" id="paper1461"><a href="#paper1461" class="title">Practical, Appropriate, Empirically-Validated Guidelines for Designing Educational Games</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979229&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Conor  Linehan</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Ben  Kirman</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Shaun  Lawson</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Gail  Chan</span> <span class="affiliation">Oxford Brookes University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There has recently been a great deal of interest in the potential of computer games to function as innovative educational tools. However, there is very little evidence of games fulfilling that potential. Indeed, the process of merging the disparate goals of education and games design appears problematic, and there are currently no practical guidelines for how to do so in a coherent manner. In this paper, we describe the successful, empirically validated teaching methods developed by behavioural psychologists and point out how they are uniquely suited to take advantage of the benefits that games offer to education. We conclude by proposing some practical steps for designing educational games, based on the techniques of Applied Behaviour Analysis. It is intended that this paper can both focus educational games designers on the features of games that are genuinely useful for education, and also introduce a successful form of teaching that this audience may not yet be familiar with.</span></div></div><div class="paper" id="cs102"><a href="#cs102" class="title">Using Community-Based Service Projects to Enhance Undergraduate HCI Education: 10 Years of Experience</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979653&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jonathan  Lazar</span> <span class="affiliation">Towson University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While community-based service projects are utilized in many different fields of study at universities, there is little documentation on how to implement community-based projects in undergraduate Human-Computer Interaction (HCI) courses. This case study provides information on the benefits and drawbacks of community-based service projects, provides a few different examples of community-based learning in undergraduate HCI classes, discusses successes and failures, and provides a set of 7 success factors, all based on 10 years of experience at a single university</span></div></div><div class="paper" id="paper487"><a href="#paper487" class="title">The Mathematical Imagery Trainer: From Embodied Interaction to Conceptual Learning</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979230&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mark  Howison</span> <span class="affiliation">Brown University</span>, <br />
<span class="author">Dragan  Trninic</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Daniel  Reinholz</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Dor  Abrahamson</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce an embodied-interaction instructional design, the Mathematical Imagery Trainer (MIT), for helping young students develop grounded understanding of proportional equivalence (e.g., 2/3 = 4/6). Taking advantage of the low-cost availability of hand-motion tracking provided by the Nintendo Wii remote, the MIT applies cognitive-science findings that mathematical concepts are grounded in mental simulation of dynamic imagery, which is acquired through perceiving, planning, and performing actions with the body. We describe our rationale for and implementation of the MIT through a design-based research approach and report on clinical interviews with twenty-two 4th&#8211;6th grade students who engaged in problem-solving tasks with the MIT.</span></div></div></td>
<td colspan="12" class="session_details" id="S5005_details"><div class="paper" id="wp654"><a href="#wp654" class="title">Can Users Remember Their Pictorial Passwords Six Years Later?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979945&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Thomas S Tullis</span> <span class="affiliation">Fidelity Investments</span>, <br />
<span class="author">Donna P Tedesco</span> <span class="affiliation">Fidelity Investments</span>, <br />
<span class="author">Kate E McCaffrey</span> <span class="affiliation">Fidelity Investments</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous research had shown that pictorial passwords, where users recognize their target images among distractors, have potential for improving the usability of authentication systems.  A method using personal photos provided by the users as their targets, shown among highly similar distractors, showed the most promise for both accuracy and security.  But the longest time period that had been tested between successive login attempts was only about one month.  We wanted to see what happens when six years have elapsed.  We recruited some of the same participants from the previous study and tested their ability to select their target photos six years later. We found that 12 of 13 participants successfully authenticated themselves.  The overall accuracy rate was 95.6%, demonstrating that most users can remember these pictorial passwords even over long periods of time.</span></div></div><div class="paper" id="wp386"><a href="#wp386" class="title">ReHandle: Towards Integrating Physical Rehabilitation in Everyday life</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979856&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Naveen  Bagalkot</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Tomas  Sokoler</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present ReHandle, an emerging design space currently inhabited and shaped by three different design sketches. We describe how the three sketches point to three possible dimensions for exploring the role of digital technology in facilitating self-monitoring; aimed at promoting an integration of the rehab activities with the everyday activities of senior citizens. We expect that our articulation of the emerging ReHandle design space will be informative and inspirational for the interaction design and HCI community exploring the role of digital technology for successful rehabilitation of senior citizens.</span></div></div><div class="paper" id="wp532"><a href="#wp532" class="title">CrowdForge: Crowdsourcing Complex Work</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979902&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aniket  Kittur</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Boris  Smus</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Robert  Kraut</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Micro-task markets such as Amazon&#8217;s Mechanical Turk represent a new paradigm for accomplishing work, in which employers can tap into a large population of workers around the globe to accomplish tasks in a fraction of the time and money of more traditional methods.  However, such markets typically support only simple, independent tasks, such as labeling an image or judging the relevance of a search result.  Here we present a general purpose framework for micro-task markets that provides a scaffolding for more complex human computation tasks which require coordination among many individuals, such as writing an article.</span></div></div><div class="paper" id="wp646"><a href="#wp646" class="title">WaveForm: Remote Video Blending for VJs Using In-Air Multitouch Gestures</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979941&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amartya  Banerjee</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Jesse  Burstyn</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present WaveForm, a system that enables a Video Jockey (VJ) to directly manipulate video content on a large display on a stage, from a distance. WaveForm implements an in-air multitouch gesture set to layer, blend, scale, rotate, and position video content on the large display. We believe this leads to a more immersive experience for the VJ user, as well as for the audience witnessing the VJ&#8217;s performance during a live event.</span></div></div><div class="paper" id="wp361"><a href="#wp361" class="title">The Adoption of Online Self-Service Technology (SST) as a Gradual Learning Process</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979847&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Calin  Gurau</span> <span class="affiliation">Montpellier Business School</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Using a combination of qualitative and quantitative analysis, this study attempts to identify the main phases of customer-SST system interaction. The findings reinforce the interpretation of SST adoption as a gradual process of learning that presents different challenges for various types of customers, depending on their level of online experience.</span></div></div><div class="paper" id="wp416"><a href="#wp416" class="title">Sympathetic Guitar:  Can a Digitally Augmented Guitar be a Social Entity?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979863&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jay  Vidyarthi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa N. Antle</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Bernhard E. Riecke</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous work suggests that people treat interactive media as if they were social entities.  By drawing a parallel between socio-cognitive theory and interface design, we intend to experimentally determine whether deliberate design decisions can have an effect on users&#8217; perception of an interactive medium as a social entity.  In this progress report, we describe the theoretical underpinnings and motivations which led to the design and implementation of the Sympathetic Guitar: a guitar interface which supplements standard acoustic sound with a spatially-separate audio response based on the user&#8217;s hand positions and performance dynamics.  This prototype will be used for investigating user response to a specific, socially-relevant design decision.</span></div></div><div class="paper" id="wp426"><a href="#wp426" class="title">Aiding Usability Evaluation via Detection of Excessive Visual Search</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979868&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Oleg  Komogortsev</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Corey  Holland</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Dan  Tamir</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Carl  Mueller</span> <span class="affiliation">Texas State University-San Marcos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an objective evaluation of several methods for the automated classification of excessive visual search, a technique which has the potential to aid in the identification of usability problems during software usability testing. Excessive visual search was identified by a number of eye movement metrics, including: fixation count, saccade amplitude, convex hull area, scanpath inflections, scanpath length, and scanpath duration. The excessive search intervals identified by each algorithm were compared to those produced by manual classification. The results indicate that automated classification can be successfully employed to substantially reduce the amount of recorded data reviewed during usability testing, with relatively little loss in accuracy.</span></div></div><div class="paper" id="wp432"><a href="#wp432" class="title">ConsiderIt: Improving Structured Public Deliberation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979869&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Travis  Kriplean</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jonathan T. Morgan</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Deen  Freelon</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alan  Borning</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Lance  Bennett</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We designed, built, and deployed ConsiderIt to support the Living Voters Guide, a website where any voter could participate in writing a voters&#8217; guide for the 2010 election in Washington. ConsiderIt is a new method of integrating the thoughts of many into a coherent form, while nudging people to consider tradeoffs of difficult decisions with an intuitive interface.</span></div></div><div class="paper" id="wp457"><a href="#wp457" class="title">Sex Toys and Designing for Sexual Wellness</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979879&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anna  Eaglin</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sexual health encompasses physical, mental and social well-being in relation to sexuality. In this paper, we argue that designing for sexual health is an important aspect of the Wellness Informatics agenda, and that research on sex toys, which is underdeveloped in HCI, has the potential to contribute to this agenda substantively. We summarize our user research and present a set of design principles to further the agenda of designing for sexual wellness.</span></div></div><div class="paper" id="wp463"><a href="#wp463" class="title">Designing A Personal Visualization Projection of Online Social Identity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979882&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mandy  Leung</span> <span class="affiliation">The University of Sydney</span>, <br />
<span class="author">Martin  Tomitsch</span> <span class="affiliation">The University of Sydney</span>, <br />
<span class="author">Andrew  Vande Moere</span> <span class="affiliation">Katholieke Universiteit Leuven</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we report on the design, implementation and evaluation of a personal visualization projection, which provides onlookers with a real-time view of the online social identity of the wearer. The wearable system was developed as a novel means of electronic self-expression, and for catalyzing increased social interaction between the wearer and onlookers with similar or complementary personality characteristics. The interactive prototype, driven by a handheld &#8220;pico&#8221; projector, was evaluated with two groups of four participants each. Based on a case study analysis followed by focus groups, we present our findings according to a contextual evaluation model, which includes aspects of environment, usability, privacy, ambientness, social interaction, and insight.</span></div></div><div class="paper" id="wp498"><a href="#wp498" class="title">Customization for Games: Lessons from Variants of Texas Hold&#8217;em</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979889&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gifford K Cheung</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">System designers who build customization into games ought to consider how players think about adjustments. The distinctiveness of gaming contexts suggests that closer inspection of customization in games is warranted and will inform the design of customizable game systems. Presented here is an analysis of 82 collected reports about variations to the rules of the poker game Texas Hold&#8217;em. A theory of &#8220;necessity&#8221; in rule adoption is developed and the systematic perspective of rule-changing in games is discussed.</span></div></div><div class="paper" id="wp502"><a href="#wp502" class="title">&#8216;Canary in a Coal Mine&#8217;: Monitoring Air Quality and Detecting Environmental Incidents by Harvesting Twitter</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979890&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Henricus  Smid</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Patrick  Mast</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Maarten  Tromp</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Andi  Winterboer</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Vanessa  Evers</span> <span class="affiliation">University of Amsterdam</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an application that facilitates environmental <br /> monitoring by and for the general public. &#8216;Canary in a <br /> Coal Mine&#8217; (CIACM) gathers and analyses pollution-related <br /> tweets in real-time from the micro-blogging <br /> platform Twitter and visualizes temporal and spatial <br /> characteristics of the data. CIACM allows citizens to <br /> keep track of the environmental quality of their region <br /> and empowers users to contribute to this public <br /> environmental monitoring system.</span></div></div><div class="paper" id="wp522"><a href="#wp522" class="title">My Own-Style Interaction: Exploring Individuals' Preferences to Interactivity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979897&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Da-jung  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Hyeon-Jeong  Suk</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There have been studies about users' preferences on different physical styles of interactive products, but the exploration of interactivity preferences and the value of customizing its expressions have not been emphasized much yet. In this paper, we conducted a three-phase user study in order to investigate individual preferences to different qualities of interactivity and its relationship with individual differences. The results showed that people have diverse preferences for several attributes of interactivity, similar to the case for appearances of products, and there are close relationships between individual differences such as human personality traits. Based on these results, we discussed their implications for designing attractive interaction.</span></div></div><div class="paper" id="wp493"><a href="#wp493" class="title">From the Lab to the World: Lessons from Extending a Pointing Technique for Real-World Use</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979888&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Jansen</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Leah  Findlater</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the Pointing Magnifier as a case study for understanding the issues and challenges of deploying lab-validated pointing facilitation techniques into the real world. The Pointing Magnifier works by magnifying the contents of an area cursor to allow for selection in a magnified visual and motor space. The technique has been shown in prior lab studies to be effective at reducing the need for fine pointing for motor-impaired users. We highlight key design and technical challenges in bringing the technique, and such techniques in general, from the lab to the field.</span></div></div><div class="paper" id="wp482"><a href="#wp482" class="title">LoOkie - It Feels Like Being There</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979884&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Talya  Porat</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span>, <br />
<span class="author">Inbal  Rief</span> <span class="affiliation">kitchen97.com</span>, <br />
<span class="author">Rami  Puzis</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span>, <br />
<span class="author">Yuval  Elovici</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we describe an interaction design process and the challenges encountered during the development of LoOkie, a social mobile application, which enables members to request and receive live videos or pictures of desired locations from people who are present at the scene. The paper describes, from a human-computer interaction perspective, the development of the application from the birth of the idea through the design process encountered up to the point of the launch of the application for Beta at the beginning of 2011.</span></div></div><div class="paper" id="wp437"><a href="#wp437" class="title">Input Observer: Measuring Text Entry and Pointing Performance from Naturalistic Everyday Computer Use</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979871&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abigail  Evans</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe the Input Observer, a background application that will be capable of measuring a user&#8217;s text entry and pointing abilities from everyday computer use &#8220;in the wild.&#8221; The application runs quietly in the background of the user&#8217;s computer and utilizes global Windows Hooks to observe the text entry input stream and use of the mouse, and will yield data equivalent to results from lab-based measures of text entry and target acquisition. A major challenge is the lack of a task model from which researchers can know the intent of the user at every <br /> moment. We describe our approach to handling this issue for both text entry and mouse pointing.</span></div></div><div class="paper" id="wp580"><a href="#wp580" class="title">Wriggle: An Exploration of Emotional and Social Effects of Movement</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979919&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katherine  Isbister</span> <span class="affiliation">NYU-Poly</span>, <br />
<span class="author">Ulf  Schwekendiek</span> <span class="affiliation">NYU-Poly</span>, <br />
<span class="author">Jonathan  Frye</span> <span class="affiliation">NYU</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Wriggle is a research prototype game that can be played either with or without movement as input. We conducted an experiment to see whether movement adds emotional impact and increases social connectedness. We found effects on arousal and results approaching significance for social connection, demonstrating the potential for this approach to help us better understand the impact of movement on user experience.</span></div></div><div class="paper" id="wp575"><a href="#wp575" class="title">Text Highlighting Improves User Experience for Reading with Magnified Displays</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979917&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tersia  Gowases</span> <span class="affiliation">University of Eastern Finland</span>, <br />
<span class="author">Roman  Bednarik</span> <span class="affiliation">University of Eastern Finland</span>, <br />
<span class="author">Markku  Tukiainen</span> <span class="affiliation">University of Eastern Finland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We report on two studies of how magnified views affect the lives of users with low vision and how simple interventions can improve their user experience. In the first study we observed three low vision users with Age-related Macular Degeneration (AMD) as they interacted with computing devices. We found that AMD users rely on the screen magnification, but the same magnified view not only makes it impossible to read longer texts independently, but also causes a loss of context. We then designed an enhancement of the conventional Windows 7 screen magnification tool by providing line-level text highlighting. We conducted an experiment in which 21 participants, with normal vision, read text from a webpage using one of three conditions: no enhancement, highlighting, and highlighting + cursor routing. We recorded the eye-movement patterns, performance, cognitive workload, and user experience. The results provide design implications and guidelines for visual aids for interaction with magnified displays.</span></div></div><div class="paper" id="wp620"><a href="#wp620" class="title">Mobile Augmented Reality: Video prototyping</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979927&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marco  de S&#225;</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">Judd  Antin</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">David  Shamma</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">Elizabeth F. Churchill</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As mobile devices become more powerful, new features and user experiences become possible. A good example of such experiences is Augmented reality (AR). Achieved through the combination of current smart- phones processing capabilities and their embedded cameras, AR is a growing trend that offers an interesting approach for a wide variety of applications. However, coupling this new approach to the already demanding design process that characterizes mobile devices, further extends challenges to designers and developers. In this paper we present a preliminary study on prototyping and evaluation techniques for mobile AR. A short experiment within the context of an ongoing design project and initial results are presented along with some resulting guidelines.</span></div></div><div class="paper" id="wp504"><a href="#wp504" class="title">Transparency in Mobile Navigation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979891&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  McGookin</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Inti  Herteleer</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We investigated the usefulness transparency can play in increasing the display space of mobile devices in navigation scenarios.   Two different systems that used transparency to display a map and image of a point of interest (POI) were compared to a control. Significant variations were identified in the strategies employed, with a strong user preference towards the transparency conditions. Significant variations in time or distance taken were not identified between conditions, although results indicate strong avenues for future investigation.</span></div></div><div class="paper" id="wp513"><a href="#wp513" class="title">Force Gestures: Augmented Touch Screen Gestures Using Normal and Tangential Force</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979895&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seongkook  Heo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Geehyuk  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Similar sliding gestures may have different meanings when they are performed with changing intensity. Touch screens, however, fail to properly distinguish those intensities due to their inability to sense variable pressures. Enabled by distinguishing normal and tangential forces, we explore new possibilities for gestures on a touch screen. We have implemented a pressure-sensitive prototype and have designed a set of gestures that utilize alterable forces. The gestures&#8217; feasibility has been tested through a simple experiment.  Finally, we discuss the new possibility of touch interactions that are sensitive to pressure.</span></div></div><div class="paper" id="wp460"><a href="#wp460" class="title">WATER Alert! Disseminating Drinking Water Quality Information to South Africans</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979880&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Deana S. Brown</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Gary  Marsden</span> <span class="affiliation">University of Cape Town</span>, <br />
<span class="author">Melissa  Loudon</span> <span class="affiliation">University of Southern California</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Drinking water quality, especially in many parts of South Africa, is far below acceptable standards. With an annual estimate of 43,000 deaths from diarrheal diseases, 3 million cases of illness, and treatment costs of over half a billion US dollars, the impact is critical [4]. This research addresses the challenge of reporting complex and critical water quality information in a way that is accessible to all South Africans as required by law. In a country with high illiteracy rates, 11 official languages and limited-to-no access to technology in many areas, this is no easy feat. We describe the details of WATER Alert!, a prototype mobile phone application designed to alert and report critical water quality information to consumers who subscribe to it. Our initial evaluation of this design with users suggests that such an application would help to improve consumers' understanding of water quality information. The symbol-based messages make critical water quality information more accessible to illiterate or low-literate users, or non-native English or Afrikaans speakers. Additionally, the use of a tool and interface design most of our users are familiar with (the mobile phone) lowers the learning curve.</span></div></div><div class="paper" id="wp563"><a href="#wp563" class="title">Dual-Space Drawing: Designing an Interface to Support Creative and Reflective Drawing Experiences</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979912&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jee Yeon  Hwang</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Henry  Holtzman</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Mitchel  Resnick</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Dual-Space Drawing is an interface that enables children to express their drawing ideas in both the digital and real worlds. It supports creative and reflective drawing experiences using two layers: a transparent layer and a screen layer. The interface takes a user&#8217;s drawing movements on the transparent display unobtrusively and then projects the movements on the screen display while presenting the user-selected multimedia components. Dual-Space Drawing lets users interact with motion graphics on a mirror-like display. In the process of designing the self-projected scenes and creating digital contents, children can express themselves and embody their ideas. While designing a digital object, a user&#8217;s response to the object creates a new relationship to the object in connection with the user&#8217;s self-reflection/projection. In this way, Dual-Space Drawing integrates the user&#8217;s drawing activity with expressive interaction.</span></div></div><div class="paper" id="wp516"><a href="#wp516" class="title">Comparative Evaluation of Recommender System Quality</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979896&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Paolo  Cremonesi</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Franca  Garzotto</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Sara  Negro</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Alessandro  Papadopoulos</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Roberto  Turrin</span> <span class="affiliation">Moviri SRL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Several researchers suggest that the Recommendation Systems (RSs) that are the "best" according to statistical metrics might not be the most satisfactory for the user. We explored this issue through an empirical study that involved 210 users and considered 7 RSs using different recommender algorithms on the same dataset.  <br /> We measured user&#8217;s perceived quality of each RS, and compared these results against measures of statistical quality of the considered algorithms as they have been assessed by past studies in the field, highlighting some interesting results.</span></div></div><div class="paper" id="wp362"><a href="#wp362" class="title">Generalizing Email Messages Digests</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979848&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Romain  Vuillemot</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span>, <br />
<span class="author">Jean-Marc  Petit</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span>, <br />
<span class="author">Mohand-Said  Hacid</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An email digest is a message that results from the combination of other messages. Mailing list management systems implement digests to let subscribers reduce their email messages frequency. In this paper we address the issue of generalizing this digest technique for any message (i.e. not only issued from mailing lists). By generalizing we mean creating new message combinations while 1) keeping an email centric approach, and 2) generating a compact visualization to assist a user task. We implemented a preliminary prototype as a webmail and we will describe a series of digests providing users multiple visualizations in the context of a meeting planning by email.</span></div></div><div class="paper" id="wp373"><a href="#wp373" class="title">Visualizing Meetings as a Graph for more Accessible Meeting Artifacts</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979850&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yurdaer  Doganata</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Mercan  Topkara</span> <span class="affiliation">IBM Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper focuses on capturing, correlating and visualizing the execution of meetings from the recorded data using a business process management approach. Relevant artifacts that are utilized or generated during a meeting as well as meeting activities are mapped onto a generic meeting data model. The execution of a meeting is then captured as a graph where generated meeting artifacts, participants and meeting tasks are connected. The graph enables faster and structured access to meeting data and gives better insight to the users about the meeting through visualization capability.</span></div></div><div class="paper" id="wp384"><a href="#wp384" class="title">Engaging Energy Saving through Motivation-Specific Social Comparison</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979855&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Petromil  Petkov</span> <span class="affiliation">Queensland University of Technology, NICTA, Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Felix  K&#246;bler</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Marcus  Foth</span> <span class="affiliation">Queensland University of Technology, NICTA</span>, <br />
<span class="author">Richard  Medland</span> <span class="affiliation">Queensland University of Technology, NICTA</span>, <br />
<span class="author">Helmut  Krcmar</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Comparison is widely used in research projects and commercial products whose goal is to motivate energy saving at home. This research builds on fundamental theories from social psychology in an attempt to shed light on how to motivate consumers to conserve energy by providing relevant people for social comparison depending on consumer&#8217;s motivation to compare. To support the research process, the mobile application EnergyWiz was developed through a theory-driven design approach. Along with other features EnergyWiz provides users with three types of social comparison &#8211; normative, one-on-one and ranking. The results of interviews with prospective users are used to derive design suggestions for relevant people for comparison (comparison subjects).</span></div></div><div class="paper" id="wp400"><a href="#wp400" class="title">AnalyzeThis: Unobtrusive Mental Health Monitoring by Voice</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979859&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Keng-hao  Chang</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Matthew  Chan</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">John  Canny</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mental illness is one of the most undertreated health problems worldwide.  Previous work has shown that there are remarkably strong cues to mental illness in short samples of the voice. These cues are evident in severe forms of illness, but it would be most valuable to make earlier diagnoses from a richer feature set. Furthermore there is an abstraction gap between these voice cues and the diagnostic cues used by practitioners. We believe that by closing this gap, we can build more effective early diagnostic systems for mental illness. In order to develop improved monitoring, we need to translate the high-level cues used by practitioners into features that can be analyzed using signal processing and machine learning techniques.  In this paper we describe the elicitation process that we used to tap the practitioners' knowledge.   We borrow from both AI (expert systems) and HCI (contextual inquiry) fields in order to perform this knowledge transfer.  The paper highlights an unusual and promising role for HCI - the analysis of interaction data for health diagnosis. <br /></span></div></div><div class="paper" id="wp409"><a href="#wp409" class="title">MouseHints: Easing Task Switching in Parallel Browsing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979861&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luis A Leiva</span> <span class="affiliation">Universidad Polit&#233;cnica de Valencia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a technique to help users regain context either after an interruption or when multitasking while performing web tasks.  <br /> Using mouse movements as an indicator of attention, a browser plugin records in background the user's interactions (including clicks, dwell times, and DOM elements). On leaving the page, this information is stored to be rendered as an overlay when the user returns to such page.  <br /> The results of a short study showed that participants resumed tasks three times faster with MouseHints and completed their tasks in about half the time. <br /> Related applications and further research are also envisioned. <br /></span></div></div><div class="paper" id="wp465"><a href="#wp465" class="title">Active Progress Bars: Facilitating the Switch to Temporary Activities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979883&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christophe  Hurter</span> <span class="affiliation">Civil Aviation Research Center, IRIT Toulouse University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Queen&#8217;s University</span>, <br />
<span class="author">Nathalie  Riche</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Catherine  Plaisant</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we seek to find a better way of effective task management when a progress bar interrupts us-er&#8217;s primary activity. We propose to augment progress bars with user controlled functionalities facilitating the switch to temporary activities. We detail a taxonomy of waiting period contexts and possible temporary tasks, then report on 5 participatory design, and a follow-up survey of 96 respondents. Finally we describe an early prototype of active progress bars, and report on initial use.</span></div></div><div class="paper" id="wp484"><a href="#wp484" class="title">PLink: Paper-Based Links for Cross-Media Information Spaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979885&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">J&#252;rgen  Steimle</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Nadir  Weibel</span> <span class="affiliation">University of California San Diego</span>, <br />
<span class="author">Simon  Olberding</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Max  M&#252;hlh&#228;user</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">James D. Hollan</span> <span class="affiliation">University of California San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">PLink is a system for integrating physical and computer desktops by creating paper links to digital resources. PLink leverages diverse formats of physical paper, ranging from tiny stickers that can be easily incorporated into traditional paper media to very large deskpad sheets that make the physical desktop partially interactive. We present PLink and initial results from a multi-week field study.</span></div></div><div class="paper" id="wp527"><a href="#wp527" class="title">Adding Haptic Feedback to Mobile TV</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979899&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jason  Alexander</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Mark T Marshall</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Sriram  Subramanian</span> <span class="affiliation">University of Bristol</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the abundance of large-screen displays, mobile device users currently have little motivation to stream video content and TV broadcasts to their device&#8212;the desire to watch content 'on the move' does not currently outweigh the necessity of viewing this content on a miniaturised screen. However, the value and appeal of mobile TV broadcasts can be increased by the addition of a haptic-feedback channel to supplement the traditional video and audio streams.  <br /> This paper discusses the development of mobile haptic TV systems. It describes the design constraints for these systems and presents one concept implementation, UltraTV. UltraTV is a mobile device that provides mid-air, multi-point, back-of-device ultrasonic haptic feedback to enhance the mobile TV experience (see Figure 1). The paper concludes with a look at avenues for further exploration within the realm of mobile haptic TV.</span></div></div><div class="paper" id="wp531"><a href="#wp531" class="title">PowerSocket: Towards On-Outlet Power Consumption Visualization</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979901&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Florian  Heller</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Power consumption is measured in W and Wh, but what do these units mean? Water consumption can easily be understood, as we all know what a liter of water looks like. Common power meters, however, rely on the physical units or their translation to costs as display. We classified existing displays and ambient visualizations in a taxonomy that focuses on the characteristics of power consumption displays. We adapted representatives of the different categories of displays to an on-outlet display and compared these using a combination of soft- and hardware prototyping. Results indicate that ambient visualizations make it easier to understand power consumption.</span></div></div><div class="paper" id="wp425"><a href="#wp425" class="title">SketchSpace: Designing Interactive Behaviors with Passive Materials</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979867&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Holman</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents SketchSpace, a system that allows designers to interactively sketch [3] device&#8217;s interactive behaviors by imbuing digital functionality to passive materials. SketchSpace requires no augmentation of the device itself, but instead it uses a depth-sensing Kinect camera to simulate the use of hardware sensors by using depth information to infer an object's three-dimensional position, motion, proximity, shape, deformations, and touch events on its surface. A designer can map these inputs to desktop applications in real-time and thus experiment with different interactions. We showcase how SketchSpace can be used to prototype two devices: from tilt sensitive mice to bendable displays. In general, we discuss how this simplifies the process of generating an interactive device sketch and supports rapid exploration of design solutions.</span></div></div><div class="paper" id="wp539"><a href="#wp539" class="title">Paper Interface Design for Classroom Orchestration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979904&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S&#233;bastien  Cuendet</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Quentin  Bonnard</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Fr&#233;d&#233;ric  Kaplan</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Pierre  Dillenbourg</span> <span class="affiliation">EPFL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designing computer systems for educational purpose is a difficult task. While many of them have been developed in the past, their use in classrooms is still scarce. We make the hypothesis that this is because those systems take into account the needs of individuals and groups, but ignore the requirements inherent in their use in a classroom. In this work, we present a computer system based on a paper and tangible interface that can be used at all three levels of interaction: individual, group, and classroom. We describe the current state of the interface design and why it is appropriate for classroom orchestration, both theoretically and through two examples for teaching geometry.</span></div></div><div class="paper" id="wp573"><a href="#wp573" class="title">Communication by Change in Taste</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979916&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hiromi  Nakamura</span> <span class="affiliation">Meiji University</span>, <br />
<span class="author">Homei  Miyashita</span> <span class="affiliation">Meiji University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we discuss the possibilities and enjoyment of communication by changes in taste, as well as the concept of expanding the sense of taste. When the tongue is electrically stimulated, it senses a characteristic taste. We developed various apparatuses to change the taste of food and drinks based on this effect . An apparatus for drinks, comprising two electrically conducting straws, is used to change the taste of the drink by the formation of an electrical circuit inside the mouth only when drinking by holding both straws in the mouth. In the case of two persons each having one straw in their mouths, shaking hands causes electricity to flow, resulting in the change in taste. With a chopsticks/fork type of apparatus, the taste changes by the electric current that flows through the human body when one person helps the other to eat. In the case of both types of apparatuses, it is possible to control the voltage by a PWM(pulse width modulation) and the pattern by a relay, and a variety of tastes can be produced by a personal computer.</span></div></div><div class="paper" id="wp589"><a href="#wp589" class="title">The Effects of Spatial Layout and View Control on Cognitive Processing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979921&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eric D Ragan</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Alex  Endert</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Doug A Bowman</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Francis  Quek</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study explores how spatial layout and view control impact learning. We performed a controlled experiment using a learning activity involving memory and comprehension of a visually represented story. We present our preliminary results comparing performance between a slideshow-type presentation on a single monitor and a spatially distributed presentation among multiple monitors, and method of view control (automatic and interactive). With the distributed layout, participants maintained better memory of the associated locations where information was presented. However, performance scores were significantly better for the slideshow presentation than for the distributed layout for the learning task.</span></div></div><div class="paper" id="wp414"><a href="#wp414" class="title">Initial Results from a Study of the Effects of Meditation on Multitasking Performance</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979862&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David M. Levy</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alfred W. Kaszniak</span> <span class="affiliation">University of Arizona</span>, <br />
<span class="author">Marilyn  Ostergren</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports initial results from a study exploring whether training in meditation or relaxation can improve office workers&#8217; ability to multitask on a computer more effectively and/or with less stress. Human resource (HR) personnel were given 8 weeks of training in either mindfulness meditation or body relaxation techniques, and were given a stressful multitasking test both before and after training. (A third group, a control group, received no intervention during the 8-week period but was tested both before and after this period.) Results indicate that overall task time and errors did not differ significantly among the three groups. However, the meditation group reported lower levels of stress and showed better memory for the tasks they had performed; they also switched tasks less often and remained focused on tasks longer.</span></div></div><div class="paper" id="wp436"><a href="#wp436" class="title">VORTEX: Design and Implementation of an Interactive Volumetric Display</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979870&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abhijit  Karnik</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Archie  Henderson</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Andrew  Dean</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Howard  Pang</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Thomas  Campbell</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Satoshi  Sakurai</span> <span class="affiliation">Osaka University</span>, <br />
<span class="author">Guido  Herrmann</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Shahram  Izadi</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Yoshifumi  Kitamura</span> <span class="affiliation">Tohoku University</span>, <br />
<span class="author">Sriram  Subramanian</span> <span class="affiliation">University of Bristol</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">True 3D display systems like volumetric displays allow generation of autostereoscopic, multi-view 3D content that has real physical dimensions. However their uptake as a research tool within the HCI community is limited largely due to difficulties in buying or building such displays. The choice of commercially available systems is limited and constrains the flexibility of their use in terms of interaction capabilities, display features and integration with multi-display environments (MDEs). In this paper we describe the steps involved in creating custom volumetric display from easily available components. By building a touch-enabled volumetric display we walk-through the steps involved in the process. This will enable us to explore various interactive systems, associated techniques and challenges related to integration of the device into a MDE.</span></div></div><div class="paper" id="wp613"><a href="#wp613" class="title">Socially-Interactive Dressing Room: An Iterative Evaluation on Interface Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979925&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jasy Suet Yan  Liew</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">Elizabeth  Kaziunas</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">JianZhao  Liu</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">Shen  Zhuo</span> <span class="affiliation">Syracuse University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the formative user interface design of a socially-interactive dressing room. The socially-interactive dressing room allows shoppers to talk to their friends in real time for opinions on their garment purchasing decisions. Our work is motivated by the observation that shoppers who lack fashion sense often rely on their friends&#8217; opinions when making garment purchasing decisions. Using the iterative user interface design methodology, we conducted a mini focus group and interviews among male and female shoppers to refine the user interface design. Our findings suggest that an iterative approach proves to be useful in uncovering and addressing usability, aesthetics, and trust issues that arise from incorporating a socially-interactive system within a dressing room context.</span></div></div><div class="paper" id="wp623"><a href="#wp623" class="title">Next Step in Electronic Brainstorming: Collaborative Creativity with the Web</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979929&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lassi A Liikkanen</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Kai  Kuikkaniemi</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Petri  Lievonen</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Pauli  Ojala</span> <span class="affiliation">Helsinki Institute for Information Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Brainstorming is an essential technique in creative group work. Research literature indicates the strengths of electronic brainstorming over face-to-face work. Despite this evidence, the old practice dominates. We believe that this is due to the inadequate integration of new tools to existing practices and the tendency to focus on idea production alone. This paper explores how to augment traditional, collocated Brainstorming and make electronic brainstorming feasible and accessible with web-based technology. We introduce an electronic brainstorming application prototype and justify its design principles. Our system aimed at facilitating conceptual design and we present design insights from a pilot study with the prototype used by 27 design students. The paper argues that by structuring the generative group process with a low-cost tool, users can sprint through a creative process, from problem definition to defining a solution.</span></div></div><div class="paper" id="wp635"><a href="#wp635" class="title">ViewSer: A Tool for Large-Scale Remote Studies of Web Search Result Examination</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979936&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dmitry  Lagun</span> <span class="affiliation">Emory University</span>, <br />
<span class="author">Eugene  Agichtein</span> <span class="affiliation">Emory University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Web search behavior studies, including eye-tracking studies of search result examination, have resulted in numerous insights to improve search result quality and presentation. Yet, these studies have been severely restricted in scale, due to the expense and effort required. We propose a novel methodology for crowdsourcing web search behavior studies &#8211; specifically focusing on performing large-scale studies of result examination behavior. We present a viewport-based examination interface (ViewSer), which enables remotely tracking searcher examination behavior, without requiring eye tracking equipment. We show that ViewSer induces similar viewing and clickthrough behavior, compared to in-lab users monitored with eye tracking, in a study with over 100 remote participants. ViewSer is a first step towards large-scale behavioral evaluation of web search, which would help improve web search result presentation, result ranking, and ultimately improve the web search experience overall.</span></div></div><div class="paper" id="wp368"><a href="#wp368" class="title">Who Said Monitoring Is Boring?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979849&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pradeep  Buddharaju</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Dvijesh  Shastri</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Anitha  Mandapathi</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Swati  Vaidya</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Ioannis  Pavlidis</span> <span class="affiliation">University of Houston</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this article, we extend our previous work [1], which blended gaming in monotonous security tasks to increase operator engagement and enjoyment. Specifically, we expand from a single game presented in [1] to an assortment of games that appeal to different tastes. These include a shooting game, a racket game, and two puzzle games. All games are designed in a way that attracts instead of detracting attention to the monitoring screens. In addition to the game set, we also include a web browser capability symbiotic to the monitoring task. All these applications are tested in a quite realistic pilot experiment, where subjects are monitoring live security feeds. This is in contrast to the experiment on a pre-recorded video feed reported in [1]. The results demonstrate that subject engagement and enjoyment is significantly higher when the monitoring task is multiplexed with imaginative interactive options. This improvement in job satisfaction is achieved without sacrificing performance, as measured by detection of suspicious activities.</span></div></div><div class="paper" id="wp637"><a href="#wp637" class="title">SoundVision: Graphic Communication Method for Blind Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979938&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chaochao  Chen</span> <span class="affiliation">Kunsthochschule Berlin-Weissensee</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Parallel visual data acquisition is not available to blind. Yet, sequential tactile scanning (e.g. white cane) allows them to form mental concepts of their surroundings, albeit slower. The purpose of this project is to demonstrate that acoustic serial scanning of graphical objects allows a blind user to form mental concepts and to reproduce these objects graphically. Moreover, this system is designed to enable blind users to obtain graphic information and express their visual ideas graphically through sound.</span></div></div><div class="paper" id="wp423"><a href="#wp423" class="title">Turkomatic: Automatic Recursive Task and Workflow Design for Mechanical Turk</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979865&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anand P Kulkarni</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Matthew  Can</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Bjoern  Hartmann</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Completing complex tasks on crowdsourcing platforms like Mechanical Turk currently requires significant up-front investment into task decomposition and workflow design. We present a new method for automating task and workflow design for high-level, complex tasks. Unlike previous approaches, our strategy is recursive, recruiting workers from the crowd to help plan out how problems can be solved most effectively. Our initial experiments suggest that this strategy can successfully create workflows to solve tasks considered difficult from an AI perspective, although it is highly sensitive to the design choices made by workers.</span></div></div><div class="paper" id="wp404"><a href="#wp404" class="title">My Mobile Story: Therapeutic Storytelling for Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979860&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mark  Matthews</span> <span class="affiliation">Trinity College</span>, <br />
<span class="author">Gavin  Doherty</span> <span class="affiliation">Trinity College</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes the design, evaluation and rationale behind a multimedia message service (MMS) based therapeutic system for adolescents attending therapy. The mobile phone is used to assist clients in engaging with therapy through the completion of structured therapeutic tasks. Content is gathered by the client with the phone, and browser-based software is then used to structure the content during a face-to-face therapeutic session. We discuss initial findings including the potential for engaging clients in remote therapeutic activities and the importance of client control over access to their content. We also consider several practical issues concerning the design and evaluation of software to be used in clinical settings.</span></div></div><div class="paper" id="wp550"><a href="#wp550" class="title">A Long-term Study of User Experience towards Interaction Designs that Support Behavior Change</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979909&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sang-Su  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Kun-pyo  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many researches on interaction design that supports users&#8217; behavior change in everyday life are studied recently especially in the domain of pervasive technology. However, not much attention has been paid to long-term effects on users in such cases. This paper presents our initial work of a long-term (8 month) study of users' self-report of experiences with an ambient dashboard feedback system in an automobile called Eco-driving system. It was notable that user satisfaction changed positively following active self-efforts made by users to understand the system after the negative shift due to initial disappointment. This work will be a first step to build a framework of how users accept systems designed to persuade them to change behavior over time.</span></div></div><div class="paper" id="wp600"><a href="#wp600" class="title">Bridging the Gap: Implementing Interaction Through Multi-User Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979922&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tom  Bartindale</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Rachel  Clarke</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Madeline  Balaam</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe an interactive museum installation designed to extend visitor participation through personal reflection and contribution. The case study describes design approaches, which focused on multiple individual simultaneous use, which we describe as multi-user design. These approaches were deployed to support the visitor moving from viewer to contributor in a temporary museum exhibition. We present the anticipated use and early analysis of some of the data from actual use of the system. We outline our initial findings for the opportunities and limits in designing for personalised user-generated content through such approaches within museums and suggest areas of future work on qualities of participation and visitor contribution.</span></div></div><div class="paper" id="wp508"><a href="#wp508" class="title">Informing Design by Recording Tangible Interaction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979893&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Augusto  Esteves</span> <span class="affiliation">Madeira Interactive Technologies Institute</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Evaluating tangible user interfaces is challenging. Despite the wealth of research describing the design of tangible systems, there is little empirical evidence highlighting the benefits they can confer. This paper presents a toolkit that logs the manipulation of tangible objects as a step towards creating specific empirical methods for the study of tangible systems. The paper argues that the data derived from toolkit can be used in three ways. Firstly: to compare tangible interaction with other interaction paradigms. Secondly: to compare among different tangible interfaces performing the same tasks. Thirdly: via integration into a structured design process. This paper focuses on this last topic and discusses how detailed data regarding object use the data could be integrated into classifications and frameworks such as the Shaer&#8217;s et al&#8217;s TAC paradigm.</span></div></div><div class="paper" id="wp354"><a href="#wp354" class="title">Effect of Levels of Automation on Emotional Experience in Intelligent Products</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979846&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Moon-Hwan  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Tek-Jin  Nam</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Hyeon-Jeong  Suk</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many scientists and engineers have researched how to apply automation technology to intelligent products. Emotional experiences in products have been considered as important factors for users&#8217; satisfaction as well. With users&#8217; emotions in mind, it is necessary to consider whether automated products indeed provide humans with emotionally satisfying experiences. In this paper, we investigated how different levels of automations affect users&#8217; experiences from an emotional point of view. Through experiments, effects of cognitive automation and motor automation were explored. The paper concludes with recommendations for applying automation technologies to intelligent products.</span></div></div><div class="paper" id="wp422"><a href="#wp422" class="title">A Cultural Knowledge-based Method to Support the Formation of Homophilous Online Communities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979864&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Junia C Anacleto</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Fernando C Balbino</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Andre O Bueno</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Gilberto O Astolfi</span> <span class="affiliation">Federal University of S&#227;o Carlos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We propose a three-step method to identify people in social networks sites (SNS) who are talking about the same topics, even though they may be from different cultural backgrounds. Our method uses a cultural knowledge base from the OMCS-Br project to normalize cultural differences and find common interest among users based on statements they make various topics in a SNS. We evaluated three initial phrases that were used to search for sentences in a large social network using the cultural translation; we found that 81% of the retrieved sentences were judged to be related to the initial phrases. Thus, we have evidence that cultural normalization can support finding people talking about the same topic in a SNS even when they have different ways of saying the same thing. We believe that these culturally translated similarities can be used in a recommender system to contribute to the formation of homophilous online communities.</span></div></div><div class="paper" id="wp455"><a href="#wp455" class="title">Listening to the Community: Social Media Monitoring Tasks for Improving Government Services</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979878&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cecile  Paris</span> <span class="affiliation">CSIRO</span>, <br />
<span class="author">Stephen  Wan</span> <span class="affiliation">CSIRO</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a preliminary analysis of the tasks and information needs of users performing social media monitoring to improve government services.  In general, our aim is to explore how text analysis tools can support a social media monitoring task in the government context.  We find that, in this context, social media monitoring is a complex activity. Social media monitors not only perform traditional media monitoring tasks, but they also take specific actions to provide an improved service, predominantly by checking and vetting information contributed by the wider online community.  In our analysis, we found a number of specific information-based actions performed in order to determine how one should respond to a particular social media post. <br /></span></div></div><div class="paper" id="wp489"><a href="#wp489" class="title">Introducing VERO: Visual Experiential Requirements Organizer</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979886&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Agnieszka  Szostek</span> <span class="affiliation">Interactive Technologies Laboratory Institute for Information Processing (OPI)</span>, <br />
<span class="author">Evangelos  Karapanos</span> <span class="affiliation">Madeira Interactive Technologies Institute Universidade da Madeira</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crucial to the advancement of the User Experience field is the ability to understand product qualities as perceived by users. Therefore we would like to introduce VERO (Visual Experiential Requirements Organizer), an online tool for the structured elicitation of users' perceptions of a given stimulus such as a product, a system or a concept. Contrary to the existing elicitation methods, VERO aims to enable users to freely express opinions about qualities relevant for a given stimulus; to indicate the importance of each quality without imposing a hierarchical order and to cluster related qualities according to users' own perception regarding the strength of the link between them. In this paper we also motivate our approach in developing VERO and sketch our research agenda regarding its validation and application in the field of User Experience.</span></div></div><div class="paper" id="wp491"><a href="#wp491" class="title">The Online Privacy Paradox: A Social Representations Perspective</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979887&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marie Caroline  Oetzel</span> <span class="affiliation">Institute for Management Information Systems, Vienna University of Economics and Business</span>, <br />
<span class="author">Tijana  Gonja</span> <span class="affiliation">Institute for Management Information Systems, Vienna University of Economics and Business</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present early results from a study, which aims at understanding the privacy paradox from a social representations perspective. After identifying adequate stimulus words with the help of a preliminary study, we conducted the main study using an online questionnaire. Participants were instructed to associate freely to the given stimulus words. The results of the polarity and sequence analysis of the associations provide a first valuable insight into the social representations of online privacy.</span></div></div><div class="paper" id="wp506"><a href="#wp506" class="title">Investigating Syntactic Alignment in Spoken Natural Language Human-Computer Communication</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979892&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Benjamin R. Cowan</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Russell  Beale</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Holly P. Branigan</span> <span class="affiliation">The University of Edinburgh</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes planned experiment-based research observing the existence of syntactic alignment in natural language computer interactions. This research will achieve this through using a computer-human version of the confederate communication task commonly used in psycholinguistic research observing syntactic alignment in human-human dialogue. The motivations of the work lie in observing the existence of syntactic alignment in human-computer dyads and how the naturalness of interaction affects the appearance of such a linguistic phenomenon. The work will also aim to identify how such a linguistic effect links to users&#8217; satisfaction and quality judgments of interaction.</span></div></div><div class="paper" id="wp524"><a href="#wp524" class="title">Mixing Psychology and HCI in Evaluation of Augmented Reality Mental Health Technology</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979898&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Maja  Wrzesien</span> <span class="affiliation">Universidad Polit&#233;cnica de Valencia</span>, <br />
<span class="author">Jean-Marie  Burkhardt</span> <span class="affiliation">Universit&#233; Paris Descartes</span>, <br />
<span class="author">Mariano  Alca&#241;iz Raya</span> <span class="affiliation">Universidad Polit&#233;cnica</span>, <br />
<span class="author">Cristina  Botella</span> <span class="affiliation">Universidad Jaume I</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent studies present Augmented Reality Exposure Therapy (ARET) as a potentially effective technology in the Mental Health (MH) field. This study evaluates the ARET system applied to treatment of cockroach phobia in a clinical setting. The results seem to show that the ARET system is useful in helping the therapist construct a therapeutic relationship with the client. ARET also produces a visible reduction in the clients&#8217; clinical measures. Possible implications in terms of future design and evaluation methodologies are discussed.</span></div></div><div class="paper" id="wp547"><a href="#wp547" class="title">A Fitt of Distraction: Measuring the Impact of Distracters and Multi-users on Pointing Efficiency</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979908&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Denis  Lalanne</span> <span class="affiliation">University of Fribourg</span>, <br />
<span class="author">Agnes  Lisowska Masson</span> <span class="affiliation">University of Fribourg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents the results of an experiment aimed at measuring the impact of the number of distracters and of co-located users on individual pointing efficiency. The experiment, performed with 20 users, is a variation of a Fitt&#8217;s Law test in which we incrementally augmented the number of distracters on the screen and the number of co-located users. The results show that the number of distracters clearly influences users&#8217; pointing performance. Further, it shows that users are more efficient at pointing items when they share the display with co-located users than when they are alone.</span></div></div><div class="paper" id="wp561"><a href="#wp561" class="title">What Do You See When You Interact with Friends Online? Face, Hand, or Canvas?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979911&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyle  Koh</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Hyunjoo  Song</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Daekyoung  Jung</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Bohyoung  Kim</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Jinwook  Seo</span> <span class="affiliation">Seoul National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">People use plethora of interactive remote conference tools for various tasks ranging from collaborative works to entertainment needs. The tasks are often distinguishable in terms of their types and users' usage patterns. We present a preliminary user study designed to explore the different usage patterns derived by performing different types of tasks. In this study, 18 people used an interactive remote conference tool for three types of tasks; Collaborative Creation, Cooperative Problem Solving, and Competitive Game Play with different screen configurations. We analyzed usage patterns using an eye-tracker as well as the result from post experimental questionnaire. We found that different tasks resulted in different gaze patterns. We also present an interesting finding on how users mistakenly report the use of the tool by contrasting the result with the questionnaire and eye-tracking log.</span></div></div><div class="paper" id="wp558"><a href="#wp558" class="title">Digital Mind Mapping: Innovations for Real-time Collaborative Thinking</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979910&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Honray  Lin</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Haakon  Faste</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the development of a new digital mind mapping tool for future research on interactive knowledge management systems, specifically with regard to real-time collaborative thinking. We have evaluated numerous existing mind mapping software applications, and performed ethnographic research with a variety of users, to develop a framework of principles to guide the design of future idea generation and management systems. Our findings indicate a rich opportunity space for digital mind mapping tools, particularly in the areas of facilitating collaboration and information storage and retrieval.</span></div></div><div class="paper" id="wp374"><a href="#wp374" class="title">Design Your Room: Adding Virtual Objects to a Real Indoor Scenario</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979851&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rui  N&#243;brega</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Nuno  Correia</span> <span class="affiliation">Universidade Nova de Lisboa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an interior design application that uses photos from real indoor spaces and rooms as input. The user is encouraged to take a picture of a certain place and virtually reshape it with furniture, different colors, textures and materials. The system analyses the still image of the physical space through image processing and computer vision algorithms to detect the world orientation relative to the camera. Knowing this, it is possible to create a natural interface where objects are laid on the floor and pushed around as in real life.</span></div></div><div class="paper" id="wp627"><a href="#wp627" class="title">Programming on the Move: Design Lessons from IPRO</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979932&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Berland</span> <span class="affiliation">University of Texas at San Antonio</span>, <br />
<span class="author">Taylor  Martin</span> <span class="affiliation">University of Texas at Austin</span>, <br />
<span class="author">Tom  Benton</span> <span class="affiliation">University of Texas at Austin</span>, <br />
<span class="author">Carmen  Petrick</span> <span class="affiliation">University of Texas at Austin</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computer programming is often a stationary, solitary task; such tasks do not work well for most novices. This work describes the IPRO project that uses our 'Programming Standing Up' framework (PSU) to reframe programming as a mobile, social game. IPRO is a programming and simulation environment for iOS in which a learner programs a virtual robot to play soccer in a virtual space shared with her cohort. This work presents examples of secondary school students learning with IPRO. We then connect the examples to PSU design principles and evaluate those principles in terms of the examples.</span></div></div><div class="paper" id="wp630"><a href="#wp630" class="title">PMRI: Development of a Pictorial Mood Reporting Instrument</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979933&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Martijn  Vastenburg</span> <span class="affiliation">Delft University of Technology</span>, <br />
<span class="author">Natalia  Romero Herrera</span> <span class="affiliation">Delft University of Technology</span>, <br />
<span class="author">Daniel  Van Bel</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Pieter  Desmet</span> <span class="affiliation">Delft University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mood capturing techniques are being used in research settings (e.g., lab evaluation and experience sampling) and to facilitate mood communication in mediated interaction (e.g., instant messaging and blogging). Instruments currently available tend to be either limited in expression or overly demanding. In this paper we describe our work-in-progress on the development of PMRI, a rich and easy-to-use pictorial mood-reporting instrument.</span></div></div><div class="paper" id="wp632"><a href="#wp632" class="title">Evaluating a Social Media Application for Sustainability in the Workplace</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979935&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Lehrer</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Janani  Vasudev</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The goal of this research is to investigate the benefits of using a web-based social network to promote energy awareness, and influence energy-saving behavior of typical office workers. We propose that a social network integrated into the workplace environment &#8212; allowing people to track their own energy-related activities, to share this information, and to view and react to peers&#8217; activities &#8212; can take advantage of social influence to positively affect behavior. We are currently developing a prototype of such an application through iterative design. In the final phase of this work we will conduct experiments with a large number of subjects to test the ability of this application to influence attitudes and behaviors of office workers, and for providing a platform for commercial building operators to better communicate with occupants.</span></div></div><div class="paper" id="wp636"><a href="#wp636" class="title">Constructing Scientific Arguments with User Collected Data in Nomadic Inquiry</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979937&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Kuhn</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Brenna  McNally</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Clara  Cahill</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Chris  Quintana</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Elliot  Soloway</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mobile devices now enable students to engage in nomadic inquiry as they collect large amounts of data from the environment to answer scientific questions. To support them with constructing scientific arguments, we created CogniBits: a system designed for tablet devices that scaffolds students through creating scientific arguments with user-collected data. The system was iteratively designed with two students and seeks to address the additional challenges these opportunities bring to science inquiry.</span></div></div><div class="paper" id="wp570"><a href="#wp570" class="title">Constructing Virtual 3D Models with Physical Building Blocks</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979915&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ricardo  Jota</span> <span class="affiliation">Inesc-ID</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Constructing virtual 3D models typically requires specialized desktop modeling tools (e.g., CAD tools), which, while very powerful, tend to require a lot of precision, time, and expertise from the user. We present StereoBlocks, a system that combines a Kinect depth camera with 3D stereoscopic projector to allow the user to build complex virtual 3D models from available physical objects. By treating the camera information as a continuous 3D digitizer, we are able to capture the details of the real world and re-project virtual objects side-by-side to real objects. The user is able to visualize such mixed reality model through stereoscopic projected imagery tightly aligned with the real world. In our system, it is literally possible to build the entire virtual castle, using only a single physical brick piece. We discuss our prototype implementation and report on early feedback from the four users that evaluated our system.</span></div></div><div class="paper" id="wp655"><a href="#wp655" class="title">Senior Wellness: Practices of Community Senior Centers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979946&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Young Seok  Lee</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Santosh  Basapur</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Shirley  Chaysinh</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Crysta  Metcalf</span> <span class="affiliation">Motorola Mobility Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In the U.S., approximately 15,000 community senior centers provide a broad spectrum of programs for seniors to increase their overall health and wellness in their community. Although previous studies reported on the various benefits of participation in such programs, little research has been conducted to understand how technology can support this practice. We initiated a research study to understand the current practices of senior centers and their potential technology needs. In this article, we describe findings from our literature review as well as a field study with nine senior centers located in urban and suburban areas of Chicago, IL, and Tampa, FL. Based on the preliminary results, we share design implications for future technology development.</span></div></div><div class="paper" id="wp439"><a href="#wp439" class="title">Effect of MobileASL on Communication Among Deaf Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979872&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joy  Kim</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jessica J Tran</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Tressa W Johnson</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Richard  Ladner</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Eve  Riskin</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">MobileASL, a software program enabling sign-language video on mobile devices over conventional U.S. cellular networks, was evaluated in a three-week field study during the summer of 2010. Through a series of interviews, questionnaires, and a focus group, we asked participants about their behavior with and perceptions of MobileASL. In addition, we used on-device experience sampling and usage logging to observe how MobileASL was used. Initial results indicate that although participants felt that MobileASL&#8217;s short battery life limited its use, participants took advantage of the mobility of the technology and used it for in-the-moment information gathering in places like buses, restaurants, and shopping areas.</span></div></div><div class="paper" id="wp588"><a href="#wp588" class="title">Towards a Psychographic User Model From Mobile Phone Usage</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979920&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rodrigo  de Oliveira</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Alexandros  Karatzoglou</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Pedro  Concejero Cerezo</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Ana  Armenta Lopez de Vicu&#241;a</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Nuria  Oliver</span> <span class="affiliation">Telefonica Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Knowing the users&#8217; personality can be a strategic advantage for the design of adaptive and personalized user interfaces. In this paper, we present the results of a first trial conducted with the aim of inferring people&#8217;s personality traits based on their mobile phone call behavior. Initial findings corroborate the efficacy of using call detail records (CDR) and Social Network Analysis (SNA) of the call graph to infer the Big Five personality factors. On-going work includes a large-scale study that shall refine the accuracy of the models with a reduced margin of error.</span></div></div><div class="paper" id="wp450"><a href="#wp450" class="title">Mourning Tree : Space Interaction Design for the Commemoration Ceremony</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979876&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jihwan  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">seyong  kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">JINJU  YU</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Sangsup  Yoon</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Sangki  Han</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The aim of this project is to improve the current culture of cherishing the memory of a deceased person through a new approach over the traditional, a cyber commemoration method. Through a preliminary research, we defined two major problems of current commemoration ceremony: separation between traditional cherish and cyber cherish, immaturity of cyber cherish method. Therefore, we focused on making a new way of commemoration, &#8216;Mourning Tree&#8217;. Mourning Tree is a digital tree which is displayed by holographic technology, and the tree can receive messages from the cherisher in the many ways (SNS, SMS, e-mail). The message is displayed as a leaf of the tree, and the more messages this tree receives, the larger and more meaningful the tree becomes. Because of the exhibition of Mourning Tree in actual cherishing area, it can not only physically interact but virtually interact with the cherisher. We developed a prototype of the Mourning Tree and conducted an examination.</span></div></div><div class="paper" id="wp576"><a href="#wp576" class="title">Medical Record Privacy: Is it a Facade?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979918&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aubrey  Baker</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Laurian  Vega</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Tom  DeHart</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Steve  Harrison</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Part of the job of healthcare providers is to manage patient information. Most is routine, but some is sensitive. For these reasons physicians&#8217; offices provide a rich environment for understanding complex, sensitive information management issues as they pertain to privacy and security. In this paper we present findings from interviews and observations of 15 offices in rural-serving southwest Virginia. Our work demonstrates how the current socio-technical system fails to meet the security needs of the patient. In particular, we found that the tensions between work practice and security, and between electronic and paper records resulted in insecure management of files.</span></div></div><div class="paper" id="wp618"><a href="#wp618" class="title">Behavioral Science-Informed Technology Interventions for Change in Residential Energy Consumption</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979926&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Crowley</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Aur&#233;lia  Heitz</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Annika  Matta</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Kevin  Mori</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Banny  Banerjee</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Behavior change represents an important new approach to addressing the energy crisis.  Utility companies and private companies are deploying sensor-based power meters and related residential electricity monitoring technologies with the view that monitoring energy use will eventually result in a reduction in energy consumption.  The success of these technologies depends largely on homeowners responding to the data with appropriate changes in their consumption behavior. Most energy feedback interfaces, however, have not been designed through a human-centered process and display data in ways that are unlikely to change behavior.  Our proposal is to design interactive interfaces that combine a deeply human-centered process with insights from behavioral economics to reduce residential energy consumption.  This paper describes our current research to develop and evaluate interactive interfaces based on three motivational categories:  cognitive, social, and affective.</span></div></div><div class="paper" id="wp451"><a href="#wp451" class="title">Technology-Mediated Parent-Child Intimacy: Designing for Ecuadorian Families Separated by Migration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979877&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marisol  Wong-Villacres</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study explores the role technology plays in supporting long-distance relationships of migrant parents and left-behind children in developing countries such as Ecuador, in order to inform the design of technology that better suits their affective needs and their context&#8217;s constraints. We derived three design principles based on our fieldwork in Ecuador: shared experience, the empowerment of children to self-express and children&#8217;s need to safely build a private communication channel with their parents. We report our research findings and propose a set of design concepts for future work.</span></div></div><div class="paper" id="wp653"><a href="#wp653" class="title">Power Ballads: Deploying Aversive Energy Feedback in Social Media</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979944&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Derek  Foster</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Conor  Linehan</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Shaun  Lawson</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Ben  Kirman</span> <span class="affiliation">University of Lincoln</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports on the pilot evaluation of &#8220;Power Ballads&#8221;, an evocative social media application which displays aversive feedback based on excessive household energy usage. Work by other researchers in persuasive technologies has previously suggested the use of aversive feedback should be avoided as it leads to a lack of engagement by users. This work evaluates whether punishment of non-desirable behaviour discourages users from engaging with a persuasive application. To this end we recruited 9 households to use the Power Ballads application over a period of 4 weeks. We found the use of aversive feedback did not act as a deterrent to regularly interacting with the application through evaluating user engagement.</span></div></div><div class="paper" id="wp611"><a href="#wp611" class="title">Interpersonal Informatics: Making Social Influence Visible</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979924&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth  Bales</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">William  Griswold</span> <span class="affiliation">University of California, San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent research in social network science has found that that what we do and say flows through our social network, impacting our friends, our friends&#8217; friends, and beyond. Likewise, our own personal choices are also the influenced by the social networks we participate in. We introduce the area of interpersonal informatics, a class of tools that allows groups of people to collect, aggregate, analyze, and share personally relevant information. The goal of interpersonal informatics is to  help people gain awareness of how those around them affect their habits, beliefs, and health.</span></div></div><div class="paper" id="wp642"><a href="#wp642" class="title">Evoked Friction on a Smooth Touch Device</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979939&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Creating realistic virtual friction forces requires using complex hardware setups. In simpler mobile systems, friction is often suggested by mimicking textures with vibration, based on the position on the screen. Even in the simplest implementations, this paper proposes that force sensing should also be used to modulate vibration. In this way, Coulomb&#8217;s model of friction can be better emulated and it can lead to conclude more easily that friction is the origin of the vibration. A proof-of-concept prototype is described, which received positive first impressions regarding improved user experience. A follow up study is warranted.</span></div></div><div class="paper" id="wp510"><a href="#wp510" class="title">Robotic Wheelchair Moving with Caregiver Collaboratively Depending on Circumstances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979894&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yoshinori  Kobayashi</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Yuki  Kinpara</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Erii  Takano</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Yoshinori  Kuno</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">keiichi  Yamazaki</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Akiko  Yamazaki</span> <span class="affiliation">Tokyo University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper introduces a robotic wheelchair that can automatically move alongside a caregiver. Because wheelchair users are often accompanied by caregivers, it is vital to consider how to reduce a caregiver&#129;fs load and support their activities, while simultaneously facilitating communication between the caregiver and the wheelchair user. Moreover, it has been pointed out that when a wheelchair user is accompanied by a companion, the latter is inevitably seen by others as a caregiver rather than a friend. To address this situation, we devised a robotic wheelchair able to move alongside a caregiver or companion, and facilitate easy communication between them and the wheelchair user. To confirm the effectiveness of the wheelchair in real-world situations, we conducted experiments at an elderly care center in Japan.</span></div></div><div class="paper" id="wp424"><a href="#wp424" class="title">A collective map to capture human behavior for the design of public spaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979866&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mizuki  Oka</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Tom  Hope</span> <span class="affiliation">Tokyo Institute of Technology</span>, <br />
<span class="author">Yasuhiro  Hashimoto</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Ryoko  Uno</span> <span class="affiliation">Tokyo University of Agriculture and Technology</span>, <br />
<span class="author">Myeong-Hee  Lee</span> <span class="affiliation">Design office matt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores potential uses of publicly created behavioral data for spatial (re)design. The widespread use of mobile devices and access to the Internet has made spontaneous sharing of information about one&#8217;s life increasingly common. These emerging trends of pervasive life logging and sensing in communal space provoke new opportunities for designers and architects. This paper reports on work in progress, introducing a set of tools to support spatial design via the collection and analysis of human behavior using Twitter, and presents the result of a workshop using the tools in a university library in Japan. We offer ways to analyze and visualize the data and discuss what we can observe from the collected data that may be useful for designing such communal spaces.</span></div></div><div class="paper" id="wp528"><a href="#wp528" class="title">How Revealing are Eye-Movements for Understanding Web Engagement in Young Children?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979900&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stacey  Birkett</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Adam  Galpin</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Simon  Cassidy</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Lynne  Marrow</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Sarah  Norgate</span> <span class="affiliation">University of Salford</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents a critical review of eye tracking as a research approach and evaluates its potential for usability testing in pre-school children. We argue that eye-tracking data is useful for assessing web engagement in this age-group, but only if triangulated against other usability methods. Recommendations for potential usability methods to use in tandem with eye-tracking are presented as part of a work in progress within a joint partner project between the University of Salford (UK) and the British Broadcasting Corporation (BBC) exploring best-fit methodologies for understanding web engagement in young children.</span></div></div><div class="paper" id="wp657"><a href="#wp657" class="title">NICU-2-HOME: Supporting the Transition to Home from the Neonatal Intensive Care Unit using a Mobile Application</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979947&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Young Seok  Lee</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Craig  Garfield</span> <span class="affiliation">NorthShore University HealthSystem</span>, <br />
<span class="author">Noel  Massey</span> <span class="affiliation">Motorola Solutions Inc.</span>, <br />
<span class="author">Shirley  Chaysinh</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Sana  Hassan</span> <span class="affiliation">Motorola Mobility Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Parenting a Very Low Birth Weight (VLBW) premature infant in the Neonatal Intensive Care Unit (NICU) and transitioning this infant home can be very stressful for parents. Few studies, however, examined the needs of parents of VLBW infants during the transition to home; moreover, even less is known about information and communication technology strategies to support parents during the transition period. To address this knowledge gap, we are conducting a study that aims to develop a mobile application/service to support the parents of VLBW infants by enhancing communication with the NICU staff and access to information resources. We report findings from our preliminary study using contextual inquiry and phone interviews and discuss implications for system development.</span></div></div><div class="paper" id="wp543"><a href="#wp543" class="title">STORIFY- A Tool to Assist Design Teams in Envisioning and Discussing User Experience</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979905&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Berke  Atasoy</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Jean-Bernard  Martens</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Design is changing into an experience-oriented discipline; consequently designers need appropriate tools and methods to incorporate experiential aspects into their designs. A story is a crafted experience and storytelling is the craft. Therefore, understanding the structural strategies behind storytelling and learning how to incorporate them into a design process is relevant for designers when they want to envision, discuss and influence user experiences. In this paper we introduce STORIFY, a multi-modal tool to provide design teams with an experiential approach towards designing interactive products by incorporating dramaturgical techniques from film and sequential art.</span></div></div><div class="paper" id="wp415"><a href="#wp415" class="title">Context Stamp -  A Topic-based Content Abstraction for Visual Concordance Analysis</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979906&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">VinhTuan  Thai</span> <span class="affiliation">National University of Ireland, Galway</span>, <br />
<span class="author">Siegfried  Handschuh</span> <span class="affiliation">National University of Ireland, Galway</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Concordance analysis supports users in studying how terms are used in a document vs. another by investigating their usage contexts. As current approaches usually present a large set of contexts in their full text form or as a large frequency-based word cloud, they still require a lot of effort from users to make sense of the underlying complex and dynamic semantic dimensions of contexts. To address this limitation, we propose Context Stamp as a visual representation of the gist of a term's usage contexts. To abstract away the textual details and yet retain the core facets of a term's contexts for visualization, we blend a statistical topic modeling method with a combination of the treemaps and Seesoft visual metaphors. This paper provides a high level description of the text analysis method and outlines the visual design of Context Stamps.</span></div></div><div class="paper" id="wp652"><a href="#wp652" class="title">The Effects of Walking and Control Method on Pressure-Based Interaction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979943&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Graham  Wilson</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen A. Brewster</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Martin  Halvey</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pressure-based interactions have largely been limited to static scenarios; very few have focused on its use on mobile devices and even fewer have investigated the use of pressure while the user is in motion (i.e. walking). Pressure input is well suited to mobile interaction as mobile devices almost universally adopt touch and gestural input. This paper presents the initial results of research looking into the effects of walking on the application of pressure during linear targeting. Positional and rate-based (velocity) control methods are compared in order to determine which allows for more stable and accurate selections. Results suggest that rate-based control is superior for both mobile (walking) and static (sitting) linear targeting and that mobility significantly increases errors, selection time and subjective workload. These results will influence the design of a second part of the study, which will evaluate user ability to control the same application using only audio feedback.</span></div></div><div class="paper" id="wp376"><a href="#wp376" class="title">Flick-and-Brake: Finger Control over Inertial/Sustained Scroll Motion</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979853&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathias  Baglioni</span> <span class="affiliation">Telecom ParisTech - LTCI-CNRS, Alcatel Lucent Bell Labs</span>, <br />
<span class="author">Sylvain  Malacria</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span>, <br />
<span class="author">Eric  Lecolinet</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span>, <br />
<span class="author">Yves  Guiard</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present two variants of Flick-and-Brake, a technique that allows users to not only trigger motion by touch-screen flicking but also to subsequently modulate scrolling speed by varying pressure of a stationary finger. These techniques, which further exploit the metaphor of a massive wheel, provide the user with online friction control. We describe a finite-state machine that models a variety of flicking interaction styles, with or without pressure control. We report the results of a preliminary user study that suggests that for medium to long distance scrolling the Flick-and-Brake techniques require less gestural activity than does standard flicking. One of the two variants of the technique is faster, but no less accurate, than state-of-the-art flicking. Users also reported they preferred Flick-and-Brake over the standard flick and judged it more efficient. We indicate some pending issues raised by the results of this preliminary investigation.</span></div></div><div class="paper" id="wp626"><a href="#wp626" class="title">Retirees on Facebook: Can Online Social Networking Enhance Their Health and Wellness?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979931&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S. Shyam  Sundar</span> <span class="affiliation">The Pennsylvania State University, Sungkyunkwan University</span>, <br />
<span class="author">Anne  Oeldorf-Hirsch</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">Jon  Nussbaum</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">Richard  Behr</span> <span class="affiliation">The Pennsylvania State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An individual&#8217;s social network has a strong impact on his or her mental and physical health. This is of particular consequence for senior citizens who are at greater risk of social isolation after retirement, due to loss of spouse, mobility issues, and recent emphasis on aging in place, i.e., in smart homes. Can online social networking sites (SNSs) such as Facebook help alleviate social isolation of aging alone by enabling seniors to maintain high-quality social interactions? How can we make senior-friendly design improvements to SNSs? A preliminary national survey (N =168) of adults over 55 revealed that for those who had joined an SNS, the primary motivation cited for signing up was persuasion by a friend or family member, while non-users cited a strong lack of interest rather than a lack of knowledge or skill, with implications for theory and design of SNS technology for senior citizens.</span></div></div><div class="paper" id="wp625"><a href="#wp625" class="title">Multimodal Video Annotation for Contemporary Dance Creation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979930&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diogo  Cabral</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Ur&#226;ndia  Carvalho</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Jo&#227;o  Silva</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Jo&#227;o  Valente</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Carla  Fernandes</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Nuno  Correia</span> <span class="affiliation">Universidade Nova de Lisboa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents a video annotator that supports multimodal annotation and is applied to contemporary dance as a creation tool. The prototype, developed for Tablet PCs, explores bimanual interaction, using pen and touch input interfaces. This combination can be more natural and familiar than the traditional input interfaces (keyboard or mouse). Contemporary dance is a domain where this type of flexible interaction with video material is relevant in order to augment and improve the rehearsal and creative processes. Motion tracking is used to define the dynamic behavior of the annotations and voice input complements the other modalities. The paper describes the design decisions done by the multidisciplinary development team and the current status of the tool.</span></div></div><div class="paper" id="wp448"><a href="#wp448" class="title">Blink: Observing Thin Slices of Behavior to Determine Users&#8217; Expectation Towards Task Difficulty</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979875&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nuno  Branco</span> <span class="affiliation">School of Technology and Management of Felgueiras</span>, <br />
<span class="author">Jo&#227;o Pedro  Ferreira</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Marta  Noronha e Sousa</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Pedro  Branco</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Nuno  Otero</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Nelson  Zagalo</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Manuel Jo&#227;o  Ferreira</span> <span class="affiliation">University of Minho</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This work aims to address the following question: is it possible to infer the users' expectations regarding task difficulty by watching them just before the actual start?  <br /> We present a study where people acting as evaluators determined users&#8217; expectations based on non-linguistic social signals in a 20 seconds video clip. The evaluations were performed using a five-point scale and the average error of the evaluations was of one point. Preliminary results suggest what type of signals was used by the evaluators to determine the users&#8217; expected difficulty with the task.</span></div></div><div class="paper" id="wp545"><a href="#wp545" class="title">CheMO: Mixed Object Instruments and Interactions for Tangible Chemistry Experiments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979907&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyohyun  Song</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Gunhee  Kim</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Inkyu  Han</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Jeongyoung  Lee</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Ji-Hyung  Park</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Sungdo  Ha</span> <span class="affiliation">Korea Institue of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we present CheMO, a system for tangible chemistry experiments where users can interact with Mixed Object (MO) instruments that consist of a graspable physical part in the real world and a digital part in a virtual world. When used for an experiment, MO instruments enable users to employ tangible interaction methods inherited from real experience and to be given digital information similar to a physical expression arising from an actual experiment. The goal of our research is to enhance the sense of reality in a virtual experiment and to enable users to learn experimental procedures effectively and easily.</span></div></div><div class="paper" id="wp601"><a href="#wp601" class="title">TweetSpiration: Leveraging Social Media for Design Inspiration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979923&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Scarlett R Herring</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Christina M Poon</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Geoffrey A Balasi</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Brian P Bailey</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present TweetSpiration, a Web-based application that leverages social media to inspire new search directions on the Web. TweetSpiration can be used at any time, but it is particularly beneficial when designers have difficulty developing new search terms or are looking for new search directions. By visualizing socially derived word associations, designers may develop new search directions based on others comments or thoughts on the search topic. In an initial study, users reported that TweetSpiration helps develop new search directions and provides new perspectives on the design problem.</span></div></div><div class="paper" id="wp388"><a href="#wp388" class="title">An Investigation of Search Behaviour in a Tactile Exploration task for Sighted and Non-sighted Adults.</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979857&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luca  Brayda</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Claudio  Campus</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Ryad  Chellali</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Guido  Rodriguez</span> <span class="affiliation">University of Genoa</span>, <br />
<span class="author">Cristina  Martinoli</span> <span class="affiliation">Istituto David Chiossone onlus</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this work in progress we propose a new method for evaluating objectively the process of performing a tactile exploration with a visuo-tactile sensory substitution system. Both behavioral and neurophysiological cues are considered to evaluate the identification process of virtual objects and surrounding environments. Our experiments suggest that both sighted and visually impaired users integrated spatial information and developed similar behavioural and neurophysiological patterns. The proposed method could also serve as a tool to evaluate touch-based interfaces for application in orientation and mobility programs.</span></div></div><div class="paper" id="wp391"><a href="#wp391" class="title">Information Used and Perceived Usefulness in Evaluating Web Source Code Search Results</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979858&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rosalva E Gallardo-Valencia</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Susan E Sim</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Software developers frequently search for source code on the Web to solve problems. Their ability to correctly evaluate the matches returned by a source code search engine is key to the success of the search, and in turn the project. We conducted a laboratory experiment to gain understanding on the kinds of information used and their usefulness during the evaluation process. We found that the most used information was not perceived as the most useful information. We also identified three patterns for relationships among the frequency of information use, the likelihood of selecting the best match, and the time to complete a task.</span></div></div><div class="paper" id="wp446"><a href="#wp446" class="title">Tangible and Body-Based Interaction with Auditory Maps</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979874&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew P Milne</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa N Antle</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Bernhard E Riecke</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Blind people face a significant challenge navigating through the world, especially in novel environments. Maps, the most common of navigational aids, are of little use to the blind, who could benefit greatly from the information they contain. Recent work in auditory maps has shown the potential for delivering spatial information through sound.  Users control their position and orientation on a digitally enhanced map and listen for the location of important landmarks. Orientation control is important because sound localization cues can sometimes be ambiguous, especially when in front of and behind a listener. Previous devices have used a tangible interface, in which users manipulate a small motion tracked object, to allow users to control their position and orientation on a map. Motivated by research that has identified the importance of body-based cues, from the joints, muscles and vestibular system in spatial perception, we expanded on previous interfaces by constructing an auditory map prototype that allows users to control their orientation through natural head movements. A pilot study was conducted to compare the head-movement-based interface to a tangible interface.</span></div></div><div class="paper" id="wp442"><a href="#wp442" class="title">ScaleMirror: A Pervasive Device to Aid Weight Analysis</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979873&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew J Younge</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Vinod  Periasamy</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Mohammed  Al-Azdee</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">William  Hazlewood</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Kay  Connelly</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As today&#8217;s fast paced environment continually encourages poor dietary habits and a lack of exercise, there is a growing need to properly monitor and control weight gain.  With the advent of pervasive and ubiquitous computing, there are new opportunities to help promote personal wellness that was previously unobtainable.  This work describes the novel design and creation of ScaleMirror; a prototype pervasive device to help users monitor their weight.  This awareness is achieved through an accurate scale system, detailed statistics with historical data, and an intuitive design seamlessly embedded into a user&#8217;s existing daily routine.  The goal is to help a wide array of people concentrate on obtaining and maintaining a proper weight to promote a healthy and fulfilling lifestyle.</span></div></div><div class="paper" id="wp621"><a href="#wp621" class="title">CAESSA: Visual Authoring of Context-Aware Experience Sampling Studies</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979928&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mirko  Fetter</span> <span class="affiliation">University of Bamberg</span>, <br />
<span class="author">Maximilian  Schirmer</span> <span class="affiliation">Bauhaus-University Weimar</span>, <br />
<span class="author">Tom  Gross</span> <span class="affiliation">University of Bamberg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present a toolkit that enables HCI practitioners to visually author and setup Context-Aware Experience Sampling studies&#8212;CAESSA (Context-Aware Ex-perience Sampling Study Authoring).</span></div></div><div class="paper" id="wp631"><a href="#wp631" class="title">Integrating Touch and Near Touch Interactions for Information Visualizations</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979934&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aras  Balali Moghaddam</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Jeremy  Svendsen</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Melanie  Tory</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Alexandra  Branzan Albu</span> <span class="affiliation">University of Victoria</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper proposes a novel interaction paradigm for multi-touch interfaces, that integrates both touch and near-touch interactions. The paper describes the hardware prototype that we have built, as well as the computer vision approach that we propose for real-time hand tracking and differentiation between near-touch and touch events. We also present a case study showing how near-touch and touch interactions can be successfully integrated in an information visualization application.</span></div></div><div class="paper" id="wp643"><a href="#wp643" class="title">Supporting greater access to pre- and post-natal information and services for women in rural Kenya</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979940&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jakita  Thomas</span> <span class="affiliation">Spelman College</span>, <br />
<span class="author">Yolanda  Rankin</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Matthew  Tuta</span> <span class="affiliation">University of Nairobi</span>, <br />
<span class="author">Eric  Mibuari</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present initial findings of on-going work, which <br /> examine pre- and post-natal services available to <br /> women in rural Laare, Kenya as well as cell phone <br /> appropriation by service providers and consumers as <br /> initial steps in service design for access.</span></div></div><div class="paper" id="wp533"><a href="#wp533" class="title">Data Type Based Security Alert Dialogs</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979903&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Max-Emanuel  Maurer</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Alexander  De Luca</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Heinrich  Hussmann</span> <span class="affiliation">University of Munich</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Making users aware of insecure situations and behavior while browsing the Internet is a highly discussed and still difficult task. Both, passive and active warnings have their own specific disadvantages. While active warnings interrupt the current task and annoy the user, passive approaches often fail since they go unnoticed. In this work, we present first results of a concept displaying data type based alert dialogs whenever a user enters critical information into an online form. Such contextual dialogs appear right in the users&#8217; field of view representing a hybrid approach between active and passive warnings. An initial user study was conducted that showed a significant improvement of security awareness by participants that used the tool.</span></div></div><div class="paper" id="wp381"><a href="#wp381" class="title">Towards Context-Sensitive Support of Vitality in Old-Age</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979854&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominik  Jednoralski</span> <span class="affiliation">Max Planck Institute</span>, <br />
<span class="author">Michael  Schellenbach</span> <span class="affiliation">Max Planck Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Over the the last century, the average lifespan extended remarkably. The economic and social implications of living longer are vast, and include offering new prospects to make latent potential in old age accessible both to senior citizens and to society. <br /> Growing evidence suggests that the brain retains its capability to change from experience into old age, a finding that encourages targeting the elderly for interventions such as physical activity which is known to impact cognitive and neural decline. In this work we suggest intervening on the basis of these findings by means of intelligent assistive technology. Therefore, we propose a system architecture for a mobile context-aware cognitive assistant (CACA) to assess and enhance cognitive functioning of older individuals. In our view, tailored context-aware assistance can activate latent physical and cognitive potential through a combination of challenge and support, aimed at enhancing individual motivation to pursue a sustainable lifestyle.</span></div></div><div class="paper" id="wp647"><a href="#wp647" class="title">What Would the Parents Like to Know About Children but are Afraid to Ask?: Designing Reports about Child Development in Online Games</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979942&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karolina  Chmiel</span> <span class="affiliation">Institute for Information Processing</span>, <br />
<span class="author">Agnieszka  Matysiak Szostek</span> <span class="affiliation">Institute for Information Processing</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Nowadays educational games constitute a large part of <br /> the learning environment. These interactive forms of <br /> education enable children to develop various <br /> competencies and also provide feedback depicting their <br /> strengths and shortcomings. Currently, portals offering <br /> educational games provide such feedback mainly to <br /> children. Surprisingly, a parent, who is responsible for a <br /> proper development and education of a child, is usually <br /> not included as a recipient of information about the <br /> child&#8217;s results tested through games. Therefore, the <br /> goal of this preliminary study was to investigate the <br /> informational needs of the parents that can be applied <br /> to educational online games for children of age 6&#8212;9.</span></div></div><div class="paper" id="wp461"><a href="#wp461" class="title">Gathering Requirements for a Personal Health Management System</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979881&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Milewski</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Hector  Parra</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Applications are being designed to make health information available to the healthcare consumer. However, little is known about the support people need in using health information. We conducted semi-structured interviews to find out how people use health information to manage the chronic illness type-2 diabetes. We found that diabetics want to be motivated to treat the disease seriously and that the patient&#8217;s social network takes on additional work that is unrelated to their existing social role to support the patient&#8217;s health-related activities. Based on our findings, we propose a set of formative requirements to be included in the design of a personal health management system.</span></div></div><div class="paper" id="wp565"><a href="#wp565" class="title">Tag Clouds and Keyword Clouds: Evaluating Zero-Interaction Benefits</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979913&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathew J Wilson</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Max L Wilson</span> <span class="affiliation">Swansea University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Tag clouds are typically presented so that users can actively utilize community-generated metadata to query a collection. This research investigates whether such keyword clouds, and other interactive search metadata, also provide measureable passive support for users who do not directly interact with them. If so, then objective interaction-based measurements may not be the best way to evaluate these kinds of search user interface features. This paper discusses our study design, and the insights provided by a pilot study that led to a series of improvements to our study design.</span></div></div><div class="paper" id="wp568"><a href="#wp568" class="title">Causal Temporal Order in HCI</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979914&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Adam  Darlow</span> <span class="affiliation">Brown University</span>, <br />
<span class="author">Gideon  Goldin</span> <span class="affiliation">Brown University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper proposes applying principles of human causal reasoning to graphical interface design to make interfaces more intuitive. In particular, we present a design guideline for making graphical interfaces consistent with causal temporal order and demonstrate its effectiveness in an experiment where participants solve a puzzle with a novel interface. We also present preliminary results of its application to a text formatting task and propose several other causal principles that are directly applicable to interface design.</span></div></div><div class="paper" id="wp818"><a href="#wp818" class="title">Multi-touch Screens for Navigating 3D Virtual Environments in Participatory Urban Planning</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979852&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Emma  Chow</span> <span class="affiliation">Concordia University</span>, <br />
<span class="author">Amin  Hammad</span> <span class="affiliation">Concordia University</span>, <br />
<span class="author">Pierre  Gauthier</span> <span class="affiliation">Concordia University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Global trends have seen a strong push for more effective participatory planning in democratic societies.  Effective communication and universal accessibility are underpinning principles of successful participatory planning.  Virtual environments (VEs) have proven to significantly improve public understanding of 3D planning data.  This paper will evaluate multi-touch screens as a 3D VE navigation device for the general public in a participatory planning context.  The interactivity of multi-touch technology may better engage participants and improve their understanding of planning policies and proposed projects.  With the recent proliferation of multi-touch technology in the personal device market, there is great potential for expanding accessibility of participatory planning applications.</span></div></div><div class="paper" id="sd174"><a href="#sd174" class="title">Face-back: Who is the Illiterate Again?</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979503&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hoda A. Hamouda</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Mariam M. Hussein</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Mohamed H. Sharaf-El Deen</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Nermeen M. Abdel-Aziz</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Shady M. Hanna</span> <span class="affiliation">German University in Cairo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mutual respect and appreciation are the keys for integrating different groups into the society. We address in our work the special case of illiterate craftsmen in Egypt. Our research has shown that due to the illiteracy, they are excluded from the social mainstream, while paradoxically, we felt as illiterates in their world. Current solutions and services do not provide a two-way communication between illiterate and literate people that would help closing the gap. Face-back is a service that aims at bringing both worlds together by taking away the anonymity that leads to stereotypical ways of thinking.</span></div></div><div class="paper" id="sd212"><a href="#sd212" class="title">Entrust: Connecting Low-Income HIV+ Individuals with Health Care Providers</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979509&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Clifford  Gentry</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Marisol Martinez  Martinez Escobar</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Philip  Vander Broek</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Douglas  Choi</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Stefan  Ganchev</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Individuals infected with Human Immunodeficiency Virus (HIV) face numerous stigmatizations and challenges, specifically with the maintenance and adherence to their medical regimen. This situation is further complicated when individuals lack monetary resources to maintain their overall wellbeing. This paper presents Entrust, a service that provides low-income HIV positive individuals (clients) with cellphones to communicate with their health care providers. The cellphone is used to foster consistent and effective communication between clients and case managers, and client compliance is motivated by free phone minutes. In this way, Entrust facilitates a higher quality of life for low-income HIV positive individuals.</span></div></div><div class="paper" id="sd180"><a href="#sd180" class="title">Cowabunga!: A System to Facilitate Multi-Cultural Diversity through CouchSurfing</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979506&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sujoy Kumar  Chowdhury</span> <span class="affiliation">Missouri Western State University</span>, <br />
<span class="author">Jody  Wynn</span> <span class="affiliation">Missouri Western State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many organizations endeavor to promote diversity through their ideals and goals. Couchsurfing.org (CS) has a large presence in that realm. They have made it their mission to &#8220;create inspiring experiences: cross-cultural encounters that are fun, engaging and illuminating&#8220;. However, even in this presumably open-minded community the participants are often advised by experienced couchsurfers (CSers) to filter their couch-searches within homogenous members to increase response rates. It is human nature to interact with people similar in values and belief systems. We propose Cowabunga!, a mobile application which augments multi-cultural exchanges instigated by CS. By facilitating chance meetings that would not happen otherwise, our solution is helping people get spontaneous exposure to others with whom they may have nothing in common except their CS membership.</span></div></div><div class="paper" id="sd168"><a href="#sd168" class="title">ViTu: A System to Help the Mexican People to Preserve and Celebrate their Culture.</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979502&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">M&#243;nica Isabel Gonz&#225;lez</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span>, <br />
<span class="author">Emilio  S&#225;nchez</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span>, <br />
<span class="author">Edgar  de los Santos</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">ViTu is the entire development of a system focused on <br /> appreciating and highlighting the culture and traditions <br /> of native Mexican communities. It also contributes <br /> towards preserving and regaining the lost Mexican <br /> roots of the Mexican-Americans living in the United <br /> States. To achieve this, a culture, customs and <br /> traditions storage device of the Mexican village of San <br /> Jeronimo Silacayoapilla, was created. The main <br /> objective of this system is to encourage people to love <br /> and be proud of their cultural roots through technology. <br /> We are confident that this project will not only highlight <br /> the lifestyle of the native communities in Mexico but it <br /> will raise awareness on the importance of sharing, <br /> celebrating and appreciating our differences.</span></div></div><div class="paper" id="sd202"><a href="#sd202" class="title">SignBright: A Storytelling Application to Connect Deaf Children and Hearing Parents</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979508&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chad  Harbig</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Melissa  Burton</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Mariam  Melkumyan</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Lei  Zhang</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Jiyoung  Choi</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Deaf children of hearing parents face many unique challenges that have been shown to adversely impact their interpersonal interactions and development. Contemporary research indicates that many of these challenges stem from environmental factors, including a lack of exposure to language concepts during early developmental stages. In this paper, we will present an innovative solution to foster connection and understanding between deaf children and hearing parents, SignBright. In addition, SignBright promotes acquisition of sign language skills by hearing parents and deaf children, providing greater opportunities for interfamilial dialogue and bonding, and promoting development of social and linguistic competencies. <br /></span></div></div><div class="paper" id="sd128"><a href="#sd128" class="title">DiversIT: Inspiring Communication about Individuals' Differences</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979500&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Timothy  Ekl</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Tianyi  Gao</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Sarah  Jabon</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Joseph  Salisbury</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Eric  Stokes</span> <span class="affiliation">Rose-Hulman Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The world is a mosaic of unique individuals. It is easy, however, to take people's differences for granted. Many people have stereotypes and perceptions of others that conceal the truth about differences between them. In order to help people appreciate differences about one another, we designed DiversIT, which facilitates communication between all people by leveraging the power of the Internet. By centering discussion on a daily question, DiversIT establishes common ground through which people can begin interacting. This increased communication can lead to an improved understanding of each other. DiversIT was developed with user-centered design processes, incorporating potential users into every part of the design process.</span></div></div><div class="paper" id="sd137"><a href="#sd137" class="title">Interactive Therapy Gloves: Reconnecting Partners After a Stroke</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979501&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Hallam</span> <span class="affiliation">Emily Carr University of Art and Design</span>, <br />
<span class="author">Vanessa  Whiteley</span> <span class="affiliation">Emily Carr University of Art and Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the challenges that affect long-term partners after one of them suffers from a stroke, and offers a design solution as part of the CHI 2011 Student Design Competition. The challenge posed was to create a design that would help us to appreciate and celebrate our differences through the novel use of technology. We examined the changes that both partners go through during the recovery period after a stroke. We then designed an interactive glove as part of the rehabilitation process. The intent was to foster acceptance of each partner&#8217;s contribution and to help them reconnect. This paper details the iterative design process involved.</span></div></div><div class="paper" id="sd179"><a href="#sd179" class="title">TimeCapsule: Connecting Past</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979505&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yikun  Liu</span> <span class="affiliation">Indiana University School of Informatics</span>, <br />
<span class="author">Haidan  Huang</span> <span class="affiliation">Indiana University School of Informatics</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our world is changing at an ever-growing rate. The tide of urbanization and globalization has resulted in population migration that consequentially separates people from what is familiar to them. To combat this issue, we propose TimeCapsule. TimeCapsule is a social networking community intending to reserve, organize, share and utilize personal and collective memories by members of the community contributing location-related digitalized materials. Two clients will be designed to meet two kinds of usage: Mobile and Desktop. The mobile application will provide real-time old and new street view fusion in order to facilitate the user experience of appreciating the change in one location.  The desktop client will help users organize and share personal and group memories. Special consideration for seniors will be addressed.   <br /> By utilizing a connection to our past, we hope this initiative will help us to position ourselves to better appreciate the disparity between cultures and generations, thus unifying us.  <br /></span></div></div><div class="paper" id="sd225"><a href="#sd225" class="title">Lingua: Cultural Exchange Through Language Partnerships</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979510&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Caitlin  Holman</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Jane  Leibrock</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Jose  Jimenez</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Daniel  Greitzer</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Tom  Haynes</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Language barriers prevent people from communicating directly and are often a reflection of larger cultural divisions that hinder connection. Exposure to foreign languages and cultures through travel can help bridge this divide, but is not always feasible given time and monetary constraints. Language exchange partnerships are an excellent way to learn a new language, but are often difficult to maintain due to lack of common ground between partners and the absence of supporting materials. We present Lingua, a system to connect individuals with different linguistic backgrounds, and provide them a digital space tailored to support language learning through conversation with a partner. Their dialogue is driven in part by the application&#8217;s support for using shared multimedia to offer examples of their respective cultures.</span></div></div><div class="paper" id="sd183"><a href="#sd183" class="title">Sharing the Knowledge</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979507&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dustin  York</span> <span class="affiliation">Art Center College of Design Massachusetts Institute of Technology</span>, <br />
<span class="author">Zhengxin  Xi</span> <span class="affiliation">Art Center College of Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sharing the Knowledge is a community literacy learning system for implementation in the isolated regions of a developing nation. The project is a set of designed interactions that enables a collaborative social effort in creating and understanding educational materials, as means of compensation for the general lack of access to formal education and trained educators. The user-generated media is used for mobile learning applications and for creating social gaming incentives.</span></div></div><div class="paper" id="sd107"><a href="#sd107" class="title">The Design Process of iConnect: Social Advice Application</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979499&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shane  Wachirawutthichai</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Nisha  Singh</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Ramji  Enamuthu</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Yun  Zhou</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With Google [9] having established itself as the de-facto standard for document search and retrieval, the focus has shifted recently to the domain of social search. Morris et al. [12] define social search as &#8220;the process of finding information online with the assistance of social resources such as friends or unknown persons&#8221;. A number of online services [1, 2, 3, 4, 5] have been created to enable social search. But most of these are not useful when a person is mobile and offline and when the information need is highly context-specific. To enable social search in such situations, we introduce iConnect, the social advice application for mobile phones. iConnect is designed to enable a unique kind of social search, where an iConnect user is connected to other iConnect users in the same geographic region or locality. This would help people to solve their daily information needs. This paper illustrates the design process that we employed to conceptualize and prototype this application.</span></div></div><div class="paper" id="sd177"><a href="#sd177" class="title">Foodmunity: Designing Community Interactions over Food</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979504&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shad  Gross</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Austin  Toombs</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Jeff  Wain</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Kevin  Walorski</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Communities contain a rich diversity of backgrounds, personal experiences, and viewpoints. Fortunately, online social networks can make it even easier for people within a community to meet each other. This leads to an opportunity space for exposing people to the differences of their neighbors through mutual interaction. Our study presents Foodmunity, a social networking site that facilitates the organization of food-related events by members of a community. Meeting over a meal provides a more comfortable environment for experiencing new ideas, new people, and new viewpoints. Foodmunity utilizes themed events based on personal experiences its users have with food. This serves as both a cultural representation of those individuals and as a method of bonding between neighbors. By encouraging its users to reflect on the experiences they want to share and the experiences they have attending others&#8217; events, our system facilitates the growth of communities and a deeper understanding of the differences within.</span></div></div></td>
<td colspan="12" class="session_details" id="S1177_details"><div class="paper" id="sp105"><a href="#sp105" class="title">Lifetime Practice Award: What's it like to design a user interface for six billion people?</a>&nbsp;-&nbsp;<span class="type">Special Events</span><div class="authors"><span class="author">Larry  Tesler</span> <span class="affiliation">Larry Tesler Consulting</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">How is creating a user interface paradigm different from designing an application? If Cut and Paste was a new paradigm in the nineteen-seventies, what old paradigm did it replace? How did missionary zeal and serial collaboration make the GUI possible? What role did participatory design, rapid prototyping and usability testing play? What accounts for the longevity of the result? What's the prognosis for today's mobile UI? There will be primary sources in the presentation and time at the end for attendees to express contrary views.</span></div></div></td>
<td colspan="12" class="session_details" id="S1171_details"><div class="sessionChair"><strong>Session Chair: </strong>Amy Bruckman (<em>Georgia Institute of Technology</em>)</div><div class="paper" id="paper2363"><a href="#paper2363" class="title">The Polymath Project: Lessons from a successful online collaboration in mathematics</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979213&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Justin  Cranshaw</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Aniket  Kittur</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although science is becoming <br /> increasingly <br /> collaborative, there are remarkably few success stories of online collaborations between professional scientists that actually result in real discoveries.  A notable exception is the Polymath Project, a group of mathematics who collaborate over the Internet to solve unsolved problems.  We provide an in-depth descriptive history of Polymath, using data analysis and visualization to elucidate the principles that led to its success, and the difficulties that must be addressed before the project can be scaled up.  We find that although a small percentage of users created most of the content, almost all users nevertheless contributed some content that was highly influential to the task at hand.  We also find that leadership played an important role in the success of the project.  Based on our analysis, we present a set of design suggestions for how future collaborative mathematics sites can encourage and foster newcomer participation.</span></div></div><div class="paper" id="paper684"><a href="#paper684" class="title">Collaborative Creativity: A Complex Systems Model with Distributed Affect</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979214&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cecilia R. Aragon</span> <span class="affiliation">University of Washington; Lawrence Berkeley National Laboratory</span>, <br />
<span class="author">Alison  Williams</span> <span class="affiliation">University of East London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The study of creativity has received significant attention over the past century, with a recent increase in interest in collaborative, distributed creativity. We posit that creativity in distributed groups is fostered by software interfaces that specifically enable socio-emotional or affective communication. However, previous work on creativity and affect has primarily focused on the individual, while group creativity research has concentrated more on cognition rather than affect. In this paper we propose a new model for creativity in distributed groups, based on the theory of groups as complex systems, that includes affect as well as cognition and that explicitly calls out the interface between individuals as a key parameter of the model. We describe the model, the four stages of collaborative creativity and the causal dynamics in each stage, and demonstrate how affect and interface can facilitate the generation, selection, and amplification of ideas in the various stages of collaborative creativity. We then validate our model with data from three field sites. The data was collected from longitudinal studies of two distributed groups involved in producing creative products&#8212;-astrophysicists studying supernovae and the expansion rate of the universe and children creating multimedia programming projects online&#8212;-and interviews with staff in a multinational engineering company.</span></div></div><div class="paper" id="paper1104"><a href="#paper1104" class="title">Predicting the Perceived Quality of Online Mathematics Contributions from Users&#8217; Reputations</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979215&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yla R. Tausczik</span> <span class="affiliation">University of Texas at Austin</span>, <br />
<span class="author">James W. Pennebaker</span> <span class="affiliation">University of Texas at Austin</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There are two perspectives on the role of reputation in collaborative online projects such as Wikipedia or Yahoo! Answers. One, user reputation should be minimized in order to increase the number of contributions from a wide user base. Two, user reputation should be used as a heuristic to identify and promote high quality contributions. The current study examined how offline and online reputations of contributors affect perceived quality in MathOverflow, an online community with 3470 active users. On MathOverflow, users post high-level mathematics questions and answers.  Community members also rate the quality of the questions and answers. This study is unique in being able to measure offline reputation of users. Both offline and online reputations were consistently and independently related to the perceived quality of authors&#8217; submissions, and there was only a moderate correlation between established offline and newly developed online reputation.</span></div></div></td>
<td colspan="12" class="session_details" id="S1174_details"><div class="sessionChair"><strong>Session Chair: </strong>Anne Roudaut (<em>Hasso Plattner Institute</em>)</div><div class="paper" id="al139"><a href="#al139" class="title">Things that Hover: Interaction with Tiny Battery-less Robots on Desktop</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979624&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Takashi  Miyaki</span> <span class="affiliation">Karlsruhe Institute of Technology</span>, <br />
<span class="author">Yong  Ding</span> <span class="affiliation">Karlsruhe Institute of Technology</span>, <br />
<span class="author">Behnam  Banitalebi</span> <span class="affiliation">Karlsruhe Institute of Technology</span>, <br />
<span class="author">Michael  Beigl</span> <span class="affiliation">Karlsruhe Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents computationally and physically augmented desktop objects - ``Things that hover'' - that is capable of moving autonomously on desktop, and discusses about technical mechanisms, future possible interaction styles and applications based on this architecture.  A goal of the design is to create self-moving robotic modules on top of a flat surface. Integrating lightweight piezoelectric air-blow actuators and contact-less power providing technology from desktop surface, tiny robots can hover and control the direction of movement without any battery, which illustrates that our approach is practically feasible. <br /></span></div></div><div class="paper" id="al114"><a href="#al114" class="title">Floating Avatar: Telepresence System using Blimps for Communication and Entertainment</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979625&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hiroaki  Tobita</span> <span class="affiliation">Sony CSL</span>, <br />
<span class="author">Shigeaki  Maruyama</span> <span class="affiliation">Sony CSL</span>, <br />
<span class="author">Takuya  Kuzi</span> <span class="affiliation">UEC</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We developed a floating avatar system that integrates a blimp with a virtual avatar to create a unique telepresence system. Our blimp works as an avatar and contains several pieces of equipment, including a projector and a speaker as the output functions. Users can communicate with others by transmitting their facial image through the projector and voice through the speaker. A camera and microphone attached to the blimp provide the input function and support the user&#8217;s manipulation from a distance. The user&#8217;s presence is dramatically enhanced compared to using conventional virtual avatars (e.g., CG and images) because the avatar is a physical object that can move freely in the real world. In addition, the user&#8217;s senses are augmented because the blimp detects dynamic information in the real world. For example, the camera provides the user with a special floating view, and the microphone catches a wide variety of sounds such as conversations and environmental noises. This paper describes our floating avatar concept and its implementation.</span></div></div><div class="paper" id="al105"><a href="#al105" class="title">3D Remote Interface for Smart Displays</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979626&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">ByungIn  Yoo</span> <span class="affiliation">Samsung Electronics Co., LTD.</span>, <br />
<span class="author">Jae-Joon  Han</span> <span class="affiliation">Samsung Electronics Co., LTD.</span>, <br />
<span class="author">Changkyu  Choi</span> <span class="affiliation">Samsung Electronics Co., LTD.</span>, <br />
<span class="author">Hee-seob  Ryu</span> <span class="affiliation">Samsung Electronics Co., LTD.</span>, <br />
<span class="author">Du Sik  Park</span> <span class="affiliation">Samsung Electronics Co., LTD.</span>, <br />
<span class="author">Chang Yeong  Kim</span> <span class="affiliation">Samsung Electronics Co., LTD.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The paper presents a novel user interface combining bare hands and the line of sight (LoS) by using a depth camera from far distance without any handheld devices; as well as a 3D GUI providing both stereoscopy and motion parallax for smart displays. The proposed user interface provides a precise and convenient manipulation which is applicable to browsing thousands of channels and/or media files. Especially, the combined interaction methods of the two modalities achieve 120(x) &#215; 70(y) &#215; 5(z) manipulation resolution. And then various user tasks were performed so as to assess the proposed user interface.</span></div></div><div class="paper" id="al102"><a href="#al102" class="title">Flying Eyes: Free-Space Content Creation Using Autonomous Aerial Vehicles</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979627&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Keita  Higuchi</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Yoshio  Ishiguro</span> <span class="affiliation">The University of Tokyo &amp; Japan Society for the Promotion of Science</span>, <br />
<span class="author">Jun  Rekimoto</span> <span class="affiliation">The University of Tokyo &amp; Sony Computer Science Laboratories, Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Highly effective 3D-camerawork techniques that do not have physical limitations have been developed for creating three-dimensional (3D) computer games.  Recent techniques used for real-world visual content creation, such as those used for sports broadcasting and motion pictures, also incorporate cameras moving in 3D physical space to provide viewers with a more engaging experience.  For such purpose, wired cameras or mechanically controlled cameras are used, but they require huge and expensive infrastructure, and their freedom of motion is limited.  To realize more flexible free-space camerawork at reasonable cost, we propose a system called &#8220;Flying Eyes&#8221; based on autonomous aerial vehicles. Flying Eyes tracks target humans based on vision processing, and computes camera paths by controlling the camera position and orientation.</span></div></div><div class="paper" id="al140"><a href="#al140" class="title">ChairMouse: Leveraging Natural Chair Rotation for Cursor Navigation on Large, High-Resolution Displays</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979628&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Endert</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Patrick  Fiaux</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Haeyong  Chung</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Michael  Stewart</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Christopher  Andrews</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Chris  North</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Large, high-resolution displays lead to more spatially based approaches. In such environments, the cursor (and hence the physical mouse) is the primary means of interaction. However, usability issues occur when standard mouse interaction is applied to workstations with large size and high pixel density. Previous studies show users navigate physically when interacting with information on large displays by rotating their chair. ChairMouse captures this natural chair movement and translates it into large-scale cursor movement while still maintaining standard mouse usage for local cursor movement. ChairMouse supports both active and passive use, reducing tedious mouse interactions by leveraging physical chair action.</span></div></div></td>
<td colspan="12" class="session_details" id="S1165_details"><div class="paper" id="pl109"><a href="#pl109" class="title">Managing Global User Experience Teams</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979492&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jhilmil  Jain</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Catherine  Courage</span> <span class="affiliation">Citrix</span>, <br />
<span class="author">Jon  Innes</span> <span class="affiliation">UX Innovation LLC.</span>, <br />
<span class="author">Arnold  Lund</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Daniel  Rosenberg</span> <span class="affiliation">SAP Labs</span>, <br />
<span class="author">Elizabeth  Churchill</span> <span class="affiliation">Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this interactive session a panel of experts from industry, consultancy and research labs will discuss emerging issues and unique challenges related to managing global user experience teams, and how these differ from other disciplines such as marketing, sales, engineering etc.</span></div></div></td>
<td colspan="12" class="session_details" id="S1175_details"><div class="sessionChair"><strong>Session Chair: </strong>Leysia Palen (<em>University of Colorado, Boulder</em>)</div><div class="paper" id="paper251"><a href="#paper251" class="title">Rigid Structures, Independent Units, Monitoring: Organizing Patterns in Frontline Firefighting</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979225&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sebastian  Denef</span> <span class="affiliation">Fraunhofer FIT</span>, <br />
<span class="author">David  Keyson</span> <span class="affiliation">TU Delft</span>, <br />
<span class="author">Reinhard  Oppermann</span> <span class="affiliation">Fraunhofer FIT</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Providing firefighters working on the frontline of interventions with ubiquitous computing support remains an open challenge. Designing meaningful solutions for this complex work environment requires reflective thought and conceptual understanding of its social configuration. This paper presents organizing patterns of firefighting frontline practice as a means to inform ubiquitous computing design processes. The patterns originate from a qualitative analysis of an extensive range of user studies conducted with French and German firefighters. As the patterns show, firefighting on the frontline is based on a rigid structure that gains its flexibility through independent units whose safety is ensured by a number of monitoring activities. We conclude that the interaction between the presented patterns forms a balanced whole and needs to be recognized by ubiquitous computing design.</span></div></div><div class="paper" id="paper161"><a href="#paper161" class="title">Zero-Fidelity Simulation of Fire Emergency Response: Improving Team Coordination Learning</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979226&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Zachary O Toups</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">William A Hamilton</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Nabeel  Shahzad</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Fire emergency responders rely on team coordination to survive and succeed in high-stress environments, but traditional education does not directly teach these essential skills. Prior simulations seek the highest possible fidelity, employing resources to capture concrete characteristics of operating environments. We take a different tack, hypothesizing that a zero-fidelity approach, focusing on human-centered aspects of work practice, will improve team coordination learning. Such an approach promotes simulation focus by developing an alternative environment that stimulates participants to engage in distributed cognition. The costs of simulation development are reduced. <br />  <br /> To supplement preparation for burn training exercises, 28 fire emergency response students played the Teaching Team Coordination game (T2eC), a zero-fidelity simulation of the distributed cognition of fire emergency response work practice. To test our hypothesis, we develop quantitative evaluation methods for impact on team coordination learning through measures of communication efficiency and cooperative activity. Results show that participants improve cooperation, become more efficient communicators, differentiate team roles through communication, and leverage multiple communication modalities. Given the context of the study amidst the educational process, qualitative data from the students and their expert instructor supports the ecological validity of the contribution of the T2eC zero-fidelity simulation to fire emergency response education.</span></div></div><div class="paper" id="paper1098"><a href="#paper1098" class="title">Kairoscope: Managing Time Perception and Scheduling Through Social Event Coordination</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979227&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">ReeD  Martin</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Henry  Holtzman</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">If everyone says time is relative, why is it still so rigidly defined? There have been many attempts to address the issue of coordinating schedules, but each of these attempts runs into an issue of rigidity: in order to negotiate an event, a specific time must be designated in advance. This model is inherently poor at accommodating life's unpredictability. Kairoscope looks at time from a human perspective, focusing on time as made up of a series of events, rather than simply a series of events in time. By removing our reliance on a fixed time system, events are coordinated socially and on the fly, without worrying about precision. This paper explores the creation of Kairoscope, rooted in ideas of time perception and aiming to reduce time-related stress, optimize time usage, and increase social interaction. The result is a socially-coordinated, constantly adapting, and highly malleable guide through time.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">10:00<br />-<br />11:00</td>

<td class="session tbd" id="S1179">
<div class="session_box">
<span class="type"></span>
<a href="#S1179" class="title">Exhibit Hall Open</a>
<span class="location">Ballroom C/D</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S5009">
<div class="session_box">
<span class="type">Interactivity</span>
<a href="#S5009" class="title">Interactivity 2 Open</a>
<span class="location">202/203/204</span>
<strong></strong>

</div>
</td>

<td class="session " id="S5004">
<div class="session_box">
<span class="type">Student Design Competition &amp; Works In Progress</span>
<a href="#S5004" class="title">Poster Interactions: Group 2 Work-in-Progress (WIP300-499) and Student Design Competition</a>
<span class="location">Ballroom Foyer</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="3" class="session_details" id="S5009_details"><div class="paper" id="in122"><a href="#in122" class="title">Coco - The Therapy Robot</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979721&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katharina  Tran phuc</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Torsten  Racky</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Florian  Roth</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Iris  Wegmann</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Christoph  Busch</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Claudia  S&#246;ller-Eckert</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Mara  Pilz</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Katharina  Horst</span> <span class="affiliation">University of Applied Sciences Darmstadt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Coco is a therapeutic robot designed for elderly people in nursing homes or other care facilities. It is an electronic pet that represents a friend and helper who animates, reminds and motivates its owner.  He has 4 main functions: reading, singing, a calendar function and quiz games and can be operated by voice, remote control or base buttons. Pressure sensors in Coco's back react to touch. He interacts with its owner on its own initiative, suggesting to read, sing or play. Coco's memory and activity settings can be customised by carers or relatives. The prototype was implemented with Lego Mindstorms and successfully tested by a focus group. <br /></span></div></div><div class="paper" id="in129"><a href="#in129" class="title">Touch and Copy, Touch and Paste</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979714&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Suranga  Nanayakkara</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">SPARSH explores a novel interaction method to seamlessly transfer data between digital devices in a fun and intuitive way. The user touches whatever data item he or she wants to copy from a device. At that moment, the data item is conceptually saved in the user. Next, the user touches the other device he or she wants to paste/pass the saved content into. SPARSH uses touch-based interactions as indications for what to copy and where to pass it. Technically, the actual transfer of media happens via the information cloud.</span></div></div><div class="paper" id="in130"><a href="#in130" class="title">Mouseless - a Computer Mouse as Small as Invisible</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979715&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mouseless is a novel input device that provides the familiarity of interaction of a physical computer mouse without requiring a real hardware mouse. It consists of an IR laser beam and an IR camera, both of which are embedded in a computer. Mouseless proposes a number of novel additional gestural interactions while supporting all the conventional computer mouse interactions. We present the design and implementation of various Mouseless prototype systems.</span></div></div><div class="paper" id="in132"><a href="#in132" class="title">Obfuscating Authentication Through Haptics, Sound and Light</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979709&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrea  Bianchi</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span>, <br />
<span class="author">Dong-Soo  Kwon</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sensitive digital content associated with or owned by individuals now pervades everyday life. Mediating accessing to it in ways that are usable and secure is an ongoing challenge. We present a series of five PIN entry and transmission systems that address observation attacks in public spaces via shoulder surfing or camera recording. They do this through the use of novel modalities including audio cues, haptic cues and modulated visible light. Each prototype is introduced and motivated, and its strengths and weaknesses are considered.</span></div></div><div class="paper" id="in137"><a href="#in137" class="title">Blinky Blocks: A Physical Ensemble Programming Platform</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979712&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Brian T Kirby</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michael  Ashley-Rollman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Seth Copen Goldstein</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A major impediment to understanding programmable matter is the lack of an existing system with sufficiently many modules of sufficient capabilities. We present the requirements of physically distributed ensembles and discuss the use of the distributed programming language Meld to program ensembles of these units. We demonstrate a new <br /> system designed to meet these requirements called Blinky Blocks and discuss the hardware design we used to create 100 of these modules.</span></div></div><div class="paper" id="in145"><a href="#in145" class="title">humanaquarium: Exploring Audience, Participation, and Interaction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span><div class="authors"><span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Guy  Schofield</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Jayne  Wallace</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Pierre  Boulanger</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">humanaquarium is a movable performance space designed to explore the dialogical relationship between artist and audience. Two musicians perform inside the cube-shaped box, collaborating with participants to co-create an aesthetic audio-visual experience. The front wall of the humanaquarium is a touch-sensitive FTIR window. Max/MSP is used to translate the locations of touches on the window into control data, manipulating the tracking of software synthesizers and audio effects generated in Ableton Live, and influencing a Jitter visualization projected upon the rear wall of the cube.</span></div></div><div class="paper" id="in150"><a href="#in150" class="title">3D-Press - Tangible 3D Haptics on Touch Surfaces: Virtual Compliance</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979717&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Suitability of current haptic three-dimensional user interface (3D-UI) technologies is low for mobile interaction. 3D-Press in reviewed in this paper: a technique to create the haptic illusion that when pressing on a rigid surface is feels compliant. The fact that the illusion is intramodal (haptics only involved in creating it), and that the technology required is simple and with low energy demands, makes it ideal for mobile use. The parameters used in the implementation of 3D-Press influence the characteristics of the illusion.</span></div></div><div class="paper" id="in152"><a href="#in152" class="title">Graffito: Crowd-based Performative Interaction at Festivals</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979725&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Sheridan</span> <span class="affiliation">BigDog Interactive Ltd</span>, <br />
<span class="author">Nick  Bryan-Kinns</span> <span class="affiliation">Queen Mary University of London</span>, <br />
<span class="author">Stuart  Reeves</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Giles  Lane</span> <span class="affiliation">Proboscis</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crowd-based events are generating new forms of crowd-based performative interaction. Nightclubs and festivals are at the cutting edge of crowd-based interaction with ubiquitous computing. The social capital of crowd-based interaction is not well understood and is usually limited to one-off events. Our intention is to explore the possibility for generating a lifelong contextual footprint of crowd-based performative interaction.</span></div></div><div class="paper" id="in154"><a href="#in154" class="title">Galvanic Skin Response-Derived Bookmarking of an Audio Stream</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979716&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew K.X.J. Pan</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gordon Jih-Shiang  Chang</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gokhan H. Himmetoglu</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">AJung  Moon</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Thomas W. Hazelton</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Karon E. MacLean</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Elizabeth A. Croft</span> <span class="affiliation">The University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We demonstrate a novel interaction paradigm driven by implicit, low-attention user control, accomplished by monitoring a user&#8223;s physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. A listener&#8223;s galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our research prototype then automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted.</span></div></div><div class="paper" id="in158"><a href="#in158" class="title">MediaDiver: Viewing and Annotating Multi-View Video</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979711&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gregor  Miller</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Abir  Al Hajri</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Michael  Ilich</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Zoltan  Foley-Fisher</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Manuel  Fernandez</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Daesik  Jang</span> <span class="affiliation">Kunsan National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our novel rich media interface called MediaDiver demonstrates our new interaction techniques for viewing and annotating multiple view video. The demonstration allows attendees to experience novel moving target selection methods (called Hold and Chase), new multi-view selection techniques, automated quality of view analysis to switch viewpoints to follow targets, integrated annotation methods for viewing or authoring meta-content and advanced context sensitive transport and timeline functions. As users have become increasingly sophisticated when managing navigation and viewing of hyper-documents, they transfer their expectations to new media. We demonstrate the technology required to meet these expectations for video. Thus users will be able to directly click on objects in the video to link to more information or other video, easily change camera views and mark-up the video with their own content. The applications of this technology stretch from home video management to broadcast quality media production, which may be consumed on both desktop and mobile platforms.</span></div></div><div class="paper" id="in161"><a href="#in161" class="title">TagURIt: A Proximity-based Game of Tag Using Lumalive e-Textile Displays</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979707&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sylvia H Cheng</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an electronic game of tag that uses proximity sensing and Lumalive displays on garments.  In our game of tag, each player physically represents a location-tagged Universal Resource Indicator (URI). The URIs, one chaser and two target players, wear touch-sensitive Lumalive display shirts. The goal of the game is for the chaser to capture a token displayed on one of the Lumalive shirts, by pressing a touch sensor located on the shirt. When the chaser is in close proximity to the token player, the token jumps to the shirt of the second closest player, making this children&#8217;s game more challenging for adult players.  Our system demonstrates the use of interactive e-textile displays to remove the technological barrier between contact and proximity in the real world, and the seamless representation of gaming information from the virtual world in that real world.</span></div></div><div class="paper" id="in165"><a href="#in165" class="title">Frictional Widgets: Enhancing Touch Interfaces with Programmable Friction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979713&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vincent  Levesque</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Louise  Oram</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Karon  MacLean</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Nicholas  Marchuk</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Dan  Johnson</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">J. Edward  Colgate</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Michael  Peshkin</span> <span class="affiliation">Northwestern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch interactions occur through flat surfaces that lack the tactile richness of physical interfaces. We explore the design possibilities offered by augmenting touchscreens with programmable surface friction. Four exemplar applications &#8211; an alarm clock, a file manager, a game, and a text editor &#8211; demonstrate tactile effects that improve touch interactions by enhancing physicality, performance, and subjective satisfaction.</span></div></div><div class="paper" id="in168"><a href="#in168" class="title">SnowGlobe: A Spherical Fish-Tank VR Display</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979719&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">John  Bolton</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a spherical display with Fish-Tank VR as a means for interacting with three-dimensional objects. We implemented the spherical display by reflecting a projected image off a hemispherical mirror, allowing for a seamless curvilinear display surface. Diffuse illumination is used for detecting touch points on the sphere. The user&#8217;s head position and the position of the sphere are also tracked using a Vicon motion capture device. Users can perform multi-touch gestures to interact with 3D content on the spherical display. Our system relies on the metaphor of a snow globe. Users can walk around a display while maintaining motion parallax corrected viewpoints of the object on the display. They can interact with the 3D object using multitouch interaction techniques, allowing for rotating and scaling of the 3D model on the display.</span></div></div><div class="paper" id="in170"><a href="#in170" class="title">ZeroTouch: A Zero-Thickness Optical Multi-Touch Force Field</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979710&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Sashikanth  Damaraju</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present zero-thickness optical multi-touch sensing, a technique that simplifies sensor/display integration, and enables new forms of interaction not previously possible with other multi-touch sensing techniques. <br /> Using low-cost modulated infrared sensors to quickly determine the visual hull of an interactive area, we enable robust real-time sensing of fingers and hands, even in the presence of strong ambient lighting. Our technology allows for 20+ fingers to be detected, many more than through prior visual hull techniques, and our use of wide-angle optoelectonics allows for excellent touch resolution, even in the corners of the sensor. <br /> With the ability to track objects in free space, as well as its use as a traditional multi-touch sensor, ZeroTouch opens up a new world of interaction possibilities.</span></div></div><div class="paper" id="in207"><a href="#in207" class="title">Immersive VR: A Non-pharmacological Analgesic for Chronic Pain?</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979704&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diane  Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Meehae  Song</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ji-Dong  Yim</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Tyler  Fox</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Steven J Barnes</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mark  Nazemi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Chris  Shaw</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Pam  Squire, MD</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the research work being carried out by the Transforming Pain Research Group &#8211; the only group whose work is entirely focused on the use of immersive VR for chronic pain management. Unlike VR research for acute or short-term pain, which relies on pain "distraction," this research posits a new paradigm for the use of VR. In addition to providing an overview of our work, the present paper also describes one of our current works in detail: the Virtual Meditative Walk.</span></div></div></td>
<td colspan="3" class="session_details" id="S5004_details"><div class="paper" id="wp654"><a href="#wp654" class="title">Can Users Remember Their Pictorial Passwords Six Years Later?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979945&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Thomas S Tullis</span> <span class="affiliation">Fidelity Investments</span>, <br />
<span class="author">Donna P Tedesco</span> <span class="affiliation">Fidelity Investments</span>, <br />
<span class="author">Kate E McCaffrey</span> <span class="affiliation">Fidelity Investments</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous research had shown that pictorial passwords, where users recognize their target images among distractors, have potential for improving the usability of authentication systems.  A method using personal photos provided by the users as their targets, shown among highly similar distractors, showed the most promise for both accuracy and security.  But the longest time period that had been tested between successive login attempts was only about one month.  We wanted to see what happens when six years have elapsed.  We recruited some of the same participants from the previous study and tested their ability to select their target photos six years later. We found that 12 of 13 participants successfully authenticated themselves.  The overall accuracy rate was 95.6%, demonstrating that most users can remember these pictorial passwords even over long periods of time.</span></div></div><div class="paper" id="wp386"><a href="#wp386" class="title">ReHandle: Towards Integrating Physical Rehabilitation in Everyday life</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979856&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Naveen  Bagalkot</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Tomas  Sokoler</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present ReHandle, an emerging design space currently inhabited and shaped by three different design sketches. We describe how the three sketches point to three possible dimensions for exploring the role of digital technology in facilitating self-monitoring; aimed at promoting an integration of the rehab activities with the everyday activities of senior citizens. We expect that our articulation of the emerging ReHandle design space will be informative and inspirational for the interaction design and HCI community exploring the role of digital technology for successful rehabilitation of senior citizens.</span></div></div><div class="paper" id="wp532"><a href="#wp532" class="title">CrowdForge: Crowdsourcing Complex Work</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979902&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aniket  Kittur</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Boris  Smus</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Robert  Kraut</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Micro-task markets such as Amazon&#8217;s Mechanical Turk represent a new paradigm for accomplishing work, in which employers can tap into a large population of workers around the globe to accomplish tasks in a fraction of the time and money of more traditional methods.  However, such markets typically support only simple, independent tasks, such as labeling an image or judging the relevance of a search result.  Here we present a general purpose framework for micro-task markets that provides a scaffolding for more complex human computation tasks which require coordination among many individuals, such as writing an article.</span></div></div><div class="paper" id="wp646"><a href="#wp646" class="title">WaveForm: Remote Video Blending for VJs Using In-Air Multitouch Gestures</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979941&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amartya  Banerjee</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Jesse  Burstyn</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present WaveForm, a system that enables a Video Jockey (VJ) to directly manipulate video content on a large display on a stage, from a distance. WaveForm implements an in-air multitouch gesture set to layer, blend, scale, rotate, and position video content on the large display. We believe this leads to a more immersive experience for the VJ user, as well as for the audience witnessing the VJ&#8217;s performance during a live event.</span></div></div><div class="paper" id="wp361"><a href="#wp361" class="title">The Adoption of Online Self-Service Technology (SST) as a Gradual Learning Process</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979847&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Calin  Gurau</span> <span class="affiliation">Montpellier Business School</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Using a combination of qualitative and quantitative analysis, this study attempts to identify the main phases of customer-SST system interaction. The findings reinforce the interpretation of SST adoption as a gradual process of learning that presents different challenges for various types of customers, depending on their level of online experience.</span></div></div><div class="paper" id="wp416"><a href="#wp416" class="title">Sympathetic Guitar:  Can a Digitally Augmented Guitar be a Social Entity?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979863&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jay  Vidyarthi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa N. Antle</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Bernhard E. Riecke</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous work suggests that people treat interactive media as if they were social entities.  By drawing a parallel between socio-cognitive theory and interface design, we intend to experimentally determine whether deliberate design decisions can have an effect on users&#8217; perception of an interactive medium as a social entity.  In this progress report, we describe the theoretical underpinnings and motivations which led to the design and implementation of the Sympathetic Guitar: a guitar interface which supplements standard acoustic sound with a spatially-separate audio response based on the user&#8217;s hand positions and performance dynamics.  This prototype will be used for investigating user response to a specific, socially-relevant design decision.</span></div></div><div class="paper" id="wp426"><a href="#wp426" class="title">Aiding Usability Evaluation via Detection of Excessive Visual Search</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979868&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Oleg  Komogortsev</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Corey  Holland</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Dan  Tamir</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Carl  Mueller</span> <span class="affiliation">Texas State University-San Marcos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an objective evaluation of several methods for the automated classification of excessive visual search, a technique which has the potential to aid in the identification of usability problems during software usability testing. Excessive visual search was identified by a number of eye movement metrics, including: fixation count, saccade amplitude, convex hull area, scanpath inflections, scanpath length, and scanpath duration. The excessive search intervals identified by each algorithm were compared to those produced by manual classification. The results indicate that automated classification can be successfully employed to substantially reduce the amount of recorded data reviewed during usability testing, with relatively little loss in accuracy.</span></div></div><div class="paper" id="wp432"><a href="#wp432" class="title">ConsiderIt: Improving Structured Public Deliberation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979869&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Travis  Kriplean</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jonathan T. Morgan</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Deen  Freelon</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alan  Borning</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Lance  Bennett</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We designed, built, and deployed ConsiderIt to support the Living Voters Guide, a website where any voter could participate in writing a voters&#8217; guide for the 2010 election in Washington. ConsiderIt is a new method of integrating the thoughts of many into a coherent form, while nudging people to consider tradeoffs of difficult decisions with an intuitive interface.</span></div></div><div class="paper" id="wp457"><a href="#wp457" class="title">Sex Toys and Designing for Sexual Wellness</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979879&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anna  Eaglin</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sexual health encompasses physical, mental and social well-being in relation to sexuality. In this paper, we argue that designing for sexual health is an important aspect of the Wellness Informatics agenda, and that research on sex toys, which is underdeveloped in HCI, has the potential to contribute to this agenda substantively. We summarize our user research and present a set of design principles to further the agenda of designing for sexual wellness.</span></div></div><div class="paper" id="wp463"><a href="#wp463" class="title">Designing A Personal Visualization Projection of Online Social Identity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979882&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mandy  Leung</span> <span class="affiliation">The University of Sydney</span>, <br />
<span class="author">Martin  Tomitsch</span> <span class="affiliation">The University of Sydney</span>, <br />
<span class="author">Andrew  Vande Moere</span> <span class="affiliation">Katholieke Universiteit Leuven</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we report on the design, implementation and evaluation of a personal visualization projection, which provides onlookers with a real-time view of the online social identity of the wearer. The wearable system was developed as a novel means of electronic self-expression, and for catalyzing increased social interaction between the wearer and onlookers with similar or complementary personality characteristics. The interactive prototype, driven by a handheld &#8220;pico&#8221; projector, was evaluated with two groups of four participants each. Based on a case study analysis followed by focus groups, we present our findings according to a contextual evaluation model, which includes aspects of environment, usability, privacy, ambientness, social interaction, and insight.</span></div></div><div class="paper" id="wp498"><a href="#wp498" class="title">Customization for Games: Lessons from Variants of Texas Hold&#8217;em</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979889&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gifford K Cheung</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">System designers who build customization into games ought to consider how players think about adjustments. The distinctiveness of gaming contexts suggests that closer inspection of customization in games is warranted and will inform the design of customizable game systems. Presented here is an analysis of 82 collected reports about variations to the rules of the poker game Texas Hold&#8217;em. A theory of &#8220;necessity&#8221; in rule adoption is developed and the systematic perspective of rule-changing in games is discussed.</span></div></div><div class="paper" id="wp502"><a href="#wp502" class="title">&#8216;Canary in a Coal Mine&#8217;: Monitoring Air Quality and Detecting Environmental Incidents by Harvesting Twitter</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979890&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Henricus  Smid</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Patrick  Mast</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Maarten  Tromp</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Andi  Winterboer</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Vanessa  Evers</span> <span class="affiliation">University of Amsterdam</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an application that facilitates environmental <br /> monitoring by and for the general public. &#8216;Canary in a <br /> Coal Mine&#8217; (CIACM) gathers and analyses pollution-related <br /> tweets in real-time from the micro-blogging <br /> platform Twitter and visualizes temporal and spatial <br /> characteristics of the data. CIACM allows citizens to <br /> keep track of the environmental quality of their region <br /> and empowers users to contribute to this public <br /> environmental monitoring system.</span></div></div><div class="paper" id="wp522"><a href="#wp522" class="title">My Own-Style Interaction: Exploring Individuals' Preferences to Interactivity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979897&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Da-jung  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Hyeon-Jeong  Suk</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There have been studies about users' preferences on different physical styles of interactive products, but the exploration of interactivity preferences and the value of customizing its expressions have not been emphasized much yet. In this paper, we conducted a three-phase user study in order to investigate individual preferences to different qualities of interactivity and its relationship with individual differences. The results showed that people have diverse preferences for several attributes of interactivity, similar to the case for appearances of products, and there are close relationships between individual differences such as human personality traits. Based on these results, we discussed their implications for designing attractive interaction.</span></div></div><div class="paper" id="wp493"><a href="#wp493" class="title">From the Lab to the World: Lessons from Extending a Pointing Technique for Real-World Use</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979888&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Jansen</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Leah  Findlater</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the Pointing Magnifier as a case study for understanding the issues and challenges of deploying lab-validated pointing facilitation techniques into the real world. The Pointing Magnifier works by magnifying the contents of an area cursor to allow for selection in a magnified visual and motor space. The technique has been shown in prior lab studies to be effective at reducing the need for fine pointing for motor-impaired users. We highlight key design and technical challenges in bringing the technique, and such techniques in general, from the lab to the field.</span></div></div><div class="paper" id="wp482"><a href="#wp482" class="title">LoOkie - It Feels Like Being There</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979884&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Talya  Porat</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span>, <br />
<span class="author">Inbal  Rief</span> <span class="affiliation">kitchen97.com</span>, <br />
<span class="author">Rami  Puzis</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span>, <br />
<span class="author">Yuval  Elovici</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we describe an interaction design process and the challenges encountered during the development of LoOkie, a social mobile application, which enables members to request and receive live videos or pictures of desired locations from people who are present at the scene. The paper describes, from a human-computer interaction perspective, the development of the application from the birth of the idea through the design process encountered up to the point of the launch of the application for Beta at the beginning of 2011.</span></div></div><div class="paper" id="wp437"><a href="#wp437" class="title">Input Observer: Measuring Text Entry and Pointing Performance from Naturalistic Everyday Computer Use</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979871&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abigail  Evans</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe the Input Observer, a background application that will be capable of measuring a user&#8217;s text entry and pointing abilities from everyday computer use &#8220;in the wild.&#8221; The application runs quietly in the background of the user&#8217;s computer and utilizes global Windows Hooks to observe the text entry input stream and use of the mouse, and will yield data equivalent to results from lab-based measures of text entry and target acquisition. A major challenge is the lack of a task model from which researchers can know the intent of the user at every <br /> moment. We describe our approach to handling this issue for both text entry and mouse pointing.</span></div></div><div class="paper" id="wp580"><a href="#wp580" class="title">Wriggle: An Exploration of Emotional and Social Effects of Movement</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979919&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katherine  Isbister</span> <span class="affiliation">NYU-Poly</span>, <br />
<span class="author">Ulf  Schwekendiek</span> <span class="affiliation">NYU-Poly</span>, <br />
<span class="author">Jonathan  Frye</span> <span class="affiliation">NYU</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Wriggle is a research prototype game that can be played either with or without movement as input. We conducted an experiment to see whether movement adds emotional impact and increases social connectedness. We found effects on arousal and results approaching significance for social connection, demonstrating the potential for this approach to help us better understand the impact of movement on user experience.</span></div></div><div class="paper" id="wp575"><a href="#wp575" class="title">Text Highlighting Improves User Experience for Reading with Magnified Displays</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979917&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tersia  Gowases</span> <span class="affiliation">University of Eastern Finland</span>, <br />
<span class="author">Roman  Bednarik</span> <span class="affiliation">University of Eastern Finland</span>, <br />
<span class="author">Markku  Tukiainen</span> <span class="affiliation">University of Eastern Finland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We report on two studies of how magnified views affect the lives of users with low vision and how simple interventions can improve their user experience. In the first study we observed three low vision users with Age-related Macular Degeneration (AMD) as they interacted with computing devices. We found that AMD users rely on the screen magnification, but the same magnified view not only makes it impossible to read longer texts independently, but also causes a loss of context. We then designed an enhancement of the conventional Windows 7 screen magnification tool by providing line-level text highlighting. We conducted an experiment in which 21 participants, with normal vision, read text from a webpage using one of three conditions: no enhancement, highlighting, and highlighting + cursor routing. We recorded the eye-movement patterns, performance, cognitive workload, and user experience. The results provide design implications and guidelines for visual aids for interaction with magnified displays.</span></div></div><div class="paper" id="wp620"><a href="#wp620" class="title">Mobile Augmented Reality: Video prototyping</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979927&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marco  de S&#225;</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">Judd  Antin</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">David  Shamma</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">Elizabeth F. Churchill</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As mobile devices become more powerful, new features and user experiences become possible. A good example of such experiences is Augmented reality (AR). Achieved through the combination of current smart- phones processing capabilities and their embedded cameras, AR is a growing trend that offers an interesting approach for a wide variety of applications. However, coupling this new approach to the already demanding design process that characterizes mobile devices, further extends challenges to designers and developers. In this paper we present a preliminary study on prototyping and evaluation techniques for mobile AR. A short experiment within the context of an ongoing design project and initial results are presented along with some resulting guidelines.</span></div></div><div class="paper" id="wp504"><a href="#wp504" class="title">Transparency in Mobile Navigation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979891&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  McGookin</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Inti  Herteleer</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We investigated the usefulness transparency can play in increasing the display space of mobile devices in navigation scenarios.   Two different systems that used transparency to display a map and image of a point of interest (POI) were compared to a control. Significant variations were identified in the strategies employed, with a strong user preference towards the transparency conditions. Significant variations in time or distance taken were not identified between conditions, although results indicate strong avenues for future investigation.</span></div></div><div class="paper" id="wp513"><a href="#wp513" class="title">Force Gestures: Augmented Touch Screen Gestures Using Normal and Tangential Force</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979895&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seongkook  Heo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Geehyuk  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Similar sliding gestures may have different meanings when they are performed with changing intensity. Touch screens, however, fail to properly distinguish those intensities due to their inability to sense variable pressures. Enabled by distinguishing normal and tangential forces, we explore new possibilities for gestures on a touch screen. We have implemented a pressure-sensitive prototype and have designed a set of gestures that utilize alterable forces. The gestures&#8217; feasibility has been tested through a simple experiment.  Finally, we discuss the new possibility of touch interactions that are sensitive to pressure.</span></div></div><div class="paper" id="wp460"><a href="#wp460" class="title">WATER Alert! Disseminating Drinking Water Quality Information to South Africans</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979880&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Deana S. Brown</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Gary  Marsden</span> <span class="affiliation">University of Cape Town</span>, <br />
<span class="author">Melissa  Loudon</span> <span class="affiliation">University of Southern California</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Drinking water quality, especially in many parts of South Africa, is far below acceptable standards. With an annual estimate of 43,000 deaths from diarrheal diseases, 3 million cases of illness, and treatment costs of over half a billion US dollars, the impact is critical [4]. This research addresses the challenge of reporting complex and critical water quality information in a way that is accessible to all South Africans as required by law. In a country with high illiteracy rates, 11 official languages and limited-to-no access to technology in many areas, this is no easy feat. We describe the details of WATER Alert!, a prototype mobile phone application designed to alert and report critical water quality information to consumers who subscribe to it. Our initial evaluation of this design with users suggests that such an application would help to improve consumers' understanding of water quality information. The symbol-based messages make critical water quality information more accessible to illiterate or low-literate users, or non-native English or Afrikaans speakers. Additionally, the use of a tool and interface design most of our users are familiar with (the mobile phone) lowers the learning curve.</span></div></div><div class="paper" id="wp563"><a href="#wp563" class="title">Dual-Space Drawing: Designing an Interface to Support Creative and Reflective Drawing Experiences</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979912&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jee Yeon  Hwang</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Henry  Holtzman</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Mitchel  Resnick</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Dual-Space Drawing is an interface that enables children to express their drawing ideas in both the digital and real worlds. It supports creative and reflective drawing experiences using two layers: a transparent layer and a screen layer. The interface takes a user&#8217;s drawing movements on the transparent display unobtrusively and then projects the movements on the screen display while presenting the user-selected multimedia components. Dual-Space Drawing lets users interact with motion graphics on a mirror-like display. In the process of designing the self-projected scenes and creating digital contents, children can express themselves and embody their ideas. While designing a digital object, a user&#8217;s response to the object creates a new relationship to the object in connection with the user&#8217;s self-reflection/projection. In this way, Dual-Space Drawing integrates the user&#8217;s drawing activity with expressive interaction.</span></div></div><div class="paper" id="wp516"><a href="#wp516" class="title">Comparative Evaluation of Recommender System Quality</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979896&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Paolo  Cremonesi</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Franca  Garzotto</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Sara  Negro</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Alessandro  Papadopoulos</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Roberto  Turrin</span> <span class="affiliation">Moviri SRL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Several researchers suggest that the Recommendation Systems (RSs) that are the "best" according to statistical metrics might not be the most satisfactory for the user. We explored this issue through an empirical study that involved 210 users and considered 7 RSs using different recommender algorithms on the same dataset.  <br /> We measured user&#8217;s perceived quality of each RS, and compared these results against measures of statistical quality of the considered algorithms as they have been assessed by past studies in the field, highlighting some interesting results.</span></div></div><div class="paper" id="wp362"><a href="#wp362" class="title">Generalizing Email Messages Digests</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979848&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Romain  Vuillemot</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span>, <br />
<span class="author">Jean-Marc  Petit</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span>, <br />
<span class="author">Mohand-Said  Hacid</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An email digest is a message that results from the combination of other messages. Mailing list management systems implement digests to let subscribers reduce their email messages frequency. In this paper we address the issue of generalizing this digest technique for any message (i.e. not only issued from mailing lists). By generalizing we mean creating new message combinations while 1) keeping an email centric approach, and 2) generating a compact visualization to assist a user task. We implemented a preliminary prototype as a webmail and we will describe a series of digests providing users multiple visualizations in the context of a meeting planning by email.</span></div></div><div class="paper" id="wp373"><a href="#wp373" class="title">Visualizing Meetings as a Graph for more Accessible Meeting Artifacts</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979850&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yurdaer  Doganata</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Mercan  Topkara</span> <span class="affiliation">IBM Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper focuses on capturing, correlating and visualizing the execution of meetings from the recorded data using a business process management approach. Relevant artifacts that are utilized or generated during a meeting as well as meeting activities are mapped onto a generic meeting data model. The execution of a meeting is then captured as a graph where generated meeting artifacts, participants and meeting tasks are connected. The graph enables faster and structured access to meeting data and gives better insight to the users about the meeting through visualization capability.</span></div></div><div class="paper" id="wp384"><a href="#wp384" class="title">Engaging Energy Saving through Motivation-Specific Social Comparison</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979855&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Petromil  Petkov</span> <span class="affiliation">Queensland University of Technology, NICTA, Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Felix  K&#246;bler</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Marcus  Foth</span> <span class="affiliation">Queensland University of Technology, NICTA</span>, <br />
<span class="author">Richard  Medland</span> <span class="affiliation">Queensland University of Technology, NICTA</span>, <br />
<span class="author">Helmut  Krcmar</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Comparison is widely used in research projects and commercial products whose goal is to motivate energy saving at home. This research builds on fundamental theories from social psychology in an attempt to shed light on how to motivate consumers to conserve energy by providing relevant people for social comparison depending on consumer&#8217;s motivation to compare. To support the research process, the mobile application EnergyWiz was developed through a theory-driven design approach. Along with other features EnergyWiz provides users with three types of social comparison &#8211; normative, one-on-one and ranking. The results of interviews with prospective users are used to derive design suggestions for relevant people for comparison (comparison subjects).</span></div></div><div class="paper" id="wp400"><a href="#wp400" class="title">AnalyzeThis: Unobtrusive Mental Health Monitoring by Voice</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979859&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Keng-hao  Chang</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Matthew  Chan</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">John  Canny</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mental illness is one of the most undertreated health problems worldwide.  Previous work has shown that there are remarkably strong cues to mental illness in short samples of the voice. These cues are evident in severe forms of illness, but it would be most valuable to make earlier diagnoses from a richer feature set. Furthermore there is an abstraction gap between these voice cues and the diagnostic cues used by practitioners. We believe that by closing this gap, we can build more effective early diagnostic systems for mental illness. In order to develop improved monitoring, we need to translate the high-level cues used by practitioners into features that can be analyzed using signal processing and machine learning techniques.  In this paper we describe the elicitation process that we used to tap the practitioners' knowledge.   We borrow from both AI (expert systems) and HCI (contextual inquiry) fields in order to perform this knowledge transfer.  The paper highlights an unusual and promising role for HCI - the analysis of interaction data for health diagnosis. <br /></span></div></div><div class="paper" id="wp409"><a href="#wp409" class="title">MouseHints: Easing Task Switching in Parallel Browsing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979861&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luis A Leiva</span> <span class="affiliation">Universidad Polit&#233;cnica de Valencia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a technique to help users regain context either after an interruption or when multitasking while performing web tasks.  <br /> Using mouse movements as an indicator of attention, a browser plugin records in background the user's interactions (including clicks, dwell times, and DOM elements). On leaving the page, this information is stored to be rendered as an overlay when the user returns to such page.  <br /> The results of a short study showed that participants resumed tasks three times faster with MouseHints and completed their tasks in about half the time. <br /> Related applications and further research are also envisioned. <br /></span></div></div><div class="paper" id="wp465"><a href="#wp465" class="title">Active Progress Bars: Facilitating the Switch to Temporary Activities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979883&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christophe  Hurter</span> <span class="affiliation">Civil Aviation Research Center, IRIT Toulouse University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Queen&#8217;s University</span>, <br />
<span class="author">Nathalie  Riche</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Catherine  Plaisant</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we seek to find a better way of effective task management when a progress bar interrupts us-er&#8217;s primary activity. We propose to augment progress bars with user controlled functionalities facilitating the switch to temporary activities. We detail a taxonomy of waiting period contexts and possible temporary tasks, then report on 5 participatory design, and a follow-up survey of 96 respondents. Finally we describe an early prototype of active progress bars, and report on initial use.</span></div></div><div class="paper" id="wp484"><a href="#wp484" class="title">PLink: Paper-Based Links for Cross-Media Information Spaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979885&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">J&#252;rgen  Steimle</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Nadir  Weibel</span> <span class="affiliation">University of California San Diego</span>, <br />
<span class="author">Simon  Olberding</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Max  M&#252;hlh&#228;user</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">James D. Hollan</span> <span class="affiliation">University of California San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">PLink is a system for integrating physical and computer desktops by creating paper links to digital resources. PLink leverages diverse formats of physical paper, ranging from tiny stickers that can be easily incorporated into traditional paper media to very large deskpad sheets that make the physical desktop partially interactive. We present PLink and initial results from a multi-week field study.</span></div></div><div class="paper" id="wp527"><a href="#wp527" class="title">Adding Haptic Feedback to Mobile TV</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979899&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jason  Alexander</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Mark T Marshall</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Sriram  Subramanian</span> <span class="affiliation">University of Bristol</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the abundance of large-screen displays, mobile device users currently have little motivation to stream video content and TV broadcasts to their device&#8212;the desire to watch content 'on the move' does not currently outweigh the necessity of viewing this content on a miniaturised screen. However, the value and appeal of mobile TV broadcasts can be increased by the addition of a haptic-feedback channel to supplement the traditional video and audio streams.  <br /> This paper discusses the development of mobile haptic TV systems. It describes the design constraints for these systems and presents one concept implementation, UltraTV. UltraTV is a mobile device that provides mid-air, multi-point, back-of-device ultrasonic haptic feedback to enhance the mobile TV experience (see Figure 1). The paper concludes with a look at avenues for further exploration within the realm of mobile haptic TV.</span></div></div><div class="paper" id="wp531"><a href="#wp531" class="title">PowerSocket: Towards On-Outlet Power Consumption Visualization</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979901&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Florian  Heller</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Power consumption is measured in W and Wh, but what do these units mean? Water consumption can easily be understood, as we all know what a liter of water looks like. Common power meters, however, rely on the physical units or their translation to costs as display. We classified existing displays and ambient visualizations in a taxonomy that focuses on the characteristics of power consumption displays. We adapted representatives of the different categories of displays to an on-outlet display and compared these using a combination of soft- and hardware prototyping. Results indicate that ambient visualizations make it easier to understand power consumption.</span></div></div><div class="paper" id="wp425"><a href="#wp425" class="title">SketchSpace: Designing Interactive Behaviors with Passive Materials</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979867&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Holman</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents SketchSpace, a system that allows designers to interactively sketch [3] device&#8217;s interactive behaviors by imbuing digital functionality to passive materials. SketchSpace requires no augmentation of the device itself, but instead it uses a depth-sensing Kinect camera to simulate the use of hardware sensors by using depth information to infer an object's three-dimensional position, motion, proximity, shape, deformations, and touch events on its surface. A designer can map these inputs to desktop applications in real-time and thus experiment with different interactions. We showcase how SketchSpace can be used to prototype two devices: from tilt sensitive mice to bendable displays. In general, we discuss how this simplifies the process of generating an interactive device sketch and supports rapid exploration of design solutions.</span></div></div><div class="paper" id="wp539"><a href="#wp539" class="title">Paper Interface Design for Classroom Orchestration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979904&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S&#233;bastien  Cuendet</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Quentin  Bonnard</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Fr&#233;d&#233;ric  Kaplan</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Pierre  Dillenbourg</span> <span class="affiliation">EPFL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designing computer systems for educational purpose is a difficult task. While many of them have been developed in the past, their use in classrooms is still scarce. We make the hypothesis that this is because those systems take into account the needs of individuals and groups, but ignore the requirements inherent in their use in a classroom. In this work, we present a computer system based on a paper and tangible interface that can be used at all three levels of interaction: individual, group, and classroom. We describe the current state of the interface design and why it is appropriate for classroom orchestration, both theoretically and through two examples for teaching geometry.</span></div></div><div class="paper" id="wp573"><a href="#wp573" class="title">Communication by Change in Taste</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979916&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hiromi  Nakamura</span> <span class="affiliation">Meiji University</span>, <br />
<span class="author">Homei  Miyashita</span> <span class="affiliation">Meiji University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we discuss the possibilities and enjoyment of communication by changes in taste, as well as the concept of expanding the sense of taste. When the tongue is electrically stimulated, it senses a characteristic taste. We developed various apparatuses to change the taste of food and drinks based on this effect . An apparatus for drinks, comprising two electrically conducting straws, is used to change the taste of the drink by the formation of an electrical circuit inside the mouth only when drinking by holding both straws in the mouth. In the case of two persons each having one straw in their mouths, shaking hands causes electricity to flow, resulting in the change in taste. With a chopsticks/fork type of apparatus, the taste changes by the electric current that flows through the human body when one person helps the other to eat. In the case of both types of apparatuses, it is possible to control the voltage by a PWM(pulse width modulation) and the pattern by a relay, and a variety of tastes can be produced by a personal computer.</span></div></div><div class="paper" id="wp589"><a href="#wp589" class="title">The Effects of Spatial Layout and View Control on Cognitive Processing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979921&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eric D Ragan</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Alex  Endert</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Doug A Bowman</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Francis  Quek</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study explores how spatial layout and view control impact learning. We performed a controlled experiment using a learning activity involving memory and comprehension of a visually represented story. We present our preliminary results comparing performance between a slideshow-type presentation on a single monitor and a spatially distributed presentation among multiple monitors, and method of view control (automatic and interactive). With the distributed layout, participants maintained better memory of the associated locations where information was presented. However, performance scores were significantly better for the slideshow presentation than for the distributed layout for the learning task.</span></div></div><div class="paper" id="wp414"><a href="#wp414" class="title">Initial Results from a Study of the Effects of Meditation on Multitasking Performance</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979862&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David M. Levy</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alfred W. Kaszniak</span> <span class="affiliation">University of Arizona</span>, <br />
<span class="author">Marilyn  Ostergren</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports initial results from a study exploring whether training in meditation or relaxation can improve office workers&#8217; ability to multitask on a computer more effectively and/or with less stress. Human resource (HR) personnel were given 8 weeks of training in either mindfulness meditation or body relaxation techniques, and were given a stressful multitasking test both before and after training. (A third group, a control group, received no intervention during the 8-week period but was tested both before and after this period.) Results indicate that overall task time and errors did not differ significantly among the three groups. However, the meditation group reported lower levels of stress and showed better memory for the tasks they had performed; they also switched tasks less often and remained focused on tasks longer.</span></div></div><div class="paper" id="wp436"><a href="#wp436" class="title">VORTEX: Design and Implementation of an Interactive Volumetric Display</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979870&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abhijit  Karnik</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Archie  Henderson</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Andrew  Dean</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Howard  Pang</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Thomas  Campbell</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Satoshi  Sakurai</span> <span class="affiliation">Osaka University</span>, <br />
<span class="author">Guido  Herrmann</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Shahram  Izadi</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Yoshifumi  Kitamura</span> <span class="affiliation">Tohoku University</span>, <br />
<span class="author">Sriram  Subramanian</span> <span class="affiliation">University of Bristol</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">True 3D display systems like volumetric displays allow generation of autostereoscopic, multi-view 3D content that has real physical dimensions. However their uptake as a research tool within the HCI community is limited largely due to difficulties in buying or building such displays. The choice of commercially available systems is limited and constrains the flexibility of their use in terms of interaction capabilities, display features and integration with multi-display environments (MDEs). In this paper we describe the steps involved in creating custom volumetric display from easily available components. By building a touch-enabled volumetric display we walk-through the steps involved in the process. This will enable us to explore various interactive systems, associated techniques and challenges related to integration of the device into a MDE.</span></div></div><div class="paper" id="wp613"><a href="#wp613" class="title">Socially-Interactive Dressing Room: An Iterative Evaluation on Interface Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979925&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jasy Suet Yan  Liew</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">Elizabeth  Kaziunas</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">JianZhao  Liu</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">Shen  Zhuo</span> <span class="affiliation">Syracuse University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the formative user interface design of a socially-interactive dressing room. The socially-interactive dressing room allows shoppers to talk to their friends in real time for opinions on their garment purchasing decisions. Our work is motivated by the observation that shoppers who lack fashion sense often rely on their friends&#8217; opinions when making garment purchasing decisions. Using the iterative user interface design methodology, we conducted a mini focus group and interviews among male and female shoppers to refine the user interface design. Our findings suggest that an iterative approach proves to be useful in uncovering and addressing usability, aesthetics, and trust issues that arise from incorporating a socially-interactive system within a dressing room context.</span></div></div><div class="paper" id="wp623"><a href="#wp623" class="title">Next Step in Electronic Brainstorming: Collaborative Creativity with the Web</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979929&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lassi A Liikkanen</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Kai  Kuikkaniemi</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Petri  Lievonen</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Pauli  Ojala</span> <span class="affiliation">Helsinki Institute for Information Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Brainstorming is an essential technique in creative group work. Research literature indicates the strengths of electronic brainstorming over face-to-face work. Despite this evidence, the old practice dominates. We believe that this is due to the inadequate integration of new tools to existing practices and the tendency to focus on idea production alone. This paper explores how to augment traditional, collocated Brainstorming and make electronic brainstorming feasible and accessible with web-based technology. We introduce an electronic brainstorming application prototype and justify its design principles. Our system aimed at facilitating conceptual design and we present design insights from a pilot study with the prototype used by 27 design students. The paper argues that by structuring the generative group process with a low-cost tool, users can sprint through a creative process, from problem definition to defining a solution.</span></div></div><div class="paper" id="wp635"><a href="#wp635" class="title">ViewSer: A Tool for Large-Scale Remote Studies of Web Search Result Examination</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979936&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dmitry  Lagun</span> <span class="affiliation">Emory University</span>, <br />
<span class="author">Eugene  Agichtein</span> <span class="affiliation">Emory University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Web search behavior studies, including eye-tracking studies of search result examination, have resulted in numerous insights to improve search result quality and presentation. Yet, these studies have been severely restricted in scale, due to the expense and effort required. We propose a novel methodology for crowdsourcing web search behavior studies &#8211; specifically focusing on performing large-scale studies of result examination behavior. We present a viewport-based examination interface (ViewSer), which enables remotely tracking searcher examination behavior, without requiring eye tracking equipment. We show that ViewSer induces similar viewing and clickthrough behavior, compared to in-lab users monitored with eye tracking, in a study with over 100 remote participants. ViewSer is a first step towards large-scale behavioral evaluation of web search, which would help improve web search result presentation, result ranking, and ultimately improve the web search experience overall.</span></div></div><div class="paper" id="wp368"><a href="#wp368" class="title">Who Said Monitoring Is Boring?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979849&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pradeep  Buddharaju</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Dvijesh  Shastri</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Anitha  Mandapathi</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Swati  Vaidya</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Ioannis  Pavlidis</span> <span class="affiliation">University of Houston</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this article, we extend our previous work [1], which blended gaming in monotonous security tasks to increase operator engagement and enjoyment. Specifically, we expand from a single game presented in [1] to an assortment of games that appeal to different tastes. These include a shooting game, a racket game, and two puzzle games. All games are designed in a way that attracts instead of detracting attention to the monitoring screens. In addition to the game set, we also include a web browser capability symbiotic to the monitoring task. All these applications are tested in a quite realistic pilot experiment, where subjects are monitoring live security feeds. This is in contrast to the experiment on a pre-recorded video feed reported in [1]. The results demonstrate that subject engagement and enjoyment is significantly higher when the monitoring task is multiplexed with imaginative interactive options. This improvement in job satisfaction is achieved without sacrificing performance, as measured by detection of suspicious activities.</span></div></div><div class="paper" id="wp637"><a href="#wp637" class="title">SoundVision: Graphic Communication Method for Blind Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979938&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chaochao  Chen</span> <span class="affiliation">Kunsthochschule Berlin-Weissensee</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Parallel visual data acquisition is not available to blind. Yet, sequential tactile scanning (e.g. white cane) allows them to form mental concepts of their surroundings, albeit slower. The purpose of this project is to demonstrate that acoustic serial scanning of graphical objects allows a blind user to form mental concepts and to reproduce these objects graphically. Moreover, this system is designed to enable blind users to obtain graphic information and express their visual ideas graphically through sound.</span></div></div><div class="paper" id="wp423"><a href="#wp423" class="title">Turkomatic: Automatic Recursive Task and Workflow Design for Mechanical Turk</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979865&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anand P Kulkarni</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Matthew  Can</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Bjoern  Hartmann</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Completing complex tasks on crowdsourcing platforms like Mechanical Turk currently requires significant up-front investment into task decomposition and workflow design. We present a new method for automating task and workflow design for high-level, complex tasks. Unlike previous approaches, our strategy is recursive, recruiting workers from the crowd to help plan out how problems can be solved most effectively. Our initial experiments suggest that this strategy can successfully create workflows to solve tasks considered difficult from an AI perspective, although it is highly sensitive to the design choices made by workers.</span></div></div><div class="paper" id="wp404"><a href="#wp404" class="title">My Mobile Story: Therapeutic Storytelling for Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979860&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mark  Matthews</span> <span class="affiliation">Trinity College</span>, <br />
<span class="author">Gavin  Doherty</span> <span class="affiliation">Trinity College</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes the design, evaluation and rationale behind a multimedia message service (MMS) based therapeutic system for adolescents attending therapy. The mobile phone is used to assist clients in engaging with therapy through the completion of structured therapeutic tasks. Content is gathered by the client with the phone, and browser-based software is then used to structure the content during a face-to-face therapeutic session. We discuss initial findings including the potential for engaging clients in remote therapeutic activities and the importance of client control over access to their content. We also consider several practical issues concerning the design and evaluation of software to be used in clinical settings.</span></div></div><div class="paper" id="wp550"><a href="#wp550" class="title">A Long-term Study of User Experience towards Interaction Designs that Support Behavior Change</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979909&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sang-Su  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Kun-pyo  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many researches on interaction design that supports users&#8217; behavior change in everyday life are studied recently especially in the domain of pervasive technology. However, not much attention has been paid to long-term effects on users in such cases. This paper presents our initial work of a long-term (8 month) study of users' self-report of experiences with an ambient dashboard feedback system in an automobile called Eco-driving system. It was notable that user satisfaction changed positively following active self-efforts made by users to understand the system after the negative shift due to initial disappointment. This work will be a first step to build a framework of how users accept systems designed to persuade them to change behavior over time.</span></div></div><div class="paper" id="wp600"><a href="#wp600" class="title">Bridging the Gap: Implementing Interaction Through Multi-User Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979922&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tom  Bartindale</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Rachel  Clarke</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Madeline  Balaam</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe an interactive museum installation designed to extend visitor participation through personal reflection and contribution. The case study describes design approaches, which focused on multiple individual simultaneous use, which we describe as multi-user design. These approaches were deployed to support the visitor moving from viewer to contributor in a temporary museum exhibition. We present the anticipated use and early analysis of some of the data from actual use of the system. We outline our initial findings for the opportunities and limits in designing for personalised user-generated content through such approaches within museums and suggest areas of future work on qualities of participation and visitor contribution.</span></div></div><div class="paper" id="wp508"><a href="#wp508" class="title">Informing Design by Recording Tangible Interaction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979893&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Augusto  Esteves</span> <span class="affiliation">Madeira Interactive Technologies Institute</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Evaluating tangible user interfaces is challenging. Despite the wealth of research describing the design of tangible systems, there is little empirical evidence highlighting the benefits they can confer. This paper presents a toolkit that logs the manipulation of tangible objects as a step towards creating specific empirical methods for the study of tangible systems. The paper argues that the data derived from toolkit can be used in three ways. Firstly: to compare tangible interaction with other interaction paradigms. Secondly: to compare among different tangible interfaces performing the same tasks. Thirdly: via integration into a structured design process. This paper focuses on this last topic and discusses how detailed data regarding object use the data could be integrated into classifications and frameworks such as the Shaer&#8217;s et al&#8217;s TAC paradigm.</span></div></div><div class="paper" id="wp354"><a href="#wp354" class="title">Effect of Levels of Automation on Emotional Experience in Intelligent Products</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979846&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Moon-Hwan  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Tek-Jin  Nam</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Hyeon-Jeong  Suk</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many scientists and engineers have researched how to apply automation technology to intelligent products. Emotional experiences in products have been considered as important factors for users&#8217; satisfaction as well. With users&#8217; emotions in mind, it is necessary to consider whether automated products indeed provide humans with emotionally satisfying experiences. In this paper, we investigated how different levels of automations affect users&#8217; experiences from an emotional point of view. Through experiments, effects of cognitive automation and motor automation were explored. The paper concludes with recommendations for applying automation technologies to intelligent products.</span></div></div><div class="paper" id="wp422"><a href="#wp422" class="title">A Cultural Knowledge-based Method to Support the Formation of Homophilous Online Communities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979864&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Junia C Anacleto</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Fernando C Balbino</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Andre O Bueno</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Gilberto O Astolfi</span> <span class="affiliation">Federal University of S&#227;o Carlos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We propose a three-step method to identify people in social networks sites (SNS) who are talking about the same topics, even though they may be from different cultural backgrounds. Our method uses a cultural knowledge base from the OMCS-Br project to normalize cultural differences and find common interest among users based on statements they make various topics in a SNS. We evaluated three initial phrases that were used to search for sentences in a large social network using the cultural translation; we found that 81% of the retrieved sentences were judged to be related to the initial phrases. Thus, we have evidence that cultural normalization can support finding people talking about the same topic in a SNS even when they have different ways of saying the same thing. We believe that these culturally translated similarities can be used in a recommender system to contribute to the formation of homophilous online communities.</span></div></div><div class="paper" id="wp455"><a href="#wp455" class="title">Listening to the Community: Social Media Monitoring Tasks for Improving Government Services</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979878&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cecile  Paris</span> <span class="affiliation">CSIRO</span>, <br />
<span class="author">Stephen  Wan</span> <span class="affiliation">CSIRO</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a preliminary analysis of the tasks and information needs of users performing social media monitoring to improve government services.  In general, our aim is to explore how text analysis tools can support a social media monitoring task in the government context.  We find that, in this context, social media monitoring is a complex activity. Social media monitors not only perform traditional media monitoring tasks, but they also take specific actions to provide an improved service, predominantly by checking and vetting information contributed by the wider online community.  In our analysis, we found a number of specific information-based actions performed in order to determine how one should respond to a particular social media post. <br /></span></div></div><div class="paper" id="wp489"><a href="#wp489" class="title">Introducing VERO: Visual Experiential Requirements Organizer</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979886&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Agnieszka  Szostek</span> <span class="affiliation">Interactive Technologies Laboratory Institute for Information Processing (OPI)</span>, <br />
<span class="author">Evangelos  Karapanos</span> <span class="affiliation">Madeira Interactive Technologies Institute Universidade da Madeira</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crucial to the advancement of the User Experience field is the ability to understand product qualities as perceived by users. Therefore we would like to introduce VERO (Visual Experiential Requirements Organizer), an online tool for the structured elicitation of users' perceptions of a given stimulus such as a product, a system or a concept. Contrary to the existing elicitation methods, VERO aims to enable users to freely express opinions about qualities relevant for a given stimulus; to indicate the importance of each quality without imposing a hierarchical order and to cluster related qualities according to users' own perception regarding the strength of the link between them. In this paper we also motivate our approach in developing VERO and sketch our research agenda regarding its validation and application in the field of User Experience.</span></div></div><div class="paper" id="wp491"><a href="#wp491" class="title">The Online Privacy Paradox: A Social Representations Perspective</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979887&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marie Caroline  Oetzel</span> <span class="affiliation">Institute for Management Information Systems, Vienna University of Economics and Business</span>, <br />
<span class="author">Tijana  Gonja</span> <span class="affiliation">Institute for Management Information Systems, Vienna University of Economics and Business</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present early results from a study, which aims at understanding the privacy paradox from a social representations perspective. After identifying adequate stimulus words with the help of a preliminary study, we conducted the main study using an online questionnaire. Participants were instructed to associate freely to the given stimulus words. The results of the polarity and sequence analysis of the associations provide a first valuable insight into the social representations of online privacy.</span></div></div><div class="paper" id="wp506"><a href="#wp506" class="title">Investigating Syntactic Alignment in Spoken Natural Language Human-Computer Communication</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979892&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Benjamin R. Cowan</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Russell  Beale</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Holly P. Branigan</span> <span class="affiliation">The University of Edinburgh</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes planned experiment-based research observing the existence of syntactic alignment in natural language computer interactions. This research will achieve this through using a computer-human version of the confederate communication task commonly used in psycholinguistic research observing syntactic alignment in human-human dialogue. The motivations of the work lie in observing the existence of syntactic alignment in human-computer dyads and how the naturalness of interaction affects the appearance of such a linguistic phenomenon. The work will also aim to identify how such a linguistic effect links to users&#8217; satisfaction and quality judgments of interaction.</span></div></div><div class="paper" id="wp524"><a href="#wp524" class="title">Mixing Psychology and HCI in Evaluation of Augmented Reality Mental Health Technology</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979898&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Maja  Wrzesien</span> <span class="affiliation">Universidad Polit&#233;cnica de Valencia</span>, <br />
<span class="author">Jean-Marie  Burkhardt</span> <span class="affiliation">Universit&#233; Paris Descartes</span>, <br />
<span class="author">Mariano  Alca&#241;iz Raya</span> <span class="affiliation">Universidad Polit&#233;cnica</span>, <br />
<span class="author">Cristina  Botella</span> <span class="affiliation">Universidad Jaume I</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent studies present Augmented Reality Exposure Therapy (ARET) as a potentially effective technology in the Mental Health (MH) field. This study evaluates the ARET system applied to treatment of cockroach phobia in a clinical setting. The results seem to show that the ARET system is useful in helping the therapist construct a therapeutic relationship with the client. ARET also produces a visible reduction in the clients&#8217; clinical measures. Possible implications in terms of future design and evaluation methodologies are discussed.</span></div></div><div class="paper" id="wp547"><a href="#wp547" class="title">A Fitt of Distraction: Measuring the Impact of Distracters and Multi-users on Pointing Efficiency</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979908&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Denis  Lalanne</span> <span class="affiliation">University of Fribourg</span>, <br />
<span class="author">Agnes  Lisowska Masson</span> <span class="affiliation">University of Fribourg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents the results of an experiment aimed at measuring the impact of the number of distracters and of co-located users on individual pointing efficiency. The experiment, performed with 20 users, is a variation of a Fitt&#8217;s Law test in which we incrementally augmented the number of distracters on the screen and the number of co-located users. The results show that the number of distracters clearly influences users&#8217; pointing performance. Further, it shows that users are more efficient at pointing items when they share the display with co-located users than when they are alone.</span></div></div><div class="paper" id="wp561"><a href="#wp561" class="title">What Do You See When You Interact with Friends Online? Face, Hand, or Canvas?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979911&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyle  Koh</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Hyunjoo  Song</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Daekyoung  Jung</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Bohyoung  Kim</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Jinwook  Seo</span> <span class="affiliation">Seoul National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">People use plethora of interactive remote conference tools for various tasks ranging from collaborative works to entertainment needs. The tasks are often distinguishable in terms of their types and users' usage patterns. We present a preliminary user study designed to explore the different usage patterns derived by performing different types of tasks. In this study, 18 people used an interactive remote conference tool for three types of tasks; Collaborative Creation, Cooperative Problem Solving, and Competitive Game Play with different screen configurations. We analyzed usage patterns using an eye-tracker as well as the result from post experimental questionnaire. We found that different tasks resulted in different gaze patterns. We also present an interesting finding on how users mistakenly report the use of the tool by contrasting the result with the questionnaire and eye-tracking log.</span></div></div><div class="paper" id="wp558"><a href="#wp558" class="title">Digital Mind Mapping: Innovations for Real-time Collaborative Thinking</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979910&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Honray  Lin</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Haakon  Faste</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the development of a new digital mind mapping tool for future research on interactive knowledge management systems, specifically with regard to real-time collaborative thinking. We have evaluated numerous existing mind mapping software applications, and performed ethnographic research with a variety of users, to develop a framework of principles to guide the design of future idea generation and management systems. Our findings indicate a rich opportunity space for digital mind mapping tools, particularly in the areas of facilitating collaboration and information storage and retrieval.</span></div></div><div class="paper" id="wp374"><a href="#wp374" class="title">Design Your Room: Adding Virtual Objects to a Real Indoor Scenario</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979851&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rui  N&#243;brega</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Nuno  Correia</span> <span class="affiliation">Universidade Nova de Lisboa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an interior design application that uses photos from real indoor spaces and rooms as input. The user is encouraged to take a picture of a certain place and virtually reshape it with furniture, different colors, textures and materials. The system analyses the still image of the physical space through image processing and computer vision algorithms to detect the world orientation relative to the camera. Knowing this, it is possible to create a natural interface where objects are laid on the floor and pushed around as in real life.</span></div></div><div class="paper" id="wp627"><a href="#wp627" class="title">Programming on the Move: Design Lessons from IPRO</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979932&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Berland</span> <span class="affiliation">University of Texas at San Antonio</span>, <br />
<span class="author">Taylor  Martin</span> <span class="affiliation">University of Texas at Austin</span>, <br />
<span class="author">Tom  Benton</span> <span class="affiliation">University of Texas at Austin</span>, <br />
<span class="author">Carmen  Petrick</span> <span class="affiliation">University of Texas at Austin</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computer programming is often a stationary, solitary task; such tasks do not work well for most novices. This work describes the IPRO project that uses our 'Programming Standing Up' framework (PSU) to reframe programming as a mobile, social game. IPRO is a programming and simulation environment for iOS in which a learner programs a virtual robot to play soccer in a virtual space shared with her cohort. This work presents examples of secondary school students learning with IPRO. We then connect the examples to PSU design principles and evaluate those principles in terms of the examples.</span></div></div><div class="paper" id="wp630"><a href="#wp630" class="title">PMRI: Development of a Pictorial Mood Reporting Instrument</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979933&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Martijn  Vastenburg</span> <span class="affiliation">Delft University of Technology</span>, <br />
<span class="author">Natalia  Romero Herrera</span> <span class="affiliation">Delft University of Technology</span>, <br />
<span class="author">Daniel  Van Bel</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Pieter  Desmet</span> <span class="affiliation">Delft University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mood capturing techniques are being used in research settings (e.g., lab evaluation and experience sampling) and to facilitate mood communication in mediated interaction (e.g., instant messaging and blogging). Instruments currently available tend to be either limited in expression or overly demanding. In this paper we describe our work-in-progress on the development of PMRI, a rich and easy-to-use pictorial mood-reporting instrument.</span></div></div><div class="paper" id="wp632"><a href="#wp632" class="title">Evaluating a Social Media Application for Sustainability in the Workplace</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979935&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Lehrer</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Janani  Vasudev</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The goal of this research is to investigate the benefits of using a web-based social network to promote energy awareness, and influence energy-saving behavior of typical office workers. We propose that a social network integrated into the workplace environment &#8212; allowing people to track their own energy-related activities, to share this information, and to view and react to peers&#8217; activities &#8212; can take advantage of social influence to positively affect behavior. We are currently developing a prototype of such an application through iterative design. In the final phase of this work we will conduct experiments with a large number of subjects to test the ability of this application to influence attitudes and behaviors of office workers, and for providing a platform for commercial building operators to better communicate with occupants.</span></div></div><div class="paper" id="wp636"><a href="#wp636" class="title">Constructing Scientific Arguments with User Collected Data in Nomadic Inquiry</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979937&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Kuhn</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Brenna  McNally</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Clara  Cahill</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Chris  Quintana</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Elliot  Soloway</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mobile devices now enable students to engage in nomadic inquiry as they collect large amounts of data from the environment to answer scientific questions. To support them with constructing scientific arguments, we created CogniBits: a system designed for tablet devices that scaffolds students through creating scientific arguments with user-collected data. The system was iteratively designed with two students and seeks to address the additional challenges these opportunities bring to science inquiry.</span></div></div><div class="paper" id="wp570"><a href="#wp570" class="title">Constructing Virtual 3D Models with Physical Building Blocks</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979915&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ricardo  Jota</span> <span class="affiliation">Inesc-ID</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Constructing virtual 3D models typically requires specialized desktop modeling tools (e.g., CAD tools), which, while very powerful, tend to require a lot of precision, time, and expertise from the user. We present StereoBlocks, a system that combines a Kinect depth camera with 3D stereoscopic projector to allow the user to build complex virtual 3D models from available physical objects. By treating the camera information as a continuous 3D digitizer, we are able to capture the details of the real world and re-project virtual objects side-by-side to real objects. The user is able to visualize such mixed reality model through stereoscopic projected imagery tightly aligned with the real world. In our system, it is literally possible to build the entire virtual castle, using only a single physical brick piece. We discuss our prototype implementation and report on early feedback from the four users that evaluated our system.</span></div></div><div class="paper" id="wp655"><a href="#wp655" class="title">Senior Wellness: Practices of Community Senior Centers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979946&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Young Seok  Lee</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Santosh  Basapur</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Shirley  Chaysinh</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Crysta  Metcalf</span> <span class="affiliation">Motorola Mobility Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In the U.S., approximately 15,000 community senior centers provide a broad spectrum of programs for seniors to increase their overall health and wellness in their community. Although previous studies reported on the various benefits of participation in such programs, little research has been conducted to understand how technology can support this practice. We initiated a research study to understand the current practices of senior centers and their potential technology needs. In this article, we describe findings from our literature review as well as a field study with nine senior centers located in urban and suburban areas of Chicago, IL, and Tampa, FL. Based on the preliminary results, we share design implications for future technology development.</span></div></div><div class="paper" id="wp439"><a href="#wp439" class="title">Effect of MobileASL on Communication Among Deaf Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979872&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joy  Kim</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jessica J Tran</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Tressa W Johnson</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Richard  Ladner</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Eve  Riskin</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">MobileASL, a software program enabling sign-language video on mobile devices over conventional U.S. cellular networks, was evaluated in a three-week field study during the summer of 2010. Through a series of interviews, questionnaires, and a focus group, we asked participants about their behavior with and perceptions of MobileASL. In addition, we used on-device experience sampling and usage logging to observe how MobileASL was used. Initial results indicate that although participants felt that MobileASL&#8217;s short battery life limited its use, participants took advantage of the mobility of the technology and used it for in-the-moment information gathering in places like buses, restaurants, and shopping areas.</span></div></div><div class="paper" id="wp588"><a href="#wp588" class="title">Towards a Psychographic User Model From Mobile Phone Usage</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979920&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rodrigo  de Oliveira</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Alexandros  Karatzoglou</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Pedro  Concejero Cerezo</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Ana  Armenta Lopez de Vicu&#241;a</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Nuria  Oliver</span> <span class="affiliation">Telefonica Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Knowing the users&#8217; personality can be a strategic advantage for the design of adaptive and personalized user interfaces. In this paper, we present the results of a first trial conducted with the aim of inferring people&#8217;s personality traits based on their mobile phone call behavior. Initial findings corroborate the efficacy of using call detail records (CDR) and Social Network Analysis (SNA) of the call graph to infer the Big Five personality factors. On-going work includes a large-scale study that shall refine the accuracy of the models with a reduced margin of error.</span></div></div><div class="paper" id="wp450"><a href="#wp450" class="title">Mourning Tree : Space Interaction Design for the Commemoration Ceremony</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979876&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jihwan  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">seyong  kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">JINJU  YU</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Sangsup  Yoon</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Sangki  Han</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The aim of this project is to improve the current culture of cherishing the memory of a deceased person through a new approach over the traditional, a cyber commemoration method. Through a preliminary research, we defined two major problems of current commemoration ceremony: separation between traditional cherish and cyber cherish, immaturity of cyber cherish method. Therefore, we focused on making a new way of commemoration, &#8216;Mourning Tree&#8217;. Mourning Tree is a digital tree which is displayed by holographic technology, and the tree can receive messages from the cherisher in the many ways (SNS, SMS, e-mail). The message is displayed as a leaf of the tree, and the more messages this tree receives, the larger and more meaningful the tree becomes. Because of the exhibition of Mourning Tree in actual cherishing area, it can not only physically interact but virtually interact with the cherisher. We developed a prototype of the Mourning Tree and conducted an examination.</span></div></div><div class="paper" id="wp576"><a href="#wp576" class="title">Medical Record Privacy: Is it a Facade?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979918&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aubrey  Baker</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Laurian  Vega</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Tom  DeHart</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Steve  Harrison</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Part of the job of healthcare providers is to manage patient information. Most is routine, but some is sensitive. For these reasons physicians&#8217; offices provide a rich environment for understanding complex, sensitive information management issues as they pertain to privacy and security. In this paper we present findings from interviews and observations of 15 offices in rural-serving southwest Virginia. Our work demonstrates how the current socio-technical system fails to meet the security needs of the patient. In particular, we found that the tensions between work practice and security, and between electronic and paper records resulted in insecure management of files.</span></div></div><div class="paper" id="wp618"><a href="#wp618" class="title">Behavioral Science-Informed Technology Interventions for Change in Residential Energy Consumption</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979926&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Crowley</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Aur&#233;lia  Heitz</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Annika  Matta</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Kevin  Mori</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Banny  Banerjee</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Behavior change represents an important new approach to addressing the energy crisis.  Utility companies and private companies are deploying sensor-based power meters and related residential electricity monitoring technologies with the view that monitoring energy use will eventually result in a reduction in energy consumption.  The success of these technologies depends largely on homeowners responding to the data with appropriate changes in their consumption behavior. Most energy feedback interfaces, however, have not been designed through a human-centered process and display data in ways that are unlikely to change behavior.  Our proposal is to design interactive interfaces that combine a deeply human-centered process with insights from behavioral economics to reduce residential energy consumption.  This paper describes our current research to develop and evaluate interactive interfaces based on three motivational categories:  cognitive, social, and affective.</span></div></div><div class="paper" id="wp451"><a href="#wp451" class="title">Technology-Mediated Parent-Child Intimacy: Designing for Ecuadorian Families Separated by Migration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979877&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marisol  Wong-Villacres</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study explores the role technology plays in supporting long-distance relationships of migrant parents and left-behind children in developing countries such as Ecuador, in order to inform the design of technology that better suits their affective needs and their context&#8217;s constraints. We derived three design principles based on our fieldwork in Ecuador: shared experience, the empowerment of children to self-express and children&#8217;s need to safely build a private communication channel with their parents. We report our research findings and propose a set of design concepts for future work.</span></div></div><div class="paper" id="wp653"><a href="#wp653" class="title">Power Ballads: Deploying Aversive Energy Feedback in Social Media</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979944&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Derek  Foster</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Conor  Linehan</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Shaun  Lawson</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Ben  Kirman</span> <span class="affiliation">University of Lincoln</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports on the pilot evaluation of &#8220;Power Ballads&#8221;, an evocative social media application which displays aversive feedback based on excessive household energy usage. Work by other researchers in persuasive technologies has previously suggested the use of aversive feedback should be avoided as it leads to a lack of engagement by users. This work evaluates whether punishment of non-desirable behaviour discourages users from engaging with a persuasive application. To this end we recruited 9 households to use the Power Ballads application over a period of 4 weeks. We found the use of aversive feedback did not act as a deterrent to regularly interacting with the application through evaluating user engagement.</span></div></div><div class="paper" id="wp611"><a href="#wp611" class="title">Interpersonal Informatics: Making Social Influence Visible</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979924&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth  Bales</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">William  Griswold</span> <span class="affiliation">University of California, San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent research in social network science has found that that what we do and say flows through our social network, impacting our friends, our friends&#8217; friends, and beyond. Likewise, our own personal choices are also the influenced by the social networks we participate in. We introduce the area of interpersonal informatics, a class of tools that allows groups of people to collect, aggregate, analyze, and share personally relevant information. The goal of interpersonal informatics is to  help people gain awareness of how those around them affect their habits, beliefs, and health.</span></div></div><div class="paper" id="wp642"><a href="#wp642" class="title">Evoked Friction on a Smooth Touch Device</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979939&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Creating realistic virtual friction forces requires using complex hardware setups. In simpler mobile systems, friction is often suggested by mimicking textures with vibration, based on the position on the screen. Even in the simplest implementations, this paper proposes that force sensing should also be used to modulate vibration. In this way, Coulomb&#8217;s model of friction can be better emulated and it can lead to conclude more easily that friction is the origin of the vibration. A proof-of-concept prototype is described, which received positive first impressions regarding improved user experience. A follow up study is warranted.</span></div></div><div class="paper" id="wp510"><a href="#wp510" class="title">Robotic Wheelchair Moving with Caregiver Collaboratively Depending on Circumstances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979894&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yoshinori  Kobayashi</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Yuki  Kinpara</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Erii  Takano</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Yoshinori  Kuno</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">keiichi  Yamazaki</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Akiko  Yamazaki</span> <span class="affiliation">Tokyo University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper introduces a robotic wheelchair that can automatically move alongside a caregiver. Because wheelchair users are often accompanied by caregivers, it is vital to consider how to reduce a caregiver&#129;fs load and support their activities, while simultaneously facilitating communication between the caregiver and the wheelchair user. Moreover, it has been pointed out that when a wheelchair user is accompanied by a companion, the latter is inevitably seen by others as a caregiver rather than a friend. To address this situation, we devised a robotic wheelchair able to move alongside a caregiver or companion, and facilitate easy communication between them and the wheelchair user. To confirm the effectiveness of the wheelchair in real-world situations, we conducted experiments at an elderly care center in Japan.</span></div></div><div class="paper" id="wp424"><a href="#wp424" class="title">A collective map to capture human behavior for the design of public spaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979866&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mizuki  Oka</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Tom  Hope</span> <span class="affiliation">Tokyo Institute of Technology</span>, <br />
<span class="author">Yasuhiro  Hashimoto</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Ryoko  Uno</span> <span class="affiliation">Tokyo University of Agriculture and Technology</span>, <br />
<span class="author">Myeong-Hee  Lee</span> <span class="affiliation">Design office matt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores potential uses of publicly created behavioral data for spatial (re)design. The widespread use of mobile devices and access to the Internet has made spontaneous sharing of information about one&#8217;s life increasingly common. These emerging trends of pervasive life logging and sensing in communal space provoke new opportunities for designers and architects. This paper reports on work in progress, introducing a set of tools to support spatial design via the collection and analysis of human behavior using Twitter, and presents the result of a workshop using the tools in a university library in Japan. We offer ways to analyze and visualize the data and discuss what we can observe from the collected data that may be useful for designing such communal spaces.</span></div></div><div class="paper" id="wp528"><a href="#wp528" class="title">How Revealing are Eye-Movements for Understanding Web Engagement in Young Children?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979900&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stacey  Birkett</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Adam  Galpin</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Simon  Cassidy</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Lynne  Marrow</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Sarah  Norgate</span> <span class="affiliation">University of Salford</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents a critical review of eye tracking as a research approach and evaluates its potential for usability testing in pre-school children. We argue that eye-tracking data is useful for assessing web engagement in this age-group, but only if triangulated against other usability methods. Recommendations for potential usability methods to use in tandem with eye-tracking are presented as part of a work in progress within a joint partner project between the University of Salford (UK) and the British Broadcasting Corporation (BBC) exploring best-fit methodologies for understanding web engagement in young children.</span></div></div><div class="paper" id="wp657"><a href="#wp657" class="title">NICU-2-HOME: Supporting the Transition to Home from the Neonatal Intensive Care Unit using a Mobile Application</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979947&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Young Seok  Lee</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Craig  Garfield</span> <span class="affiliation">NorthShore University HealthSystem</span>, <br />
<span class="author">Noel  Massey</span> <span class="affiliation">Motorola Solutions Inc.</span>, <br />
<span class="author">Shirley  Chaysinh</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Sana  Hassan</span> <span class="affiliation">Motorola Mobility Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Parenting a Very Low Birth Weight (VLBW) premature infant in the Neonatal Intensive Care Unit (NICU) and transitioning this infant home can be very stressful for parents. Few studies, however, examined the needs of parents of VLBW infants during the transition to home; moreover, even less is known about information and communication technology strategies to support parents during the transition period. To address this knowledge gap, we are conducting a study that aims to develop a mobile application/service to support the parents of VLBW infants by enhancing communication with the NICU staff and access to information resources. We report findings from our preliminary study using contextual inquiry and phone interviews and discuss implications for system development.</span></div></div><div class="paper" id="wp543"><a href="#wp543" class="title">STORIFY- A Tool to Assist Design Teams in Envisioning and Discussing User Experience</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979905&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Berke  Atasoy</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Jean-Bernard  Martens</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Design is changing into an experience-oriented discipline; consequently designers need appropriate tools and methods to incorporate experiential aspects into their designs. A story is a crafted experience and storytelling is the craft. Therefore, understanding the structural strategies behind storytelling and learning how to incorporate them into a design process is relevant for designers when they want to envision, discuss and influence user experiences. In this paper we introduce STORIFY, a multi-modal tool to provide design teams with an experiential approach towards designing interactive products by incorporating dramaturgical techniques from film and sequential art.</span></div></div><div class="paper" id="wp415"><a href="#wp415" class="title">Context Stamp -  A Topic-based Content Abstraction for Visual Concordance Analysis</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979906&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">VinhTuan  Thai</span> <span class="affiliation">National University of Ireland, Galway</span>, <br />
<span class="author">Siegfried  Handschuh</span> <span class="affiliation">National University of Ireland, Galway</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Concordance analysis supports users in studying how terms are used in a document vs. another by investigating their usage contexts. As current approaches usually present a large set of contexts in their full text form or as a large frequency-based word cloud, they still require a lot of effort from users to make sense of the underlying complex and dynamic semantic dimensions of contexts. To address this limitation, we propose Context Stamp as a visual representation of the gist of a term's usage contexts. To abstract away the textual details and yet retain the core facets of a term's contexts for visualization, we blend a statistical topic modeling method with a combination of the treemaps and Seesoft visual metaphors. This paper provides a high level description of the text analysis method and outlines the visual design of Context Stamps.</span></div></div><div class="paper" id="wp652"><a href="#wp652" class="title">The Effects of Walking and Control Method on Pressure-Based Interaction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979943&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Graham  Wilson</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen A. Brewster</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Martin  Halvey</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pressure-based interactions have largely been limited to static scenarios; very few have focused on its use on mobile devices and even fewer have investigated the use of pressure while the user is in motion (i.e. walking). Pressure input is well suited to mobile interaction as mobile devices almost universally adopt touch and gestural input. This paper presents the initial results of research looking into the effects of walking on the application of pressure during linear targeting. Positional and rate-based (velocity) control methods are compared in order to determine which allows for more stable and accurate selections. Results suggest that rate-based control is superior for both mobile (walking) and static (sitting) linear targeting and that mobility significantly increases errors, selection time and subjective workload. These results will influence the design of a second part of the study, which will evaluate user ability to control the same application using only audio feedback.</span></div></div><div class="paper" id="wp376"><a href="#wp376" class="title">Flick-and-Brake: Finger Control over Inertial/Sustained Scroll Motion</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979853&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathias  Baglioni</span> <span class="affiliation">Telecom ParisTech - LTCI-CNRS, Alcatel Lucent Bell Labs</span>, <br />
<span class="author">Sylvain  Malacria</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span>, <br />
<span class="author">Eric  Lecolinet</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span>, <br />
<span class="author">Yves  Guiard</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present two variants of Flick-and-Brake, a technique that allows users to not only trigger motion by touch-screen flicking but also to subsequently modulate scrolling speed by varying pressure of a stationary finger. These techniques, which further exploit the metaphor of a massive wheel, provide the user with online friction control. We describe a finite-state machine that models a variety of flicking interaction styles, with or without pressure control. We report the results of a preliminary user study that suggests that for medium to long distance scrolling the Flick-and-Brake techniques require less gestural activity than does standard flicking. One of the two variants of the technique is faster, but no less accurate, than state-of-the-art flicking. Users also reported they preferred Flick-and-Brake over the standard flick and judged it more efficient. We indicate some pending issues raised by the results of this preliminary investigation.</span></div></div><div class="paper" id="wp626"><a href="#wp626" class="title">Retirees on Facebook: Can Online Social Networking Enhance Their Health and Wellness?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979931&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S. Shyam  Sundar</span> <span class="affiliation">The Pennsylvania State University, Sungkyunkwan University</span>, <br />
<span class="author">Anne  Oeldorf-Hirsch</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">Jon  Nussbaum</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">Richard  Behr</span> <span class="affiliation">The Pennsylvania State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An individual&#8217;s social network has a strong impact on his or her mental and physical health. This is of particular consequence for senior citizens who are at greater risk of social isolation after retirement, due to loss of spouse, mobility issues, and recent emphasis on aging in place, i.e., in smart homes. Can online social networking sites (SNSs) such as Facebook help alleviate social isolation of aging alone by enabling seniors to maintain high-quality social interactions? How can we make senior-friendly design improvements to SNSs? A preliminary national survey (N =168) of adults over 55 revealed that for those who had joined an SNS, the primary motivation cited for signing up was persuasion by a friend or family member, while non-users cited a strong lack of interest rather than a lack of knowledge or skill, with implications for theory and design of SNS technology for senior citizens.</span></div></div><div class="paper" id="wp625"><a href="#wp625" class="title">Multimodal Video Annotation for Contemporary Dance Creation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979930&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diogo  Cabral</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Ur&#226;ndia  Carvalho</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Jo&#227;o  Silva</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Jo&#227;o  Valente</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Carla  Fernandes</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Nuno  Correia</span> <span class="affiliation">Universidade Nova de Lisboa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents a video annotator that supports multimodal annotation and is applied to contemporary dance as a creation tool. The prototype, developed for Tablet PCs, explores bimanual interaction, using pen and touch input interfaces. This combination can be more natural and familiar than the traditional input interfaces (keyboard or mouse). Contemporary dance is a domain where this type of flexible interaction with video material is relevant in order to augment and improve the rehearsal and creative processes. Motion tracking is used to define the dynamic behavior of the annotations and voice input complements the other modalities. The paper describes the design decisions done by the multidisciplinary development team and the current status of the tool.</span></div></div><div class="paper" id="wp448"><a href="#wp448" class="title">Blink: Observing Thin Slices of Behavior to Determine Users&#8217; Expectation Towards Task Difficulty</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979875&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nuno  Branco</span> <span class="affiliation">School of Technology and Management of Felgueiras</span>, <br />
<span class="author">Jo&#227;o Pedro  Ferreira</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Marta  Noronha e Sousa</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Pedro  Branco</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Nuno  Otero</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Nelson  Zagalo</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Manuel Jo&#227;o  Ferreira</span> <span class="affiliation">University of Minho</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This work aims to address the following question: is it possible to infer the users' expectations regarding task difficulty by watching them just before the actual start?  <br /> We present a study where people acting as evaluators determined users&#8217; expectations based on non-linguistic social signals in a 20 seconds video clip. The evaluations were performed using a five-point scale and the average error of the evaluations was of one point. Preliminary results suggest what type of signals was used by the evaluators to determine the users&#8217; expected difficulty with the task.</span></div></div><div class="paper" id="wp545"><a href="#wp545" class="title">CheMO: Mixed Object Instruments and Interactions for Tangible Chemistry Experiments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979907&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyohyun  Song</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Gunhee  Kim</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Inkyu  Han</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Jeongyoung  Lee</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Ji-Hyung  Park</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Sungdo  Ha</span> <span class="affiliation">Korea Institue of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we present CheMO, a system for tangible chemistry experiments where users can interact with Mixed Object (MO) instruments that consist of a graspable physical part in the real world and a digital part in a virtual world. When used for an experiment, MO instruments enable users to employ tangible interaction methods inherited from real experience and to be given digital information similar to a physical expression arising from an actual experiment. The goal of our research is to enhance the sense of reality in a virtual experiment and to enable users to learn experimental procedures effectively and easily.</span></div></div><div class="paper" id="wp601"><a href="#wp601" class="title">TweetSpiration: Leveraging Social Media for Design Inspiration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979923&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Scarlett R Herring</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Christina M Poon</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Geoffrey A Balasi</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Brian P Bailey</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present TweetSpiration, a Web-based application that leverages social media to inspire new search directions on the Web. TweetSpiration can be used at any time, but it is particularly beneficial when designers have difficulty developing new search terms or are looking for new search directions. By visualizing socially derived word associations, designers may develop new search directions based on others comments or thoughts on the search topic. In an initial study, users reported that TweetSpiration helps develop new search directions and provides new perspectives on the design problem.</span></div></div><div class="paper" id="wp388"><a href="#wp388" class="title">An Investigation of Search Behaviour in a Tactile Exploration task for Sighted and Non-sighted Adults.</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979857&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luca  Brayda</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Claudio  Campus</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Ryad  Chellali</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Guido  Rodriguez</span> <span class="affiliation">University of Genoa</span>, <br />
<span class="author">Cristina  Martinoli</span> <span class="affiliation">Istituto David Chiossone onlus</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this work in progress we propose a new method for evaluating objectively the process of performing a tactile exploration with a visuo-tactile sensory substitution system. Both behavioral and neurophysiological cues are considered to evaluate the identification process of virtual objects and surrounding environments. Our experiments suggest that both sighted and visually impaired users integrated spatial information and developed similar behavioural and neurophysiological patterns. The proposed method could also serve as a tool to evaluate touch-based interfaces for application in orientation and mobility programs.</span></div></div><div class="paper" id="wp391"><a href="#wp391" class="title">Information Used and Perceived Usefulness in Evaluating Web Source Code Search Results</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979858&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rosalva E Gallardo-Valencia</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Susan E Sim</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Software developers frequently search for source code on the Web to solve problems. Their ability to correctly evaluate the matches returned by a source code search engine is key to the success of the search, and in turn the project. We conducted a laboratory experiment to gain understanding on the kinds of information used and their usefulness during the evaluation process. We found that the most used information was not perceived as the most useful information. We also identified three patterns for relationships among the frequency of information use, the likelihood of selecting the best match, and the time to complete a task.</span></div></div><div class="paper" id="wp446"><a href="#wp446" class="title">Tangible and Body-Based Interaction with Auditory Maps</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979874&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew P Milne</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa N Antle</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Bernhard E Riecke</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Blind people face a significant challenge navigating through the world, especially in novel environments. Maps, the most common of navigational aids, are of little use to the blind, who could benefit greatly from the information they contain. Recent work in auditory maps has shown the potential for delivering spatial information through sound.  Users control their position and orientation on a digitally enhanced map and listen for the location of important landmarks. Orientation control is important because sound localization cues can sometimes be ambiguous, especially when in front of and behind a listener. Previous devices have used a tangible interface, in which users manipulate a small motion tracked object, to allow users to control their position and orientation on a map. Motivated by research that has identified the importance of body-based cues, from the joints, muscles and vestibular system in spatial perception, we expanded on previous interfaces by constructing an auditory map prototype that allows users to control their orientation through natural head movements. A pilot study was conducted to compare the head-movement-based interface to a tangible interface.</span></div></div><div class="paper" id="wp442"><a href="#wp442" class="title">ScaleMirror: A Pervasive Device to Aid Weight Analysis</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979873&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew J Younge</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Vinod  Periasamy</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Mohammed  Al-Azdee</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">William  Hazlewood</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Kay  Connelly</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As today&#8217;s fast paced environment continually encourages poor dietary habits and a lack of exercise, there is a growing need to properly monitor and control weight gain.  With the advent of pervasive and ubiquitous computing, there are new opportunities to help promote personal wellness that was previously unobtainable.  This work describes the novel design and creation of ScaleMirror; a prototype pervasive device to help users monitor their weight.  This awareness is achieved through an accurate scale system, detailed statistics with historical data, and an intuitive design seamlessly embedded into a user&#8217;s existing daily routine.  The goal is to help a wide array of people concentrate on obtaining and maintaining a proper weight to promote a healthy and fulfilling lifestyle.</span></div></div><div class="paper" id="wp621"><a href="#wp621" class="title">CAESSA: Visual Authoring of Context-Aware Experience Sampling Studies</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979928&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mirko  Fetter</span> <span class="affiliation">University of Bamberg</span>, <br />
<span class="author">Maximilian  Schirmer</span> <span class="affiliation">Bauhaus-University Weimar</span>, <br />
<span class="author">Tom  Gross</span> <span class="affiliation">University of Bamberg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present a toolkit that enables HCI practitioners to visually author and setup Context-Aware Experience Sampling studies&#8212;CAESSA (Context-Aware Ex-perience Sampling Study Authoring).</span></div></div><div class="paper" id="wp631"><a href="#wp631" class="title">Integrating Touch and Near Touch Interactions for Information Visualizations</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979934&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aras  Balali Moghaddam</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Jeremy  Svendsen</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Melanie  Tory</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Alexandra  Branzan Albu</span> <span class="affiliation">University of Victoria</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper proposes a novel interaction paradigm for multi-touch interfaces, that integrates both touch and near-touch interactions. The paper describes the hardware prototype that we have built, as well as the computer vision approach that we propose for real-time hand tracking and differentiation between near-touch and touch events. We also present a case study showing how near-touch and touch interactions can be successfully integrated in an information visualization application.</span></div></div><div class="paper" id="wp643"><a href="#wp643" class="title">Supporting greater access to pre- and post-natal information and services for women in rural Kenya</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979940&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jakita  Thomas</span> <span class="affiliation">Spelman College</span>, <br />
<span class="author">Yolanda  Rankin</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Matthew  Tuta</span> <span class="affiliation">University of Nairobi</span>, <br />
<span class="author">Eric  Mibuari</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present initial findings of on-going work, which <br /> examine pre- and post-natal services available to <br /> women in rural Laare, Kenya as well as cell phone <br /> appropriation by service providers and consumers as <br /> initial steps in service design for access.</span></div></div><div class="paper" id="wp533"><a href="#wp533" class="title">Data Type Based Security Alert Dialogs</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979903&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Max-Emanuel  Maurer</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Alexander  De Luca</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Heinrich  Hussmann</span> <span class="affiliation">University of Munich</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Making users aware of insecure situations and behavior while browsing the Internet is a highly discussed and still difficult task. Both, passive and active warnings have their own specific disadvantages. While active warnings interrupt the current task and annoy the user, passive approaches often fail since they go unnoticed. In this work, we present first results of a concept displaying data type based alert dialogs whenever a user enters critical information into an online form. Such contextual dialogs appear right in the users&#8217; field of view representing a hybrid approach between active and passive warnings. An initial user study was conducted that showed a significant improvement of security awareness by participants that used the tool.</span></div></div><div class="paper" id="wp381"><a href="#wp381" class="title">Towards Context-Sensitive Support of Vitality in Old-Age</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979854&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominik  Jednoralski</span> <span class="affiliation">Max Planck Institute</span>, <br />
<span class="author">Michael  Schellenbach</span> <span class="affiliation">Max Planck Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Over the the last century, the average lifespan extended remarkably. The economic and social implications of living longer are vast, and include offering new prospects to make latent potential in old age accessible both to senior citizens and to society. <br /> Growing evidence suggests that the brain retains its capability to change from experience into old age, a finding that encourages targeting the elderly for interventions such as physical activity which is known to impact cognitive and neural decline. In this work we suggest intervening on the basis of these findings by means of intelligent assistive technology. Therefore, we propose a system architecture for a mobile context-aware cognitive assistant (CACA) to assess and enhance cognitive functioning of older individuals. In our view, tailored context-aware assistance can activate latent physical and cognitive potential through a combination of challenge and support, aimed at enhancing individual motivation to pursue a sustainable lifestyle.</span></div></div><div class="paper" id="wp647"><a href="#wp647" class="title">What Would the Parents Like to Know About Children but are Afraid to Ask?: Designing Reports about Child Development in Online Games</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979942&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karolina  Chmiel</span> <span class="affiliation">Institute for Information Processing</span>, <br />
<span class="author">Agnieszka  Matysiak Szostek</span> <span class="affiliation">Institute for Information Processing</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Nowadays educational games constitute a large part of <br /> the learning environment. These interactive forms of <br /> education enable children to develop various <br /> competencies and also provide feedback depicting their <br /> strengths and shortcomings. Currently, portals offering <br /> educational games provide such feedback mainly to <br /> children. Surprisingly, a parent, who is responsible for a <br /> proper development and education of a child, is usually <br /> not included as a recipient of information about the <br /> child&#8217;s results tested through games. Therefore, the <br /> goal of this preliminary study was to investigate the <br /> informational needs of the parents that can be applied <br /> to educational online games for children of age 6&#8212;9.</span></div></div><div class="paper" id="wp461"><a href="#wp461" class="title">Gathering Requirements for a Personal Health Management System</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979881&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Milewski</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Hector  Parra</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Applications are being designed to make health information available to the healthcare consumer. However, little is known about the support people need in using health information. We conducted semi-structured interviews to find out how people use health information to manage the chronic illness type-2 diabetes. We found that diabetics want to be motivated to treat the disease seriously and that the patient&#8217;s social network takes on additional work that is unrelated to their existing social role to support the patient&#8217;s health-related activities. Based on our findings, we propose a set of formative requirements to be included in the design of a personal health management system.</span></div></div><div class="paper" id="wp565"><a href="#wp565" class="title">Tag Clouds and Keyword Clouds: Evaluating Zero-Interaction Benefits</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979913&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathew J Wilson</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Max L Wilson</span> <span class="affiliation">Swansea University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Tag clouds are typically presented so that users can actively utilize community-generated metadata to query a collection. This research investigates whether such keyword clouds, and other interactive search metadata, also provide measureable passive support for users who do not directly interact with them. If so, then objective interaction-based measurements may not be the best way to evaluate these kinds of search user interface features. This paper discusses our study design, and the insights provided by a pilot study that led to a series of improvements to our study design.</span></div></div><div class="paper" id="wp568"><a href="#wp568" class="title">Causal Temporal Order in HCI</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979914&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Adam  Darlow</span> <span class="affiliation">Brown University</span>, <br />
<span class="author">Gideon  Goldin</span> <span class="affiliation">Brown University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper proposes applying principles of human causal reasoning to graphical interface design to make interfaces more intuitive. In particular, we present a design guideline for making graphical interfaces consistent with causal temporal order and demonstrate its effectiveness in an experiment where participants solve a puzzle with a novel interface. We also present preliminary results of its application to a text formatting task and propose several other causal principles that are directly applicable to interface design.</span></div></div><div class="paper" id="wp818"><a href="#wp818" class="title">Multi-touch Screens for Navigating 3D Virtual Environments in Participatory Urban Planning</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979852&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Emma  Chow</span> <span class="affiliation">Concordia University</span>, <br />
<span class="author">Amin  Hammad</span> <span class="affiliation">Concordia University</span>, <br />
<span class="author">Pierre  Gauthier</span> <span class="affiliation">Concordia University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Global trends have seen a strong push for more effective participatory planning in democratic societies.  Effective communication and universal accessibility are underpinning principles of successful participatory planning.  Virtual environments (VEs) have proven to significantly improve public understanding of 3D planning data.  This paper will evaluate multi-touch screens as a 3D VE navigation device for the general public in a participatory planning context.  The interactivity of multi-touch technology may better engage participants and improve their understanding of planning policies and proposed projects.  With the recent proliferation of multi-touch technology in the personal device market, there is great potential for expanding accessibility of participatory planning applications.</span></div></div><div class="paper" id="sd174"><a href="#sd174" class="title">Face-back: Who is the Illiterate Again?</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979503&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hoda A. Hamouda</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Mariam M. Hussein</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Mohamed H. Sharaf-El Deen</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Nermeen M. Abdel-Aziz</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Shady M. Hanna</span> <span class="affiliation">German University in Cairo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mutual respect and appreciation are the keys for integrating different groups into the society. We address in our work the special case of illiterate craftsmen in Egypt. Our research has shown that due to the illiteracy, they are excluded from the social mainstream, while paradoxically, we felt as illiterates in their world. Current solutions and services do not provide a two-way communication between illiterate and literate people that would help closing the gap. Face-back is a service that aims at bringing both worlds together by taking away the anonymity that leads to stereotypical ways of thinking.</span></div></div><div class="paper" id="sd212"><a href="#sd212" class="title">Entrust: Connecting Low-Income HIV+ Individuals with Health Care Providers</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979509&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Clifford  Gentry</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Marisol Martinez  Martinez Escobar</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Philip  Vander Broek</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Douglas  Choi</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Stefan  Ganchev</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Individuals infected with Human Immunodeficiency Virus (HIV) face numerous stigmatizations and challenges, specifically with the maintenance and adherence to their medical regimen. This situation is further complicated when individuals lack monetary resources to maintain their overall wellbeing. This paper presents Entrust, a service that provides low-income HIV positive individuals (clients) with cellphones to communicate with their health care providers. The cellphone is used to foster consistent and effective communication between clients and case managers, and client compliance is motivated by free phone minutes. In this way, Entrust facilitates a higher quality of life for low-income HIV positive individuals.</span></div></div><div class="paper" id="sd180"><a href="#sd180" class="title">Cowabunga!: A System to Facilitate Multi-Cultural Diversity through CouchSurfing</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979506&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sujoy Kumar  Chowdhury</span> <span class="affiliation">Missouri Western State University</span>, <br />
<span class="author">Jody  Wynn</span> <span class="affiliation">Missouri Western State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many organizations endeavor to promote diversity through their ideals and goals. Couchsurfing.org (CS) has a large presence in that realm. They have made it their mission to &#8220;create inspiring experiences: cross-cultural encounters that are fun, engaging and illuminating&#8220;. However, even in this presumably open-minded community the participants are often advised by experienced couchsurfers (CSers) to filter their couch-searches within homogenous members to increase response rates. It is human nature to interact with people similar in values and belief systems. We propose Cowabunga!, a mobile application which augments multi-cultural exchanges instigated by CS. By facilitating chance meetings that would not happen otherwise, our solution is helping people get spontaneous exposure to others with whom they may have nothing in common except their CS membership.</span></div></div><div class="paper" id="sd168"><a href="#sd168" class="title">ViTu: A System to Help the Mexican People to Preserve and Celebrate their Culture.</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979502&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">M&#243;nica Isabel Gonz&#225;lez</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span>, <br />
<span class="author">Emilio  S&#225;nchez</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span>, <br />
<span class="author">Edgar  de los Santos</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">ViTu is the entire development of a system focused on <br /> appreciating and highlighting the culture and traditions <br /> of native Mexican communities. It also contributes <br /> towards preserving and regaining the lost Mexican <br /> roots of the Mexican-Americans living in the United <br /> States. To achieve this, a culture, customs and <br /> traditions storage device of the Mexican village of San <br /> Jeronimo Silacayoapilla, was created. The main <br /> objective of this system is to encourage people to love <br /> and be proud of their cultural roots through technology. <br /> We are confident that this project will not only highlight <br /> the lifestyle of the native communities in Mexico but it <br /> will raise awareness on the importance of sharing, <br /> celebrating and appreciating our differences.</span></div></div><div class="paper" id="sd202"><a href="#sd202" class="title">SignBright: A Storytelling Application to Connect Deaf Children and Hearing Parents</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979508&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chad  Harbig</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Melissa  Burton</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Mariam  Melkumyan</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Lei  Zhang</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Jiyoung  Choi</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Deaf children of hearing parents face many unique challenges that have been shown to adversely impact their interpersonal interactions and development. Contemporary research indicates that many of these challenges stem from environmental factors, including a lack of exposure to language concepts during early developmental stages. In this paper, we will present an innovative solution to foster connection and understanding between deaf children and hearing parents, SignBright. In addition, SignBright promotes acquisition of sign language skills by hearing parents and deaf children, providing greater opportunities for interfamilial dialogue and bonding, and promoting development of social and linguistic competencies. <br /></span></div></div><div class="paper" id="sd128"><a href="#sd128" class="title">DiversIT: Inspiring Communication about Individuals' Differences</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979500&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Timothy  Ekl</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Tianyi  Gao</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Sarah  Jabon</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Joseph  Salisbury</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Eric  Stokes</span> <span class="affiliation">Rose-Hulman Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The world is a mosaic of unique individuals. It is easy, however, to take people's differences for granted. Many people have stereotypes and perceptions of others that conceal the truth about differences between them. In order to help people appreciate differences about one another, we designed DiversIT, which facilitates communication between all people by leveraging the power of the Internet. By centering discussion on a daily question, DiversIT establishes common ground through which people can begin interacting. This increased communication can lead to an improved understanding of each other. DiversIT was developed with user-centered design processes, incorporating potential users into every part of the design process.</span></div></div><div class="paper" id="sd137"><a href="#sd137" class="title">Interactive Therapy Gloves: Reconnecting Partners After a Stroke</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979501&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Hallam</span> <span class="affiliation">Emily Carr University of Art and Design</span>, <br />
<span class="author">Vanessa  Whiteley</span> <span class="affiliation">Emily Carr University of Art and Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the challenges that affect long-term partners after one of them suffers from a stroke, and offers a design solution as part of the CHI 2011 Student Design Competition. The challenge posed was to create a design that would help us to appreciate and celebrate our differences through the novel use of technology. We examined the changes that both partners go through during the recovery period after a stroke. We then designed an interactive glove as part of the rehabilitation process. The intent was to foster acceptance of each partner&#8217;s contribution and to help them reconnect. This paper details the iterative design process involved.</span></div></div><div class="paper" id="sd179"><a href="#sd179" class="title">TimeCapsule: Connecting Past</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979505&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yikun  Liu</span> <span class="affiliation">Indiana University School of Informatics</span>, <br />
<span class="author">Haidan  Huang</span> <span class="affiliation">Indiana University School of Informatics</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our world is changing at an ever-growing rate. The tide of urbanization and globalization has resulted in population migration that consequentially separates people from what is familiar to them. To combat this issue, we propose TimeCapsule. TimeCapsule is a social networking community intending to reserve, organize, share and utilize personal and collective memories by members of the community contributing location-related digitalized materials. Two clients will be designed to meet two kinds of usage: Mobile and Desktop. The mobile application will provide real-time old and new street view fusion in order to facilitate the user experience of appreciating the change in one location.  The desktop client will help users organize and share personal and group memories. Special consideration for seniors will be addressed.   <br /> By utilizing a connection to our past, we hope this initiative will help us to position ourselves to better appreciate the disparity between cultures and generations, thus unifying us.  <br /></span></div></div><div class="paper" id="sd225"><a href="#sd225" class="title">Lingua: Cultural Exchange Through Language Partnerships</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979510&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Caitlin  Holman</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Jane  Leibrock</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Jose  Jimenez</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Daniel  Greitzer</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Tom  Haynes</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Language barriers prevent people from communicating directly and are often a reflection of larger cultural divisions that hinder connection. Exposure to foreign languages and cultures through travel can help bridge this divide, but is not always feasible given time and monetary constraints. Language exchange partnerships are an excellent way to learn a new language, but are often difficult to maintain due to lack of common ground between partners and the absence of supporting materials. We present Lingua, a system to connect individuals with different linguistic backgrounds, and provide them a digital space tailored to support language learning through conversation with a partner. Their dialogue is driven in part by the application&#8217;s support for using shared multimedia to offer examples of their respective cultures.</span></div></div><div class="paper" id="sd183"><a href="#sd183" class="title">Sharing the Knowledge</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979507&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dustin  York</span> <span class="affiliation">Art Center College of Design Massachusetts Institute of Technology</span>, <br />
<span class="author">Zhengxin  Xi</span> <span class="affiliation">Art Center College of Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sharing the Knowledge is a community literacy learning system for implementation in the isolated regions of a developing nation. The project is a set of designed interactions that enables a collaborative social effort in creating and understanding educational materials, as means of compensation for the general lack of access to formal education and trained educators. The user-generated media is used for mobile learning applications and for creating social gaming incentives.</span></div></div><div class="paper" id="sd107"><a href="#sd107" class="title">The Design Process of iConnect: Social Advice Application</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979499&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shane  Wachirawutthichai</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Nisha  Singh</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Ramji  Enamuthu</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Yun  Zhou</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With Google [9] having established itself as the de-facto standard for document search and retrieval, the focus has shifted recently to the domain of social search. Morris et al. [12] define social search as &#8220;the process of finding information online with the assistance of social resources such as friends or unknown persons&#8221;. A number of online services [1, 2, 3, 4, 5] have been created to enable social search. But most of these are not useful when a person is mobile and offline and when the information need is highly context-specific. To enable social search in such situations, we introduce iConnect, the social advice application for mobile phones. iConnect is designed to enable a unique kind of social search, where an iConnect user is connected to other iConnect users in the same geographic region or locality. This would help people to solve their daily information needs. This paper illustrates the design process that we employed to conceptualize and prototype this application.</span></div></div><div class="paper" id="sd177"><a href="#sd177" class="title">Foodmunity: Designing Community Interactions over Food</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979504&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shad  Gross</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Austin  Toombs</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Jeff  Wain</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Kevin  Walorski</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Communities contain a rich diversity of backgrounds, personal experiences, and viewpoints. Fortunately, online social networks can make it even easier for people within a community to meet each other. This leads to an opportunity space for exposing people to the differences of their neighbors through mutual interaction. Our study presents Foodmunity, a social networking site that facilitates the organization of food-related events by members of a community. Meeting over a meal provides a more comfortable environment for experiencing new ideas, new people, and new viewpoints. Foodmunity utilizes themed events based on personal experiences its users have with food. This serves as both a cultural representation of those individuals and as a method of bonding between neighbors. By encouraging its users to reflect on the experiences they want to share and the experiences they have attending others&#8217; events, our system facilitates the growth of communities and a deeper understanding of the differences within.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">11:00<br />-<br />12:20</td>

<td class="session " id="S1181">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1181" class="title">Digital Arts and Interaction (Invited)</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1180">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1180" class="title">Engineering Community: The Role of Engineering Work in CHI</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1190">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1190" class="title">Home Automation</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1195">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1195" class="title">Design Methods</a>
<span class="location">223/224</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1189">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1189" class="title">Security (Systems)</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1193">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1193" class="title">Website &amp; Application Design</a>
<span class="location">217/218/219</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1194">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1194" class="title">New Approaches to Usability</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1188">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1188" class="title">Touch 1: Tactile &amp; Haptics</a>
<span class="location">205/206/207</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1191">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1191" class="title">Sustainability 1</a>
<span class="location">212/213/214</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1182">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1182" class="title">HCI for Peace: From Idealism to Concrete Steps</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1192">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1192" class="title">Mobile Issues</a>
<span class="location">215/216</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>
</tr>
<tr class="details_row"><td colspan="11" class="session_details" id="S1181_details"><div class="paper" id="si138"><a href="#si138" class="title">Digital Arts and Interaction (Invited)</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979538&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  England</span> <span class="affiliation">Liverpool John Moores University</span>, <br />
<span class="author">ernest  edmonds</span> <span class="affiliation">University of Technology, Sydney</span>, <br />
<span class="author">Jennifer  Sheridan</span> <span class="affiliation">Bigdog Interactive</span>, <br />
<span class="author">Scott  Pobiner</span> <span class="affiliation">The New School for Design</span>, <br />
<span class="author">Nick  Bryan-Kinns</span> <span class="affiliation">University of London</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Michael  Twidale</span> <span class="affiliation">University of Illinois, Champaign</span>, <br />
<span class="author">Carla  Diana</span> <span class="affiliation">Smart Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This SIG proposal, sponsored by the CHI Design Community, looks at the intersection and cross-fertilization between HCI, and Digital and Performance Arts. We consider how the exploration of engaging and meaningful artistic experience can further push the boundaries of HCI research and practice and how tool use and models of evaluation can be explored to assist the development of creative enterprises. We consider how artists&#8217; early experiments with technology can inform mainstream design thinking, and how theories and practice in aesthetics can feed into User Experience.</span></div></div></td>
<td colspan="11" class="session_details" id="S1180_details"><div class="paper" id="si132"><a href="#si132" class="title">Engineering Community: The Role of Engineering Work in CHI</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979537&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Keith  Butler</span> <span class="affiliation">Human Centered Design &amp;   EngineeringUniversity of WashingtonSeattle, WA 98195 USA</span>, <br />
<span class="author">Ruven  Brooks</span> <span class="affiliation">Ruven Brooks ConsultingAustin TX</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The Engineering Community faces a number of serious challenges around its role in the larger CHI community and its contribution to CHI-sponsored conferences. This SIG is its forum to report progress on key issues for 2011, identify objectives for 2012, and develop plans to address them.</span></div></div></td>
<td colspan="11" class="session_details" id="S1190_details"><div class="sessionChair"><strong>Session Chair: </strong>Gregory Abowd (<em>Georgia Institute of Technology</em>)</div><div class="paper" id="paper1136"><a href="#paper1136" class="title">Reflecting on Pills and Phone Use: Supporting Awareness of Functional Abilities for Older Adults</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979247&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew L Lee</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Anind K Dey</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Older adults often struggle with maintaining self-aware of their ability to carry out everyday activities important for independence. Unobtrusive sensors embedded in the home can monitor how older adults interact with objects around the home and can provide objective accounts of behaviors to support self-awareness. In this paper, we describe the design and four month deployment of a prototype sensing system that tracks medication taking and phone use in the homes of two older adults. We describe two case studies on 1) how they engaged with the data by looking for and explaining their own anomalous behaviors and 2) how they used the sensor data to reflect on their actions and their own self-awareness of their abilities to remain independent. Finally, we propose recommendations for the design of home sensing systems that support awareness of functional abilities for older adults using reflection.</span></div></div><div class="paper" id="paper1609"><a href="#paper1609" class="title">User-Centred Multimodal Reminders for Assistive Living</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979248&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marilyn Rose McGee-Lennon</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Maria Klara Wolters</span> <span class="affiliation">University of Edinburgh</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While there has been a lot of research on the usability of reminders and alarms in the work context, the home has been somewhat neglected despite the importance of reminder systems for telecare and assistive living systems. We conducted a comprehensive mixed-methods study into the requirements for useable and acceptable reminders in the home. The study consisted of a questionnaire  (N=379), 6 focus groups, and 7 home tour interviews. Our results highlight the need for highly flexible and contextualized multimodal and multi-device reminder solutions that build on existing successful strategies for remembering in and around the home. We suggest that developers of home care reminder systems should design for diversity, context, priorities, autonomy, shared spaces, and optimal care.</span></div></div><div class="paper" id="cs162"><a href="#cs162" class="title">Speech@Home: An Exploratory Study</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979657&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">A.J.  Brush</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Paul  Johns</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Kori  Inkpen</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Brian  Meyers</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">To understand how people might use a speech dialog system in the public areas of their homes, we conducted an exploratory field study in six households. For two weeks each household used a system that logged motion and usage data, recorded speech diary entries and used Experience Sampling Methodology (ESM) to prompt participants for additional examples of speech commands. The results demonstrated our participants&#8217; interest in speech interaction at home, in particular for web browsing, calendaring and email tasks, although there are still many technical challenges that need to be overcome. More generally, our study suggests the value of using speech to enable a wide range of interactions.</span></div></div><div class="paper" id="paper940"><a href="#paper940" class="title">Home Automation in the Wild: Challenges and Opportunities</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979249&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">A.J. Bernheim Brush</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Bongshin  Lee</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Ratul  Mahajan</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Sharad  Agarwal</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Stefan  Saroiu</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Colin  Dixon</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Visions of smart homes have long caught the attention of researchers and considerable effort has been put toward enabling home automation. However, these technologies have not been widely adopted despite being available for over three decades. To gain insight into this state of affairs, we conducted semi-structured home visits to 14 households with home automation. The long term experience, both positive and negative, of the households we interviewed illustrates four barriers that need to be addressed before home automation becomes amenable to broader adoption. These barriers are high cost of ownership, inflexibility, poor manageability, and difficulty achieving security. Our findings also provide several directions for further research, which include eliminating the need for structural changes for installing home automation, providing users with simple security primitives that they can confidently configure, and enabling composition of home devices.</span></div></div></td>
<td colspan="11" class="session_details" id="S1195_details"><div class="sessionChair"><strong>Session Chair: </strong>Chen Zhao (<em>Microsoft Research</em>)</div><div class="paper" id="to107"><a href="#to107" class="title">Parallel Prototyping Leads to Better Design Results, More Divergence, and Increased Self-Efficacy</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Steven  Dow</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Alana  Glassco</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Jonathan  Kass</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Melissa  Schwarz</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Dan  Schwartz</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott  Klemmer</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Iteration can help people improve ideas. It can also give rise to fixation &#8212; continuously refining one option without considering others. Does creating and receiving feedback on multiple prototypes in parallel &#8212; as opposed to serially &#8212; affect learning, self-efficacy, and design exploration? An experiment manipulated whether independent novice designers created graphic Web advertisements in parallel or in series. Serial participants received descriptive critique directly after each prototype. Parallel participants created multiple prototypes before receiving feedback. As measured by click-through data and expert ratings, ads created in the Parallel condition significantly outperformed those from the Serial condition. Moreover, independent raters found Parallel prototypes to be more diverse. Parallel participants also reported a larger increase in task-specific self-confidence. This paper outlines a theoretical foundation for why parallel prototyping produces better design results and discusses the implications for design education.</span></div></div><div class="paper" id="paper890"><a href="#paper890" class="title">Collaboration personas: A new approach to designing workplace collaboration tools</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979272&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tara  Matthews</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Steve  Whittaker</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Thomas  Moran</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Sandra  Yuen</span> <span class="affiliation">IBM Research - Almaden</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The success of social computing has generated a host of workplace collaboration tools. However, adoption of these tools by entire groups is a major problem. One reason for the adoption problem is a lack of methods for considering collaborative groups in technology design. Even when designing collaboration tools, designers often employ methods that focus on individuals. This leads to tools that are not well targeted at the groups who will use them. To solve this problem, we propose the notion of collaboration personas, which are empirically derived descriptions of hypothetical groups, including details that inform the design of collaboration tools. Collaboration personas differ from individual personas in having (1) multiple, inter-related individuals playing specific roles; (2) a focus on collective goals and elaboration of individual goals that affect the collective goal; and (3) new attributes that characterize collaborative aspects of the group&#8217;s work. We contrast collaboration personas with other design approaches and provide examples of how they can be used to design new collaborative tools that better meet the needs of typical groups.</span></div></div><div class="paper" id="paper1992"><a href="#paper1992" class="title">From Garments to Gardens: Negotiating Material Relationships Online and &#8216;By Hand&#8217;</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979273&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth  Goodman</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Daniela  Rosner</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">From home improvement to scrapbooking, leisure activities performed &#8220;by hand&#8221; increasingly involve digital tools. In turn, software and devices to support handwork are proliferating. We use data from an observational field study of gardening and knitting to examine relationships to information technology. Handwork experiences of patience, effort, sensation, and cleverness can shift with the introduction of new tools. Our participants' attachment to these experiences made them sensitive to the potential consequences of introducing new tools. Digital tools were sometimes rejected and other times woven into handwork activities. In response, we propose three metaphors for handwork practice -- extending, interjecting, and segmenting -- as a resource for moving beyond the binary opposition of digital and physical practices.</span></div></div><div class="paper" id="paper407"><a href="#paper407" class="title">Persona Cases: A Technique for grounding Personas</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979274&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shamal  Faily</span> <span class="affiliation">University of Oxford</span>, <br />
<span class="author">Ivan  Flechais</span> <span class="affiliation">University of Oxford</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Personas are a popular technique in User-Centered Design, however their validity can be called into question.  While the techniques used to developed personas and their integration with other design activities provide some measure of validity, a persona's legitimacy can be threatened by challenging its characteristics.  This note presents Persona Cases: personas whose characteristics are both grounded in, and traceable to their originating source of empirical data.  This approach builds on the premise that sense-making in qualitative data analysis is an argumentative activity, and aligns concepts associated with a Grounded Theory analysis with recent work on arguing the characteristics of personas.  We illustrate this approach using a case study in the Critical Infrastructure Protection domain.</span></div></div><div class="paper" id="paper218"><a href="#paper218" class="title">When the Implication Is Not to Design (Technology)</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979275&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eric P. S. Baumer</span> <span class="affiliation">Cornell University</span>, <br />
<span class="author">Six  Silberman</span> <span class="affiliation">Bureau of Economic Interpretation</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As HCI is applied in increasingly diverse contexts, it is important to consider situations in which computational or information technologies may be less appropriate. This paper presents a series of questions that can help researchers, designers, and practitioners articulate a technology's appropriateness or inappropriateness. Use of these questions is demonstrated via examples from the literature. The paper concludes with specific arguments for improving the conduct of HCI. This paper provides a means for understanding and articulating the limits of HCI technologies, an important but heretofore under-explored contribution to the field.</span></div></div></td>
<td colspan="11" class="session_details" id="S1189_details"><div class="sessionChair"><strong>Session Chair: </strong>Keith Edwards (<em>Georgia Institute of Technology</em>)</div><div class="paper" id="paper1974"><a href="#paper1974" class="title">Security through a different kind of obscurity: Evaluating Distortion in Graphical Authentication Schemes</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979242&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eiji  Hayashi</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jason  Hong</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Nicolas  Christin</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While a large body of research on image-based authentication has focused on memorability, comparatively less attention has been paid to the new security challenges these schemes may introduce. Because images can convey more information than text, image-based authentication may be more vulnerable to educated guess attacks than passwords. In this paper, we evaluate the resilience of a recognition-based graphical authentication scheme using distorted images against two types of educated guess attacks through two user studies. <br />  <br /> The first study, consisting of 30 participants, investigates whether distortion prevents educated guess attacks primarily based on information about individual users. The second study, using <br /> Amazon Mechanical Turk, investigates whether distortion mitigates the risk of educated guess attacks based on collective information about users. Our results show that authentication images without distortion are vulnerable to educated guess attacks, especially when information about the target is known, and that distortion makes authentication images more resilient against educated guess attacks.</span></div></div><div class="paper" id="paper896"><a href="#paper896" class="title">More than skin deep:  Measuring effects of the underlying model on access-control system usability</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979243&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Robert W Reeder</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Lujo  Bauer</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Lorrie F Cranor</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michael K Reiter</span> <span class="affiliation">University of North Carolina, Chapel Hill</span>, <br />
<span class="author">Kami  Vaniea</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In access-control systems, policy rules conflict when they <br /> prescribe different decisions (ALLOW or DENY) for the same <br /> access. We present the results of a user study that demonstrates <br /> the significant impact of conflict-resolution method <br /> on policy-authoring usability. In our study of 54 participants, <br /> varying the conflict-resolution method yielded statistically <br /> significant differences in accuracy in five of the six <br /> tasks we tested, including differences in accuracy rates of up <br /> to 78%. Our results suggest that a conflict-resolution method <br /> favoring rules of smaller scope over rules of larger scope is <br /> more usable than the MicrosoftWindows operating system&#8217;s <br /> method of favoring deny rules over allow rules. Perhaps <br /> more importantly, our results demonstrate that even seemingly <br /> small changes to a system&#8217;s semantics can fundamentally <br /> affect the system&#8217;s usability in ways that are beyond the <br /> power of user interfaces to correct.</span></div></div><div class="paper" id="paper586"><a href="#paper586" class="title">Does Domain Highlighting Help People Identify Phishing Sites?</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979244&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eric  Lin</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">Saul  Greenberg</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">Eileah  Trotter</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">David  Ma</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">John  Aycock</span> <span class="affiliation">University of Calgary</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Phishers are fraudsters that mimic legitimate websites to steal user&#8217;s creden&#172;tial information and exploit that information for identity theft and other criminal activities. Various anti-phishing techniques attempt to mitigate such attacks. Domain highlighting is one such approach recently incorporated by several popular web browsers. The idea is simple: the domain name of an address is highlighted in the address bar, so that users can inspect it to determine a web site&#8217;s legitimacy. Our research asks a basic question: how well does domain highlighting work? To answer this, we showed 22 participants 16 web pages typical of those targeted for phishing attacks, where participants had to determine the page&#8217;s le&#172;gitimacy. In the first round, they judged the page&#8217;s le&#172;gitimacy by whatever means they chose. In the second round, they were directed specifically to look at the address bar. We found that participants fell into 3 types in terms of how they determined the legitimacy of a web page; while domain highlighting was somewhat effective for one user type, it was much less effective for others. We conclude that domain highlighting, while providing some benefit, cannot be relied upon as the sole method to prevent phishing attacks.</span></div></div><div class="paper" id="paper298"><a href="#paper298" class="title">Exploring Reactive Access Control</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979245&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michelle L. Mazurek</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Peter F. Klemperer</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Richard  Shay</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Hassan  Takabi</span> <span class="affiliation">University of Pittsburgh</span>, <br />
<span class="author">Lujo  Bauer</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Lorrie Faith Cranor</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As users store and share more digital content at home, access control becomes increasingly important. One promising approach for helping non-expert users create accurate access policies is reactive policy creation}, in which users can update their policy dynamically in response to access requests that would not otherwise succeed. An earlier study suggested reactive policy creation might be a good fit for file access control at home. To test this, we conducted an experience-sampling study in which participants used a simulated reactive access-control system for a week. Our results bolster the case for reactive policy creation as one mode by which home users specify access-control policy. We found both quantitative and qualitative evidence of dynamic, situational policies that are hard to implement using traditional models but that reactive policy creation can facilitate. While we found some clear disadvantages to the reactive model, they do not seem insurmountable.</span></div></div></td>
<td colspan="11" class="session_details" id="S1193_details"><div class="sessionChair"><strong>Session Chair: </strong>Shelly Farnham (<em>Microsoft Research</em>)</div><div class="paper" id="paper180"><a href="#paper180" class="title">FeedLack Detects Missing Feedback in Web Applications</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979260&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew J Ko</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Xing  Zhang</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While usability methods such as user studies and inspections can reveal a wide range of problems, they do so for only a subset of an application&#8217;s features and states. We present FeedLack, a tool that explores the full range of web applications&#8217; behaviors for one class of usability problems, namely that of missing feedback. It does this by enumerating control flow paths originating from user input, identifying paths that lack output-affecting code. FeedLack was applied to 330 applications; of the 129 that contained input handlers and did not contain syntax errors, 115 were successfully analyzed, resulting in 647 warnings. Of these 36% were missing crucial feedback; 34% were executable and missing feedback, but followed conventions that made feedback inessential; 18% were scenarios that did produce feedback; 12% could not be executed. We end with a discussion of the viability of FeedLack as a usability testing tool.</span></div></div><div class="paper" id="paper855"><a href="#paper855" class="title">Entity-Linking Interfaces in User-Contributed Content: Preference and Performance</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979261&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Xiao  Dong</span> <span class="affiliation">University of Minnesota</span>, <br />
<span class="author">F. Maxwell  Harper</span> <span class="affiliation">University of Minnesota</span>, <br />
<span class="author">Joseph A.  Konstan</span> <span class="affiliation">University of Minnesota</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The ability to embed links to other resources in user generated content can help authors create more useful and usable content.  A variety of interfaces have emerged for entity-linking at popular online sites; such interfaces vary in the way that entity linking is initiated (in-band or out-of-band with respect to the message creation), the timing of entity resolution (interrupting or deferred), and the method of resolving the entity (auto-completion or search).  Four interfaces mimicking popular entity linking websites were developed and tested. Results showed that out-of-band initiation (e.g., a link button) was faster to learn, but that in-band initiation performance improved with familiarity.  Deferred search was disliked and led to worse performance.  And auto-completion was generally preferred to search interfaces.</span></div></div><div class="paper" id="paper1102"><a href="#paper1102" class="title">Bricolage: Example-Based Retargeting for Web Design</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979262&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ranjitha  Kumar</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Jerry O. Talton</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Salman  Ahmad</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott R. Klemmer</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The Web provides a corpus of design examples unparalleled in human history. However, leveraging existing designs to produce new pages is often difficult.  This paper introduces the Bricolage algorithm for transferring design and content between Web pages.  Bricolage employs a novel, structured-prediction technique that learns to create coherent mappings between pages by training on human-generated exemplars.  The produced mappings are then used to automatically transfer the content from one page into the style and layout of another.  We show that Bricolage can learn to accurately reproduce human page mappings, and that it provides a general, efficient, and automatic technique for retargeting content between a variety of real Web pages.</span></div></div><div class="paper" id="paper1248"><a href="#paper1248" class="title">HyperSource: Bridging the Gap Between Source and Code-Related Web Sites</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979263&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Mark  Dhillon</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Matthew K Chan</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Programmers frequently use the Web while writing code: they search for libraries, code examples, tutorials, and documentation. This link between code and visited Web pages remains implicit today. Connecting source code and browsing histories might help programmers maintain con-text, reduce the cost of Web page re-retrieval, and enhance understanding when code is shared. This note introduces HyperSource, an IDE augmentation that associates brows-ing histories with source code edits. HyperSource com-prises a browser extension that logs visited pages; an IDE that tracks user activity and maps pages to code edits; a source document model that tracks visited pages at a char-acter level; and a user interface that enables interaction with these histories. We discuss relevance heuristics and privacy issues inherent in this approach. Informal log analyses and user feedback suggest that our annotation model is promising for code editing and might also apply to other document authoring tasks after refinement.</span></div></div><div class="paper" id="paper906"><a href="#paper906" class="title">Item Sampling for Information Architecture</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979264&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Craig S Miller</span> <span class="affiliation">DePaul University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">When creating a taxonomy for information architecture, practitioners or design participants typically work with a sample of content items to form categories that allow users to successfully navigate to desired information, commands, or items. In order to examine how sample selection affects the coverage of the desired taxonomy, computer simulations were conducted that models the process of sample selection. The simulations reveal how the number of categories, the distribution of items in the taxonomy and the method of selection affect the coverage of a sample at various sizes.</span></div></div></td>
<td colspan="11" class="session_details" id="S1194_details"><div class="sessionChair"><strong>Session Chair: </strong>Elizabeth Buie (<em>Luminanze Consulting</em>)</div><div class="paper" id="paper1794"><a href="#paper1794" class="title">When Designing Usability Questionnaires, Does It Hurt to Be Positive?</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979266&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jeff  Sauro</span> <span class="affiliation">Oracle, Measuring Usability LLC</span>, <br />
<span class="author">James R Lewis</span> <span class="affiliation">IBM</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">When designing questionnaires there is a tradition of including items with both positive and negative wording to minimize acquiescence and extreme response biases. Two disadvantages of this approach are respondents accidentally agreeing with negative items (mistakes) and researchers forgetting to reverse the scales (miscoding). <br /> The original System Usability Scale (SUS) and an all positively worded version were administered in two experiments (n=161 and n=213) across eleven websites.  There was no evidence for differences in the response biases between the different versions. A review of 27 SUS datasets found 3 (11%) were miscoded by researchers and 21 out of 158 questionnaires (13%) contained mistakes from users. <br /> We found no evidence that the purported advantages of including negative and positive items in usability questionnaires outweigh the disadvantages of mistakes and miscoding. It is recommended that researchers using the standard SUS verify the proper coding of scores and include procedural steps to ensure error-free completion of the SUS by users.  <br /> Researchers can use the all positive version with confidence because respondents are less likely to make mistakes when responding, researchers are less likely to make errors in coding, and the scores will be similar to the standard SUS. <br /></span></div></div><div class="paper" id="paper192"><a href="#paper192" class="title">Synchronous Remote Usability Testing - A New Approach Facilitated By Virtual Worlds</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979267&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kapil  Chalil Madathil</span> <span class="affiliation">Clemson University</span>, <br />
<span class="author">Joel S. Greenstein</span> <span class="affiliation">Clemson University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study proposes a new methodology for conducting synchronous remote usability studies using a three-dimensional virtual usability testing laboratory built using the Open Wonderland toolkit. This virtual laboratory method is then compared with two other commonly used synchronous usability test methods: the traditional lab approach and WebEx, a web-based conferencing and screen sharing approach. A study was conducted with 48 participants in total, 36 test participants and 12 test facilitators. The test participants completed 5 tasks on a simulated e-commerce website. The three methodologies were compared with respect to the following dependent variables: the time taken to complete the tasks; the usability defects identified; the severity of these usability defects; and the subjective ratings from NASA-TLX, presence and post-test subjective questionnaires. The three methodologies agreed closely in terms of the total number defects identified, number of high severity defects identified and the time taken to complete the tasks. However, there was a significant difference in the workload experienced by the test participants and facilitators, with the traditional lab condition imposing the least and the virtual lab and the WebEx conditions imposing similar levels. It was also found that the test participants experienced greater involvement and a more immersive experience in the virtual world condition than the WebEx condition. These ratings were not significantly different from those in the traditional lab condition.  The results of this study suggest that participants were productive and enjoyed the virtual lab condition, indicating the potential of a virtual world based approach as an alternative to the conventional approaches for synchronous usability testing.</span></div></div><div class="paper" id="paper1129"><a href="#paper1129" class="title">Representing Users in Accessibility Research</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979268&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew  Sears</span> <span class="affiliation">University of Maryland, Baltimore County</span>, <br />
<span class="author">Vicki  Hanson</span> <span class="affiliation">University of Dundee</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The need to study representative users is widely accepted within the human-computer interaction (HCI) community. While exceptions exist, and alternative populations are sometimes studied, virtually any introduction to the process of designing user interfaces will discuss the importance of understanding the intended users as well as the significant impact individual differences can have on how effectively individuals can use various technologies. HCI researchers are expected to provide relevant demographics regarding study participants as well as information about experience using similar technologies. Yet, in the field of accessibility we continue to see studies that do not appropriately include representative users. Highlighting ways to remedy this multifaceted problem, we argue that expectations regarding how accessibility research is conducted and reported must be raised if this field is to have the desired impact with regard to inclusive design, the information technologies studied, and the lives of the individuals being studied.</span></div></div><div class="paper" id="paper2104"><a href="#paper2104" class="title">Democratising Technology: Making Transformation using Designing, Performance and Props</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979269&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ann  Light</span> <span class="affiliation">Sheffield Hallam University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study of personal transformation is offered as HCI increasingly seeks to change behavior with persuasive products. Performance-derived improvisation methods were used to inspire a sense of agency with ICT in people marginalized from digital design. A case study of an older person&#8217;s experience shows the techniques supporting her to reconceive her response to technology. In particular, we analyze how using a &#8216;prop&#8217; as a design artifact allows her to imagine new possibilities and take a more assertive role.</span></div></div><div class="paper" id="cs164"><a href="#cs164" class="title">Assisted collection and organization for laddering interview data</a>&nbsp;-&nbsp;<span class="type">Case Study (Short)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979661&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stephanie  Deutsch</span> <span class="affiliation">CURE - Center for Usability Research and Engineering</span>, <br />
<span class="author">Genc  Begolli</span> <span class="affiliation">CURE - Center for Usability Research and Engineering</span>, <br />
<span class="author">Martin  Lugmayr</span> <span class="affiliation">CURE - Center for Usability Research and Engineering</span>, <br />
<span class="author">Manfred  Tscheligi</span> <span class="affiliation">CURE - Center for Usability Research and Engineering and HCI-Unit, ICT&amp;S Center, University of Salzburg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Today several narrative techniques for acquiring subjective information from users are widely applied in HCI Research. As an emerging technique in this field, the laddering approach is widely used in marketing research contexts to learn more about personal values and customer behaviors. However, the method is in search of serious improvement in terms of ensuring objectivity and reliability of the resulting data. In this paper we propose a tool that supports the collection and organization of qualitative data from narrative laddering interviews. We describe how LadderAssist supports the interviewer by preventing errors in data acquisition and saving time in data organization and processing.</span></div></div><div class="paper" id="paper431"><a href="#paper431" class="title">Post-deployment Usability: A Survey of Current Practices</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979270&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Parmit K. Chilana</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Andrew J. Ko</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Tovi  Grossman</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">George  Fitzmaurice</span> <span class="affiliation">Autodesk Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Despite the growing research on usability in the pre-development <br /> phase, we know little about post-deployment usability activities. To characterize these activities, we surveyed 333 full-time usability professionals and consultants working in large and small corporations from a wide range of industries. Our results show that, as a whole, usability professionals are currently not playing a substantial role in the post-deployment phase compared to other phases of user-centered <br /> design, but when they do, practitioners find their interactions quite valuable. We highlight opportunities in HCI research and practice to bridge this gap by working more closely with software support and maintenance teams. We also raise the need to understand what might be called 'usability maintenance,' that is, the process and procedures, by which usability is maintained after deployment.</span></div></div></td>
<td colspan="11" class="session_details" id="S1188_details"><div class="sessionChair"><strong>Session Chair: </strong>Karon MacLean (<em>University of British Columbia</em>)</div><div class="paper" id="paper898"><a href="#paper898" class="title">Tactile Brush: Drawing on Skin with a Tactile Grid Display</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979235&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ali  Israr</span> <span class="affiliation">Disney Research Pittsburgh</span>, <br />
<span class="author">Ivan  Poupyrev</span> <span class="affiliation">Disney Research Pittsburgh</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Tactile Brush is an algorithm that produces smooth, two-dimensional tactile moving strokes with varying frequency, intensity, velocity and direction of motion. The design of the algorithm is derived from the results of psychophysical investigations of two tactile illusions &#8211; apparent tactile motion and phantom sensations. Combined together they allow for the design of high-density two-dimensional tactile displays using sparse vibrotactile arrays. In a series of experiments and evaluations we demonstrate that Tactile Brush is robust and can reliably generate a wide variety of moving tactile sensations for a broad range of applications.</span></div></div><div class="paper" id="paper797"><a href="#paper797" class="title">A Comparative Study of Tactile Representation Techniques for Landmarks on a Wearable Device</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979236&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mayuree  Srikulwong</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Eamonn  O'Neill</span> <span class="affiliation">University of Bath</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Wearable tactile navigation displays may provide an alternative or complement to mobile visual navigation displays.  Landmark information may provide a useful complement to directional information for navigation, however, there has been no reported use of landmark information in tactile navigation displays.  We report a study that compared two tactile display techniques for landmark representation using one or two actuators respectively.  The single-actuator technique generated different vibration patterns on a single actuator to represent different landmarks.  The dual-actuator technique generated a single vibration pattern using two simultaneous actuators and different pairs of actuators around the body represented different landmarks.  We compared the two techniques on four measures: distinguishability, learnability, short term memorability and user preference.  Results showed that users performed equally well when either technique was used to represent landmarks alone.  However, when landmark representations were presented together with directional signals, performance with the single-actuator technique was significantly reduced while performance with the dual-actuator technique remained unchanged.</span></div></div><div class="paper" id="paper1762"><a href="#paper1762" class="title">Handscope: Enabling Blind People to Experience Statistical Graphics on Websites through Haptics</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979237&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Da-jung  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Statistical graphics on the web such as a tag cloud visually represent statistical data which are generated by website users. While sighted people can scan the latest information through the dynamic changes of statistical graphics, blind people, who cannot perceive them, lose opportunities to keep up to date in this quickly-changing society. In order to enable blind people to experience socially-generated statistical graphics, we propose a new assistive device, namely, Handscope, which translates statistical graphics on websites into simple height changes of its haptic pole. We conducted a two-phase user study with blind people in order to test its usability and explore its effects on the quality of blind users&#162;&#174;&#175; web experiences. The results show the meaningful contribution of Handscope in extending the area of blind people&#162;&#174;&#175;s web experiences.</span></div></div><div class="paper" id="paper1906"><a href="#paper1906" class="title">Nenya: Subtle and Eyes-Free Mobile Input with a Magnetically-Tracked Finger Ring</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979238&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Ashbrook</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Patrick  Baudisch</span> <span class="affiliation">Hasso Plattner Institute</span>, <br />
<span class="author">Sean  White</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present Nenya, a new input device in the shape of a finger ring. Nenya provides an input mechanism that is always available, fast to access, and allows analog input, while remaining socially acceptable by being embodied in commonly worn items. Users make selections by twisting the ring and &#8220;click&#8221; by sliding it along the finger. The ring&#8212;the size of a regular wedding band&#8212;is magnetic, and is tracked by a wrist-worn sensor. Nenya&#8217;s tiny size, eyes-free usability, and physical form indistinguishable from a regular ring make its use subtle and socially acceptable. We present two user studies (one- and two-handed) in which we studied sighted and eyes-free use, finding that even with no visual feedback users were able to select from eight targets.</span></div></div><div class="paper" id="paper1119"><a href="#paper1119" class="title">The Haptic Laser: Multi-Sensation Tactile Feedback for  At-a-Distance Physical Space Perception and Interaction</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979239&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Francis  Iannacci</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Erik  Turnquist</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Daniel  Avrahami</span> <span class="affiliation">Intel Research</span>, <br />
<span class="author">Shwetak N Patel</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the Haptic Laser, a system for providing a range of tactile sensations to represent a physical environment at-a-distance. The Haptic Laser is a handheld device that simulates interaction with physical surfaces as a user targets objects of interest (e.g., a light switch, TV, etc). Using simple computer vision techniques for scene analysis and laser range finding for calculating distance, the Haptic Laser extracts information about the physical environment and conveys it haptically through a collection of hardware actuators. Pointing the Haptic Laser around a room, for example, presents the user with information about the presence of objects, transitions, and edges through touch rather than, or in addition to, vision. The Haptic Laser extends current work on haptic touch screens and pens, and is designed to allow for haptic feedback from a distance using multiple feedback channels.</span></div></div><div class="paper" id="paper703"><a href="#paper703" class="title">Interactive Generator: A Self-Powered Haptic Feedback Device</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979240&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Akash  Badshah</span> <span class="affiliation">Phillips Exeter Academy</span>, <br />
<span class="author">Sidhant  Gupta</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Gabe  Cohn</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Nicolas  Villar</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Steve  Hodges</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Shwetak  Patel</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present Interactive Generator (InGen), a self-powered wireless rotary input device capable of generating haptic or force feedback without the need for any external power source. Our approach uses a modified servomotor to perform three functions: (1) generating power for wireless communication and embedded electronics, (2) sensing the direction and speed of rotation, and (3) providing force feedback during rotation. While InGen is rotating, the de-vice is capable of providing the sensation of detents or bumps, changes in stiffness, and abrupt stops using only power that is harvested during interaction.  We describe the device in detail, demonstrate an initial &#8216;TV remote control&#8217; application, and end with a discussion of our experiences developing the prototype and application. To the best of our knowledge, InGen is the first self-powered device, which also provides haptic feedback during operation. More broadly, this work demonstrates a new class of input sys-tems that uses human-generated power to provide feedback to the user and wirelessly communicate sensed information.</span></div></div></td>
<td colspan="11" class="session_details" id="S1191_details"><div class="sessionChair"><strong>Session Chair: </strong>Eli Blevis (<em>Indiana University</em>)</div><div class="paper" id="paper1872"><a href="#paper1872" class="title">Creek Watch: Pairing Usefulness and Usability for Successful Citizen Science</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979251&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sunyoung  Kim</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Christine  Robson</span> <span class="affiliation">IBM Almaden Research Center; University of California, Berkeley</span>, <br />
<span class="author">Thomas  Zimmerman</span> <span class="affiliation">IBM Almaden Research Center</span>, <br />
<span class="author">Jeffrey  Pierce</span> <span class="affiliation">IBM Almaden Research Center</span>, <br />
<span class="author">Eben  Haber</span> <span class="affiliation">IBM Almaden Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Citizen science projects can collect a wealth of scientific data, but that data is only helpful if it is actually used. While previous citizen science research has mostly focused on designing effective capture interfaces and incentive mechanisms, in this paper we explore the application of HCI methods to ensure that the data itself is useful. To provide a focus for this exploration we designed and implemented Creek Watch, an iPhone application and website that allow volunteers to report information about waterways in order to aid water management programs. Working with state and local officials and private groups involved in water monitoring, we conducted a series of contextual inquiries to uncover what data they wanted, what data they could immediately use, and how to most effectively deliver that data to them. We iteratively developed the Creek Watch application and website based on our findings and conducted evaluations of it with both contributors and consumers of water data, including scientists at the city water resources department. Our study reveals that the data collected is indeed useful for their existing practices and is already in use in water and trash management programs. Our results suggest the application of HCI methods to design the data for the end users is just as important as their use in designing the user interface.</span></div></div><div class="paper" id="paper937"><a href="#paper937" class="title">Designing eco-feedback systems for everyday life</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979252&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yolande A A Strengers</span> <span class="affiliation">Centre for Design, RMIT University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Eco-feedback systems currently frame householders as micro-resource managers, who weigh up the costs and benefits of their consumption, and make autonomous, rational and efficient decisions. Reporting on findings from a qualitative study of three Australian energy and water eco-feedback programs utilising an in-home display (IHD) system, this paper challenges this view. The research finds that householders consume energy and water to carry out everyday practices, such as showering, laundering and cooling, which are mediated by social, cultural, technical and institutional dynamics. The paper proposes an alternative design paradigm for eco-feedback systems premised on the realities of everyday life and identifies several design directions that emerge from this new starting point.</span></div></div><div class="paper" id="cs190"><a href="#cs190" class="title">With a Little Help from a Friend: A Shower Calendar to Save Water</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979659&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthias  Laschke</span> <span class="affiliation">Folkwang University of the Arts</span>, <br />
<span class="author">Marc  Hassenzahl</span> <span class="affiliation">Folkwang University of the Arts</span>, <br />
<span class="author">Sarah  Diefenbach</span> <span class="affiliation">Folkwang University of the Arts</span>, <br />
<span class="author">Marius  Tippk&#228;mper</span> <span class="affiliation">Folkwang University of the Arts</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This design case presents and discusses the Shower Calendar, a "persuasive" concept for reducing the con-sumption of water for showering. It starts from a dis-cussion of different types of feedback employed by earlier design cases. Based on this, we designed the Calendar concept as an ambient, persistent and indi-vidualized feedback. A field study with two families (6 individuals) revealed that the Calendar fosters goal setting, comparison, competition, and communication. In addition, quantitative data showed one family to have been more successful in translating the Calendars offer into actual behavior change, i.e., saving water. This highlights that change is not achieved by the product itself (as in automation or regulation), but by the people involved.</span></div></div><div class="paper" id="paper1361"><a href="#paper1361" class="title">BeeParking: Feedback Interfaces for Collective Behavior Change</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979253&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Silvia  Gabrielli</span> <span class="affiliation">Create-Net</span>, <br />
<span class="author">Alessandra  Sabatino</span> <span class="affiliation">Create-Net</span>, <br />
<span class="author">Jesus  Munoz</span> <span class="affiliation">Create-Net</span>, <br />
<span class="author">Michele  Marchesoni</span> <span class="affiliation">Create-Net</span>, <br />
<span class="author">Oscar  Mayora</span> <span class="affiliation">Create-Net</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent years have seen a growing interest for the study of feedback interfaces to support behavior change in different research areas, from personal healthcare and wellbeing, to energy saving and proenvironmental sustainability. While HCI design has been primarily inspired by behavior change models that best fit individual change, less attention has been deserved to test their validity in the context of collective behavior change, where interdependencies between people&#8217;s choices and behaviors matter, as in the shared use of limited resources or public goods. <br /> We discuss some relevant directions to fill this gap, based on the iterative design of BeeParking, a feedback display aimed to induce more cooperative use of a parking facility within a work environment.</span></div></div><div class="paper" id="paper2016"><a href="#paper2016" class="title">GreenHat: Exploring the Natural Environment  Through Experts&#8217; Perspectives</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979254&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kimiko  Ryokai</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Lora  Oehlberg</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Michael  Manoochehri</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Alice  Agogino</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present GreenHat, an interactive mobile learning application that helps students learn about biodiversity and sustainability issues in their surroundings from experts&#8217; points of view, before participating in unfamiliar debates about their familiar surroundings. Using the interactive location-sensitive map and video on a smart phone, GreenHat simulates how experts go about making observations in the field and encourages students to actively observe their environment. We present our design process, our initial prototype, report the results from our preliminary evaluation, and discuss ongoing work.</span></div></div></td>
<td colspan="11" class="session_details" id="S1182_details"><div class="paper" id="pl105"><a href="#pl105" class="title">HCI for Peace: From Idealism to Concrete Steps</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979493&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Juan Pablo  Hourcade</span> <span class="affiliation">University of Iowa</span>, <br />
<span class="author">Natasha E Bullock-Rest</span> <span class="affiliation">University of Iowa</span>, <br />
<span class="author">Batya  Friedman</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Mark  Nelson</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Ben  Shneiderman</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Panayiotis  Zaphiris</span> <span class="affiliation">Cyprus University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This panel will contribute diverse perspectives on the use of computer technology to promote peace and prevent armed conflict. These perspectives include: the use of social media to promote democracy and citizen participation, the role of computers in helping people communicate across division lines in zones of conflict, how persuasive technology can promote peace, and how interaction design can play a role in post-conflict reconciliation.</span></div></div></td>
<td colspan="11" class="session_details" id="S1192_details"><div class="sessionChair"><strong>Session Chair: </strong>Jeffrey Nichols (<em>IBM Research</em>)</div><div class="paper" id="paper2235"><a href="#paper2235" class="title">Telling Calls: Facilitating Mobile Phone Conversation Grounding and Management</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979256&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sukeshini A Grandhi</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Richard  Schuler</span> <span class="affiliation">New Jersey Institute of Technology</span>, <br />
<span class="author">Quentin (Gad)  Jones</span> <span class="affiliation">New Jersey Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Current cell phone designs are limited by the information a caller can provide to the receiver at the time of a call. As a result callers are handicapped in effectively negotiating interaction commitment from the receiver, and perhaps more importantly, receivers are unable to make informed call handling decisions. To examine the nature of this information gap we 1) developed Telling Calls, a mobile phone application which allows users to provide and receive information such as what the call is about and the circumstances of the caller under which it is being made, and 2) conducted a qualitative field study (36 users) and a quantitative field study (30 users) of Telling Calls use. Together these studies provide insights on how additional caller generated information shared at the time of call handling effectively improves the process of negotiating interaction commitment, and establishing common ground.</span></div></div><div class="paper" id="paper849"><a href="#paper849" class="title">Deep Shot: A Framework for Migrating Tasks Across Devices Using Mobile Phone Cameras</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979257&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tsung-Hsiang  Chang</span> <span class="affiliation">MIT CSAIL</span>, <br />
<span class="author">Yang  Li</span> <span class="affiliation">Google Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A user task often spans multiple heterogeneous devices, e.g., working on a PC in the office and continuing the work on a laptop or a mobile phone while commuting on a shuttle. However, there is a lack of support for users to easily migrate their tasks across devices. To address this problem, we created Deep Shot, a framework for capturing the user&#8217;s work state that is needed for a task (e.g., the specific part of a webpage being viewed) and resuming it on a different device. In particular, Deep Shot supports two novel and intuitive interaction techniques, deep shooting and deep posting, for pulling and pushing work states, respectively, using a mobile phone camera. In addition, Deep Shot provides a concise API for developers to leverage its services and make their application states migratable. We demonstrated that Deep Shot can be used to support a range of everyday tasks migrating across devices. An evaluation consisting of a series of experiments showed that our framework and techniques are feasible.</span></div></div><div class="paper" id="to113"><a href="#to113" class="title">Interaction Design for Mobile Product Recommendation Agents: Supporting Users&#8217; Decisions in Retail Stores</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Young Eun  Lee</span> <span class="affiliation">Fordham University, New York, NY USA</span>, <br />
<span class="author">Izak  Benbasat</span> <span class="affiliation">University of British Columbia, Vancouver, CANADA</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mobile product recommendation agents (RAs) are software systems that operate on mobile handheld devices, using wireless Internet to support users&#8217; decisions en route, such as consumers&#8217; product choices in retail stores. As the demand for ubiquitous access to the web grows, potential benefits of mobile RAs have been recognized, albeit with little supporting empirical evidence. We investigate whether and how mobile RAs enhance users&#8217; decisions in retail stores by reducing the effort to make purchase decisions while augmenting the accuracy of <br /> the decisions. In addition, to identify potential design principles for mobile RAs, we compare and evaluate two interaction styles of mobile RAs: alternative-driven (RA-AL) versus attribute-driven (RA-AT) interactions. The results of a laboratory experiment conducted in a simulated store indicate that mobile RAs reduced users&#8217; perceived effort and increased accuracy of their decisions. Furthermore, RA-AL users made more accurate decisions than RA-AT users due to the RA-AL&#8217;s interaction style, which was compatible with the way in which <br /> users processed information and made decisions in the store. These empirical results support the notion that mobile RAs should be designed to fit the user&#8217;s task undertaken in the particular context.</span></div></div><div class="paper" id="paper1501"><a href="#paper1501" class="title">Eyes-Free Multitasking: The Effect of Cognitive Load on Mobile Spatial Audio Interfaces</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979258&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yolanda  Vazquez-Alvarez</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen A. Brewster</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As mobile devices increase in functionality, users perform more tasks when on the move. Spatial audio interfaces offer a solution for eyes-free interaction. However, such interfaces face a number of challenges when supporting multiple and simultaneous tasks, namely: 1) interference amongst multiple audio streams, and 2) the constraints of cognitive load. We present a comparative study of spatial audio techniques evaluated in a divided- and selective-attention task. A podcast was used for high cognitive load (divided-attention) and classical music for low cognitive load (selective-attention), while interacting with an audio menu. Results showed that spatial audio techniques were preferred when cognitive load was kept low, while a baseline technique using an interruptible single audio stream was significantly less preferred. Conversely, when cognitive load was increased the preferences reversed. Thus, given an appropriate task structure, spatial techniques offer a means of designing effective audio interfaces to support eyes-free mobile multitasking.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">12:20<br />-<br />14:00</td>

<td class="session tbd" id="S1196">
<div class="session_box">
<span class="type"></span>
<a href="#S1196" class="title">SIGCHI Town Hall Meeting Lunch</a>
<span class="location">223/224</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">14:00<br />-<br />15:20</td>

<td class="session " id="S1197">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1197" class="title">Child Computer Interaction: IDC Remixed, CCI Remapped</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1206">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1206" class="title">Games</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1211">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1211" class="title">Methods to Aid &amp; Structure Design</a>
<span class="location">223/224</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1205">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1205" class="title">Security (Social)</a>
<span class="location">208/209</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1209">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1209" class="title">Text Entry &amp; Typing</a>
<span class="location">217/218/219</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1210">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1210" class="title">Touch 2: Tactile &amp; Targets</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1204">
<div class="session_box">
<span class="type">Case Study, Paper &amp; ToCHI</span>
<a href="#S1204" class="title">Decision Making &amp; the Web</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1207">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1207" class="title">Sustainability 2</a>
<span class="location">212/213/214</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1198">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1198" class="title">Transferability of Research Findings:  Context-Dependent or Model-Driven</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1208">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1208" class="title">Location Sharing</a>
<span class="location">215/216</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="10" class="session_details" id="S1197_details"><div class="paper" id="si152"><a href="#si152" class="title">Child Computer Interaction: IDC Remixed, CCI Remapped</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979540&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janet C Read</span> <span class="affiliation">UCLan</span>, <br />
<span class="author">Juan Pablo  Hourcade</span> <span class="affiliation">University of Iowa</span>, <br />
<span class="author">Panos  Markopoulos</span> <span class="affiliation">Technical University Eindhoven</span>, <br />
<span class="author">Allison  Druin</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Over the past fifteen years, the discipline of Child Computer Interaction has been steadily growing.  As the community matures and as methods and processes are refined, and become situated, there is an urgent need to start to develop a theory around CCI that can be used with some confidence by the research community.   <br /> The CCI Community SIG at CHI is supporting this process by looking at the influences on the community.  In a lively debate that will include presentations and discussion, this SIG will bring the community together in a discussion that will impact on the way the community proceeds. <br /></span></div></div></td>
<td colspan="10" class="session_details" id="S1206_details"><div class="sessionChair"><strong>Session Chair: </strong>Zach Toups (<em>Texas A&amp;M University</em>)</div><div class="paper" id="paper243"><a href="#paper243" class="title">Building Sensitising Terms to Understand Free-play in Open-ended Interactive Art Environments</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979285&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ann  Morrison</span> <span class="affiliation">Aalborg University</span>, <br />
<span class="author">Stephen  Viller</span> <span class="affiliation">University of Queensland</span>, <br />
<span class="author">Peta  Mitchell</span> <span class="affiliation">University of Queensland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we introduce and discuss the nature of free-play in the context of three open-ended interactive art installation works. We observe the interaction work of situated free-play of the participants in these environments and, building on precedent work, devise a set of sensitising terms derived both from the literature and from what we observe from participants interacting there. These sensitising terms act as guides and are designed to be used by those who experience, evaluate or report on open-ended interactive art. That is, we propose these terms as a common-ground language to be used by participants communicating while in the art work to describe their experience, by researchers in the various stages of research process (observation, coding activity, analysis, reporting, and publication), and by inter-disciplinary researchers working across the fields of HCI and art. This work builds a foundation for understanding the relationship between free-play, open-ended environments, and interactive installations and contributes sensitising terms useful for the HCI community for discussion and analysis of open-ended interactive art works.</span></div></div><div class="paper" id="paper1869"><a href="#paper1869" class="title">Evaluating the Benefits of 3D Stereo in Modern Video Games</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979286&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joseph J. LaViola Jr.</span> <span class="affiliation">University of Central Florida</span>, <br />
<span class="author">Tad  Litwiller</span> <span class="affiliation">University of Central Florida</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a study that investigates user performance benefits of 3D stereo in modern video games.  Based on an analysis of several video games that are best suited for use with commercial 3D stereo drivers and vision systems, we chose five modern titles focusing on racing, first and third person shooter, and sports game genres.  For each game, quantitative and qualitative measures were taken to determine if users performed better and learned faster in the experimental group (3D stereo display) than in the control group (2D display). A game experience pre-questionnaire was used to classify participants into beginner, intermediate, and advanced gameplay categories to ensure prior game experience did not bias the experiment.  Our results indicate that although participants preferred playing in 3D stereo for the games we tested, it does not provide any significant advantage in overall user performance. In addition, users&#8217; learning rates were comparable in the 3D stereo display and 2D display cases.</span></div></div><div class="paper" id="paper383"><a href="#paper383" class="title">Target Assistance for Subtly Balancing Competitive Play</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979287&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Scott  Bateman</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Regan L Mandryk</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Tadeusz  Stach</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Carl  Gutwin</span> <span class="affiliation">University of Saskatchewan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In games where skills such as targeting are critical to winning, it is difficult for players with different skill levels to have a competitive and engaging experience. Although several mechanisms for accommodating different skill levels have been proposed, traditional approaches can be too obvious and can change the nature of the game. For games involving aiming, we propose the use of target assistance techniques (such as area cursors, target gravity, and sticky targets) to accommodate skill imbalances. We compared three techniques in a study, and found that area cursors and target gravity significantly reduced score differential in a shooting-gallery game. Further, less skilled players reported having more fun when the techniques helped them be more competitive, and even after they learned assistance was given, felt that this form of balancing was good for group gameplay. Our results show that target assistance techniques can make target-based games more competitive for shared play.</span></div></div><div class="paper" id="paper1575"><a href="#paper1575" class="title">Data Cracker: Developing a Visual Game Analytic Tool for Analyzing Online Gameplay</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979288&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ben  Medler</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Michael  John</span> <span class="affiliation">Electronic Arts (EA)</span>, <br />
<span class="author">Jeff  Lane</span> <span class="affiliation">Great Northern Way</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Game analytics is a domain that focuses on the systems and methods used to analyze game-related data. In this paper we present how a visual game analytic tool can be developed to analyze player gameplay behavior. Our tool, Data Cracker, was built for monitoring gameplay in Dead Space 2, the newest game being released within the Dead Space franchise. We use Data Cracker as a case study to inform a larger discussion of how to design a visual game analytic tool while working with an external game team. Many design insights gained and communication barriers we faced working with a game development team are discussed. As game analytics continues to grow as a research area we hope this paper provides value for discussing where game analytics can go in the future.</span></div></div></td>
<td colspan="10" class="session_details" id="S1211_details"><div class="sessionChair"><strong>Session Chair: </strong>Rob Miller (<em>Massachusetts Institute of Technology</em>)</div><div class="paper" id="paper1412"><a href="#paper1412" class="title">Benefits of Matching Domain Structure for Planning Software: The Right Stuff</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979311&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dorrit  Billman</span> <span class="affiliation">NASA Ames Research Center</span>, <br />
<span class="author">Lucia  Arsintescu</span> <span class="affiliation">NASA Ames Research Center</span>, <br />
<span class="author">Michael  Feary</span> <span class="affiliation">NASA Ames Research Center</span>, <br />
<span class="author">Jessica  Lee</span> <span class="affiliation">NASA Ames Research Center</span>, <br />
<span class="author">Asha  Smith</span> <span class="affiliation">NASA Ames Research Center</span>, <br />
<span class="author">Rachna  Tiwary</span> <span class="affiliation">NASA Ames Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We investigated the role of domain structure in designing for software usefulness and usability. We ran through the whole application development cycle, in miniature, from needs analysis through design, implementation, and evaluation, for planning needs of one NASA Mission Control group.  Based on our needs analysis, we developed prototype software that matched domain structure better than did the legacy system. We compared our new prototype to the legacy application in a laboratory, high-fidelity analog of the natural planning work.  We found large performance differences favoring the prototype, which better captured domain structure.  Our research illustrates the importance of needs analysis (particularly Domain Structure Analysis), and the viability of the design process that we are exploring.</span></div></div><div class="paper" id="paper1333"><a href="#paper1333" class="title">Developmentally Situated Design (DSD): Making Theoretical Knowledge Accessible to Designers of Children&#8217;s Technology</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979312&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tilde  Bekker</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Alissa N. Antle</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There is a wealth of theoretical knowledge about the developmental abilities and skills of children. However, this knowledge is not readily accessible to designers of interactive products. In this paper, we present the requirements, design and evaluation of developmentally situated design (DSD) cards. DSD cards are a design tool that makes age specific information about children&#8217;s developing cognitive, physical, social, and emotional abilities readily accessible for designers. Initial requirements were elicited through interviews with design practitioners and students. The cards were evaluated through a design-in-use study in which design students used the cards to address three different design problems. Our analysis of observational notes and post-design interviews revealed how the cards&#8217; characteristics enabled different kinds of uses including framing, orienting, inspiring, informing, integrating and constraining. Based on our evaluation we suggest refinements to the DSD cards. We conclude with a discussion of the strengths and weaknesses of our approach.</span></div></div><div class="paper" id="paper577"><a href="#paper577" class="title">A Spreadsheet-Based User Interface for Managing Plural Relationships in Structured Data</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979313&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eirik  Bakke</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">David R Karger</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Robert C Miller</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A key feature of relational database applications is managing <br />emph{plural} relationships---one-to-many and many-to-many---between entities. However, since it is often infeasible to adopt or develop a new database application for any given schema at hand, information workers instead turn to spreadsheets, which lend themselves poorly to schemas requiring multiple related entity sets. In this paper, we propose to reduce the cost-usability gap between spreadsheets and tailor-made relational database applications by extending the spreadsheet paradigm to let the user establish relationships between rows in related worksheets as well as view and navigate the hierarchical cell structure that arises as a result. We present Related Worksheets, a spreadsheet-like prototype application, and evaluate it with a screencast-based user study on 36 Mechanical Turk workers. First-time users of our software were able to solve lookup-type query tasks with the same or higher accuracy as subjects using Microsoft Excel, in one case 40<br />% faster on average.</span></div></div><div class="paper" id="paper772"><a href="#paper772" class="title">Variation in Importance of Time-on-Task with Familiarity with Mobile Phone Models</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979314&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shunsuke  Suzuki</span> <span class="affiliation">NEC Corporation</span>, <br />
<span class="author">Victoria  Bellotti</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Nick  Yee</span> <span class="affiliation">Palo Alto Research Center (PARC)</span>, <br />
<span class="author">Bonnie E John</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Yusuke  Nakao</span> <span class="affiliation">NEC Corporation</span>, <br />
<span class="author">Toshiyuki  Asahi</span> <span class="affiliation">NEC Corporation</span>, <br />
<span class="author">Shin'ichi  Fukuzumi</span> <span class="affiliation">NEC Corporation</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We studied the extent to which time-on-task is correlated with perception of usability for people who are familiar with a phone model and for those who are not. Our controlled experiment, conducted in Japan, correlated subjective usability assessments with time-on-task for expert and novice users on three different mobile phone models. We found that the correlation between perceived usability and time-on-task is stronger when participants are more familiar with the phone model. While not significant when initially inspecting a new phone model, a negative correlation between time-on-task and perceived usability becomes significant with as little as an hour&#8217;s time doing tasks on the unfamiliar phone. This suggests that designing the UI to make time-on-task as short as possible may not have much effect on the purchase decision, but as experience increases, it may increase the loyalty of existing users.</span></div></div></td>
<td colspan="10" class="session_details" id="S1205_details"><div class="sessionChair"><strong>Session Chair: </strong>Heather Richter Lipford (<em>University of North Carolina, Charlotte</em>)</div><div class="paper" id="paper354"><a href="#paper354" class="title">Oops, I Did It Again: Mitigating Repeated Access Control Errors on Facebook</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979280&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Serge  Egelman</span> <span class="affiliation">National Institute of Standards and Technology</span>, <br />
<span class="author">Andrew  Oates</span> <span class="affiliation">Google, Inc.</span>, <br />
<span class="author">Shriram  Krishnamurthi</span> <span class="affiliation">Brown University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We performed a study of Facebook users to examine how they coped with limitations of the Facebook privacy settings interface.  Students graduating and joining the workforce create significant problems for all but the most basic privacy settings on social networking websites. We therefore created realistic scenarios exploiting work/play boundaries that required users to specify access control policies that were impossible due to various limitations.  We examined whether users were aware of these problems without being prompted, and once given feedback, what their coping strategies were.  Overall, we found that simply alerting participants to potential errors was ineffective, but when choices were also presented, participants introduced significantly fewer errors.  Based on our findings, we designed a privacy settings interface based on Venn diagrams, which we validated with a usability study.  We conclude that this interface may be more effective than the current privacy settings interface.</span></div></div><div class="paper" id="paper1427"><a href="#paper1427" class="title">Integrating User Feedback with Heuristic Security and Privacy Management Systems</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979281&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Prashanth  Ayyavu</span> <span class="affiliation">Oregon State University</span>, <br />
<span class="author">Carlos  Jensen</span> <span class="affiliation">Oregon State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Tools aimed at helping users safely navigate the web and safeguard themselves against potential online predators have become reasonably common. Currently there are two families of tools; heuristics analysis tools that test websites directly using automated scripts and programs, and community based tools where users rate websites and write reviews for the benefit of others. In this paper we examine the relative strengths and weaknesses of each technique, whether these techniques are compatible, and how community feedback can be combined with heuristic-based evaluations. In order to do this we conduct a large-scale comparison of the ratings of heuristic and community based tools, and explore novel methods for abstracting key information from user comments, which could be used to add context and nuance to heuristic based ratings. We find that heuristic and community based ratings are highly complementary, and can be combined to potentially guide users to make more informed decisions.</span></div></div><div class="paper" id="paper1420"><a href="#paper1420" class="title">Pairing Devices for Social Interactions: A Comparative Usability Evaluation</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979282&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ersin  Uzun</span> <span class="affiliation">Palo Alto Research Center</span>, <br />
<span class="author">Nitesh  Saxena</span> <span class="affiliation">New York University Polytechnic Institute</span>, <br />
<span class="author">Arun  Kumar</span> <span class="affiliation">New York University Polytechnic Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">When users wish to establish wireless radio communication between/among their devices, the channel has to be bootstrapped first. The process of setting up a secure communication channel between two previously unassociated devices is referred to as &#8220;Secure Device Pairing&#8221;. The focus of prior research on this topic has mostly been limited to &#8220;personal pairing&#8221; scenarios, whereby a single user controls both the devices. In this paper, we instead consider &#8220;social pairing&#8221; scenarios, whereby two different users establish pairing between their respective devices. We present a comprehensive study to identify methods suitable for social pairing, and comparatively evaluate the usability and security of these methods. Our results identify methods best-suited for users, in terms of efficiency, error-tolerance and of course, usability. Our work provides insights on the applicability and usability of methods for emerging social pairing scenarios, a topic largely ignored so far.</span></div></div><div class="paper" id="paper785"><a href="#paper785" class="title">Experiencing Security in Interaction Design</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979283&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Niels Raabjerg Mathiasen</span> <span class="affiliation">Aarhus University</span>, <br />
<span class="author">Susanne  B&#248;dker</span> <span class="affiliation">Aarhus University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Security is experienced differently in different contexts. This paper argues that in everyday situations, users base their security decisions on a mix of prior experiences. When approaching security and interaction design from an experience approach, tools that help bring out such relevant experiences for design are needed. This paper reports on how Prompted exploration workshops and Acting out security were developed to target such experiences when iteratively designing a mobile digital signature solution in a participatory design process. We discuss how these tools helped the design process and illustrate how the tangibility of such tools matters. We further demonstrate how the approach grants access to non-trivial insights into people&#8217;s security experience. We point out how the specific context is essential for exploring the space between experience and expectations, and we illustrate how people activate their collections of security experiences rather than deploying one security strategy in all situations.</span></div></div></td>
<td colspan="10" class="session_details" id="S1209_details"><div class="sessionChair"><strong>Session Chair: </strong>Daniel Wigdor (<em>Microsoft Research</em>)</div><div class="paper" id="paper907"><a href="#paper907" class="title">Typing on Flat Glass: Examining Ten-Finger Expert Typing Patterns on Touch Surfaces</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979301&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Leah  Findlater</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Daniel  Wigdor</span> <span class="affiliation">Microsoft Research, University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch screen surfaces large enough for ten-finger input have become increasingly popular, yet typing on touch screens pales in comparison to physical keyboards. We examine typing patterns that emerge when expert users of physical keyboards touch-type on a flat surface. Our aim is to inform future designs of touch screen keyboards, with the ultimate goal of supporting touch-typing with limited tactile feedback. To study the issues inherent to flat-glass typing, we asked 20 expert typists to enter text under three conditions: (1) with no visual keyboard and no feedback on input errors, then (2) with and (3) without a visual keyboard, but with some feedback. We analyzed touch contact points and hand contours, looking at attributes such as natural finger positioning, the spread of hits among individual keys, and the pattern of non-finger touches. We also show that expert typists exhibit spatially consistent key press distributions within an individual, which provides evidence that eyes-free touch-typing may be possible on touch surfaces and points to the role of personalization in such a solution. We conclude with implications for design.</span></div></div><div class="paper" id="paper1000"><a href="#paper1000" class="title">CHANTI: Predictive Text Entry Using Non-verbal Vocal Input</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979302&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Adam J Sporka</span> <span class="affiliation">Czech Technical University in Prague</span>, <br />
<span class="author">Torsten  Felzer</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Sri H Kurniawan</span> <span class="affiliation">University of California Santa Cruz</span>, <br />
<span class="author">Ondrej  Polacek</span> <span class="affiliation">Czech Technical University in Prague</span>, <br />
<span class="author">Paul  Haiduk</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Scott  MacKenzie</span> <span class="affiliation">York University Toronto</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper introduces a text entry application for users with physical disabilities who cannot utilize a manual keyboard. The system allows the user to enter text hands-free, with the help of Non-verbal Vocal Input (e.g., humming or whistling). To keep the number of input sounds small, an ambiguous keyboard is used. As the user makes a sequence of sounds, each representing a subset of the alphabet, the program searches for matches in a dictionary. As a model for the system, the scanning-based application QANTI was redesigned and adapted to accept the alternative input signals. The usability of the software was investigated in an international longitudinal study done at locations in the Czech Republic, Germany, and the United States. Eight test users were recruited from the target community. The users differed in the level of speech impairment. Three users did not complete the study due to the severity of their impairment. By the end of the experiment, the users were able to enter text at rates between 10 and 15 characters per minute.</span></div></div><div class="paper" id="cs104"><a href="#cs104" class="title">Using the Keystroke-Level Model for Designing User Interface on Middle-Sized Touch Screens</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979667&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Evgeniy  Abdulin</span> <span class="affiliation">Russian Academy of Sciences</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The Keystroke-Level Model was developed to predict accurately task execution time for mouse-and-keyboard systems. Middle-sized touch screens are becoming much more popular so it is important to determine whether KLM can provide useful predictions for these interfaces as well.  The KLMs were created using special software CogTool for three touch screen interfaces for integrated control systems and were compared to experimental data. The results showed that the KLM prediction error for middle-sized touch screens reached less than 5%. This conclusion is that KLM has acceptable accuracy level in this environment for making predictions for the task execution times.</span></div></div><div class="paper" id="paper915"><a href="#paper915" class="title">AirStroke: Bringing Unistroke Text Entry to Freehand Gesture Interfaces</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979303&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tao  Ni</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Doug  Bowman</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Chris  North</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we explore the opportunity of bringing unistroke text entry to freehand gesture interfaces. Using existing text entry methods directly in such interfaces is impractical because of the differences between freehand gestures and traditional forms of input. To address this problem, we consider the design constraints of text entry methods using freehand gestures, and present AirStroke, a new technique based on a reengineering of the well-known unistroke technique Graffiti. Using Graffiti&#8217;s alphabet, AirStroke takes advantage of the richer input capabilities of two-handed freehand gestures by providing combined mode selection and character entry with one hand, as well as word completion with the other hand. A longitudinal study suggests that AirStroke has competitive speed and accuracy to unistroke methods based on stylus input.</span></div></div><div class="paper" id="paper2036"><a href="#paper2036" class="title">Sampling Representative Phrase Sets for Text Entry Experiments: A Procedure and Public Resource</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979304&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tim  Paek</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Bo-June (Paul)  Hsu</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Text entry experiments evaluating the effectiveness of various input techniques often employ a procedure whereby users are prompted with natural language phrases which they are instructed to enter as stimuli. For experimental validity, it is desirable to control the stimuli and present text that is representative of a target task, domain or language. MacKenzie and Soukoreff (2001) manually selected a set of 500 phrases for text entry experiments. To demonstrate representativeness, they correlated the distribution of single letters in their phrase set to a relatively small (by current standards) corpus of English prior to 1966, which may not reflect the style of text input today. In this paper, we ground the notion of representativeness in terms of information theory and propose a procedure for sampling representative phrases from any large corpus so that researchers can curate their own stimuli. We then describe the characteristics of phrase sets we generated using the procedure for email and social media (Facebook and Twitter). The phrase sets and code for the procedure are publicly available for download.</span></div></div></td>
<td colspan="10" class="session_details" id="S1210_details"><div class="sessionChair"><strong>Session Chair: </strong>Kelly Booth (<em>University of British Columbia</em>)</div><div class="paper" id="paper882"><a href="#paper882" class="title">Enhancing Physicality in Touch Interaction with Programmable Friction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979306&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vincent  Levesque</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Louise  Oram</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Karon  MacLean</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Nicholas D. Marchuk</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Dan  Johnson</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">J. Edward  Colgate</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Michael A. Peshkin</span> <span class="affiliation">Northwestern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch interactions have refreshed some of the &#8216;glowing enthusiasm&#8217; of thirty years ago for direct manipulation interfaces. However, today&#8217;s touch technologies, whose interactions are supported by graphics, sounds or crude clicks, have a tactile sameness and gaps in usability. We use a Large Area Tactile Pattern Display (LATPaD) to examine design possibilities and outcomes when touch interactions are enhanced with variable surface friction. In a series of four studies, we first confirm that variable friction gives significant performance advantages in low-level targeting activities. We then explore the design space of variable friction interface controls and assess user reactions. Most importantly, we demonstrate that variable friction can have a positive impact on the enjoyment, engagement and sense of realism experienced by users of touch interfaces.</span></div></div><div class="paper" id="paper985"><a href="#paper985" class="title">Surfpad: Riding Towards Targets on a Squeeze Film Effect</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979307&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">G&#233;ry  Casiez</span> <span class="affiliation">LIFL &amp; INRIA Lille &amp; University of Lille</span>, <br />
<span class="author">Nicolas  Roussel</span> <span class="affiliation">INRIA Lille</span>, <br />
<span class="author">Romuald  Vanbelleghem</span> <span class="affiliation">INRIA Lille</span>, <br />
<span class="author">Fr&#233;d&#233;ric  Giraud</span> <span class="affiliation">L2EP &amp; INRIA Lille &amp; University of Lille</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present Surfpad, a pointing facilitation technique that does not decrease target distance or increase target width in either control or display space. This new technique operates instead in the tactile domain by taking advantage of the ability to alter a touchpad's coefficient of friction by means of a squeeze film effect. We report on three experiments comparing Surfpad to the Semantic Pointing technique and constant control-display gain with and without distractor targets. Our results clearly show the limits of traditional target-aware control-display gain adaptation in the latter case, and the benefits of our tactile approach in both cases. Surfpad leads to a performance improvement close to 9% compared to unassisted pointing at small targets with no distractor. It is also robust to high distractor densities, keeping an average performance improvement of nearly 10% while Semantic Pointing can degrade up to 100%. Our results also suggest the performance improvement is caused by tactile information feedback rather than mechanical causes, and that the feedback is more effective when friction is increased on targets using a simple step function.</span></div></div><div class="paper" id="paper719"><a href="#paper719" class="title">Understanding Touch</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979308&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christian  Holz</span> <span class="affiliation">Hasso Plattner Institute</span>, <br />
<span class="author">Patrick  Baudisch</span> <span class="affiliation">Hasso Plattner Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Current touch devices, such as capacitive touchscreens are based on the implicit assumption that users acquire targets with the center of the contact area between finger and device. Findings from our previous work indicate, however, that such devices are subject to systematic error offsets. This suggests that the underlying assumption is most likely wrong. In this paper, we therefore revisit this assumption.  <br />  <br /> In a series of three user studies, we find evidence that the features that users align with the target are visual features. These features are located on the top of the user&#8217;s fingers, not at the bottom, as assumed by traditional devices. We present the projected center model, under which error offsets drop to 1.6mm, compared to 4mm for the traditional model. This suggests that the new model is indeed a good approximation of how users conceptualize touch input. <br />  <br /> The primary contribution of this paper is to help understand touch&#8212;one of the key input technologies in human-computer interaction. At the same time, our findings inform the design of future touch input technology. They explain the inaccuracy of traditional touch devices as a &#8220;parallax&#8221; artifact between user control based on the top of the finger and sensing based on the bottom side of the finger. We conclude that certain camera-based sensing technologies can inherently be more accurate than contact area-based sensing. <br />  <br /></span></div></div><div class="paper" id="paper1528"><a href="#paper1528" class="title">Magic Desk: Bringing Multi-Touch Surfaces into  Desktop Work</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979309&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Xiaojun  Bi</span> <span class="affiliation">Autodesk Research, University of Toronto</span>, <br />
<span class="author">Tovi  Grossman</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">Justin  Matejka</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">George  Fitzmaurice</span> <span class="affiliation">Autodesk Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Despite the prominence of multi-touch technologies, there has been little work investigating its integration into the desktop environment. Bringing multi-touch into desktop computing would give users an additional input channel to leverage, enriching the current interaction paradigm dominated by a mouse and keyboard. We provide two main contributions in this domain. First, we describe the results from a study we performed, which systematically evaluates the various potential regions within the traditional desktop configuration that could become multi-touch enabled. The study sheds light on good or bad regions for multi-touch, and also the type of input most appropriate for each of these regions. Second, guided by the results from our study, we explore the design space of multi-touch-integrated desktop experiences. A set of new interaction techniques are coherently integrated into a desktop prototype, called Magic Desk, demonstrating potential uses for multi-touch enabled desktop configurations.</span></div></div></td>
<td colspan="10" class="session_details" id="S1204_details"><div class="sessionChair"><strong>Session Chair: </strong>Joanna McGrenere (<em>University of British Columbia</em>)</div><div class="paper" id="paper900"><a href="#paper900" class="title">Utility of Human-Computer Interactions: Toward a Science of Preference Measurement</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979277&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Toomim</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Travis  Kriplean</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Claus  P&#246;rtner</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">James A. Landay</span> <span class="affiliation">University of Washington and Microsoft Resesarch</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The success of a computer system depends upon a user choosing it, but the field of Human-Computer Interaction has little ability to predict this user choice. We present a new method that measures user choice, and quantifies it as a measure of utility. Our method has two core features. First, it introduces an economic definition of utility, one that we can operationalize through economic experiments. Second, we employ a novel method of crowdsourcing that enables the collection of thousands of economic judgments from real users.</span></div></div><div class="paper" id="to123"><a href="#to123" class="title">An exploration of relations between visual appeal, trustworthiness and perceived usability of homepages</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Gitte  Lindgaard</span> <span class="affiliation">Carleton University</span>, <br />
<span class="author">Cathy  Dudek</span> <span class="affiliation">Carleton University</span>, <br />
<span class="author">Devjani  Sen</span> <span class="affiliation">Carleton University</span>, <br />
<span class="author">Livia  Sumegi</span> <span class="affiliation">Carleton University</span>, <br />
<span class="author">Patrick  Noonan</span> <span class="affiliation">Carleton University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">High correlations between repeated visual-appeal judgments of homepages shown very briefly have been interpreted as a mere exposure effect. The present research had two objectives: it investigated the relationship between judgments differing in cognitive demands, and it identified visual attributes contributing to those judgments. By disrupting processing beyond the stimulus offset, Experiment 1 ensured that the previous findings could not be attributed to continued processing. Experiment 2 (within-subjects) investigated if judgments differing in cognitive demands (visual appeal, perceived usability, trustworthiness) may be driven by visual characteristics. It also enabled analyses of visual attributes contributing most to the judgments. Experiment 3 replicated Experiment 2 using a between-subject design to prevent practice effects. Results suggest that all three judgments are largely driven by visual characteristics. Cognitively demanding judgments are processed in a qualitatively different manner than visual appeal, relying on somewhat different visual attributes. A model accounting for the results is provided.</span></div></div><div class="paper" id="paper1092"><a href="#paper1092" class="title">Informing Decisions: How people use online rating information to make choices</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979278&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stelios  Lelis</span> <span class="affiliation">University of Manchester</span>, <br />
<span class="author">Andrew  Howes</span> <span class="affiliation">University of Manchester</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we investigate how people use online rating information to inform decision making. We examine whether a theory of searching for information to discriminate between alternative choices can explain behavior, and we contrast it to the normative theory. Partly in accord with the theory, findings from a controlled experiment suggest that in an environment dominated by positive reviews, such as the World-Wide Web, people gather more information for the best alternative under consideration, and they take more time to inspect reviews of lower rating. We discuss the theoretical and experimental implications, and propose a bounded optimal account of the way in which people acquire information in service of decision making.</span></div></div><div class="paper" id="cs157"><a href="#cs157" class="title">Does &#8220;Letting Go of the Words&#8221; Increase Engagement? A Traffic Study</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979663&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Martin  Colbert</span> <span class="affiliation">Kingston University</span>, <br />
<span class="author">Angela  Boodoo</span> <span class="affiliation">Digital Content and User Experience Strategist</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This case study explores the effects of written online content on user engagement, and describes the challenges of conducting experiments on live web sites.  It compares two versions of a website about bicycle maintenance and repair.  One version complied with the guidelines for written online content in &#8216;Letting Go of the Words&#8217; (Redish, 2007), the other version did not.  Web metrics suggested visitors were more engaged with the guideline-compliant version in some respects.  Visitors appeared to spend longer on the compliant site, and were more likely to revisit the compliant site, but they were not tempted to explore it further.  Conducting this traffic study presented several challenges - notably, how to profile visitors, and how to demonstrate statistical significance.</span></div></div></td>
<td colspan="10" class="session_details" id="S1207_details"><div class="sessionChair"><strong>Session Chair: </strong>Thomas Erickson (<em>IBM Research</em>)</div><div class="paper" id="paper1356"><a href="#paper1356" class="title">Ceci N'est Pas Une Pipe Bombe:  Authoring Urban Landscapes with Air Quality Sensors</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979290&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stacey  Kuznetsov</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">George  Davis</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jian  Cheung</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Eric  Paulos</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our work explores the convergence between participatory sensing, political activism and public expressions. Unlike prior research, which focuses on personal sensing, we present low-cost, networked air quality sensors, designed to be repositioned across public landscapes by communities of citizen stakeholders. Our GPS-enabled sensors report dust, exhaust, or VOC&#8217;s (volatile organic compounds), along with temperature, humidity and light levels to a website that visualizes this data in real time. The sensors can be attached to a variety of surfaces serving as research probes to demarcate (&#8216;tag&#8217;) public spaces with environmental concerns. We deploy our fully functional system with four urban communities- parents, bicyclists, homeless and activists, positioning our system as a tool for studying and supporting community togetherness and public activism. Our findings highlight community sharing of the physical sensors and dialogues surrounding the collected data.</span></div></div><div class="paper" id="paper957"><a href="#paper957" class="title">Second-Hand Interactions:  Investigating Reacquisition and Dispossession Practices around Domestic Objects</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979291&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Pierce</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Eric  Paulos</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a qualitative study of reacquisition&#8212;the acquisition of previously possessed goods&#8212;involving in-depth interviews with 18 reacquirers within or nearby Pittsburgh, PA, USA. Based on critiques of sustainable consumption and our findings, we reframe technology consumption as acquisition, possession, dispossession and reacquisition. We present four reacquisition orientations describing our participants&#8217; motivations and practices: casual, necessary, critical, and experiential. We then present a range of findings including issues with work, time and effort involved in reacquisition, and values and practices of care and patience associated with invested reacquirers. We conclude with implications for designing technologies to support current reacquisition practices, as well as broader opportunities for HCI and interaction design to incorporate non-mainstream reacquisition practices and values into more mainstream technologies.</span></div></div><div class="paper" id="paper1241"><a href="#paper1241" class="title">Practices in the Creative Reuse of e-Waste</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979292&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sunyoung  Kim</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Eric  Paulos</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">E-waste is a generic term embracing various forms of electric and electronic equipment that is loosely discarded, surplus, obsolete, or broken. When e-waste is improperly discarded as trash, there are predictable negative impacts on the environment and human health. Existing e-waste solutions range from designing for reuse to fabricating with eco-friendly decomposable materials to more radical critiques of current practices surrounding capitalism and consumerism. Complementary to theses efforts, this paper presents an accessible reuse framework that encourages creativity while maintaining personal ownership of e-waste. Through a series of online surveys of existing personal e-waste stockpiling behaviors combined with observational studies of existing reuse practices, we developed a design reuse vocabulary: materials, shapes, and operations to enable wide ranging and creative reuse of obsolete electronics by everyday people. We operationalized this vocabulary and evaluated its legibility and usefulness. As a result, we derived a novel reuse composition framework: reuse as-is, remake, and remanufacture designed to be accessible and to have broader impact in encouraging creative reuse across a wide range of e-waste types beyond those specifically used in our study. We believe these frameworks will be a catalyst for the creative reuse of e-waste.</span></div></div><div class="paper" id="paper969"><a href="#paper969" class="title">A Phenomenology of Human-Electricity Relations</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979293&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Pierce</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Eric  Paulos</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper investigates the philosophical question of how we can experience energy with the aim of informing the design of future ways of experiencing energy by means of technology. Four human-technology relations formulated by philosopher of technology Don Ihde are presented. Each is then developed in the context of electrical interactive technologies. In conclusion these human-electricity and human-technology relations are employed in order to interpret current work related to energy and sustainability within HCI and point to future work in these areas.</span></div></div><div class="paper" id="cs155"><a href="#cs155" class="title">Flo: Raising Family Awareness about Electricity Use</a>&nbsp;-&nbsp;<span class="type">Case Study (Short)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979665&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Paul  Shrubsole</span> <span class="affiliation">Philips Research, Eindhoven</span>, <br />
<span class="author">Tine  Lavrysen</span> <span class="affiliation">Delft University of Technology</span>, <br />
<span class="author">Maddy  Janse</span> <span class="affiliation">Philips Research, Eindhoven</span>, <br />
<span class="author">Hans  Weda</span> <span class="affiliation">Philips Research, Eindhoven</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this case study, we designed a family game to explore whether this could be an effective and fun approach for raising the awareness of family members towards their energy use and, in the long run, to provide an effective tool for affecting their habits regarding sustainable behavior. The design of the family game implemented the metaphor of electricity as flowing liquid, fostered fun experiences and supported competitive and social elements. Dutch families with children, aged 5-11 years, participated in the design and evaluation of the concept. We obtained valuable insights into the use and understanding of electricity by the families, how the families looked at responsible behaviors around their usage and how a game could integrate into the family context in a fun way.</span></div></div></td>
<td colspan="10" class="session_details" id="S1198_details"><div class="paper" id="pl112"><a href="#pl112" class="title">Transferability of Research Findings:  Context-Dependent or Model-Driven</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979494&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ed H. Chi</span> <span class="affiliation">Google Research</span>, <br />
<span class="author">Mary  Czerwinski</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">David  Millen</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Dave  Randall</span> <span class="affiliation">Metropolitan University Manchester</span>, <br />
<span class="author">Gunnar  Stevens</span> <span class="affiliation">University of Siegen</span>, <br />
<span class="author">Volker  Wulf</span> <span class="affiliation">University of Siegen</span>, <br />
<span class="author">John  Zimmerman</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this panel we will explore two distinct approaches to reach transferability currently prevailing in the HCI community. We will discuss epistemological differences and the strengths and criticisms of each approach. Importantly, we will discuss the implications for HCI research practice given this diversity of methodological approaches.</span></div></div></td>
<td colspan="10" class="session_details" id="S1208_details"><div class="sessionChair"><strong>Session Chair: </strong>Lars Erik Holmquist (<em>Swedish Institute of Computer Science</em>)</div><div class="paper" id="paper2085"><a href="#paper2085" class="title">I'm the Mayor of My House: Examining Why People Use foursquare - a Social-Driven Location Sharing Application</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979295&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janne  Lindqvist</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Justin  Cranshaw</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jason  Wiese</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jason  Hong</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">John  Zimmerman</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There have been many location sharing systems developed over the past two decades, and only recently have they started to be adopted by consumers. In this paper, we present the results of three studies focusing on the foursquare check-in system. We conducted interviews and two surveys to understand, both qualitatively and quantitatively, how and why people use location sharing applications, as well as how they manage their privacy. We also document surprising uses of foursquare, and discuss implications for design of mobile social services.</span></div></div><div class="paper" id="paper2077"><a href="#paper2077" class="title">In the Best Families: Tracking and Relationships</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979296&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Clara  Mancini</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Yvonne  Rogers</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Keerthi  Thomas</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Adam  Joinson</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Blaine  Price</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Arosha  Bandara</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Lukasz  Jedrzejczyk</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Bashar  Nuseibeh</span> <span class="affiliation">The Open University/University of Limerick</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A growing body of research has been exploring the use of control mechanisms to address the privacy concerns raised by location-tracking technology. We report on a qualitative study of two family groups who used a custom-built tracking application for an extended period of time. Akin to sociological breaching experiments, the study focuses on the interferences between location tracking and relationship management. We analyze the tensions that can arise between affordances of the technology and uses that the contracts between family members legitimize. We describe how, by fostering misperceptions and &#8216;nudging&#8217; behaviors, location-tracking technology can generate anxieties and conflicts even in close relationships. We discuss their vulnerability to the overreaching effects of tracking, against which the use of mechanisms such as location-sharing preferences and feedback may not be socially viable.</span></div></div><div class="paper" id="paper1993"><a href="#paper1993" class="title">Opportunities Exist: Continuous Discovery of Places to Perform Activities</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979297&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Dearman</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Timothy  Sohn</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Khai N Truong</span> <span class="affiliation">University of Toronto</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A rich cognitive map of a space can enhance the individual&#8217;s experience within the space. However, cognitive maps develop gradually through repeated experience; and because of this, on-demand mobile search services (e.g., Google Maps, Yelp) are often used to compensate for missing knowledge. In this work, we developed and evaluated a context-aware place discovery application called Opportunities Exist to assist in the acquisition of spatial knowledge and meaning. The application differs from traditional search in that places are discovered using an activity (e.g., drink coffee, sit in the sun) and the discovery process runs continuously, maintaining a history of places the user can perform her activities as she goes about her day. We conducted a 4-week deployment in two North American cities. The results show that users were able to discover new places to perform their activities in familiar spaces and learned to associate new activities with familiar places. In addition, participants leveraged the application to perform activities opportunistically, and used continuous place discovery as an opportunistic reminder of routines they wanted to break out of or resume.</span></div></div><div class="paper" id="paper1175"><a href="#paper1175" class="title">Location Visualization in Social Media Applications</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979298&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Minna  Pakanen</span> <span class="affiliation">Intel and Nokia Joint Innovation Center</span>, <br />
<span class="author">Jussi  Huhtala</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Jonna  H&#228;kkil&#228;</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Location sharing applications are becoming increasingly popular in social media and for use on mobile devices, yet little research has focused on their user interface design. In this paper we describe our method of charting and creating comparable designs, and present a survey-based study of 106 social media users on their preferences regarding location indicators. Our paper contributes in proposing a methodology for visual element evaluation purposes, and reveals results, e.g., that users preferred simple indicators such as points or pins for their own location, and friend location indicators to include the corresponding name.</span></div></div><div class="paper" id="paper1971"><a href="#paper1971" class="title">When Are Users Comfortable Sharing Locations with Advertisers?</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979299&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Patrick Gage Kelley</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michael  Benisch</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Lorrie Faith Cranor</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Norman  Sadeh</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As smartphones and other mobile computing devices have increased in ubiquity, advertisers have begun to realize a more effective way of targeting users and a promising area for revenue growth: location-based advertising. This trend brings to bear new questions about whether or not users will adopt products involving this potentially invasive form of advertising and what sorts of protections they should be given. Our real-world user study of 27 participants echoes earlier findings that users have significant privacy concerns regarding sharing their locations with advertisers. However, we examine these concerns in more detail and find that they are complex (e.g., relating not only to the quantity of ads, but the locations and times at which they are received). With advanced privacy settings, users stated they would feel more comfortable and share more information than with a simple opt-in/opt-out mechanism.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">15:20<br />-<br />16:00</td>

<td class="session " id="S5018">
<div class="session_box">
<span class="type">Interactivity</span>
<a href="#S5018" class="title">Interactivity 1 Open</a>
<span class="location">Ballroom C/D</span>
<strong></strong>

</div>
</td>

<td class="session " id="S5017">
<div class="session_box">
<span class="type">Interactivity</span>
<a href="#S5017" class="title">Interactivity 2 Open</a>
<span class="location">202/203/204</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="2" class="session_details" id="S5018_details"><div class="paper" id="in135"><a href="#in135" class="title">ChronoViz: A System for Supporting Navigation of Time-coded Data</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979706&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Adam  Fouse</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">Nadir  Weibel</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">Edwin  Hutchins</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">James D Hollan</span> <span class="affiliation">University of California, San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present ChronoViz, a system to aid annotation, visualization, navigation, and analysis of multimodal time-coded data. Exploiting interactive paper technology, ChronoViz also integrates researcher's paper notes into the composite data set. Researchers can navigate data in multiple ways, taking advantage of synchronized visualizations and annotations. The goal is to decrease the time and effort required to analyze multimodal data by providing direct indexing and flexible mechanisms to control data exploration.</span></div></div><div class="paper" id="in143"><a href="#in143" class="title">i*Chameleon: A Scalable and Extensible Framework for Multimodal Interaction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979703&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wai Wa  Tang</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Kenneth W.K.  Lo</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Alvin T.S.  Chan</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Stephen  Chan</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Hong Va  Leong</span> <span class="affiliation">The Hong Kong Polytechnic University</span>, <br />
<span class="author">Grace  Ngai</span> <span class="affiliation">The Hong Kong Polytechnic University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">i*Chameleon is a multimodal interaction framework that enables programmers to readily prototype and test new interactive devices or interaction modes. It allows users to customize their own desktop environment for interaction beyond the usual KVM devices, which would be particularly useful for users with difficulty using the keyboard and mouse, or for systems deployed in specialized environments. This is made possible with the engineering of an interaction framework that distills the complexity of control processing to a set of semantically-rich modal controls that are discoverable, composable and adaptable. The framework can also be used for developing new applications with multimodal interactions, for example, distributed applications in collaborative environments or robot control.</span></div></div><div class="paper" id="in147"><a href="#in147" class="title">INVISQUE: Intuitive Information Exploration through Interactive Visualization</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979720&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">B L William  Wong</span> <span class="affiliation">Middlesex University</span>, <br />
<span class="author">Raymond  Chen</span> <span class="affiliation">Middlesex University</span>, <br />
<span class="author">Neesha  Kodagoda</span> <span class="affiliation">Middlesex University</span>, <br />
<span class="author">Chris  Rooney</span> <span class="affiliation">Middlesex University</span>, <br />
<span class="author">Kai  Xu</span> <span class="affiliation">Middlesex University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present INVISQUE, a novel system designed for interactive information exploration. Instead of a conventional list-style arrangement, in INVISQUE information is represented by a two-dimensional spatial canvas, with each dimension representing user-defined semantics.  Search results are presented as index cards, ordered in both dimensions. Intuitive interactions are used to perform tasks such as keyword searching, results browsing, categorizing, and linking to online resources such as Google and Twitter. The interaction-based query style also naturally lends the system to different types of user input such as multi-touch gestures. As a result, INVISQUE gives users a much more intuitive and smooth experience of exploring large information spaces.</span></div></div><div class="paper" id="in148"><a href="#in148" class="title">Tactile Display for the Visually Impaired Using TeslaTouch</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979705&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cheng  Xu</span> <span class="affiliation">Disney Research Pittsburgh &amp; Carnegie Mellon University</span>, <br />
<span class="author">Ali  Israr</span> <span class="affiliation">Disney Research Pittsburgh</span>, <br />
<span class="author">Ivan  Poupyrev</span> <span class="affiliation">Disney Research Pittsburgh</span>, <br />
<span class="author">Olivier  Bau</span> <span class="affiliation">Disney Research Pittsburgh</span>, <br />
<span class="author">Chris  Harrison</span> <span class="affiliation">Disney Research Pittsburgh &amp; Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">TeslaTouch is a technology that provides tactile sensation to moving fingers on touch screens. Based on TeslaTouch, we have developed applications for the visually impaired to interpret and create 2D tactile information. We demonstrate these applications, present observations from the interaction, and discuss TeslaTouch&#8217;s potential in supporting communication among visually impaired individuals.</span></div></div><div class="paper" id="in151"><a href="#in151" class="title">MudPad: Tactile Feedback for Touch Surfaces</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979702&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yvonne  Jansen</span> <span class="affiliation">INRIA / RWTH Aachen University</span>, <br />
<span class="author">Thorsten  Karrer</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">MudPad is a system enriching touch surfaces with localized active haptic feedback. A soft and flexible overlay containing magnetorheological fluid is actuated by an array of electromagnets to create a variety of tactile sensations. As each magnet can be controlled individually, we are able to produce feedback in realtime locally at arbitrary points of interaction.</span></div></div><div class="paper" id="in162"><a href="#in162" class="title">Snaplet: Using Body Shape to Inform Function in Mobile Flexible Display Devices</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979701&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aneesh P Tarun</span> <span class="affiliation">Human Media Lab, Queen's University</span>, <br />
<span class="author">Byron  Lahey</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Human Media Lab, Queen's University</span>, <br />
<span class="author">Winslow  Burleson</span> <span class="affiliation">Arizona State University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Human Media Lab, Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With recent advances in flexible displays, computer displays are no longer restricted to flat, rigid form factors. We propose that the physical form of a flexible display, depending on the way it is held or worn, can help shape its current functionality. We propose Snaplet, a wearable flexible E Ink display augmented with sensors that allow the shape of the display to be detected. Snaplet is a paper computer in the form of a bracelet. When in a convex shape on the wrist, Snaplet functions as a watch and media player. When held flat in the hand it is a PDA with notepad functionality. When held in a concave shape Snaplet functions as a phone. Calls are dropped by returning its shape to a flat or convex shape.</span></div></div><div class="paper" id="in171"><a href="#in171" class="title">Ubiquitous Voice Synthesis: Interactive Manipulation of Speech and Singing on Mobile Distributed Platforms</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979700&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicolas  d'Alessandro</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Robert  Pritchard</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Johnty  Wang</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Vocal production is one of the most ubiquitous and expressive activities of people, yet understanding its production and synthesis remains elusive. When vocal synthesis is elevated to include new forms of singing and sound production, fundamental changes to culture and musical expression emerge. Nowadays, Text-To-Speech (TTS) synthesis seems unable to suggest innovative solutions for new computing trends, such as mobility, interactivity, ubiquitous computing or expressive manipulation. <br />  <br /> We describe our pioneering work in developing interactive voice synthesis beyond the TTS paradigm. We present DiVA and HandSketch as our two current voice-based digital musical instruments. We then discuss the evolution of this performance practice into a new ubiquitous model applied to voice synthesis, and we describe our first prototype using a mobile phone and wireless embodied devices in order to allow a group of users to collaboratively produce voice synthesis in real-time.</span></div></div><div class="paper" id="in173"><a href="#in173" class="title">RayMatic: Ambient meter display with facial expression and gesture</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979718&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ray  Yun</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Mark D Gross</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an experimental thermostat display that moves beyond a conventional, number-based interface. It explores an approach to engaging and emotional human-computer interaction through facial expression and gesture. Using sensors and touch technology, an ordinary picture frame becomes an interactive meter and conveys environmental information as an ambient display.</span></div></div></td>
<td colspan="2" class="session_details" id="S5017_details"><div class="paper" id="in122"><a href="#in122" class="title">Coco - The Therapy Robot</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979721&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katharina  Tran phuc</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Torsten  Racky</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Florian  Roth</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Iris  Wegmann</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Christoph  Busch</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Claudia  S&#246;ller-Eckert</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Mara  Pilz</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Katharina  Horst</span> <span class="affiliation">University of Applied Sciences Darmstadt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Coco is a therapeutic robot designed for elderly people in nursing homes or other care facilities. It is an electronic pet that represents a friend and helper who animates, reminds and motivates its owner.  He has 4 main functions: reading, singing, a calendar function and quiz games and can be operated by voice, remote control or base buttons. Pressure sensors in Coco's back react to touch. He interacts with its owner on its own initiative, suggesting to read, sing or play. Coco's memory and activity settings can be customised by carers or relatives. The prototype was implemented with Lego Mindstorms and successfully tested by a focus group. <br /></span></div></div><div class="paper" id="in129"><a href="#in129" class="title">Touch and Copy, Touch and Paste</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979714&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Suranga  Nanayakkara</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">SPARSH explores a novel interaction method to seamlessly transfer data between digital devices in a fun and intuitive way. The user touches whatever data item he or she wants to copy from a device. At that moment, the data item is conceptually saved in the user. Next, the user touches the other device he or she wants to paste/pass the saved content into. SPARSH uses touch-based interactions as indications for what to copy and where to pass it. Technically, the actual transfer of media happens via the information cloud.</span></div></div><div class="paper" id="in130"><a href="#in130" class="title">Mouseless - a Computer Mouse as Small as Invisible</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979715&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mouseless is a novel input device that provides the familiarity of interaction of a physical computer mouse without requiring a real hardware mouse. It consists of an IR laser beam and an IR camera, both of which are embedded in a computer. Mouseless proposes a number of novel additional gestural interactions while supporting all the conventional computer mouse interactions. We present the design and implementation of various Mouseless prototype systems.</span></div></div><div class="paper" id="in132"><a href="#in132" class="title">Obfuscating Authentication Through Haptics, Sound and Light</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979709&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrea  Bianchi</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span>, <br />
<span class="author">Dong-Soo  Kwon</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sensitive digital content associated with or owned by individuals now pervades everyday life. Mediating accessing to it in ways that are usable and secure is an ongoing challenge. We present a series of five PIN entry and transmission systems that address observation attacks in public spaces via shoulder surfing or camera recording. They do this through the use of novel modalities including audio cues, haptic cues and modulated visible light. Each prototype is introduced and motivated, and its strengths and weaknesses are considered.</span></div></div><div class="paper" id="in137"><a href="#in137" class="title">Blinky Blocks: A Physical Ensemble Programming Platform</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979712&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Brian T Kirby</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michael  Ashley-Rollman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Seth Copen Goldstein</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A major impediment to understanding programmable matter is the lack of an existing system with sufficiently many modules of sufficient capabilities. We present the requirements of physically distributed ensembles and discuss the use of the distributed programming language Meld to program ensembles of these units. We demonstrate a new <br /> system designed to meet these requirements called Blinky Blocks and discuss the hardware design we used to create 100 of these modules.</span></div></div><div class="paper" id="in145"><a href="#in145" class="title">humanaquarium: Exploring Audience, Participation, and Interaction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span><div class="authors"><span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Guy  Schofield</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Jayne  Wallace</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Pierre  Boulanger</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">humanaquarium is a movable performance space designed to explore the dialogical relationship between artist and audience. Two musicians perform inside the cube-shaped box, collaborating with participants to co-create an aesthetic audio-visual experience. The front wall of the humanaquarium is a touch-sensitive FTIR window. Max/MSP is used to translate the locations of touches on the window into control data, manipulating the tracking of software synthesizers and audio effects generated in Ableton Live, and influencing a Jitter visualization projected upon the rear wall of the cube.</span></div></div><div class="paper" id="in150"><a href="#in150" class="title">3D-Press - Tangible 3D Haptics on Touch Surfaces: Virtual Compliance</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979717&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Suitability of current haptic three-dimensional user interface (3D-UI) technologies is low for mobile interaction. 3D-Press in reviewed in this paper: a technique to create the haptic illusion that when pressing on a rigid surface is feels compliant. The fact that the illusion is intramodal (haptics only involved in creating it), and that the technology required is simple and with low energy demands, makes it ideal for mobile use. The parameters used in the implementation of 3D-Press influence the characteristics of the illusion.</span></div></div><div class="paper" id="in152"><a href="#in152" class="title">Graffito: Crowd-based Performative Interaction at Festivals</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979725&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Sheridan</span> <span class="affiliation">BigDog Interactive Ltd</span>, <br />
<span class="author">Nick  Bryan-Kinns</span> <span class="affiliation">Queen Mary University of London</span>, <br />
<span class="author">Stuart  Reeves</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Giles  Lane</span> <span class="affiliation">Proboscis</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crowd-based events are generating new forms of crowd-based performative interaction. Nightclubs and festivals are at the cutting edge of crowd-based interaction with ubiquitous computing. The social capital of crowd-based interaction is not well understood and is usually limited to one-off events. Our intention is to explore the possibility for generating a lifelong contextual footprint of crowd-based performative interaction.</span></div></div><div class="paper" id="in154"><a href="#in154" class="title">Galvanic Skin Response-Derived Bookmarking of an Audio Stream</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979716&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew K.X.J. Pan</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gordon Jih-Shiang  Chang</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gokhan H. Himmetoglu</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">AJung  Moon</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Thomas W. Hazelton</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Karon E. MacLean</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Elizabeth A. Croft</span> <span class="affiliation">The University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We demonstrate a novel interaction paradigm driven by implicit, low-attention user control, accomplished by monitoring a user&#8223;s physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. A listener&#8223;s galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our research prototype then automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted.</span></div></div><div class="paper" id="in158"><a href="#in158" class="title">MediaDiver: Viewing and Annotating Multi-View Video</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979711&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gregor  Miller</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Abir  Al Hajri</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Michael  Ilich</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Zoltan  Foley-Fisher</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Manuel  Fernandez</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Daesik  Jang</span> <span class="affiliation">Kunsan National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our novel rich media interface called MediaDiver demonstrates our new interaction techniques for viewing and annotating multiple view video. The demonstration allows attendees to experience novel moving target selection methods (called Hold and Chase), new multi-view selection techniques, automated quality of view analysis to switch viewpoints to follow targets, integrated annotation methods for viewing or authoring meta-content and advanced context sensitive transport and timeline functions. As users have become increasingly sophisticated when managing navigation and viewing of hyper-documents, they transfer their expectations to new media. We demonstrate the technology required to meet these expectations for video. Thus users will be able to directly click on objects in the video to link to more information or other video, easily change camera views and mark-up the video with their own content. The applications of this technology stretch from home video management to broadcast quality media production, which may be consumed on both desktop and mobile platforms.</span></div></div><div class="paper" id="in161"><a href="#in161" class="title">TagURIt: A Proximity-based Game of Tag Using Lumalive e-Textile Displays</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979707&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sylvia H Cheng</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an electronic game of tag that uses proximity sensing and Lumalive displays on garments.  In our game of tag, each player physically represents a location-tagged Universal Resource Indicator (URI). The URIs, one chaser and two target players, wear touch-sensitive Lumalive display shirts. The goal of the game is for the chaser to capture a token displayed on one of the Lumalive shirts, by pressing a touch sensor located on the shirt. When the chaser is in close proximity to the token player, the token jumps to the shirt of the second closest player, making this children&#8217;s game more challenging for adult players.  Our system demonstrates the use of interactive e-textile displays to remove the technological barrier between contact and proximity in the real world, and the seamless representation of gaming information from the virtual world in that real world.</span></div></div><div class="paper" id="in165"><a href="#in165" class="title">Frictional Widgets: Enhancing Touch Interfaces with Programmable Friction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979713&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vincent  Levesque</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Louise  Oram</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Karon  MacLean</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Nicholas  Marchuk</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Dan  Johnson</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">J. Edward  Colgate</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Michael  Peshkin</span> <span class="affiliation">Northwestern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch interactions occur through flat surfaces that lack the tactile richness of physical interfaces. We explore the design possibilities offered by augmenting touchscreens with programmable surface friction. Four exemplar applications &#8211; an alarm clock, a file manager, a game, and a text editor &#8211; demonstrate tactile effects that improve touch interactions by enhancing physicality, performance, and subjective satisfaction.</span></div></div><div class="paper" id="in168"><a href="#in168" class="title">SnowGlobe: A Spherical Fish-Tank VR Display</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979719&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">John  Bolton</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a spherical display with Fish-Tank VR as a means for interacting with three-dimensional objects. We implemented the spherical display by reflecting a projected image off a hemispherical mirror, allowing for a seamless curvilinear display surface. Diffuse illumination is used for detecting touch points on the sphere. The user&#8217;s head position and the position of the sphere are also tracked using a Vicon motion capture device. Users can perform multi-touch gestures to interact with 3D content on the spherical display. Our system relies on the metaphor of a snow globe. Users can walk around a display while maintaining motion parallax corrected viewpoints of the object on the display. They can interact with the 3D object using multitouch interaction techniques, allowing for rotating and scaling of the 3D model on the display.</span></div></div><div class="paper" id="in170"><a href="#in170" class="title">ZeroTouch: A Zero-Thickness Optical Multi-Touch Force Field</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979710&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Sashikanth  Damaraju</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present zero-thickness optical multi-touch sensing, a technique that simplifies sensor/display integration, and enables new forms of interaction not previously possible with other multi-touch sensing techniques. <br /> Using low-cost modulated infrared sensors to quickly determine the visual hull of an interactive area, we enable robust real-time sensing of fingers and hands, even in the presence of strong ambient lighting. Our technology allows for 20+ fingers to be detected, many more than through prior visual hull techniques, and our use of wide-angle optoelectonics allows for excellent touch resolution, even in the corners of the sensor. <br /> With the ability to track objects in free space, as well as its use as a traditional multi-touch sensor, ZeroTouch opens up a new world of interaction possibilities.</span></div></div><div class="paper" id="in207"><a href="#in207" class="title">Immersive VR: A Non-pharmacological Analgesic for Chronic Pain?</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979704&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diane  Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Meehae  Song</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ji-Dong  Yim</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Tyler  Fox</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Steven J Barnes</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mark  Nazemi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Chris  Shaw</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Pam  Squire, MD</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the research work being carried out by the Transforming Pain Research Group &#8211; the only group whose work is entirely focused on the use of immersive VR for chronic pain management. Unlike VR research for acute or short-term pain, which relies on pain "distraction," this research posits a new paradigm for the use of VR. In addition to providing an overview of our work, the present paper also describes one of our current works in detail: the Virtual Meditative Walk.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">16:00<br />-<br />17:20</td>

<td class="session " id="S1213">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1213" class="title">CHI Conference Communities</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1212">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1212" class="title">User Experience Community: The Role of UX Work in SIGCHI</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1222">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1222" class="title">Cats, Dogs, Sports, Games &amp; Books</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1227">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1227" class="title">Innovation &amp; Design</a>
<span class="location">223/224</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1221">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1221" class="title">Authentication</a>
<span class="location">208/209</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1225">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1225" class="title">Shortcuts Commands &amp; Expertise</a>
<span class="location">217/218/219</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1226">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1226" class="title">Sound Interactions</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1220">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1220" class="title">Touch 3: Sensing</a>
<span class="location">205/206/207</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1223">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1223" class="title">User Experience</a>
<span class="location">212/213/214</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1214">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1214" class="title">The Future of  Child-Computer Interaction</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1224">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1224" class="title">Interaction on Mobile Devices</a>
<span class="location">215/216</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="11" class="session_details" id="S1213_details"><div class="paper" id="si106"><a href="#si106" class="title">CHI Conference Communities</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span><div class="authors"><span class="author">Arnold  Lund</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Bo  Begole</span> <span class="affiliation">PARC</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Lessons learned about organizing Communities at CHI, and discussion of the future of Core and Featured Communities.</span></div></div></td>
<td colspan="11" class="session_details" id="S1212_details"><div class="paper" id="si151"><a href="#si151" class="title">User Experience Community: The Role of UX Work in SIGCHI</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979539&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth A Buie</span> <span class="affiliation">Luminanze Consulting</span>, <br />
<span class="author">Jhilmil  Jain</span> <span class="affiliation">Microsoft</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This SIG will discuss the ongoing work of the UX Community in SIGCHI and will talk about what the Community can do for UX practitioners and UX researchers. We will discuss the new "practitioner's takeaways" instituted for CHI 2011, discuss an idea for an "idea market" session at upcoming CHI conferences, and explore other ideas for making the SIGCHI UX Community work.</span></div></div></td>
<td colspan="11" class="session_details" id="S1222_details"><div class="sessionChair"><strong>Session Chair: </strong>Sara Kiesler (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper1085"><a href="#paper1085" class="title">Understanding People and Animals: The Use of a Positioning System in Ordinary Human-Canine Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979328&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alexandra  Weilenmann</span> <span class="affiliation">University of Gothenburg</span>, <br />
<span class="author">Oskar  Juhlin</span> <span class="affiliation">Mobile Life @ Stockholm University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Animals are increasingly integrated in interactive contexts depending on digital technologies. The current and future use of such technologies is a relevant topic for HCI research. However, the field is struggling with the inherent problem of &#8216;interaction&#8217; in understanding interaction with animals. We argue for a way forward based on an ethnomethodological perspective on anthropomorphism, with a focus on manifest interaction. Drawing upon a field study of hunters&#8217; use of a GPS dog tracking-device, we discuss how interaction between dogs and humans is affected when new technology is introduced. The GPS data is situated and interpreted by the dog handler, and supports the hunter&#8217;s work of dealing with the dogs&#8217; intentions. This opens up for new forms of interactions with the dog. When studying and designing for interaction between humans and animals we should move beyond merely looking at dyadic relationships, and also consider the social organization of the interaction.</span></div></div><div class="paper" id="paper1692"><a href="#paper1692" class="title">Communication Technology for Human-Dog Interaction: Exploration of Dog Owners&#8217; Experiences and Expectations</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979329&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mikko  Paldanius</span> <span class="affiliation">Nokia Research Center</span>, <br />
<span class="author">Tuula  K&#228;rkk&#228;inen</span> <span class="affiliation">Tampere University of Technology</span>, <br />
<span class="author">Kaisa  V&#228;&#228;n&#228;nen-Vainio-Mattila</span> <span class="affiliation">Tampere University of Technology</span>, <br />
<span class="author">Oskar  Juhlin</span> <span class="affiliation">Mobile Life, Interactive Institute Stockholm</span>, <br />
<span class="author">Jonna  H&#228;kkil&#228;</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Whereas communication technology to connect people has long been an integral part of our everyday lives, it has only recently expanded to offer applications for dogs and dog-owners. In this paper, we present two explorative studies to understand the experiences and expectations of dog owners for communication technology to support their interaction with dogs. These studies look at two different user groups, hunters and pet owners, charting the lessons learnt from the current technology and exploring the aspects that should be taken into account when designing future applications and services. Our findings reveal that usability problems are still the dominant issue with current applications. We also suggest key design implications which can be utilized in the development of future human-dog interaction systems.</span></div></div><div class="paper" id="paper1234"><a href="#paper1234" class="title">Designing Sports: A Framework for Exertion Games</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979330&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Florian 'Floyd'  Mueller</span> <span class="affiliation">The University of Melbourne</span>, <br />
<span class="author">Darren  Edge</span> <span class="affiliation">Microsoft Research Asia</span>, <br />
<span class="author">Frank  Vetere</span> <span class="affiliation">The University of Melbourne</span>, <br />
<span class="author">Martin  Gibbs</span> <span class="affiliation">The University of Melbourne</span>, <br />
<span class="author">Stefan  Agamanolis</span> <span class="affiliation">Distance Lab</span>, <br />
<span class="author">Bert  Bongers</span> <span class="affiliation">University Technology Sydney</span>, <br />
<span class="author">Jennifer  Sheridan</span> <span class="affiliation">BigDog Interactive</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Exertion games require investing physical effort. The fact that such games can support physical health is tempered by our limited understanding of how to design for engaging exertion experiences. This paper introduces the Exertion Framework as a way to think and talk about Exertion Games, both for their formative design and summative analysis. Our Exertion Framework is based on the ways in which we can conceive of the body investing in game-directed exertion, supported by four perspectives on the body (the Responding Body, Moving Body, Sensing Body and Relating Body) and three perspectives on gaming (rules, play and context). The paper illustrates how this framework was derived from prior systems and theory, and presents a case study of how it has been used to inspire novel exertion interactions.</span></div></div><div class="paper" id="paper676"><a href="#paper676" class="title">Cat Cat Revolution: An Interspecies Gaming Experience</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979331&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Frank  Noz</span> <span class="affiliation">Carnegie Mellon University, University of Madeira</span>, <br />
<span class="author">Jinsoo  An</span> <span class="affiliation"></span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Despite owners&#8217; desires to include pets in their everyday activities, pets have yet to be included in the digital gaming experience. The Cat Cat Revolution (CCR) is a digital game of cat and mouse that allows cats to participate in play through a species-appropriate interface. The game applies Human-Computer Interaction (HCI) principles to pets and casts pets as participants in the gaming experience. During the pilot study, pet owners characterized CCR as a mutually positive experience, describing the game as a &#8220;fun&#8221; way to play. CCR explores the effects of including pets in the digital gaming experience.</span></div></div><div class="paper" id="paper2019"><a href="#paper2019" class="title">Antiquarian Answers: Book Restoration as a Resource for Design</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979332&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniela K. Rosner</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Alex S. Taylor</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As technologies age, they experience wear and degradation, sometimes resulting in loss of functionality. In response, parts are replaced and software is updated. Yet restoration&#8212;the process of returning something to a previous condition, often regardless of its instrumental value&#8212;is a relatively rare practice with computational technologies. The aim of this paper is to enrich HCI design practices by considering the material qualities of restoration. We consider what makes a technology worth restoring and what constitutes the process of restoration by examining data collected from a three-month apprenticeship-based qualitative study of bookbinding. Building on relevant literatures, we offer antiquarian books&#8212;long-established information technologies&#8212;as a lens onto the ways values are enacted through material engagements. We conclude with a discussion of restoration&#8217;s role in HCI.</span></div></div></td>
<td colspan="11" class="session_details" id="S1227_details"><div class="sessionChair"><strong>Session Chair: </strong>Volkmar Pipek (<em>University of Siegen</em>)</div><div class="paper" id="cs147"><a href="#cs147" class="title">Measuring the Effectiveness of Social Media on an Innovation Process</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979669&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lester  Holtzblatt</span> <span class="affiliation">MITRE Corporation</span>, <br />
<span class="author">Mary Lou  Tierney</span> <span class="affiliation">MITRE Corporation</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Incorporating social media into the Enterprise is a key opportunity as well as critical challenge facing many organizations today.  Tantamount in decision-making about social media implementation is the question of &#8216;value&#8217;.  Our research examines the deployment of an online innovation management platform to execute an annual research and development proposal competition over two cycles of usage.  Our findings suggest strategies for monitoring and measuring the effectiveness of social media&#8217;s impact to an existing innovation process within the context of a business strategy.</span></div></div><div class="paper" id="cs197"><a href="#cs197" class="title">HCI and innovation</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979670&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David M. Frohlich</span> <span class="affiliation">University of Surrey</span>, <br />
<span class="author">Risto  Sarvas</span> <span class="affiliation">Helsinki Institute for Information Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The user-centered design (UCD) process in HCI has recently been criticized for not delivering breakthrough innovations in technology. In this paper we consider this critique through a literature review and two case studies of innovation. Our conclusions suggest that there is nothing wrong with the attitude of user-centered design which has probably been present in all major innovations down the centuries. Rather, the practice of UCD in HCI lacks attention to business factors and long term uptake of technology in society. This compromises its impact on products and should be incorporated into the study of HCI itself.</span></div></div><div class="paper" id="cs201"><a href="#cs201" class="title">Leading Change with Collaborative Design Workshops</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979671&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jim  Nieters</span> <span class="affiliation">Yahoo! Inc. ACM</span>, <br />
<span class="author">Eric  Bollman</span> <span class="affiliation">Yahoo! Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Numerous companies have demonstrated that game- changing design can differentiate them competitively. FastCompany1 and BusinessWeek2 magazines show examples weekly. At the same time, as difficult as coming up with a new idea that differentiates a company&#8217;s product from those of its competitors can be, just coming up with the idea itself sometimes seems easy compared to the challenge of getting an organization to accept and act on it. Enabling User Experience Research and Design teams to deliver design solutions that change market dynamics often requires changes to culture and process. It also requires improving the political positioning of the User Experience organization. This case study highlights a method one UX team used to bring key stakeholders, including UX, Engineering, and Product Management, to the strategy table, and enable such strategic design. <br /> This UX team introduced collaborative design workshops to enable them to collaboratively generate great ideas and align their multidisciplinary product team around them. Such workshops enabled integrative thinking3 to enable teams to arrive at the optimal solution. They also fostered trust, promoted free expression, and quietly created a new strategy table, where UX led the discussion about product strategy, introducing design as a key differentiator. In this example, such workshops provided a venue for engaging a cross-functional team in brainstorming and creative ideation, filtering a large set of ideas, collaborating on design, rapidly gathering user feedback and iterating designs, and getting the consensus the team needed to drive innovative products to market.</span></div></div><div class="paper" id="paper1940"><a href="#paper1940" class="title">Prototyping Dynamics: Sharing Multiple Designs Improves Exploration, Group Rapport, and Results</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979359&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Steven  Dow</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Julie  Fortuna</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Dan  Schwartz</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Beth  Altringer</span> <span class="affiliation">Harvard University</span>, <br />
<span class="author">Daniel  Schwartz</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Scott  Klemmer</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Prototypes ground group communication and facilitate decision making. However, overly investing in a single design idea can lead to fixation and impede the collaborative process. Does sharing multiple designs improve collaboration? In a study, participants created advertisements individually and then met with a partner. In the Share Multiple condition, participants designed and shared three ads. In the Share Best condition, participants designed three ads and selected one to share. In the Share One condition, participants designed and shared one ad. Sharing multiple designs improved outcome, exploration, sharing, and group rapport. These participants integrated more of their partner's ideas into their own subsequent designs, explored a more divergent set of ideas, and provided more productive critiques of their partner's designs. Furthermore, their ads were rated more highly and garnered a higher click-through rate when hosted online.</span></div></div></td>
<td colspan="11" class="session_details" id="S1221_details"><div class="sessionChair"><strong>Session Chair: </strong>Lorrie Cranor (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper1960"><a href="#paper1960" class="title">Of Passwords and People: Measuring the Effect of Password-Composition Policies</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979321&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Saranga  Komanduri</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Richard  Shay</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Patrick Gage  Kelley</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michelle L. Mazurek</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Lujo  Bauer</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Nicolas  Christin</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Lorrie Faith Cranor</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Serge  Egelman</span> <span class="affiliation">National Institute of Standards and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Text-based passwords are the most common mechanism for authenticating humans to computer systems. To prevent users from picking passwords that are too easy for an adversary to guess, system administrators adopt password-composition policies (e.g., requiring passwords to contain symbols and numbers). Unfortunately, little is known about the relationship between password-composition policies and the strength of the resulting passwords, or about the behavior of users (e.g., writing down passwords) in response to different policies. We present a large-scale study that investigates password strength, user behavior, and user sentiment across four password-composition policies. We characterize the predictability of passwords by calculating their entropy, and find that a number of commonly held beliefs about password composition and strength are inaccurate. We correlate our results with user behavior and sentiment to produce several recommendations for password-composition policies that result in strong passwords without unduly burdening users.</span></div></div><div class="paper" id="paper1554"><a href="#paper1554" class="title">MARASIM: A Novel Jigsaw Based Authentication Scheme Using Tagging</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979322&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rohit Ashok Khot</span> <span class="affiliation">International Institute of Information Technology, Hyderabad</span>, <br />
<span class="author">Kannan  Srinathan</span> <span class="affiliation">International Institute of Information Technology, Hyderabad</span>, <br />
<span class="author">Ponnurangam  Kumaraguru</span> <span class="affiliation">Indraprastha Institute of Information Technology, Delhi</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we propose and evaluate Marasim, a novel Jigsaw based graphical authentication mechanism using tagging. Marasim is aimed at achieving the security of random images with the memorability of personal images. Our scheme relies on the human ability to remember a personal image and later recognize the alternate visual representations (images) of the concepts occurred in the image. These concepts are retrieved from the tags assigned to the image. We illustrate how a Jigsaw based approach helps to create a portfolio of system-chosen random images to be used for authentication. The paper describes the complete design of Marasim along with the empirical studies of Marasim that provide evidences of increased memorability. Results show that 93% of all participants succeeded in the authentication tests using Marasim after three months while 71% succeeded in authentication tests using Marasim after nine months. Our findings indicate that Marasim has potential applications, especially where text input is hard (e.g., PDAs or ATMs), or in situations where passwords are infrequently used (e.g., web site passwords).</span></div></div><div class="paper" id="paper1373"><a href="#paper1373" class="title">Exploring Implicit Memory for Painless Password Recovery</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979323&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tamara  Denning</span> <span class="affiliation">RSA Labs / University of Washington</span>, <br />
<span class="author">Kevin  Bowers</span> <span class="affiliation">RSA Labs</span>, <br />
<span class="author">Marten  van Dijk</span> <span class="affiliation">RSA Labs</span>, <br />
<span class="author">Ari  Juels</span> <span class="affiliation">RSA Labs</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Knowledge-based authentication systems generally rely upon users' explicit recollection of passwords, facts, or personal preferences. These systems impose a cognitive burden that often results in forgotten secrets or secrets with poor entropy. We propose an authentication system that instead draws on implicit memory--that is, the unconscious encoding and usage of information. In such a system, a user is initially presented with images of common objects in a casual familiarization task. When the user later authenticates, she is asked to perform a task involving a set of degraded images, some of which are based upon the images in the familiarization task. The prior exposure to those images influences the user's responses in the task, thereby eliciting authentication information. We ran a user study to investigate the plausibility of our system design. Our results suggest that implicit memory has potential as a basis for low-cognitive-overhead, high-stability, knowledge-based authentication.</span></div></div><div class="paper" id="paper2247"><a href="#paper2247" class="title">Understanding Self-reported Password Sharing Strategies</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979324&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joseph 'Jofish'  Kaye</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper contributes to the growing body of literature on privacy and security by looking at self-reported password sharing practices. 62 men and 60 women recruited through a combination of snowball sampling and small ads answered a series of open-ended questions about their password sharing strategies. One third of respondants shared their personal email password, and a quarter shared their Facebook pass- word, both primarily with partners and close friends. Ap- proximately 20 % of people who had work email passwords reported sharing them with colleagues. These results support understanding password sharing not as a deviant practice to be stamped out, but rather a nuanced practice engaged in with thought and care.</span></div></div><div class="paper" id="paper760"><a href="#paper760" class="title">On the Necessity of User-Friendly CAPTCHA</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979325&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christos A. Fidas</span> <span class="affiliation">University of Patras</span>, <br />
<span class="author">Artemios G. Voyiatzis</span> <span class="affiliation">Industrial Systems Institute</span>, <br />
<span class="author">Nikolaos M. Avouris</span> <span class="affiliation">University of Patras</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A "Completely Automated Public Turing test to tell Computers and Humans Apart" (CAPTCHA) is a mechanism widely used nowadays for protection of web applications, interfaces, and services from malicious users.  A questionnaire-based survey combined with a real usage scenario of a native-language CAPTCHA mechanism was conducted in order to investigate several aspects that affect end-user perceptions related to the quality of CAPTCHA. A total of 210 participants of age between 19 and 64 participated during May and July 2010. The survey results validate the common belief that CAPTCHAs are still difficult for humans to solve. They also provide insights that can be applied to improve users&#8217; experience on interacting with CAPTCHA systems.</span></div></div><div class="paper" id="paper561"><a href="#paper561" class="title">A Diary Study of Password Usage in Daily Life</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979326&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eiji  Hayashi</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Jason  Hong</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While past work has examined password usage on a specific computer, web site, or organization, there is little work examining overall password usage in daily life. Through a diary study, we examine all usage of passwords, and offer some new findings based on quantitative analyses regarding how often people log in, where they log in, and how frequently people use foreign computers. Our analysis also confirms or updates existing statistics about password usage patterns. We also discuss some implications for design as well as security education.</span></div></div></td>
<td colspan="11" class="session_details" id="S1225_details"><div class="sessionChair"><strong>Session Chair: </strong>Bonnie John (<em>Carnegie Mellon University</em>)</div><div class="paper" id="to110"><a href="#to110" class="title">A Model of Novice and Expert Navigation Performance in Constrained Input Interfaces</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Carl  Gutwin</span> <span class="affiliation">University of Saskatchewan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many interactive systems require users to navigate through large sets of data and commands using constrained input devices &#8211;- such as scroll rings, rocker switches, or specialised keypads &#8211;- that provide less power and flexibility than traditional input devices like mice or touch screens. While performance with more traditional devices has been extensively studied in human-computer interaction, there has been relatively little investigation of human performance with constrained input. As a result, there is little understanding of what factors govern performance in these situations, and how interfaces should be designed to optimize interface actions such as navigation and selection. Since constrained input is now common in a wide variety of interactive systems (such as mobile phones, audio players, in-car navigation systems, and kiosk displays), it is important for designers to understand what factors affect performance. To aid in this understanding, we present the Constrained Input Navigation (CIN) model, a predictive model that allows accurate determination of human navigation and selection performance in constrained-input scenarios. CIN identifies three factors that underlie <br /> user efficiency: the performance of the interface type for single-level item selection (where interface type depends on the input and output devices, the interactive behaviour, and the data organisation), the hierarchical structure of the information space, and the user&#8217;s experience with the items to be selected. We show through experiments that, after empirical calibration, the model&#8217;s predictions fit empirical data well, and discuss why and how each of the factors affects performance. Models like CIN can provide valuable theoretical and practical benefits to designers of constrained-input systems, allowing them to explore and compare a much wider variety of alternate interface designs without the need for extensive user studies.</span></div></div><div class="paper" id="paper377"><a href="#paper377" class="title">Dips and Ceilings: Understanding and Supporting Transitions to Expertise in User Interfaces</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979348&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joey  Scarr</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Carl  Gutwin</span> <span class="affiliation">University of Saskatchewan</span>, <br />
<span class="author">Philip  Quinn</span> <span class="affiliation">University of Canterbury</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Interface guidelines encourage designers to include shortcut mechanisms that enable high levels of expert performance, but prior research has demonstrated that few users switch to using them. To help understand how interfaces can better support a transition to expert performance we develop a framework of the interface and human factors influencing expertise development. We then present a system called Blur that addresses three main problems in promoting the transition: prompting an initial switch to expert techniques, minimising the performance dip arising from the switch, and enabling a high performance ceiling. Blur observes the user&#8217;s interaction with unaltered desktop applications and uses calm notification to support learning and promote awareness of an alternative hot command interface. An empirical study validates Blur&#8217;s design, demonstrating that users make an early and sustained switch to hot commands, and that doing so improves their performance and satisfaction.</span></div></div><div class="paper" id="paper2056"><a href="#paper2056" class="title">Ambient Help</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979349&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Justin  Matejka</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">Tovi  Grossman</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">George  Fitzmaurice</span> <span class="affiliation">Autodesk Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present Ambient Help, a system that supports opportunistic learning by providing automatic, context-sensitive learning resources while a user works. Multiple videos and textual help resources are presented ambiently on a secondary display. We define and examine a collection of design consideration for this type of interface. After describing our implementation details, we report on an experiment which shows that Ambient Help supports finding more helpful information, while not having a negative impact on the user&#8217;s productivity, as compared to a traditional help condition.</span></div></div><div class="paper" id="paper304"><a href="#paper304" class="title">Parameter Selection in Keyboard-Based Dialog Boxes</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979350&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jeff C. Hendy</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Juliette  Link</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Kellogg S. Booth</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Joanna  McGrenere</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent keyboard-based alternatives to WIMP interfaces do not have good support for commands that require multiple parameters. We remedy this by extending a previous design and mimicking dialog boxes to provide good visual feedback while still keeping the advantages of keyboard input. A laboratory study showed the new technique to be competitive with dialog boxes on speed and error rate, but strongly preferred over dialog boxes by experienced command line users. This is a marked improvement over the previous design, which was also preferred by the target user group but did not compete with dialog boxes in terms of performance.</span></div></div><div class="paper" id="paper1265"><a href="#paper1265" class="title">Categorization Costs for Hierarchical Keyboard Commands</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979351&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Craig S. Miller</span> <span class="affiliation">DePaul University</span>, <br />
<span class="author">Svetlin  Denkov</span> <span class="affiliation">DePaul University</span>, <br />
<span class="author">Richard C. Omanson</span> <span class="affiliation">User Centric</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; "><br />begin{abstract} <br />  <br />   Previous research comparing methods of issuing commands found that <br />   selecting a toolbar item is faster than selecting an item from two <br />   menus with either a mouse or keyboard shortcut. Over the course of <br />   90 trials, however, the keyboard method showed the most improvement, <br />   nearing the toolbar response time. The study presented in this paper <br />   compared the response time of the keyboard method across 240 trials <br />   when items were drawn from a single versus two menus. Throughout the <br />   trials, the 1-menu condition produced selection times that were on <br />   average 600 ms to 800 ms faster than the 2-menu condition suggesting <br />   users in the 2-menu condition were not able to bypass the menu <br />   decision by chunking the 3-key sequence into one cognitive <br />   unit. Models are presented to describe performance at <br />   various stages of learning. Practical implications are that <br />   hierarchical, category-based keyboard commands do not provide a <br />   clear advantage to toolbar-based selection and that theory-based <br />   evaluation methods may need to reflect this result. <br />  <br /> <br />end{abstract} <br /></span></div></div></td>
<td colspan="11" class="session_details" id="S1226_details"><div class="sessionChair"><strong>Session Chair: </strong>Jeffrey Bigham (<em>University of Rochester</em>)</div><div class="paper" id="paper945"><a href="#paper945" class="title">Sasayaki: Augmented Voice Web Browsing Experience</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979353&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daisuke  Sato</span> <span class="affiliation">IBM Research Tokyo</span>, <br />
<span class="author">Shaojian  Zhu</span> <span class="affiliation">UMBC</span>, <br />
<span class="author">Masatomo  Kobayashi</span> <span class="affiliation">IBM Research Tokyo</span>, <br />
<span class="author">Hironobu  Takagi</span> <span class="affiliation">IBM Research Tokyo</span>, <br />
<span class="author">Chieko  Asakawa</span> <span class="affiliation">IBM Research Tokyo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Auditory user interfaces have great Web-access potential for billions of people with visual impairments, with limited literacy, who are driving, or who are otherwise unable to use a visual interface. However a sequential speech-based representation can only convey a limited amount of information. In addition, typical auditory user interfaces lose the visual cues such as text styles and page structures, and lack effective feedback about the current focus. To address these limitations, we created Sasayaki (from &#8216;whisper&#8217; in Japanese), which augments the primary voice output with a secondary whisper of contextually relevant information, automatically or in response to user requests. It also offers new ways to jump to semantically meaningful locations. A prototype was implemented as a plug-in for an auditory Web browser. Our experimental results show that the Sasayaki can reduce the task completion times for finding elements in webpages and increase satisfaction and confidence.</span></div></div><div class="paper" id="paper1491"><a href="#paper1491" class="title">On the audio representation of radial direction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979354&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Susumu  Harada</span> <span class="affiliation">IBM Research - Tokyo</span>, <br />
<span class="author">Hironobu  Takagi</span> <span class="affiliation">IBM Research - Tokyo</span>, <br />
<span class="author">Chieko  Asakawa</span> <span class="affiliation">IBM Research - Tokyo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present and evaluate an approach towards eyes-free auditory display of spatial information that considers radial direction as a fundamental type of value primitive. There are many benefits to being able to sonify radial directions, such as indicating the heading towards a point of interest in a direct and dynamic manner, rendering a path or shape outline by sonifying a continual sequence of tangent directions as the path is traced, and providing direct feedback of the direction of motion of the user in a physical space or a pointer in a virtual space. We propose a concrete mapping of vowel-like sounds to radial directions as one potential method to enable sonification of such information. We conducted a longitudinal study with five sighted and two blind participants to evaluate the learnability and effectiveness of this method. Results suggest that our directional sound mapping can be learned within a few hours and be used to aurally perceive spatial information such as shape outlines and path contours.</span></div></div><div class="paper" id="paper2007"><a href="#paper2007" class="title">Multidimensional Gesture Sensing at the Piano Keyboard</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979355&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew P McPherson</span> <span class="affiliation">Drexel University</span>, <br />
<span class="author">Youngmoo E Kim</span> <span class="affiliation">Drexel University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present a new keyboard interface for computer music applications. Where traditional keyboard controllers report the velocity of each key-press, our interface senses up to five separate dimensions: velocity, percussiveness, rigidity, weight, and depth. These dimensions, which we identified based on the pedagogical piano literature and pilot studies with professional pianists, together present a rich picture of physical gestures at the keyboard, including information on the performer&#8217;s motion before, during, and after a note is played. User studies confirm that the sensed dimensions are intuitive and controllable and that mappings between gesture and sound produce novel, playable musical instruments, even for users without prior keyboard experience. The multidimensional sensing capability demonstrated in this paper is also potentially applicable to button interfaces outside the musical domain.</span></div></div><div class="paper" id="paper887"><a href="#paper887" class="title">Spatialized Sound Enhances Biomechanically-Induced Self-Motion Illusion (Vection)</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979356&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Bernhard E.  Riecke</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Daniel  Feuereissen</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">John J.  Rieser</span> <span class="affiliation">Vanderbilt University</span>, <br />
<span class="author">Timothy P.  McNamara</span> <span class="affiliation">Vanderbilt University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The use of vection, the illusion of self-movement, has recently been explored as a novel way to immerse observers in mediated environments through illusory yet compelling self-motion without physically moving. This provides advantages over existing systems that employ costly, cumbersome, and potentially hazardous motion platforms, which are often surprisingly inadequate to provide life-like motion experiences. This study investigates whether spatialized sound rotating around the stationary, blindfolded listener can facilitate biomechanical vection, the illusion of self-rotation induced by stepping along a rotating floor plate. For the first time, integrating simple auditory and biomechanical cues for turning in place evoked convincing circular vection. In an auditory baseline condition, participants experienced only spatialized auditory cues. In a purely biomechanical condition, seated participants stepped along sideways on a rotating plate while listening to mono masking sounds. Scores of the bi-modal condition (binaural+biomechanical cues) exceeded the sum of both single cue conditions, which may imply super-additive or synergistic effects.</span></div></div><div class="paper" id="paper1431"><a href="#paper1431" class="title">Name That Tune: Musicons as Reminders in the Home</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979357&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marilyn  McGee-Lennon</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Maria  Wolters</span> <span class="affiliation">University of Edinburgh</span>, <br />
<span class="author">Ross  McLachlan</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Cordelia  Hall</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we argue that Musicons, short samples from pieces of music are a useful way to present private but memorable reminder messages. We investigated accuracy, memo&#172;rability and response times for short, medium, and long Musicons. User performance on the Musicons was also compared to short spoken reminders. The study consisted of two sessions a week apart. Quantitative measures were augmented with qualitative questions about associations and memories. Overall, participants achieved a high level of accuracy (89%) on the Musicons. Recognition was stable at 90% or better across sessions for users who were able to construct meaningful links between Musicons and the associated tasks. Optimal response times were achieved for medium-length 0.5 sec. Musicons. We conclude that Musicons are a viable option for alarms and notifications that combine the high learnability of Auditory Icons with the more private nature of Earcons.</span></div></div></td>
<td colspan="11" class="session_details" id="S1220_details"><div class="sessionChair"><strong>Session Chair: </strong>Chris Harrison (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper1572"><a href="#paper1572" class="title">Some Like it Hot? Thermal Feedback for Mobile Devices</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979316&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Graham  Wilson</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Martin  Halvey</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen A Brewster</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen A Hughes</span> <span class="affiliation">SAMH Engineering</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Thermal stimulation is a rich, emotive and salient feedback channel that is well suited to HCI, but one that is yet to be fully investigated. Thermal feedback may be suited to environments that are too loud for audio or too bumpy for vibrotactile feedback. This paper presents two studies into how well users could detect hot and cold stimuli presented to the fingertips, the palm, the dorsal surface of the forearm and the dorsal surface of the upper arm. Evaluations were carried out in static and mobile settings. Results showed that the palm is most sensitive, cold is more perceivable and comfortable than warm and that stronger and faster-changing stimuli are more detectable but less comfortable. Guidelines for the design of thermal feedback are outlined, with attention paid to perceptual and hedonic factors.</span></div></div><div class="paper" id="paper1210"><a href="#paper1210" class="title">HeatWave: Thermal Imaging for Surface User Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979317&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eric  Larson</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Gabe  Cohn</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Sidhant  Gupta</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Xiaofeng  Ren</span> <span class="affiliation">Intel Labs Seattle</span>, <br />
<span class="author">Beverly  Harrison</span> <span class="affiliation">Intel Labs Seattle</span>, <br />
<span class="author">Dieter  Fox</span> <span class="affiliation">Intel Labs Seattle</span>, <br />
<span class="author">Shwetak  Patel</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present HeatWave, a system that uses digital thermal imaging cameras to detect, track, and support user interaction on arbitrary surfaces. Thermal sensing has had limited examination in the HCI research community and is generally under-explored outside of law enforcement and energy auditing applications. We examine the role of thermal imaging as a new sensing solution for enhancing user surface interaction. In particular, we demonstrate how thermal imaging in combination with existing computer vision techniques can make segmentation and detection of routine interaction techniques possible in real-time, and can be used to complement or simplify algorithms for traditional RGB and depth cameras. Example interactions include (1) distinguishing hovering above a surface from touch events, (2) shape-based gestures similar to ink strokes, (3) pressure based gestures, and (4) multi-finger gestures. We close by discussing the practicality of thermal sensing for naturalistic user interaction and opportunities for future work.</span></div></div><div class="paper" id="paper1499"><a href="#paper1499" class="title">AnglePose: robust, precise capacitive touch tracking via 3D orientation estimation</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979318&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Simon  Rogers</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">John  Williamson</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Craig  Stewart</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Roderick  Murray-Smith</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a finger-tracking system for touch-based interaction <br /> which can track 3D finger angle in addition to position, <br /> using low-resolution conventional capacitive sensors, <br /> therefore compensating for the inaccuracy due to pose variation <br /> in conventional touch systems. Probabilistic inference <br /> about the pose of the finger is carried out in real-time using <br /> a particle filter; this results in an efficient and robust pose estimator <br /> which also gives appropriate uncertainty estimates. <br /> We show empirically that tracking the full pose of the finger <br /> results in greater accuracy in pointing tasks with small targets <br /> than competitive techniques. Our model can detect and <br /> cope with different finger sizes and the use of either fingers <br /> or thumbs, bringing a significant potential for improvement <br /> in one-handed interaction with touch devices. In addition <br /> to the gain in accuracy we also give examples of how this <br /> technique could open up the space of novel interactions.</span></div></div><div class="paper" id="paper2275"><a href="#paper2275" class="title">TouchCuts and TouchZoom: Enhanced Target Selection for Touch Displays using Finger Proximity Sensing</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979319&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Xing-Dong  Yang</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Tovi  Grossman</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">Pourang  Irani</span> <span class="affiliation">University of Manitoba</span>, <br />
<span class="author">George  Fitzmaurice</span> <span class="affiliation">Autodesk Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although touch-screen laptops are increasing in popularity, users still do not comfortably rely on touch in these environments, as current software interfaces were not designed for being used by the finger. In this paper, we first demonstrate the benefits of using touch as a complementary input modality along with the keyboard and mouse or touchpad in a laptop setting. To alleviate the frustration users experience with touch, we then design two techniques, TouchCuts, a single target expansion technique, and TouchZoom, a multiple target expansion technique. Both techniques facilitate the selection of small icons, by detecting the finger proximity above the display surface, and expanding the target as the finger approaches. In a controlled evaluation, we show that our techniques improve performance in comparison to both the computer mouse and a baseline touch-based target acquisition technique. We conclude by discussing other application scenarios that our techniques support.</span></div></div></td>
<td colspan="11" class="session_details" id="S1223_details"><div class="sessionChair"><strong>Session Chair: </strong>Jettie Hoonhout (<em>Philips Research</em>)</div><div class="paper" id="paper610"><a href="#paper610" class="title">Which Version is This?: Improving the Desktop Experience within a Copy-Aware Computing Ecosystem</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979334&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amy K. Karlson</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Greg  Smith</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Bongshin  Lee</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computers today make it easy for people to scatter copies and versions of digital items across their file systems, but do little to help people manage the resulting mess. In this paper, we introduce the concept of a copy-aware computing ecosystem, inspired by a vision of computing when systems track and surface copy relationships between files. Based on two deployments of a copy-aware software prototype and in-depth interviews with individuals in collaborative relationships, we present our findings on the origins of copies and the barriers to eliminating them, but offer a promising solution based on the set of files that together represent a user&#8217;s conceptual view of a document - the versionset. We show that the versionset is viable to infer, and we draw upon user activity logs and feedback on personalized views of versionsets to distill guidelines for the factors that define a versionset. We conclude by enumerating the many PIM user experiences that could be transformed as a result.</span></div></div><div class="paper" id="paper997"><a href="#paper997" class="title">Enticing Consumers via Incomplete Product Experience: An Investigation of Online Product Interactivity Designs</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979335&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cheng  Yi</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Zhenhui  Jiang</span> <span class="affiliation">National University of Singapore</span>, <br />
<span class="author">Izak  Benbasat</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports on two studies that investigate the design of online product interactivity. The first study compares three different presentation formats: a video presentation and two Virtual Product Experience (VPE) presentations, namely, triggered interaction and full interaction. The findings suggest that triggered interaction VPE is more effective in enticing users to attend to and further explore the featured products than both the non-interactive video presentation and the full interaction VPE. The second study builds upon the first and focuses on two specific VPE design factors. In particular, it investigates interaction constraint (high versus low constraint) in addition to the activation mode of interaction (process-based interaction versus event-based interaction). The results reveal interesting interaction patterns between the two design factors, i.e., providing less constrained interaction performs better when process-based interaction design is adopted, but performs worse when event-based interaction is employed.</span></div></div><div class="paper" id="paper949"><a href="#paper949" class="title">Old Wine in New Bottles or Novel Challenges? A Critical Analysis of Empirical Studies of User Experience</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979336&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Javier A. Bargas-Avila</span> <span class="affiliation">University of Basel</span>, <br />
<span class="author">Kasper  Hornb&#230;k</span> <span class="affiliation">University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reviews how empirical research on User Experience (UX) is conducted. It integrates products, dimensions of experience, and methodologies across a systematically selected sample of 51 publications from 2005-2009, reporting a total of 66 empirical studies. Results show a shift in the products and use contexts that are studied, from work towards leisure, from controlled tasks towards open use situations, and from desktop computing towards consumer products and art. Context of use and anticipated use, often named key factors of UX, are rarely researched. Emotions, enjoyment and aesthetics are the most frequently assessed dimensions. The methodologies used are mostly qualitative, and known from traditional usability studies, though constructive methods with unclear validity are being developed and used. Many studies use self-developed questionnaires without providing items or statistical validations. We discuss underexplored research questions and potential improvements of UX research.</span></div></div><div class="paper" id="paper591"><a href="#paper591" class="title">Perceptual Analysis of Talking Avatar Head Movements: A Quantitative Perspective</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979337&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Xiaohan  Ma</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Binh Huy Le</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Zhigang  Deng</span> <span class="affiliation">University of Houston</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Lifelike interface agents (e.g. talking avatars) have been increasingly used in human-computer interaction applications. In this work, we quantitatively analyze how human perception is affected by audio-head motion characteristics of talking avatars. Specifically, we quantify the correlation between perceptual user ratings (obtained via user study) and joint audio-head motion features as well as head motion patterns in the frequency-domain. Our quantitative analysis results clearly show that the correlation coefficient between the pitch of speech signals (but not the RMS energy of speech signals) and head motions is approximately linearly proportional to the perceptual user rating, and a larger proportion of high frequency signals in talking avatar head movements tends to degrade the user perception in terms of naturalness.</span></div></div><div class="paper" id="paper1870"><a href="#paper1870" class="title">Diminishing Returns?  Revisiting Perception of Computing Performance</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979338&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Glen  Anderson</span> <span class="affiliation">Intel Corporation</span>, <br />
<span class="author">Rina  Doherty</span> <span class="affiliation">Intel Corporation</span>, <br />
<span class="author">Eric  Baugh</span> <span class="affiliation">Intel Corporation</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The computing performance literature offers guidelines and frameworks, but data on the limits of user appreciation for performance are scarce.  This paper presents a study of user satisfaction with different levels of computing performance.  Thirty-five participants performed common computing tasks such as creating email and Web surfing.  They rated computing performance for specific task elements - such as application launching and menu responsiveness - that occurred during those tasks.  They repeated the tasks under varying levels of computer performance.  Results include user ratings as a function of computing performance for each of the task elements.  The results have implications for system designers who create products that must meet user expectations for performance.</span></div></div></td>
<td colspan="11" class="session_details" id="S1214_details"><div class="paper" id="pl124"><a href="#pl124" class="title">The Future of  Child-Computer Interaction</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979495&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Allison  Druin</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Gary  Knell</span> <span class="affiliation">Sesame Workshop</span>, <br />
<span class="author">Elliot  Soloway</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Daniel  Russell</span> <span class="affiliation">Google</span>, <br />
<span class="author">Elizabeth  Mynatt</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Yvonne  Rogers</span> <span class="affiliation">Open University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this panel, academic, non-profit, and industry professionals will ask, what does the future hold for &#8220;child-computer interaction?&#8221;  Panelists will explore such issues as how new mobile, social, and ubiquitous technologies change children&#8217;s future patterns of searching, exploration, and expression of information; how learning environments will be ever-changing because of new technologies; and the challenges and opportunities of designing for child-computer interaction.</span></div></div></td>
<td colspan="11" class="session_details" id="S1224_details"><div class="sessionChair"><strong>Session Chair: </strong>Catalina Danis (<em>IBM Research</em>)</div><div class="paper" id="paper1353"><a href="#paper1353" class="title">ShadowPuppets: Supporting Collocated Interaction with Mobile Projector Phones Using Hand Shadows</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979340&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lisa G Cowan</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">Kevin A Li</span> <span class="affiliation">AT&amp;T Labs Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pico projectors attached to mobile phones allow users to view phone content using a large display. However, to provide input to projector phones, users have to look at the device, diverting their attention from the projected image. Additionally, other collocated users have no way of interacting with the device.  <br />  <br /> We present ShadowPuppets, a system that supports collocated interaction with mobile projector phones. Shadow-Puppets allows users to cast hand shadows as input to mo-bile projector phones. Most people understand how to cast hand shadows, which provide an easy input modality. Additionally, they implicitly support collocated usage, as nearby users can cast shadows as input and one user can see and understand another user&#8217;s hand shadows.  <br />  <br /> We describe the results of three user studies. The first study examines what hand shadows users expect will cause various effects. The second study looks at how users perceive hand shadows, examining what effects they think various hand shadows will cause. Finally, we present qualitative results from a study with our functional prototype and discuss design implications for systems using shadows as input. Our findings suggest that shadow input can provide a natural and intuitive way of interacting with projected interfaces and can support collocated collaboration. <br /></span></div></div><div class="paper" id="paper1294"><a href="#paper1294" class="title">DoubleFlip: A Motion Gesture Delimiter for Mobile Interaction</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979341&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jaime  Ruiz</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Yang  Li</span> <span class="affiliation">Google Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">To make motion gestures more widely adopted on mobile devices it is important that devices be able to distinguish between motion intended for mobile interaction and every-day motion. In this paper, we present DoubleFlip, a unique motion gesture designed as an input delimiter for mobile motion-based interaction. The DoubleFlip gesture is distinct from regular motion of a mobile device. Based on a collec-tion of 2,100 hours of motion data captured from 99 users, we found that our DoubleFlip recognizer is extremely resis-tant to false positive conditions, while still achieving a high recognition rate. Since DoubleFlip is easy to perform and unlikely to be accidentally invoked, it provides an always-active input event for mobile interaction.</span></div></div><div class="paper" id="paper1078"><a href="#paper1078" class="title">Multi-User Interaction on Media Facades through Live Video on Mobile Devices</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979342&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sebastian  Boring</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Sven  Gehring</span> <span class="affiliation">DFKI</span>, <br />
<span class="author">Alexander  Wiethoff</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Anna Magdalena  Bl&#246;ckner</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Johannes  Sch&#246;ning</span> <span class="affiliation">DFKI</span>, <br />
<span class="author">Andreas  Butz</span> <span class="affiliation">University of Munich</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The increasing number of media facades in urban spaces offers great potential for new forms of interaction &#8211; especially for collaborative multi-user scenarios. In this paper, we present a way to directly interact with them through live video on mobile devices. We extend the Touch Projector interface to accommodate multiple users by showing individual content on the mobile display that would otherwise clutter the facade's canvas or distract other users. To demonstrate our concept, we built two collaborative multi-user applications: (1) painting on the facade and (2) solving a 15-puzzle. We gathered informal feedback during the ARS Electronica Festival in Linz, Austria and found that our interaction technique is (1) considered easy-to-learn, but (2) may leave users unaware of the actions of others.</span></div></div><div class="paper" id="paper873"><a href="#paper873" class="title">Interaction with Magic Lenses: Real-World Validation of a Fitts' Law Model</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979343&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Michael  Rohs</span> <span class="affiliation">LMU Munich</span>, <br />
<span class="author">Antti  Oulasvirta</span> <span class="affiliation">Helsinki Institute for Information Technology HIIT</span>, <br />
<span class="author">Tiia  Suomalainen</span> <span class="affiliation">Helsinki Institute for Information Technology HIIT</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Rohs and Oulasvirta (2008) proposed a two-component Fitts&#8217; law model for target acquisition with magic lenses in mobile augmented reality (AR) with 1) a physical pointing phase, in which the target can be directly observed on the background surface, and 2) a virtual pointing phase, in which the target can only be observed through the device display. The model provides a good fit (R^2=0.88) with laboratory data, but it is not known if it generalizes to real-world AR tasks. In the present outdoor study, subjects (N=12) did building-selection tasks in an urban area. The differences in task characteristics to the laboratory study are drastic: targets are three-dimensional and they vary in shape, size, z-distance, and visual context. Nevertheless, the model yielded an R^2 of 0.80, and when using effective target width an R^2 of 0.88 was achieved.</span></div></div><div class="paper" id="paper753"><a href="#paper753" class="title">Xpaaand: Interaction Techniques for Rollable Displays</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979344&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mohammadreza  Khalilbeigi</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Roman  Lissermann</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Max  M&#252;hlh&#228;user</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">J&#252;rgen  Steimle</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a device concept and a prototype of a future mobile device. By featuring a rollable display, its display size and its form factor can be dynamically changed. Moreover, we investigate how physical resizing of the display can be used as an input technique for interacting with digital contents and present a set of novel interaction techniques. Evaluation results show that physical resizing of the display can improve the way we interact with digital contents on mobile devices.</span></div></div><div class="paper" id="paper283"><a href="#paper283" class="title">TapBack: Towards Richer Mobile Interfaces in Impoverished Contexts</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979345&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Simon  Robinson</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Nitendra  Rajput</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Matt  Jones</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Anupam  Jain</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Shrey  Sahay</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Amit  Nanavati</span> <span class="affiliation">IBM Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Much of the mobile work by HCI researchers explores a future world populated by high-end devices and relatively affluent users. This paper turns to consider the hundreds of millions of people for whom such sophistication will not be realised for many years to come. In developing world contexts, people will continue to rely on voice-primary interactions due to both literacy and economic reasons. Here, we motivate research into how to accommodate advanced mobile interface techniques while overcoming the handset, data-connection and user limitations. As a first step we introduce TapBack: back-of-device taps to control a dialled-up, telephone-network-based voice service. We show how these audio gestures might be recognised over a standard telephone connection, via users' existing low-end devices. Further, in a longitudinal deployment, the techniques were made available on a live voice service used by rural Indian farmers. Data from the study illustrates the desire by users to adopt the approach and its potential extensions.</span></div></div><div class="paper" id="paper317"><a href="#paper317" class="title">"ClearPlate" for Capturing Printed Information: A Scanner and Viewfinder in One Optical Unit</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979346&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Atsuhiko  Maeda</span> <span class="affiliation">NTT Cyber Solutions Laboratories, NTT Corporation</span>, <br />
<span class="author">Kenji  Hara</span> <span class="affiliation">NTT Communications Corporation</span>, <br />
<span class="author">Minoru  Kobayashi</span> <span class="affiliation">NTT Cyber Solutions Laboratories, NTT Corporation</span>, <br />
<span class="author">Masanobu  Abe</span> <span class="affiliation">Okayama University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As it is becoming more common for various handheld devices to be equipped with a camera, applications that use image recognition are increasing. Therefore, improving the usability of these devices by enhancing their image capture characteristics is becoming more important. We present ClearPlate &#8211; a new optical unit for image capture. It has a physically transparent viewfinder through which the user can observe the target directly without offset; the framed image is captured by the built-in camera. We also present a user study that evaluates ClearPlate performance in the 2D barcode acquisition task. Results show that ClearPlate significantly outperforms the camera-phone-based approach with regard to 2D barcode acquisition.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">18:00<br />-<br />20:00</td>

<td class="session tbd" id="S1228">
<div class="session_box">
<span class="type"></span>
<a href="#S1228" class="title">Hospitality Events</a>
<span class="location"></span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
</table>
</div>

<div class="day" id="day6"><h1>Thursday, May 12, 2011</h1><table cellspacing="0" class="program" id="day_6">
<tr class="timeslot">
<td class="time">08:15<br />-<br />8:45</td>

<td class="session tbd" id="S1230">
<div class="session_box">
<span class="type"></span>
<a href="#S1230" class="title">Madness</a>
<span class="location">Ballroom A/B</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">08:00<br />-<br />16:00</td>

<td class="session tbd" id="S1229">
<div class="session_box">
<span class="type"></span>
<a href="#S1229" class="title">Registration Open</a>
<span class="location">Ballroom Foyer</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"></tr>
<tr class="timeslot">
<td class="time">09:00<br />-<br />10:00</td>

<td class="session " id="S1232">
<div class="session_box">
<span class="type">Special Events</span>
<a href="#S1232" class="title">SIGCHI Social Impact Award</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1237">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1237" class="title">Games and HCI: Perspectives on Intersections and Opportunities</a>
<span class="location">119/120</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1231">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1231" class="title">Using Eye Tracking for Interaction</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1241">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1241" class="title">Social Q &amp; A</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1246">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1246" class="title">Organizations &amp; Distributed Work</a>
<span class="location">223/224</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1240">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1240" class="title">Tabletop Synchronous Collaboration</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1244">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1244" class="title">Empowering Users in Developing Regions</a>
<span class="location">217/218/219</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S5006">
<div class="session_box">
<span class="type">Student Design Competition &amp; Works In Progress</span>
<a href="#S5006" class="title">Poster Group 2 Displayed</a>
<span class="location">Ballroom Foyer</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1245">
<div class="session_box">
<span class="type">Special Events</span>
<a href="#S1245" class="title">SIGCHI Social Impact Award</a>
<span class="location">220/221/222</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1239">
<div class="session_box">
<span class="type"></span>
<a href="#S1239" class="title">reserved</a>
<span class="location">205/206/207</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1242">
<div class="session_box">
<span class="type">alt.chi</span>
<a href="#S1242" class="title">alt.chi: Is there a Designer in the house?</a>
<span class="location">212/213/214</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1233">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1233" class="title">Increasing Legal Requirements for Interface Accessibility</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1243">
<div class="session_box">
<span class="type"></span>
<a href="#S1243" class="title">Open</a>
<span class="location">215/216</span>
<strong>Details : TBA</strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="13" class="session_details" id="S1232_details"><div class="paper" id="sp106"><a href="#sp106" class="title">Social Impact Award: Older people  -  a commercial imperative</a>&nbsp;-&nbsp;<span class="type">Special Events</span><div class="authors"><span class="author">Alan  Newell</span> <span class="affiliation">Dundee University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">25 years ago, at CHI &#8217;86, Ben Shneiderman said that &#8220;We should be aware of subtle design decisions that make use more difficult for people with physical and mental disabilities, and for individuals from different cultures &#8230;. and not create a situation where the disadvantaged become more disadvantaged&#8221;.  20 years ago, at InterChi &#8217;91, in an attempt to raise the issue of design for older and disabled people, I suggested the concept of  &#8220;Ordinary and Extra-ordinary HCI&#8221; .   With a mild sense of d&#233;j&#224;-vue, this lecture will address the challenges of devising HCI for older and disabled people in 2011, the rewards and benefits of this work, and the extent to which the CHI community addresses, and should further address, these needs.</span></div></div></td>
<td colspan="13" class="session_details" id="S1237_details"><div class="paper" id="pl120"><a href="#pl120" class="title">Games and HCI: Perspectives on Intersections and Opportunities</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979487&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Regina  Bernhaupt</span> <span class="affiliation">IRIT</span>, <br />
<span class="author">Katherine  Isbister</span> <span class="affiliation">NYU-Poly</span>, <br />
<span class="author">John  Buchanan</span> <span class="affiliation">Relic Entertainment</span>, <br />
<span class="author">Dan  Cook</span> <span class="affiliation">Spry Fox</span>, <br />
<span class="author">Dave  Warfield</span> <span class="affiliation">Vancouver Film School</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">What can HCI practitioners learn from what game designers do? How have games influenced technology interfaces and experiences in the past, and how might this unfold in the future? Is the recent trend toward 'gamification' of everyday computer-supported activities a fruitful approach? This panel will tackle these and other related questions about how games and HCI connect. The panel is an invited event of the newly established Games and Entertainment Community.</span></div></div></td>
<td colspan="13" class="session_details" id="S1231_details"><div class="paper" id="si109"><a href="#si109" class="title">Using Eye Tracking for Interaction</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979541&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anneli  Olsen</span> <span class="affiliation">Tobii Technology AB</span>, <br />
<span class="author">Albrecht  Schmidt</span> <span class="affiliation">University Duisburg-Essen</span>, <br />
<span class="author">Paul  Marshall</span> <span class="affiliation">University of Warwick</span>, <br />
<span class="author">Veronica  Sundstedt</span> <span class="affiliation">Blekinge Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The development of cheaper eye trackers and open source software for eye tracking and gaze interaction brings the possibility to integrate eye tracking into everyday use devices as well as highly specialized equipment. Apart from providing means for analyzing eye movements, eye tracking also offers the possibility of a natural user interaction modality. Gaze control interfaces are already used within assistive applications for disabled users. However, this novel user interaction possibility comes with its own set of limitations and challenges. <br /> The aim of this SIG is to provide a forum for Designers, Researchers and Usability Professionals to discuss the role of eye tracking as a user interaction method in the future as well as the technical and user interaction challenges that using eye tracking as an interaction method brings.  <br /></span></div></div></td>
<td colspan="13" class="session_details" id="S1241_details"><div class="sessionChair"><strong>Session Chair: </strong>Scott Counts (<em>Microsoft Research</em>)</div><div class="paper" id="paper1827"><a href="#paper1827" class="title">Effects of Community Size and Contact Rate in Synchronous Social Q&amp;A</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979364&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ryen W. White</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Matthew  Richardson</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Yandong  Liu</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social question-and-answer (Q&amp;A) involves the location of answers to questions through communication with people. Social Q&amp;A systems, such as mailing lists and Web forums are popular, but their asynchronous nature can lead to high answer latency. Synchronous Q&amp;A systems facilitate real-time dialog, usually via instant messaging, but face challenges with interruption costs and the availability of knowledgeable answerers at question time. We ran a longitudinal study of a synchronous social Q&amp;A system to investigate the effects of the rate with which potential answerers were contacted (trading off time-to-answer against interruption cost) and community size (varying total number of mem-bers). We found important differences in subjective and objective measures of system performance with these variations. Our findings help us understand the costs and benefits of varying contact rate and community size in synchronous social Q&amp;A, and inform system design for social Q&amp;A.</span></div></div><div class="paper" id="paper749"><a href="#paper749" class="title">Redesign as an Act of Violence: Disrupted Interaction Patterns and the Fragmenting of a Social Q&amp;A Community</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979365&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rich  Gazan</span> <span class="affiliation">University of Hawaii</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The worst-case scenario for the redesign of an established online community is a subsequent mass migration of its core members to other sites.  Using data from transaction logs, content analysis and participant observation, this paper presents a descriptive analysis of the fragmentation of a social question answering (Q&amp;A) community in the immediate aftermath of a fundamental redesign, where site-based communication mechanisms no longer functioned.  The ways in which the community and its diaspora reacted, reconnected and resettled on other sites provides empirical data to support recent research on the life cycle of online communities.  The results suggest that many of the same processes that help social Q&amp;A sites generate content and motivate participation can work to dismantle an established community if communications between members are even temporarily disrupted.  Modeling a redesign as an attack on a community can help future designers anticipate alternative paths of communication and information flows.</span></div></div><div class="paper" id="paper1301"><a href="#paper1301" class="title">Design Lessons from the Fastest Q&amp;A Site in the West</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979366&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lena  Mamykina</span> <span class="affiliation">Columbia University</span>, <br />
<span class="author">Bella  Manoim</span> <span class="affiliation">Bard College</span>, <br />
<span class="author">Manas  Mittal</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">George  Hripcsak</span> <span class="affiliation">Columbia University</span>, <br />
<span class="author">Bj&#246;rn  Hartmann</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper analyzes a Question &amp; Answer site for programmers, Stack Overflow, that dramatically improves on the utility and performance of Q&amp;A systems for technical domains. Over 92% of Stack Overflow questions about expert topics are answered &#8212; in a median time of 11 minutes. Using a mixed methods approach that combines statistical data analysis with user interviews, we seek to understand this success. We argue that it is not primarily due to an a priori superior technical design, but also to the high visibility and daily involvement of the design team within the community they serve. This model of continued community leadership presents challenges to both CSCW systems research as well as to attempts to apply the Stack Overflow model to other specialized knowledge domains.</span></div></div></td>
<td colspan="13" class="session_details" id="S1246_details"><div class="sessionChair"><strong>Session Chair: </strong>Judith S. Olson (<em>University of California, Irvine</em>)</div><div class="paper" id="paper1916"><a href="#paper1916" class="title">Reuse in the Wild: an Empirical and Ethnographic Study  of Organizational Content Reuse</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979370&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yelena  Mejova</span> <span class="affiliation">University of Iowa</span>, <br />
<span class="author">Klaar  De Schepper</span> <span class="affiliation">Columbia University</span>, <br />
<span class="author">Lawrence  Bergman</span> <span class="affiliation">IBM T.J. Watson Research Center</span>, <br />
<span class="author">Jie  Lu</span> <span class="affiliation">IBM T.J. Watson Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a large-scale study of content reuse networks in <br /> a large and highly hierarchical organization. In our study, <br /> we combine analysis of a collection of presentations <br /> produced by employees with interviews conducted <br /> throughout the organization and a survey to study <br /> presentation content reuse. Study results show a variety of <br /> information needs and behaviors related to content reuse as <br /> well as a need for a personalized and socially-integrated <br /> networking tool for enabling easy access to previously <br /> generated presentation material. In this paper we describe <br /> our findings and outline a set of requirements for an <br /> effective content reuse facility.</span></div></div><div class="paper" id="paper1226"><a href="#paper1226" class="title">Do you KnowDis? A User Study of a Knowledge Discovery Tool for Organizations</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979371&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sven  Laqua</span> <span class="affiliation">University College London</span>, <br />
<span class="author">M. Angela  Sasse</span> <span class="affiliation">University College London</span>, <br />
<span class="author">Carrie  Gates</span> <span class="affiliation">CA Technologies</span>, <br />
<span class="author">Steven  Greenspan</span> <span class="affiliation">CA Technologies</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Organisations today have no reliable way of ensuring that all employees are aware of information that may be relevant to their work. In this paper we report on a 2-year project in which we have iteratively designed, developed and tested a knowledge discovery system (KnowDis) for organizations. Early stages of our study revealed that, employees do not know what is available on the corporate intranet, or files and messages they have stored. KnowDis proactively fetches relevant information and displays it in an unobtrusive form; this increases employee awareness without disrupting their tasks. We discuss and characterize knowledge workers&#8217; email usage behavior. Our main study with 28 users of KnowDis-enhanced email showed it can improve the user experience and performance on information retrieval tasks for knowledge workers.</span></div></div><div class="paper" id="paper230"><a href="#paper230" class="title">What's in a Move? Normal Disruption and a Design Challenge</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979372&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Reza B Zadeh</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Aruna D Balakrishnan</span> <span class="affiliation">Carnegie Mellon</span>, <br />
<span class="author">Sara  Kiesler</span> <span class="affiliation">Carnegie Mellon</span>, <br />
<span class="author">Jonathon N Cummings</span> <span class="affiliation">Duke University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The CHI community has led efforts to support teamwork, but has neglected team disruption, as may occur if team members relocate to another institution. We studied moves in 548 interdisciplinary research projects with 2691 researchers (PIs). Moves, and thus disruptions, were not rare, especially in large distributed projects. Overall, one-third of all projects experienced at least one member relocating but most moves reflected churn across high-ranking institutions. When collaborators moved, the project was disrupted. Our data suggest that moves exemplify normal disruptions. A design challenge is to help projects adapt to disruption.</span></div></div></td>
<td colspan="13" class="session_details" id="S1240_details"><div class="sessionChair"><strong>Session Chair: </strong>Sheelagh Carpendale (<em>University of Calgary</em>)</div><div class="paper" id="paper1193"><a href="#paper1193" class="title">Enhancing Genomic Learning through Tabletop Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979361&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Orit  Shaer</span> <span class="affiliation">Wellesley College</span>, <br />
<span class="author">Megan  Strait</span> <span class="affiliation">Tufts University</span>, <br />
<span class="author">Consuelo  Valdes</span> <span class="affiliation">Wellesley College</span>, <br />
<span class="author">Taili  Feng</span> <span class="affiliation">Wellesley College</span>, <br />
<span class="author">Michael  Lintz</span> <span class="affiliation">Olin College of Engineering</span>, <br />
<span class="author">Heidi  Wang</span> <span class="affiliation">Wellesley College</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present G-nome Surfer 2.0, a tabletop interface for fostering inquiry-based learning of genomics. We conducted an experimental study with 48 participants that compared students&#8217; learning of genomic concepts using existing bioinformatics tools and using two alternative implementations of G-nome Surfer: a collaborative multi-mouse GUI and a tabletop interface. Our findings indicate that G-nome Surfer improves students&#8217; performance, reduces workload, and increases enjoyment. The comparison of tabletop and multi-mouse implementations further shows that the tabletop condition results in four educational benefits: 1) increasing physical participation, 2) encouraging reflection, 3) fostering effective collaboration, and 4) facilitating more intuitive interaction.</span></div></div><div class="paper" id="paper1463"><a href="#paper1463" class="title">Supporting Fluid Tabletop Collaboration across Distances</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979362&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Naomi  Yamashita</span> <span class="affiliation">NTT Communication Science Laboratories</span>, <br />
<span class="author">Hideaki  Kuzuoka</span> <span class="affiliation">University of Tsukuba</span>, <br />
<span class="author">Keiji  Hirata</span> <span class="affiliation">NTT Communication Science Laboratories</span>, <br />
<span class="author">Shigemi  Aoyagi</span> <span class="affiliation">NTT Communication Science Laboratories</span>, <br />
<span class="author">Yoshinari  Shirai</span> <span class="affiliation">NTT Communication Science Laboratories</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this study, we examine how remote collaborators&#129;f upper body view affects collaboration when people engage in multiparty fluid tabletop activities across distances. We experimentally investigated the effects of upper body view on four-person group tabletop collaboration, two-by-two at identical locations: shared tabletop vs. shared tabletop plus upper body view. Although previous research has often failed to illustrate the advantages of showing remote participants&#129;f upper body view, our study showed that task performance was significantly higher in conditions with upper body view. Furthermore, participants with upper body view tended to take a step away from their remote partners to effectively glance at them while taking a comparable perspective of the tabletop objects. Detailed analysis of the video recordings revealed that upper body view was effective for fluid tabletop collaboration because it helped achieve joint perspective and helped estimate the timing and rough location of subsequent tabletop activity.</span></div></div><div class="paper" id="cs204"><a href="#cs204" class="title">Prezi Meeting: Collaboration in a Zoomable Canvas Based Environment</a>&nbsp;-&nbsp;<span class="type">Case Study (Short)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979673&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Laszlo  Laufer</span> <span class="affiliation">Budapest University of Tachnology and Economics</span>, <br />
<span class="author">Peter  Halacsy</span> <span class="affiliation">Prezi Inc.</span>, <br />
<span class="author">Adam  Somlai-Fischer</span> <span class="affiliation">Prezi Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We are introducing a zoomable, canvas based editor called Prezi, in which multiple users can collaborate synchronously, and share a common workspace for various purposes. They can develop a presentation together, create a mindmap, a storyline or do brainstorming. In this paper we would like to describe our key ideas, when designing the user experience of the collaboration function. We are arguing that the use of avatars in zoomable user interfaces are providing a uniquely efficient environment for collaboration in productivity applications. This kind of representation in a ZUI collaboration environment is raising group awareness, articulation work, and also gamifies presentaion editing, facilitating casual interaction between the participants.</span></div></div></td>
<td colspan="13" class="session_details" id="S1244_details"><div class="sessionChair"><strong>Session Chair: </strong>Lucia Terrenghi (<em>Google</em>)</div><div class="paper" id="paper576"><a href="#paper576" class="title">Towards a Design Model for Women&#8217;s Empowerment in the Developing World</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979368&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Geeta  Shroff</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Matthew  Kam</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pulitzer Prize-winning journalist Nicholas Kristof argues that &#8220;in this century the paramount moral challenge will be the struggle for gender equality around the world.&#8221; In this paper, we present a design model for empowering low-income women in the developing world, in ways that cut across individual application areas. Specifically, this model characterizes a possible trajectory for NGOs and women to engage with each other and among themselves &#8211; potentially augmented by technology &#8211; to help women escape from poverty. The fieldwork components in this study took place over 15 weeks in three phases, with a total of 47 NGO staff members and 35 socio-economically challenged women in rural and urban India. Interviews and co-design sessions with seven proof-of-concept prototypes showed that women appeared to belong to five distinct stages of &#8220;growth&#8221; in striving towards independence. We report the technology design lessons from our co-design sessions to illustrate how user readiness, relationship building at the community and family levels, and integration with state, national and international level programs, should be taken into account in the broader context of intervention design.</span></div></div><div class="paper" id="cs152"><a href="#cs152" class="title">Designing an E-Solution for Linking Informal Self-Help Groups in Africa &#8211; A Case Study</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979675&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mokeira  Masita-Mwangi</span> <span class="affiliation">Nokia Research Center, Africa</span>, <br />
<span class="author">Faith  Ronoh-Boreh</span> <span class="affiliation">Nokia Research Center, Africa</span>, <br />
<span class="author">Nyambura  Kimani</span> <span class="affiliation">Nokia Research Center, Africa</span>, <br />
<span class="author">Nancy  Mwakaba</span> <span class="affiliation">Nokia Research Center, Africa</span>, <br />
<span class="author">Grace  Kihumba</span> <span class="affiliation">Nokia Research Center, Africa</span>, <br />
<span class="author">Imelda  Mueni</span> <span class="affiliation">Nokia Research Center, Africa</span>, <br />
<span class="author">Jussi  Impio</span> <span class="affiliation">Nokia Research Center, Africa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe the process of designing an e-solution for linking informal self-help groups in Africa as a case study.  As in many parts of the developing world, participation in these groups in Africa is very popular.  Also loosely referred to as Merry-Go-Rounds (MGRs) these are groups of people who come together for either or all of: sharing knowledge, news, ideas, tradition, supporting one another in times of need (social welfare), saving and borrowing together in a rotational manner (informal banking), and carrying out local income generating or self / community development projects.  In Africa majority of MGRs are geographically isolated particularly those in rural areas hence interaction between different groups in different regions is minimal yet linking the groups could benefit them in various ways as described in this paper. Worthy of consideration is the implementation of linkages through e-solutions that would help overcome the geographical dispersion of groups.  The MGR Solution designed by Nokia Research Center (NRC) Africa is one such tool. It is a mobile solution for self-help groups to better manage their group activities and link them to other groups thus creating financial and social synergy. It provides for various functions to support internal group activities (administrative, financial and projects), group to group activities (e.g. sharing news, ideas, and assets, pooling finances, collaborating on projects) and other external functions (organizations that desire to be linked to and work with groups).  To satisfy this, the prototype developed includes a website for the MGR service designed to be accessed from a mobile phone based on the limited screen size and a website that can be accessed from a Personal Computer (PC) as it has more features as compared to the strip down version for mobile phones.  The solution also includes a mobile client for the internal group management activities, ability to access MGR web services via the mobile client, and use of SMS for communication by the MGR service. <br /> This paper examines the design process of the MGR Solution through ethnographic research, concept development and implementation, and generated user feedback, and hence related Human Computer Interaction (HCI) circumstances, consequences and opportunities. A virtual platform for sharing and exchange provides a good opportunity for growth and development of self-help groups due to increased access to information. It mitigates the geographical hurdle and other related socio-cultural and cost challenges. However certain things may need to be taken into account. These include possible language barriers and how to overcome these e.g. through translations, low literacy levels hence potential to explore audio technologies such as speech to text and text to speech, and elements that can be incorporated on the virtual platform to help build and increase trust amongst the users so that they are able to interact successfully.  For example, groups using the system need to be able to verify authenticity of other groups, have some kind of guarantee or mitigation of risks associated to resource sharing with other groups and control and ownership of the shared content. <br /></span></div></div></td>
<td colspan="13" class="session_details" id="S5006_details"><div class="paper" id="wp654"><a href="#wp654" class="title">Can Users Remember Their Pictorial Passwords Six Years Later?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979945&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Thomas S Tullis</span> <span class="affiliation">Fidelity Investments</span>, <br />
<span class="author">Donna P Tedesco</span> <span class="affiliation">Fidelity Investments</span>, <br />
<span class="author">Kate E McCaffrey</span> <span class="affiliation">Fidelity Investments</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous research had shown that pictorial passwords, where users recognize their target images among distractors, have potential for improving the usability of authentication systems.  A method using personal photos provided by the users as their targets, shown among highly similar distractors, showed the most promise for both accuracy and security.  But the longest time period that had been tested between successive login attempts was only about one month.  We wanted to see what happens when six years have elapsed.  We recruited some of the same participants from the previous study and tested their ability to select their target photos six years later. We found that 12 of 13 participants successfully authenticated themselves.  The overall accuracy rate was 95.6%, demonstrating that most users can remember these pictorial passwords even over long periods of time.</span></div></div><div class="paper" id="wp386"><a href="#wp386" class="title">ReHandle: Towards Integrating Physical Rehabilitation in Everyday life</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979856&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Naveen  Bagalkot</span> <span class="affiliation">IT University of Copenhagen</span>, <br />
<span class="author">Tomas  Sokoler</span> <span class="affiliation">IT University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present ReHandle, an emerging design space currently inhabited and shaped by three different design sketches. We describe how the three sketches point to three possible dimensions for exploring the role of digital technology in facilitating self-monitoring; aimed at promoting an integration of the rehab activities with the everyday activities of senior citizens. We expect that our articulation of the emerging ReHandle design space will be informative and inspirational for the interaction design and HCI community exploring the role of digital technology for successful rehabilitation of senior citizens.</span></div></div><div class="paper" id="wp532"><a href="#wp532" class="title">CrowdForge: Crowdsourcing Complex Work</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979902&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aniket  Kittur</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Boris  Smus</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Robert  Kraut</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Micro-task markets such as Amazon&#8217;s Mechanical Turk represent a new paradigm for accomplishing work, in which employers can tap into a large population of workers around the globe to accomplish tasks in a fraction of the time and money of more traditional methods.  However, such markets typically support only simple, independent tasks, such as labeling an image or judging the relevance of a search result.  Here we present a general purpose framework for micro-task markets that provides a scaffolding for more complex human computation tasks which require coordination among many individuals, such as writing an article.</span></div></div><div class="paper" id="wp646"><a href="#wp646" class="title">WaveForm: Remote Video Blending for VJs Using In-Air Multitouch Gestures</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979941&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Amartya  Banerjee</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Jesse  Burstyn</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present WaveForm, a system that enables a Video Jockey (VJ) to directly manipulate video content on a large display on a stage, from a distance. WaveForm implements an in-air multitouch gesture set to layer, blend, scale, rotate, and position video content on the large display. We believe this leads to a more immersive experience for the VJ user, as well as for the audience witnessing the VJ&#8217;s performance during a live event.</span></div></div><div class="paper" id="wp361"><a href="#wp361" class="title">The Adoption of Online Self-Service Technology (SST) as a Gradual Learning Process</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979847&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Calin  Gurau</span> <span class="affiliation">Montpellier Business School</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Using a combination of qualitative and quantitative analysis, this study attempts to identify the main phases of customer-SST system interaction. The findings reinforce the interpretation of SST adoption as a gradual process of learning that presents different challenges for various types of customers, depending on their level of online experience.</span></div></div><div class="paper" id="wp416"><a href="#wp416" class="title">Sympathetic Guitar:  Can a Digitally Augmented Guitar be a Social Entity?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979863&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jay  Vidyarthi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa N. Antle</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Bernhard E. Riecke</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous work suggests that people treat interactive media as if they were social entities.  By drawing a parallel between socio-cognitive theory and interface design, we intend to experimentally determine whether deliberate design decisions can have an effect on users&#8217; perception of an interactive medium as a social entity.  In this progress report, we describe the theoretical underpinnings and motivations which led to the design and implementation of the Sympathetic Guitar: a guitar interface which supplements standard acoustic sound with a spatially-separate audio response based on the user&#8217;s hand positions and performance dynamics.  This prototype will be used for investigating user response to a specific, socially-relevant design decision.</span></div></div><div class="paper" id="wp426"><a href="#wp426" class="title">Aiding Usability Evaluation via Detection of Excessive Visual Search</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979868&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Oleg  Komogortsev</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Corey  Holland</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Dan  Tamir</span> <span class="affiliation">Texas State University-San Marcos</span>, <br />
<span class="author">Carl  Mueller</span> <span class="affiliation">Texas State University-San Marcos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an objective evaluation of several methods for the automated classification of excessive visual search, a technique which has the potential to aid in the identification of usability problems during software usability testing. Excessive visual search was identified by a number of eye movement metrics, including: fixation count, saccade amplitude, convex hull area, scanpath inflections, scanpath length, and scanpath duration. The excessive search intervals identified by each algorithm were compared to those produced by manual classification. The results indicate that automated classification can be successfully employed to substantially reduce the amount of recorded data reviewed during usability testing, with relatively little loss in accuracy.</span></div></div><div class="paper" id="wp432"><a href="#wp432" class="title">ConsiderIt: Improving Structured Public Deliberation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979869&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Travis  Kriplean</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jonathan T. Morgan</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Deen  Freelon</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alan  Borning</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Lance  Bennett</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We designed, built, and deployed ConsiderIt to support the Living Voters Guide, a website where any voter could participate in writing a voters&#8217; guide for the 2010 election in Washington. ConsiderIt is a new method of integrating the thoughts of many into a coherent form, while nudging people to consider tradeoffs of difficult decisions with an intuitive interface.</span></div></div><div class="paper" id="wp457"><a href="#wp457" class="title">Sex Toys and Designing for Sexual Wellness</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979879&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anna  Eaglin</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sexual health encompasses physical, mental and social well-being in relation to sexuality. In this paper, we argue that designing for sexual health is an important aspect of the Wellness Informatics agenda, and that research on sex toys, which is underdeveloped in HCI, has the potential to contribute to this agenda substantively. We summarize our user research and present a set of design principles to further the agenda of designing for sexual wellness.</span></div></div><div class="paper" id="wp463"><a href="#wp463" class="title">Designing A Personal Visualization Projection of Online Social Identity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979882&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mandy  Leung</span> <span class="affiliation">The University of Sydney</span>, <br />
<span class="author">Martin  Tomitsch</span> <span class="affiliation">The University of Sydney</span>, <br />
<span class="author">Andrew  Vande Moere</span> <span class="affiliation">Katholieke Universiteit Leuven</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we report on the design, implementation and evaluation of a personal visualization projection, which provides onlookers with a real-time view of the online social identity of the wearer. The wearable system was developed as a novel means of electronic self-expression, and for catalyzing increased social interaction between the wearer and onlookers with similar or complementary personality characteristics. The interactive prototype, driven by a handheld &#8220;pico&#8221; projector, was evaluated with two groups of four participants each. Based on a case study analysis followed by focus groups, we present our findings according to a contextual evaluation model, which includes aspects of environment, usability, privacy, ambientness, social interaction, and insight.</span></div></div><div class="paper" id="wp498"><a href="#wp498" class="title">Customization for Games: Lessons from Variants of Texas Hold&#8217;em</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979889&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gifford K Cheung</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">System designers who build customization into games ought to consider how players think about adjustments. The distinctiveness of gaming contexts suggests that closer inspection of customization in games is warranted and will inform the design of customizable game systems. Presented here is an analysis of 82 collected reports about variations to the rules of the poker game Texas Hold&#8217;em. A theory of &#8220;necessity&#8221; in rule adoption is developed and the systematic perspective of rule-changing in games is discussed.</span></div></div><div class="paper" id="wp502"><a href="#wp502" class="title">&#8216;Canary in a Coal Mine&#8217;: Monitoring Air Quality and Detecting Environmental Incidents by Harvesting Twitter</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979890&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Henricus  Smid</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Patrick  Mast</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Maarten  Tromp</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Andi  Winterboer</span> <span class="affiliation">University of Amsterdam</span>, <br />
<span class="author">Vanessa  Evers</span> <span class="affiliation">University of Amsterdam</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an application that facilitates environmental <br /> monitoring by and for the general public. &#8216;Canary in a <br /> Coal Mine&#8217; (CIACM) gathers and analyses pollution-related <br /> tweets in real-time from the micro-blogging <br /> platform Twitter and visualizes temporal and spatial <br /> characteristics of the data. CIACM allows citizens to <br /> keep track of the environmental quality of their region <br /> and empowers users to contribute to this public <br /> environmental monitoring system.</span></div></div><div class="paper" id="wp522"><a href="#wp522" class="title">My Own-Style Interaction: Exploring Individuals' Preferences to Interactivity</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979897&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Da-jung  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Hyeon-Jeong  Suk</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There have been studies about users' preferences on different physical styles of interactive products, but the exploration of interactivity preferences and the value of customizing its expressions have not been emphasized much yet. In this paper, we conducted a three-phase user study in order to investigate individual preferences to different qualities of interactivity and its relationship with individual differences. The results showed that people have diverse preferences for several attributes of interactivity, similar to the case for appearances of products, and there are close relationships between individual differences such as human personality traits. Based on these results, we discussed their implications for designing attractive interaction.</span></div></div><div class="paper" id="wp493"><a href="#wp493" class="title">From the Lab to the World: Lessons from Extending a Pointing Technique for Real-World Use</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979888&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Jansen</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Leah  Findlater</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present the Pointing Magnifier as a case study for understanding the issues and challenges of deploying lab-validated pointing facilitation techniques into the real world. The Pointing Magnifier works by magnifying the contents of an area cursor to allow for selection in a magnified visual and motor space. The technique has been shown in prior lab studies to be effective at reducing the need for fine pointing for motor-impaired users. We highlight key design and technical challenges in bringing the technique, and such techniques in general, from the lab to the field.</span></div></div><div class="paper" id="wp482"><a href="#wp482" class="title">LoOkie - It Feels Like Being There</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979884&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Talya  Porat</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span>, <br />
<span class="author">Inbal  Rief</span> <span class="affiliation">kitchen97.com</span>, <br />
<span class="author">Rami  Puzis</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span>, <br />
<span class="author">Yuval  Elovici</span> <span class="affiliation">Deutsche Telekom Laboratories at Ben Gurion University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we describe an interaction design process and the challenges encountered during the development of LoOkie, a social mobile application, which enables members to request and receive live videos or pictures of desired locations from people who are present at the scene. The paper describes, from a human-computer interaction perspective, the development of the application from the birth of the idea through the design process encountered up to the point of the launch of the application for Beta at the beginning of 2011.</span></div></div><div class="paper" id="wp437"><a href="#wp437" class="title">Input Observer: Measuring Text Entry and Pointing Performance from Naturalistic Everyday Computer Use</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979871&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abigail  Evans</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe the Input Observer, a background application that will be capable of measuring a user&#8217;s text entry and pointing abilities from everyday computer use &#8220;in the wild.&#8221; The application runs quietly in the background of the user&#8217;s computer and utilizes global Windows Hooks to observe the text entry input stream and use of the mouse, and will yield data equivalent to results from lab-based measures of text entry and target acquisition. A major challenge is the lack of a task model from which researchers can know the intent of the user at every <br /> moment. We describe our approach to handling this issue for both text entry and mouse pointing.</span></div></div><div class="paper" id="wp580"><a href="#wp580" class="title">Wriggle: An Exploration of Emotional and Social Effects of Movement</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979919&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katherine  Isbister</span> <span class="affiliation">NYU-Poly</span>, <br />
<span class="author">Ulf  Schwekendiek</span> <span class="affiliation">NYU-Poly</span>, <br />
<span class="author">Jonathan  Frye</span> <span class="affiliation">NYU</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Wriggle is a research prototype game that can be played either with or without movement as input. We conducted an experiment to see whether movement adds emotional impact and increases social connectedness. We found effects on arousal and results approaching significance for social connection, demonstrating the potential for this approach to help us better understand the impact of movement on user experience.</span></div></div><div class="paper" id="wp575"><a href="#wp575" class="title">Text Highlighting Improves User Experience for Reading with Magnified Displays</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979917&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tersia  Gowases</span> <span class="affiliation">University of Eastern Finland</span>, <br />
<span class="author">Roman  Bednarik</span> <span class="affiliation">University of Eastern Finland</span>, <br />
<span class="author">Markku  Tukiainen</span> <span class="affiliation">University of Eastern Finland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We report on two studies of how magnified views affect the lives of users with low vision and how simple interventions can improve their user experience. In the first study we observed three low vision users with Age-related Macular Degeneration (AMD) as they interacted with computing devices. We found that AMD users rely on the screen magnification, but the same magnified view not only makes it impossible to read longer texts independently, but also causes a loss of context. We then designed an enhancement of the conventional Windows 7 screen magnification tool by providing line-level text highlighting. We conducted an experiment in which 21 participants, with normal vision, read text from a webpage using one of three conditions: no enhancement, highlighting, and highlighting + cursor routing. We recorded the eye-movement patterns, performance, cognitive workload, and user experience. The results provide design implications and guidelines for visual aids for interaction with magnified displays.</span></div></div><div class="paper" id="wp620"><a href="#wp620" class="title">Mobile Augmented Reality: Video prototyping</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979927&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marco  de S&#225;</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">Judd  Antin</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">David  Shamma</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span>, <br />
<span class="author">Elizabeth F. Churchill</span> <span class="affiliation">Internet Experiences Group  Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As mobile devices become more powerful, new features and user experiences become possible. A good example of such experiences is Augmented reality (AR). Achieved through the combination of current smart- phones processing capabilities and their embedded cameras, AR is a growing trend that offers an interesting approach for a wide variety of applications. However, coupling this new approach to the already demanding design process that characterizes mobile devices, further extends challenges to designers and developers. In this paper we present a preliminary study on prototyping and evaluation techniques for mobile AR. A short experiment within the context of an ongoing design project and initial results are presented along with some resulting guidelines.</span></div></div><div class="paper" id="wp504"><a href="#wp504" class="title">Transparency in Mobile Navigation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979891&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  McGookin</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Inti  Herteleer</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen  Brewster</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We investigated the usefulness transparency can play in increasing the display space of mobile devices in navigation scenarios.   Two different systems that used transparency to display a map and image of a point of interest (POI) were compared to a control. Significant variations were identified in the strategies employed, with a strong user preference towards the transparency conditions. Significant variations in time or distance taken were not identified between conditions, although results indicate strong avenues for future investigation.</span></div></div><div class="paper" id="wp513"><a href="#wp513" class="title">Force Gestures: Augmented Touch Screen Gestures Using Normal and Tangential Force</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979895&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seongkook  Heo</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Geehyuk  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Similar sliding gestures may have different meanings when they are performed with changing intensity. Touch screens, however, fail to properly distinguish those intensities due to their inability to sense variable pressures. Enabled by distinguishing normal and tangential forces, we explore new possibilities for gestures on a touch screen. We have implemented a pressure-sensitive prototype and have designed a set of gestures that utilize alterable forces. The gestures&#8217; feasibility has been tested through a simple experiment.  Finally, we discuss the new possibility of touch interactions that are sensitive to pressure.</span></div></div><div class="paper" id="wp460"><a href="#wp460" class="title">WATER Alert! Disseminating Drinking Water Quality Information to South Africans</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979880&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Deana S. Brown</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Gary  Marsden</span> <span class="affiliation">University of Cape Town</span>, <br />
<span class="author">Melissa  Loudon</span> <span class="affiliation">University of Southern California</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Drinking water quality, especially in many parts of South Africa, is far below acceptable standards. With an annual estimate of 43,000 deaths from diarrheal diseases, 3 million cases of illness, and treatment costs of over half a billion US dollars, the impact is critical [4]. This research addresses the challenge of reporting complex and critical water quality information in a way that is accessible to all South Africans as required by law. In a country with high illiteracy rates, 11 official languages and limited-to-no access to technology in many areas, this is no easy feat. We describe the details of WATER Alert!, a prototype mobile phone application designed to alert and report critical water quality information to consumers who subscribe to it. Our initial evaluation of this design with users suggests that such an application would help to improve consumers' understanding of water quality information. The symbol-based messages make critical water quality information more accessible to illiterate or low-literate users, or non-native English or Afrikaans speakers. Additionally, the use of a tool and interface design most of our users are familiar with (the mobile phone) lowers the learning curve.</span></div></div><div class="paper" id="wp563"><a href="#wp563" class="title">Dual-Space Drawing: Designing an Interface to Support Creative and Reflective Drawing Experiences</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979912&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jee Yeon  Hwang</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Henry  Holtzman</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Mitchel  Resnick</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Dual-Space Drawing is an interface that enables children to express their drawing ideas in both the digital and real worlds. It supports creative and reflective drawing experiences using two layers: a transparent layer and a screen layer. The interface takes a user&#8217;s drawing movements on the transparent display unobtrusively and then projects the movements on the screen display while presenting the user-selected multimedia components. Dual-Space Drawing lets users interact with motion graphics on a mirror-like display. In the process of designing the self-projected scenes and creating digital contents, children can express themselves and embody their ideas. While designing a digital object, a user&#8217;s response to the object creates a new relationship to the object in connection with the user&#8217;s self-reflection/projection. In this way, Dual-Space Drawing integrates the user&#8217;s drawing activity with expressive interaction.</span></div></div><div class="paper" id="wp516"><a href="#wp516" class="title">Comparative Evaluation of Recommender System Quality</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979896&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Paolo  Cremonesi</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Franca  Garzotto</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Sara  Negro</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Alessandro  Papadopoulos</span> <span class="affiliation">Politecnico di Milano</span>, <br />
<span class="author">Roberto  Turrin</span> <span class="affiliation">Moviri SRL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Several researchers suggest that the Recommendation Systems (RSs) that are the "best" according to statistical metrics might not be the most satisfactory for the user. We explored this issue through an empirical study that involved 210 users and considered 7 RSs using different recommender algorithms on the same dataset.  <br /> We measured user&#8217;s perceived quality of each RS, and compared these results against measures of statistical quality of the considered algorithms as they have been assessed by past studies in the field, highlighting some interesting results.</span></div></div><div class="paper" id="wp362"><a href="#wp362" class="title">Generalizing Email Messages Digests</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979848&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Romain  Vuillemot</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span>, <br />
<span class="author">Jean-Marc  Petit</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span>, <br />
<span class="author">Mohand-Said  Hacid</span> <span class="affiliation">Universit&#233; de Lyon, CNRS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An email digest is a message that results from the combination of other messages. Mailing list management systems implement digests to let subscribers reduce their email messages frequency. In this paper we address the issue of generalizing this digest technique for any message (i.e. not only issued from mailing lists). By generalizing we mean creating new message combinations while 1) keeping an email centric approach, and 2) generating a compact visualization to assist a user task. We implemented a preliminary prototype as a webmail and we will describe a series of digests providing users multiple visualizations in the context of a meeting planning by email.</span></div></div><div class="paper" id="wp373"><a href="#wp373" class="title">Visualizing Meetings as a Graph for more Accessible Meeting Artifacts</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979850&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yurdaer  Doganata</span> <span class="affiliation">IBM Research</span>, <br />
<span class="author">Mercan  Topkara</span> <span class="affiliation">IBM Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper focuses on capturing, correlating and visualizing the execution of meetings from the recorded data using a business process management approach. Relevant artifacts that are utilized or generated during a meeting as well as meeting activities are mapped onto a generic meeting data model. The execution of a meeting is then captured as a graph where generated meeting artifacts, participants and meeting tasks are connected. The graph enables faster and structured access to meeting data and gives better insight to the users about the meeting through visualization capability.</span></div></div><div class="paper" id="wp384"><a href="#wp384" class="title">Engaging Energy Saving through Motivation-Specific Social Comparison</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979855&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Petromil  Petkov</span> <span class="affiliation">Queensland University of Technology, NICTA, Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Felix  K&#246;bler</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span>, <br />
<span class="author">Marcus  Foth</span> <span class="affiliation">Queensland University of Technology, NICTA</span>, <br />
<span class="author">Richard  Medland</span> <span class="affiliation">Queensland University of Technology, NICTA</span>, <br />
<span class="author">Helmut  Krcmar</span> <span class="affiliation">Technische Universit&#228;t M&#252;nchen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Comparison is widely used in research projects and commercial products whose goal is to motivate energy saving at home. This research builds on fundamental theories from social psychology in an attempt to shed light on how to motivate consumers to conserve energy by providing relevant people for social comparison depending on consumer&#8217;s motivation to compare. To support the research process, the mobile application EnergyWiz was developed through a theory-driven design approach. Along with other features EnergyWiz provides users with three types of social comparison &#8211; normative, one-on-one and ranking. The results of interviews with prospective users are used to derive design suggestions for relevant people for comparison (comparison subjects).</span></div></div><div class="paper" id="wp400"><a href="#wp400" class="title">AnalyzeThis: Unobtrusive Mental Health Monitoring by Voice</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979859&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Keng-hao  Chang</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Matthew  Chan</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">John  Canny</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mental illness is one of the most undertreated health problems worldwide.  Previous work has shown that there are remarkably strong cues to mental illness in short samples of the voice. These cues are evident in severe forms of illness, but it would be most valuable to make earlier diagnoses from a richer feature set. Furthermore there is an abstraction gap between these voice cues and the diagnostic cues used by practitioners. We believe that by closing this gap, we can build more effective early diagnostic systems for mental illness. In order to develop improved monitoring, we need to translate the high-level cues used by practitioners into features that can be analyzed using signal processing and machine learning techniques.  In this paper we describe the elicitation process that we used to tap the practitioners' knowledge.   We borrow from both AI (expert systems) and HCI (contextual inquiry) fields in order to perform this knowledge transfer.  The paper highlights an unusual and promising role for HCI - the analysis of interaction data for health diagnosis. <br /></span></div></div><div class="paper" id="wp409"><a href="#wp409" class="title">MouseHints: Easing Task Switching in Parallel Browsing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979861&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luis A Leiva</span> <span class="affiliation">Universidad Polit&#233;cnica de Valencia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a technique to help users regain context either after an interruption or when multitasking while performing web tasks.  <br /> Using mouse movements as an indicator of attention, a browser plugin records in background the user's interactions (including clicks, dwell times, and DOM elements). On leaving the page, this information is stored to be rendered as an overlay when the user returns to such page.  <br /> The results of a short study showed that participants resumed tasks three times faster with MouseHints and completed their tasks in about half the time. <br /> Related applications and further research are also envisioned. <br /></span></div></div><div class="paper" id="wp465"><a href="#wp465" class="title">Active Progress Bars: Facilitating the Switch to Temporary Activities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979883&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christophe  Hurter</span> <span class="affiliation">Civil Aviation Research Center, IRIT Toulouse University</span>, <br />
<span class="author">Audrey  Girouard</span> <span class="affiliation">Queen&#8217;s University</span>, <br />
<span class="author">Nathalie  Riche</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Catherine  Plaisant</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we seek to find a better way of effective task management when a progress bar interrupts us-er&#8217;s primary activity. We propose to augment progress bars with user controlled functionalities facilitating the switch to temporary activities. We detail a taxonomy of waiting period contexts and possible temporary tasks, then report on 5 participatory design, and a follow-up survey of 96 respondents. Finally we describe an early prototype of active progress bars, and report on initial use.</span></div></div><div class="paper" id="wp484"><a href="#wp484" class="title">PLink: Paper-Based Links for Cross-Media Information Spaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979885&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">J&#252;rgen  Steimle</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Nadir  Weibel</span> <span class="affiliation">University of California San Diego</span>, <br />
<span class="author">Simon  Olberding</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Max  M&#252;hlh&#228;user</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">James D. Hollan</span> <span class="affiliation">University of California San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">PLink is a system for integrating physical and computer desktops by creating paper links to digital resources. PLink leverages diverse formats of physical paper, ranging from tiny stickers that can be easily incorporated into traditional paper media to very large deskpad sheets that make the physical desktop partially interactive. We present PLink and initial results from a multi-week field study.</span></div></div><div class="paper" id="wp527"><a href="#wp527" class="title">Adding Haptic Feedback to Mobile TV</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979899&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jason  Alexander</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Mark T Marshall</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Sriram  Subramanian</span> <span class="affiliation">University of Bristol</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With the abundance of large-screen displays, mobile device users currently have little motivation to stream video content and TV broadcasts to their device&#8212;the desire to watch content 'on the move' does not currently outweigh the necessity of viewing this content on a miniaturised screen. However, the value and appeal of mobile TV broadcasts can be increased by the addition of a haptic-feedback channel to supplement the traditional video and audio streams.  <br /> This paper discusses the development of mobile haptic TV systems. It describes the design constraints for these systems and presents one concept implementation, UltraTV. UltraTV is a mobile device that provides mid-air, multi-point, back-of-device ultrasonic haptic feedback to enhance the mobile TV experience (see Figure 1). The paper concludes with a look at avenues for further exploration within the realm of mobile haptic TV.</span></div></div><div class="paper" id="wp531"><a href="#wp531" class="title">PowerSocket: Towards On-Outlet Power Consumption Visualization</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979901&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Florian  Heller</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Power consumption is measured in W and Wh, but what do these units mean? Water consumption can easily be understood, as we all know what a liter of water looks like. Common power meters, however, rely on the physical units or their translation to costs as display. We classified existing displays and ambient visualizations in a taxonomy that focuses on the characteristics of power consumption displays. We adapted representatives of the different categories of displays to an on-outlet display and compared these using a combination of soft- and hardware prototyping. Results indicate that ambient visualizations make it easier to understand power consumption.</span></div></div><div class="paper" id="wp425"><a href="#wp425" class="title">SketchSpace: Designing Interactive Behaviors with Passive Materials</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979867&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Holman</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents SketchSpace, a system that allows designers to interactively sketch [3] device&#8217;s interactive behaviors by imbuing digital functionality to passive materials. SketchSpace requires no augmentation of the device itself, but instead it uses a depth-sensing Kinect camera to simulate the use of hardware sensors by using depth information to infer an object's three-dimensional position, motion, proximity, shape, deformations, and touch events on its surface. A designer can map these inputs to desktop applications in real-time and thus experiment with different interactions. We showcase how SketchSpace can be used to prototype two devices: from tilt sensitive mice to bendable displays. In general, we discuss how this simplifies the process of generating an interactive device sketch and supports rapid exploration of design solutions.</span></div></div><div class="paper" id="wp539"><a href="#wp539" class="title">Paper Interface Design for Classroom Orchestration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979904&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S&#233;bastien  Cuendet</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Quentin  Bonnard</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Fr&#233;d&#233;ric  Kaplan</span> <span class="affiliation">EPFL</span>, <br />
<span class="author">Pierre  Dillenbourg</span> <span class="affiliation">EPFL</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Designing computer systems for educational purpose is a difficult task. While many of them have been developed in the past, their use in classrooms is still scarce. We make the hypothesis that this is because those systems take into account the needs of individuals and groups, but ignore the requirements inherent in their use in a classroom. In this work, we present a computer system based on a paper and tangible interface that can be used at all three levels of interaction: individual, group, and classroom. We describe the current state of the interface design and why it is appropriate for classroom orchestration, both theoretically and through two examples for teaching geometry.</span></div></div><div class="paper" id="wp573"><a href="#wp573" class="title">Communication by Change in Taste</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979916&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hiromi  Nakamura</span> <span class="affiliation">Meiji University</span>, <br />
<span class="author">Homei  Miyashita</span> <span class="affiliation">Meiji University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we discuss the possibilities and enjoyment of communication by changes in taste, as well as the concept of expanding the sense of taste. When the tongue is electrically stimulated, it senses a characteristic taste. We developed various apparatuses to change the taste of food and drinks based on this effect . An apparatus for drinks, comprising two electrically conducting straws, is used to change the taste of the drink by the formation of an electrical circuit inside the mouth only when drinking by holding both straws in the mouth. In the case of two persons each having one straw in their mouths, shaking hands causes electricity to flow, resulting in the change in taste. With a chopsticks/fork type of apparatus, the taste changes by the electric current that flows through the human body when one person helps the other to eat. In the case of both types of apparatuses, it is possible to control the voltage by a PWM(pulse width modulation) and the pattern by a relay, and a variety of tastes can be produced by a personal computer.</span></div></div><div class="paper" id="wp589"><a href="#wp589" class="title">The Effects of Spatial Layout and View Control on Cognitive Processing</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979921&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eric D Ragan</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Alex  Endert</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Doug A Bowman</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span>, <br />
<span class="author">Francis  Quek</span> <span class="affiliation">Virginia Polytechnic Institute and State University (Virginia Tech)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study explores how spatial layout and view control impact learning. We performed a controlled experiment using a learning activity involving memory and comprehension of a visually represented story. We present our preliminary results comparing performance between a slideshow-type presentation on a single monitor and a spatially distributed presentation among multiple monitors, and method of view control (automatic and interactive). With the distributed layout, participants maintained better memory of the associated locations where information was presented. However, performance scores were significantly better for the slideshow presentation than for the distributed layout for the learning task.</span></div></div><div class="paper" id="wp414"><a href="#wp414" class="title">Initial Results from a Study of the Effects of Meditation on Multitasking Performance</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979862&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David M. Levy</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alfred W. Kaszniak</span> <span class="affiliation">University of Arizona</span>, <br />
<span class="author">Marilyn  Ostergren</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports initial results from a study exploring whether training in meditation or relaxation can improve office workers&#8217; ability to multitask on a computer more effectively and/or with less stress. Human resource (HR) personnel were given 8 weeks of training in either mindfulness meditation or body relaxation techniques, and were given a stressful multitasking test both before and after training. (A third group, a control group, received no intervention during the 8-week period but was tested both before and after this period.) Results indicate that overall task time and errors did not differ significantly among the three groups. However, the meditation group reported lower levels of stress and showed better memory for the tasks they had performed; they also switched tasks less often and remained focused on tasks longer.</span></div></div><div class="paper" id="wp436"><a href="#wp436" class="title">VORTEX: Design and Implementation of an Interactive Volumetric Display</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979870&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abhijit  Karnik</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Archie  Henderson</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Andrew  Dean</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Howard  Pang</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Thomas  Campbell</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Satoshi  Sakurai</span> <span class="affiliation">Osaka University</span>, <br />
<span class="author">Guido  Herrmann</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Shahram  Izadi</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Yoshifumi  Kitamura</span> <span class="affiliation">Tohoku University</span>, <br />
<span class="author">Sriram  Subramanian</span> <span class="affiliation">University of Bristol</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">True 3D display systems like volumetric displays allow generation of autostereoscopic, multi-view 3D content that has real physical dimensions. However their uptake as a research tool within the HCI community is limited largely due to difficulties in buying or building such displays. The choice of commercially available systems is limited and constrains the flexibility of their use in terms of interaction capabilities, display features and integration with multi-display environments (MDEs). In this paper we describe the steps involved in creating custom volumetric display from easily available components. By building a touch-enabled volumetric display we walk-through the steps involved in the process. This will enable us to explore various interactive systems, associated techniques and challenges related to integration of the device into a MDE.</span></div></div><div class="paper" id="wp613"><a href="#wp613" class="title">Socially-Interactive Dressing Room: An Iterative Evaluation on Interface Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979925&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jasy Suet Yan  Liew</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">Elizabeth  Kaziunas</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">JianZhao  Liu</span> <span class="affiliation">Syracuse University</span>, <br />
<span class="author">Shen  Zhuo</span> <span class="affiliation">Syracuse University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the formative user interface design of a socially-interactive dressing room. The socially-interactive dressing room allows shoppers to talk to their friends in real time for opinions on their garment purchasing decisions. Our work is motivated by the observation that shoppers who lack fashion sense often rely on their friends&#8217; opinions when making garment purchasing decisions. Using the iterative user interface design methodology, we conducted a mini focus group and interviews among male and female shoppers to refine the user interface design. Our findings suggest that an iterative approach proves to be useful in uncovering and addressing usability, aesthetics, and trust issues that arise from incorporating a socially-interactive system within a dressing room context.</span></div></div><div class="paper" id="wp623"><a href="#wp623" class="title">Next Step in Electronic Brainstorming: Collaborative Creativity with the Web</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979929&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lassi A Liikkanen</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Kai  Kuikkaniemi</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Petri  Lievonen</span> <span class="affiliation">Helsinki Institute for Information Technology</span>, <br />
<span class="author">Pauli  Ojala</span> <span class="affiliation">Helsinki Institute for Information Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Brainstorming is an essential technique in creative group work. Research literature indicates the strengths of electronic brainstorming over face-to-face work. Despite this evidence, the old practice dominates. We believe that this is due to the inadequate integration of new tools to existing practices and the tendency to focus on idea production alone. This paper explores how to augment traditional, collocated Brainstorming and make electronic brainstorming feasible and accessible with web-based technology. We introduce an electronic brainstorming application prototype and justify its design principles. Our system aimed at facilitating conceptual design and we present design insights from a pilot study with the prototype used by 27 design students. The paper argues that by structuring the generative group process with a low-cost tool, users can sprint through a creative process, from problem definition to defining a solution.</span></div></div><div class="paper" id="wp635"><a href="#wp635" class="title">ViewSer: A Tool for Large-Scale Remote Studies of Web Search Result Examination</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979936&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dmitry  Lagun</span> <span class="affiliation">Emory University</span>, <br />
<span class="author">Eugene  Agichtein</span> <span class="affiliation">Emory University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Web search behavior studies, including eye-tracking studies of search result examination, have resulted in numerous insights to improve search result quality and presentation. Yet, these studies have been severely restricted in scale, due to the expense and effort required. We propose a novel methodology for crowdsourcing web search behavior studies &#8211; specifically focusing on performing large-scale studies of result examination behavior. We present a viewport-based examination interface (ViewSer), which enables remotely tracking searcher examination behavior, without requiring eye tracking equipment. We show that ViewSer induces similar viewing and clickthrough behavior, compared to in-lab users monitored with eye tracking, in a study with over 100 remote participants. ViewSer is a first step towards large-scale behavioral evaluation of web search, which would help improve web search result presentation, result ranking, and ultimately improve the web search experience overall.</span></div></div><div class="paper" id="wp368"><a href="#wp368" class="title">Who Said Monitoring Is Boring?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979849&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pradeep  Buddharaju</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Dvijesh  Shastri</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Anitha  Mandapathi</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Swati  Vaidya</span> <span class="affiliation">University of Houston</span>, <br />
<span class="author">Ioannis  Pavlidis</span> <span class="affiliation">University of Houston</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this article, we extend our previous work [1], which blended gaming in monotonous security tasks to increase operator engagement and enjoyment. Specifically, we expand from a single game presented in [1] to an assortment of games that appeal to different tastes. These include a shooting game, a racket game, and two puzzle games. All games are designed in a way that attracts instead of detracting attention to the monitoring screens. In addition to the game set, we also include a web browser capability symbiotic to the monitoring task. All these applications are tested in a quite realistic pilot experiment, where subjects are monitoring live security feeds. This is in contrast to the experiment on a pre-recorded video feed reported in [1]. The results demonstrate that subject engagement and enjoyment is significantly higher when the monitoring task is multiplexed with imaginative interactive options. This improvement in job satisfaction is achieved without sacrificing performance, as measured by detection of suspicious activities.</span></div></div><div class="paper" id="wp637"><a href="#wp637" class="title">SoundVision: Graphic Communication Method for Blind Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979938&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chaochao  Chen</span> <span class="affiliation">Kunsthochschule Berlin-Weissensee</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Parallel visual data acquisition is not available to blind. Yet, sequential tactile scanning (e.g. white cane) allows them to form mental concepts of their surroundings, albeit slower. The purpose of this project is to demonstrate that acoustic serial scanning of graphical objects allows a blind user to form mental concepts and to reproduce these objects graphically. Moreover, this system is designed to enable blind users to obtain graphic information and express their visual ideas graphically through sound.</span></div></div><div class="paper" id="wp423"><a href="#wp423" class="title">Turkomatic: Automatic Recursive Task and Workflow Design for Mechanical Turk</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979865&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Anand P Kulkarni</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Matthew  Can</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Bjoern  Hartmann</span> <span class="affiliation">UC Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Completing complex tasks on crowdsourcing platforms like Mechanical Turk currently requires significant up-front investment into task decomposition and workflow design. We present a new method for automating task and workflow design for high-level, complex tasks. Unlike previous approaches, our strategy is recursive, recruiting workers from the crowd to help plan out how problems can be solved most effectively. Our initial experiments suggest that this strategy can successfully create workflows to solve tasks considered difficult from an AI perspective, although it is highly sensitive to the design choices made by workers.</span></div></div><div class="paper" id="wp404"><a href="#wp404" class="title">My Mobile Story: Therapeutic Storytelling for Children</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979860&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mark  Matthews</span> <span class="affiliation">Trinity College</span>, <br />
<span class="author">Gavin  Doherty</span> <span class="affiliation">Trinity College</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes the design, evaluation and rationale behind a multimedia message service (MMS) based therapeutic system for adolescents attending therapy. The mobile phone is used to assist clients in engaging with therapy through the completion of structured therapeutic tasks. Content is gathered by the client with the phone, and browser-based software is then used to structure the content during a face-to-face therapeutic session. We discuss initial findings including the potential for engaging clients in remote therapeutic activities and the importance of client control over access to their content. We also consider several practical issues concerning the design and evaluation of software to be used in clinical settings.</span></div></div><div class="paper" id="wp550"><a href="#wp550" class="title">A Long-term Study of User Experience towards Interaction Designs that Support Behavior Change</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979909&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sang-Su  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Youn-kyung  Lim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Kun-pyo  Lee</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many researches on interaction design that supports users&#8217; behavior change in everyday life are studied recently especially in the domain of pervasive technology. However, not much attention has been paid to long-term effects on users in such cases. This paper presents our initial work of a long-term (8 month) study of users' self-report of experiences with an ambient dashboard feedback system in an automobile called Eco-driving system. It was notable that user satisfaction changed positively following active self-efforts made by users to understand the system after the negative shift due to initial disappointment. This work will be a first step to build a framework of how users accept systems designed to persuade them to change behavior over time.</span></div></div><div class="paper" id="wp600"><a href="#wp600" class="title">Bridging the Gap: Implementing Interaction Through Multi-User Design</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979922&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tom  Bartindale</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Rachel  Clarke</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Madeline  Balaam</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe an interactive museum installation designed to extend visitor participation through personal reflection and contribution. The case study describes design approaches, which focused on multiple individual simultaneous use, which we describe as multi-user design. These approaches were deployed to support the visitor moving from viewer to contributor in a temporary museum exhibition. We present the anticipated use and early analysis of some of the data from actual use of the system. We outline our initial findings for the opportunities and limits in designing for personalised user-generated content through such approaches within museums and suggest areas of future work on qualities of participation and visitor contribution.</span></div></div><div class="paper" id="wp508"><a href="#wp508" class="title">Informing Design by Recording Tangible Interaction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979893&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Augusto  Esteves</span> <span class="affiliation">Madeira Interactive Technologies Institute</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Evaluating tangible user interfaces is challenging. Despite the wealth of research describing the design of tangible systems, there is little empirical evidence highlighting the benefits they can confer. This paper presents a toolkit that logs the manipulation of tangible objects as a step towards creating specific empirical methods for the study of tangible systems. The paper argues that the data derived from toolkit can be used in three ways. Firstly: to compare tangible interaction with other interaction paradigms. Secondly: to compare among different tangible interfaces performing the same tasks. Thirdly: via integration into a structured design process. This paper focuses on this last topic and discusses how detailed data regarding object use the data could be integrated into classifications and frameworks such as the Shaer&#8217;s et al&#8217;s TAC paradigm.</span></div></div><div class="paper" id="wp354"><a href="#wp354" class="title">Effect of Levels of Automation on Emotional Experience in Intelligent Products</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979846&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Moon-Hwan  Lee</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Tek-Jin  Nam</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Hyeon-Jeong  Suk</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many scientists and engineers have researched how to apply automation technology to intelligent products. Emotional experiences in products have been considered as important factors for users&#8217; satisfaction as well. With users&#8217; emotions in mind, it is necessary to consider whether automated products indeed provide humans with emotionally satisfying experiences. In this paper, we investigated how different levels of automations affect users&#8217; experiences from an emotional point of view. Through experiments, effects of cognitive automation and motor automation were explored. The paper concludes with recommendations for applying automation technologies to intelligent products.</span></div></div><div class="paper" id="wp422"><a href="#wp422" class="title">A Cultural Knowledge-based Method to Support the Formation of Homophilous Online Communities</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979864&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Junia C Anacleto</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Fernando C Balbino</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Andre O Bueno</span> <span class="affiliation">Federal University of S&#227;o Carlos</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Gilberto O Astolfi</span> <span class="affiliation">Federal University of S&#227;o Carlos</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We propose a three-step method to identify people in social networks sites (SNS) who are talking about the same topics, even though they may be from different cultural backgrounds. Our method uses a cultural knowledge base from the OMCS-Br project to normalize cultural differences and find common interest among users based on statements they make various topics in a SNS. We evaluated three initial phrases that were used to search for sentences in a large social network using the cultural translation; we found that 81% of the retrieved sentences were judged to be related to the initial phrases. Thus, we have evidence that cultural normalization can support finding people talking about the same topic in a SNS even when they have different ways of saying the same thing. We believe that these culturally translated similarities can be used in a recommender system to contribute to the formation of homophilous online communities.</span></div></div><div class="paper" id="wp455"><a href="#wp455" class="title">Listening to the Community: Social Media Monitoring Tasks for Improving Government Services</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979878&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Cecile  Paris</span> <span class="affiliation">CSIRO</span>, <br />
<span class="author">Stephen  Wan</span> <span class="affiliation">CSIRO</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a preliminary analysis of the tasks and information needs of users performing social media monitoring to improve government services.  In general, our aim is to explore how text analysis tools can support a social media monitoring task in the government context.  We find that, in this context, social media monitoring is a complex activity. Social media monitors not only perform traditional media monitoring tasks, but they also take specific actions to provide an improved service, predominantly by checking and vetting information contributed by the wider online community.  In our analysis, we found a number of specific information-based actions performed in order to determine how one should respond to a particular social media post. <br /></span></div></div><div class="paper" id="wp489"><a href="#wp489" class="title">Introducing VERO: Visual Experiential Requirements Organizer</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979886&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Agnieszka  Szostek</span> <span class="affiliation">Interactive Technologies Laboratory Institute for Information Processing (OPI)</span>, <br />
<span class="author">Evangelos  Karapanos</span> <span class="affiliation">Madeira Interactive Technologies Institute Universidade da Madeira</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crucial to the advancement of the User Experience field is the ability to understand product qualities as perceived by users. Therefore we would like to introduce VERO (Visual Experiential Requirements Organizer), an online tool for the structured elicitation of users' perceptions of a given stimulus such as a product, a system or a concept. Contrary to the existing elicitation methods, VERO aims to enable users to freely express opinions about qualities relevant for a given stimulus; to indicate the importance of each quality without imposing a hierarchical order and to cluster related qualities according to users' own perception regarding the strength of the link between them. In this paper we also motivate our approach in developing VERO and sketch our research agenda regarding its validation and application in the field of User Experience.</span></div></div><div class="paper" id="wp491"><a href="#wp491" class="title">The Online Privacy Paradox: A Social Representations Perspective</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979887&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marie Caroline  Oetzel</span> <span class="affiliation">Institute for Management Information Systems, Vienna University of Economics and Business</span>, <br />
<span class="author">Tijana  Gonja</span> <span class="affiliation">Institute for Management Information Systems, Vienna University of Economics and Business</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present early results from a study, which aims at understanding the privacy paradox from a social representations perspective. After identifying adequate stimulus words with the help of a preliminary study, we conducted the main study using an online questionnaire. Participants were instructed to associate freely to the given stimulus words. The results of the polarity and sequence analysis of the associations provide a first valuable insight into the social representations of online privacy.</span></div></div><div class="paper" id="wp506"><a href="#wp506" class="title">Investigating Syntactic Alignment in Spoken Natural Language Human-Computer Communication</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979892&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Benjamin R. Cowan</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Russell  Beale</span> <span class="affiliation">The University of Birmingham</span>, <br />
<span class="author">Holly P. Branigan</span> <span class="affiliation">The University of Edinburgh</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper describes planned experiment-based research observing the existence of syntactic alignment in natural language computer interactions. This research will achieve this through using a computer-human version of the confederate communication task commonly used in psycholinguistic research observing syntactic alignment in human-human dialogue. The motivations of the work lie in observing the existence of syntactic alignment in human-computer dyads and how the naturalness of interaction affects the appearance of such a linguistic phenomenon. The work will also aim to identify how such a linguistic effect links to users&#8217; satisfaction and quality judgments of interaction.</span></div></div><div class="paper" id="wp524"><a href="#wp524" class="title">Mixing Psychology and HCI in Evaluation of Augmented Reality Mental Health Technology</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979898&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Maja  Wrzesien</span> <span class="affiliation">Universidad Polit&#233;cnica de Valencia</span>, <br />
<span class="author">Jean-Marie  Burkhardt</span> <span class="affiliation">Universit&#233; Paris Descartes</span>, <br />
<span class="author">Mariano  Alca&#241;iz Raya</span> <span class="affiliation">Universidad Polit&#233;cnica</span>, <br />
<span class="author">Cristina  Botella</span> <span class="affiliation">Universidad Jaume I</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent studies present Augmented Reality Exposure Therapy (ARET) as a potentially effective technology in the Mental Health (MH) field. This study evaluates the ARET system applied to treatment of cockroach phobia in a clinical setting. The results seem to show that the ARET system is useful in helping the therapist construct a therapeutic relationship with the client. ARET also produces a visible reduction in the clients&#8217; clinical measures. Possible implications in terms of future design and evaluation methodologies are discussed.</span></div></div><div class="paper" id="wp547"><a href="#wp547" class="title">A Fitt of Distraction: Measuring the Impact of Distracters and Multi-users on Pointing Efficiency</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979908&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Denis  Lalanne</span> <span class="affiliation">University of Fribourg</span>, <br />
<span class="author">Agnes  Lisowska Masson</span> <span class="affiliation">University of Fribourg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents the results of an experiment aimed at measuring the impact of the number of distracters and of co-located users on individual pointing efficiency. The experiment, performed with 20 users, is a variation of a Fitt&#8217;s Law test in which we incrementally augmented the number of distracters on the screen and the number of co-located users. The results show that the number of distracters clearly influences users&#8217; pointing performance. Further, it shows that users are more efficient at pointing items when they share the display with co-located users than when they are alone.</span></div></div><div class="paper" id="wp561"><a href="#wp561" class="title">What Do You See When You Interact with Friends Online? Face, Hand, or Canvas?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979911&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyle  Koh</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Hyunjoo  Song</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Daekyoung  Jung</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Bohyoung  Kim</span> <span class="affiliation">Seoul National University</span>, <br />
<span class="author">Jinwook  Seo</span> <span class="affiliation">Seoul National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">People use plethora of interactive remote conference tools for various tasks ranging from collaborative works to entertainment needs. The tasks are often distinguishable in terms of their types and users' usage patterns. We present a preliminary user study designed to explore the different usage patterns derived by performing different types of tasks. In this study, 18 people used an interactive remote conference tool for three types of tasks; Collaborative Creation, Cooperative Problem Solving, and Competitive Game Play with different screen configurations. We analyzed usage patterns using an eye-tracker as well as the result from post experimental questionnaire. We found that different tasks resulted in different gaze patterns. We also present an interesting finding on how users mistakenly report the use of the tool by contrasting the result with the questionnaire and eye-tracking log.</span></div></div><div class="paper" id="wp558"><a href="#wp558" class="title">Digital Mind Mapping: Innovations for Real-time Collaborative Thinking</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979910&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Honray  Lin</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Haakon  Faste</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the development of a new digital mind mapping tool for future research on interactive knowledge management systems, specifically with regard to real-time collaborative thinking. We have evaluated numerous existing mind mapping software applications, and performed ethnographic research with a variety of users, to develop a framework of principles to guide the design of future idea generation and management systems. Our findings indicate a rich opportunity space for digital mind mapping tools, particularly in the areas of facilitating collaboration and information storage and retrieval.</span></div></div><div class="paper" id="wp374"><a href="#wp374" class="title">Design Your Room: Adding Virtual Objects to a Real Indoor Scenario</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979851&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rui  N&#243;brega</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Nuno  Correia</span> <span class="affiliation">Universidade Nova de Lisboa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents an interior design application that uses photos from real indoor spaces and rooms as input. The user is encouraged to take a picture of a certain place and virtually reshape it with furniture, different colors, textures and materials. The system analyses the still image of the physical space through image processing and computer vision algorithms to detect the world orientation relative to the camera. Knowing this, it is possible to create a natural interface where objects are laid on the floor and pushed around as in real life.</span></div></div><div class="paper" id="wp627"><a href="#wp627" class="title">Programming on the Move: Design Lessons from IPRO</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979932&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Berland</span> <span class="affiliation">University of Texas at San Antonio</span>, <br />
<span class="author">Taylor  Martin</span> <span class="affiliation">University of Texas at Austin</span>, <br />
<span class="author">Tom  Benton</span> <span class="affiliation">University of Texas at Austin</span>, <br />
<span class="author">Carmen  Petrick</span> <span class="affiliation">University of Texas at Austin</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computer programming is often a stationary, solitary task; such tasks do not work well for most novices. This work describes the IPRO project that uses our 'Programming Standing Up' framework (PSU) to reframe programming as a mobile, social game. IPRO is a programming and simulation environment for iOS in which a learner programs a virtual robot to play soccer in a virtual space shared with her cohort. This work presents examples of secondary school students learning with IPRO. We then connect the examples to PSU design principles and evaluate those principles in terms of the examples.</span></div></div><div class="paper" id="wp630"><a href="#wp630" class="title">PMRI: Development of a Pictorial Mood Reporting Instrument</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979933&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Martijn  Vastenburg</span> <span class="affiliation">Delft University of Technology</span>, <br />
<span class="author">Natalia  Romero Herrera</span> <span class="affiliation">Delft University of Technology</span>, <br />
<span class="author">Daniel  Van Bel</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Pieter  Desmet</span> <span class="affiliation">Delft University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mood capturing techniques are being used in research settings (e.g., lab evaluation and experience sampling) and to facilitate mood communication in mediated interaction (e.g., instant messaging and blogging). Instruments currently available tend to be either limited in expression or overly demanding. In this paper we describe our work-in-progress on the development of PMRI, a rich and easy-to-use pictorial mood-reporting instrument.</span></div></div><div class="paper" id="wp632"><a href="#wp632" class="title">Evaluating a Social Media Application for Sustainability in the Workplace</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979935&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Lehrer</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Janani  Vasudev</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The goal of this research is to investigate the benefits of using a web-based social network to promote energy awareness, and influence energy-saving behavior of typical office workers. We propose that a social network integrated into the workplace environment &#8212; allowing people to track their own energy-related activities, to share this information, and to view and react to peers&#8217; activities &#8212; can take advantage of social influence to positively affect behavior. We are currently developing a prototype of such an application through iterative design. In the final phase of this work we will conduct experiments with a large number of subjects to test the ability of this application to influence attitudes and behaviors of office workers, and for providing a platform for commercial building operators to better communicate with occupants.</span></div></div><div class="paper" id="wp636"><a href="#wp636" class="title">Constructing Scientific Arguments with User Collected Data in Nomadic Inquiry</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979937&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Kuhn</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Brenna  McNally</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Clara  Cahill</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Chris  Quintana</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Elliot  Soloway</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mobile devices now enable students to engage in nomadic inquiry as they collect large amounts of data from the environment to answer scientific questions. To support them with constructing scientific arguments, we created CogniBits: a system designed for tablet devices that scaffolds students through creating scientific arguments with user-collected data. The system was iteratively designed with two students and seeks to address the additional challenges these opportunities bring to science inquiry.</span></div></div><div class="paper" id="wp570"><a href="#wp570" class="title">Constructing Virtual 3D Models with Physical Building Blocks</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979915&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ricardo  Jota</span> <span class="affiliation">Inesc-ID</span>, <br />
<span class="author">Hrvoje  Benko</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Constructing virtual 3D models typically requires specialized desktop modeling tools (e.g., CAD tools), which, while very powerful, tend to require a lot of precision, time, and expertise from the user. We present StereoBlocks, a system that combines a Kinect depth camera with 3D stereoscopic projector to allow the user to build complex virtual 3D models from available physical objects. By treating the camera information as a continuous 3D digitizer, we are able to capture the details of the real world and re-project virtual objects side-by-side to real objects. The user is able to visualize such mixed reality model through stereoscopic projected imagery tightly aligned with the real world. In our system, it is literally possible to build the entire virtual castle, using only a single physical brick piece. We discuss our prototype implementation and report on early feedback from the four users that evaluated our system.</span></div></div><div class="paper" id="wp655"><a href="#wp655" class="title">Senior Wellness: Practices of Community Senior Centers</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979946&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Young Seok  Lee</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Santosh  Basapur</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Shirley  Chaysinh</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Crysta  Metcalf</span> <span class="affiliation">Motorola Mobility Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In the U.S., approximately 15,000 community senior centers provide a broad spectrum of programs for seniors to increase their overall health and wellness in their community. Although previous studies reported on the various benefits of participation in such programs, little research has been conducted to understand how technology can support this practice. We initiated a research study to understand the current practices of senior centers and their potential technology needs. In this article, we describe findings from our literature review as well as a field study with nine senior centers located in urban and suburban areas of Chicago, IL, and Tampa, FL. Based on the preliminary results, we share design implications for future technology development.</span></div></div><div class="paper" id="wp439"><a href="#wp439" class="title">Effect of MobileASL on Communication Among Deaf Users</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979872&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joy  Kim</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jessica J Tran</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Tressa W Johnson</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Richard  Ladner</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Eve  Riskin</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">MobileASL, a software program enabling sign-language video on mobile devices over conventional U.S. cellular networks, was evaluated in a three-week field study during the summer of 2010. Through a series of interviews, questionnaires, and a focus group, we asked participants about their behavior with and perceptions of MobileASL. In addition, we used on-device experience sampling and usage logging to observe how MobileASL was used. Initial results indicate that although participants felt that MobileASL&#8217;s short battery life limited its use, participants took advantage of the mobility of the technology and used it for in-the-moment information gathering in places like buses, restaurants, and shopping areas.</span></div></div><div class="paper" id="wp588"><a href="#wp588" class="title">Towards a Psychographic User Model From Mobile Phone Usage</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979920&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rodrigo  de Oliveira</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Alexandros  Karatzoglou</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Pedro  Concejero Cerezo</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Ana  Armenta Lopez de Vicu&#241;a</span> <span class="affiliation">Telefonica Research</span>, <br />
<span class="author">Nuria  Oliver</span> <span class="affiliation">Telefonica Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Knowing the users&#8217; personality can be a strategic advantage for the design of adaptive and personalized user interfaces. In this paper, we present the results of a first trial conducted with the aim of inferring people&#8217;s personality traits based on their mobile phone call behavior. Initial findings corroborate the efficacy of using call detail records (CDR) and Social Network Analysis (SNA) of the call graph to infer the Big Five personality factors. On-going work includes a large-scale study that shall refine the accuracy of the models with a reduced margin of error.</span></div></div><div class="paper" id="wp450"><a href="#wp450" class="title">Mourning Tree : Space Interaction Design for the Commemoration Ceremony</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979876&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jihwan  Kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">seyong  kim</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">JINJU  YU</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Sangsup  Yoon</span> <span class="affiliation">KAIST</span>, <br />
<span class="author">Sangki  Han</span> <span class="affiliation">KAIST</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The aim of this project is to improve the current culture of cherishing the memory of a deceased person through a new approach over the traditional, a cyber commemoration method. Through a preliminary research, we defined two major problems of current commemoration ceremony: separation between traditional cherish and cyber cherish, immaturity of cyber cherish method. Therefore, we focused on making a new way of commemoration, &#8216;Mourning Tree&#8217;. Mourning Tree is a digital tree which is displayed by holographic technology, and the tree can receive messages from the cherisher in the many ways (SNS, SMS, e-mail). The message is displayed as a leaf of the tree, and the more messages this tree receives, the larger and more meaningful the tree becomes. Because of the exhibition of Mourning Tree in actual cherishing area, it can not only physically interact but virtually interact with the cherisher. We developed a prototype of the Mourning Tree and conducted an examination.</span></div></div><div class="paper" id="wp576"><a href="#wp576" class="title">Medical Record Privacy: Is it a Facade?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979918&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aubrey  Baker</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Laurian  Vega</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Tom  DeHart</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Steve  Harrison</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Part of the job of healthcare providers is to manage patient information. Most is routine, but some is sensitive. For these reasons physicians&#8217; offices provide a rich environment for understanding complex, sensitive information management issues as they pertain to privacy and security. In this paper we present findings from interviews and observations of 15 offices in rural-serving southwest Virginia. Our work demonstrates how the current socio-technical system fails to meet the security needs of the patient. In particular, we found that the tensions between work practice and security, and between electronic and paper records resulted in insecure management of files.</span></div></div><div class="paper" id="wp618"><a href="#wp618" class="title">Behavioral Science-Informed Technology Interventions for Change in Residential Energy Consumption</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979926&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew  Crowley</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Aur&#233;lia  Heitz</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Annika  Matta</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Kevin  Mori</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Banny  Banerjee</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Behavior change represents an important new approach to addressing the energy crisis.  Utility companies and private companies are deploying sensor-based power meters and related residential electricity monitoring technologies with the view that monitoring energy use will eventually result in a reduction in energy consumption.  The success of these technologies depends largely on homeowners responding to the data with appropriate changes in their consumption behavior. Most energy feedback interfaces, however, have not been designed through a human-centered process and display data in ways that are unlikely to change behavior.  Our proposal is to design interactive interfaces that combine a deeply human-centered process with insights from behavioral economics to reduce residential energy consumption.  This paper describes our current research to develop and evaluate interactive interfaces based on three motivational categories:  cognitive, social, and affective.</span></div></div><div class="paper" id="wp451"><a href="#wp451" class="title">Technology-Mediated Parent-Child Intimacy: Designing for Ecuadorian Families Separated by Migration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979877&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Marisol  Wong-Villacres</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Shaowen  Bardzell</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study explores the role technology plays in supporting long-distance relationships of migrant parents and left-behind children in developing countries such as Ecuador, in order to inform the design of technology that better suits their affective needs and their context&#8217;s constraints. We derived three design principles based on our fieldwork in Ecuador: shared experience, the empowerment of children to self-express and children&#8217;s need to safely build a private communication channel with their parents. We report our research findings and propose a set of design concepts for future work.</span></div></div><div class="paper" id="wp653"><a href="#wp653" class="title">Power Ballads: Deploying Aversive Energy Feedback in Social Media</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979944&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Derek  Foster</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Conor  Linehan</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Shaun  Lawson</span> <span class="affiliation">University of Lincoln</span>, <br />
<span class="author">Ben  Kirman</span> <span class="affiliation">University of Lincoln</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports on the pilot evaluation of &#8220;Power Ballads&#8221;, an evocative social media application which displays aversive feedback based on excessive household energy usage. Work by other researchers in persuasive technologies has previously suggested the use of aversive feedback should be avoided as it leads to a lack of engagement by users. This work evaluates whether punishment of non-desirable behaviour discourages users from engaging with a persuasive application. To this end we recruited 9 households to use the Power Ballads application over a period of 4 weeks. We found the use of aversive feedback did not act as a deterrent to regularly interacting with the application through evaluating user engagement.</span></div></div><div class="paper" id="wp611"><a href="#wp611" class="title">Interpersonal Informatics: Making Social Influence Visible</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979924&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Elizabeth  Bales</span> <span class="affiliation">University of California, San Diego</span>, <br />
<span class="author">William  Griswold</span> <span class="affiliation">University of California, San Diego</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Recent research in social network science has found that that what we do and say flows through our social network, impacting our friends, our friends&#8217; friends, and beyond. Likewise, our own personal choices are also the influenced by the social networks we participate in. We introduce the area of interpersonal informatics, a class of tools that allows groups of people to collect, aggregate, analyze, and share personally relevant information. The goal of interpersonal informatics is to  help people gain awareness of how those around them affect their habits, beliefs, and health.</span></div></div><div class="paper" id="wp642"><a href="#wp642" class="title">Evoked Friction on a Smooth Touch Device</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979939&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Creating realistic virtual friction forces requires using complex hardware setups. In simpler mobile systems, friction is often suggested by mimicking textures with vibration, based on the position on the screen. Even in the simplest implementations, this paper proposes that force sensing should also be used to modulate vibration. In this way, Coulomb&#8217;s model of friction can be better emulated and it can lead to conclude more easily that friction is the origin of the vibration. A proof-of-concept prototype is described, which received positive first impressions regarding improved user experience. A follow up study is warranted.</span></div></div><div class="paper" id="wp510"><a href="#wp510" class="title">Robotic Wheelchair Moving with Caregiver Collaboratively Depending on Circumstances</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979894&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yoshinori  Kobayashi</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Yuki  Kinpara</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Erii  Takano</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Yoshinori  Kuno</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">keiichi  Yamazaki</span> <span class="affiliation">Saitama University</span>, <br />
<span class="author">Akiko  Yamazaki</span> <span class="affiliation">Tokyo University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper introduces a robotic wheelchair that can automatically move alongside a caregiver. Because wheelchair users are often accompanied by caregivers, it is vital to consider how to reduce a caregiver&#129;fs load and support their activities, while simultaneously facilitating communication between the caregiver and the wheelchair user. Moreover, it has been pointed out that when a wheelchair user is accompanied by a companion, the latter is inevitably seen by others as a caregiver rather than a friend. To address this situation, we devised a robotic wheelchair able to move alongside a caregiver or companion, and facilitate easy communication between them and the wheelchair user. To confirm the effectiveness of the wheelchair in real-world situations, we conducted experiments at an elderly care center in Japan.</span></div></div><div class="paper" id="wp424"><a href="#wp424" class="title">A collective map to capture human behavior for the design of public spaces</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979866&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mizuki  Oka</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Tom  Hope</span> <span class="affiliation">Tokyo Institute of Technology</span>, <br />
<span class="author">Yasuhiro  Hashimoto</span> <span class="affiliation">The University of Tokyo</span>, <br />
<span class="author">Ryoko  Uno</span> <span class="affiliation">Tokyo University of Agriculture and Technology</span>, <br />
<span class="author">Myeong-Hee  Lee</span> <span class="affiliation">Design office matt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores potential uses of publicly created behavioral data for spatial (re)design. The widespread use of mobile devices and access to the Internet has made spontaneous sharing of information about one&#8217;s life increasingly common. These emerging trends of pervasive life logging and sensing in communal space provoke new opportunities for designers and architects. This paper reports on work in progress, introducing a set of tools to support spatial design via the collection and analysis of human behavior using Twitter, and presents the result of a workshop using the tools in a university library in Japan. We offer ways to analyze and visualize the data and discuss what we can observe from the collected data that may be useful for designing such communal spaces.</span></div></div><div class="paper" id="wp528"><a href="#wp528" class="title">How Revealing are Eye-Movements for Understanding Web Engagement in Young Children?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979900&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stacey  Birkett</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Adam  Galpin</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Simon  Cassidy</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Lynne  Marrow</span> <span class="affiliation">University of Salford</span>, <br />
<span class="author">Sarah  Norgate</span> <span class="affiliation">University of Salford</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents a critical review of eye tracking as a research approach and evaluates its potential for usability testing in pre-school children. We argue that eye-tracking data is useful for assessing web engagement in this age-group, but only if triangulated against other usability methods. Recommendations for potential usability methods to use in tandem with eye-tracking are presented as part of a work in progress within a joint partner project between the University of Salford (UK) and the British Broadcasting Corporation (BBC) exploring best-fit methodologies for understanding web engagement in young children.</span></div></div><div class="paper" id="wp657"><a href="#wp657" class="title">NICU-2-HOME: Supporting the Transition to Home from the Neonatal Intensive Care Unit using a Mobile Application</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979947&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Young Seok  Lee</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Craig  Garfield</span> <span class="affiliation">NorthShore University HealthSystem</span>, <br />
<span class="author">Noel  Massey</span> <span class="affiliation">Motorola Solutions Inc.</span>, <br />
<span class="author">Shirley  Chaysinh</span> <span class="affiliation">Motorola Mobility Research</span>, <br />
<span class="author">Sana  Hassan</span> <span class="affiliation">Motorola Mobility Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Parenting a Very Low Birth Weight (VLBW) premature infant in the Neonatal Intensive Care Unit (NICU) and transitioning this infant home can be very stressful for parents. Few studies, however, examined the needs of parents of VLBW infants during the transition to home; moreover, even less is known about information and communication technology strategies to support parents during the transition period. To address this knowledge gap, we are conducting a study that aims to develop a mobile application/service to support the parents of VLBW infants by enhancing communication with the NICU staff and access to information resources. We report findings from our preliminary study using contextual inquiry and phone interviews and discuss implications for system development.</span></div></div><div class="paper" id="wp543"><a href="#wp543" class="title">STORIFY- A Tool to Assist Design Teams in Envisioning and Discussing User Experience</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979905&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Berke  Atasoy</span> <span class="affiliation">Eindhoven University of Technology</span>, <br />
<span class="author">Jean-Bernard  Martens</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Design is changing into an experience-oriented discipline; consequently designers need appropriate tools and methods to incorporate experiential aspects into their designs. A story is a crafted experience and storytelling is the craft. Therefore, understanding the structural strategies behind storytelling and learning how to incorporate them into a design process is relevant for designers when they want to envision, discuss and influence user experiences. In this paper we introduce STORIFY, a multi-modal tool to provide design teams with an experiential approach towards designing interactive products by incorporating dramaturgical techniques from film and sequential art.</span></div></div><div class="paper" id="wp415"><a href="#wp415" class="title">Context Stamp -  A Topic-based Content Abstraction for Visual Concordance Analysis</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979906&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">VinhTuan  Thai</span> <span class="affiliation">National University of Ireland, Galway</span>, <br />
<span class="author">Siegfried  Handschuh</span> <span class="affiliation">National University of Ireland, Galway</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Concordance analysis supports users in studying how terms are used in a document vs. another by investigating their usage contexts. As current approaches usually present a large set of contexts in their full text form or as a large frequency-based word cloud, they still require a lot of effort from users to make sense of the underlying complex and dynamic semantic dimensions of contexts. To address this limitation, we propose Context Stamp as a visual representation of the gist of a term's usage contexts. To abstract away the textual details and yet retain the core facets of a term's contexts for visualization, we blend a statistical topic modeling method with a combination of the treemaps and Seesoft visual metaphors. This paper provides a high level description of the text analysis method and outlines the visual design of Context Stamps.</span></div></div><div class="paper" id="wp652"><a href="#wp652" class="title">The Effects of Walking and Control Method on Pressure-Based Interaction</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979943&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Graham  Wilson</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Stephen A. Brewster</span> <span class="affiliation">University of Glasgow</span>, <br />
<span class="author">Martin  Halvey</span> <span class="affiliation">University of Glasgow</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pressure-based interactions have largely been limited to static scenarios; very few have focused on its use on mobile devices and even fewer have investigated the use of pressure while the user is in motion (i.e. walking). Pressure input is well suited to mobile interaction as mobile devices almost universally adopt touch and gestural input. This paper presents the initial results of research looking into the effects of walking on the application of pressure during linear targeting. Positional and rate-based (velocity) control methods are compared in order to determine which allows for more stable and accurate selections. Results suggest that rate-based control is superior for both mobile (walking) and static (sitting) linear targeting and that mobility significantly increases errors, selection time and subjective workload. These results will influence the design of a second part of the study, which will evaluate user ability to control the same application using only audio feedback.</span></div></div><div class="paper" id="wp376"><a href="#wp376" class="title">Flick-and-Brake: Finger Control over Inertial/Sustained Scroll Motion</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979853&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathias  Baglioni</span> <span class="affiliation">Telecom ParisTech - LTCI-CNRS, Alcatel Lucent Bell Labs</span>, <br />
<span class="author">Sylvain  Malacria</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span>, <br />
<span class="author">Eric  Lecolinet</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span>, <br />
<span class="author">Yves  Guiard</span> <span class="affiliation">Telecom ParisTech- LTCI-CNRS</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present two variants of Flick-and-Brake, a technique that allows users to not only trigger motion by touch-screen flicking but also to subsequently modulate scrolling speed by varying pressure of a stationary finger. These techniques, which further exploit the metaphor of a massive wheel, provide the user with online friction control. We describe a finite-state machine that models a variety of flicking interaction styles, with or without pressure control. We report the results of a preliminary user study that suggests that for medium to long distance scrolling the Flick-and-Brake techniques require less gestural activity than does standard flicking. One of the two variants of the technique is faster, but no less accurate, than state-of-the-art flicking. Users also reported they preferred Flick-and-Brake over the standard flick and judged it more efficient. We indicate some pending issues raised by the results of this preliminary investigation.</span></div></div><div class="paper" id="wp626"><a href="#wp626" class="title">Retirees on Facebook: Can Online Social Networking Enhance Their Health and Wellness?</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979931&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">S. Shyam  Sundar</span> <span class="affiliation">The Pennsylvania State University, Sungkyunkwan University</span>, <br />
<span class="author">Anne  Oeldorf-Hirsch</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">Jon  Nussbaum</span> <span class="affiliation">The Pennsylvania State University</span>, <br />
<span class="author">Richard  Behr</span> <span class="affiliation">The Pennsylvania State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An individual&#8217;s social network has a strong impact on his or her mental and physical health. This is of particular consequence for senior citizens who are at greater risk of social isolation after retirement, due to loss of spouse, mobility issues, and recent emphasis on aging in place, i.e., in smart homes. Can online social networking sites (SNSs) such as Facebook help alleviate social isolation of aging alone by enabling seniors to maintain high-quality social interactions? How can we make senior-friendly design improvements to SNSs? A preliminary national survey (N =168) of adults over 55 revealed that for those who had joined an SNS, the primary motivation cited for signing up was persuasion by a friend or family member, while non-users cited a strong lack of interest rather than a lack of knowledge or skill, with implications for theory and design of SNS technology for senior citizens.</span></div></div><div class="paper" id="wp625"><a href="#wp625" class="title">Multimodal Video Annotation for Contemporary Dance Creation</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979930&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diogo  Cabral</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Ur&#226;ndia  Carvalho</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Jo&#227;o  Silva</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Jo&#227;o  Valente</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Carla  Fernandes</span> <span class="affiliation">Universidade Nova de Lisboa</span>, <br />
<span class="author">Nuno  Correia</span> <span class="affiliation">Universidade Nova de Lisboa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents a video annotator that supports multimodal annotation and is applied to contemporary dance as a creation tool. The prototype, developed for Tablet PCs, explores bimanual interaction, using pen and touch input interfaces. This combination can be more natural and familiar than the traditional input interfaces (keyboard or mouse). Contemporary dance is a domain where this type of flexible interaction with video material is relevant in order to augment and improve the rehearsal and creative processes. Motion tracking is used to define the dynamic behavior of the annotations and voice input complements the other modalities. The paper describes the design decisions done by the multidisciplinary development team and the current status of the tool.</span></div></div><div class="paper" id="wp448"><a href="#wp448" class="title">Blink: Observing Thin Slices of Behavior to Determine Users&#8217; Expectation Towards Task Difficulty</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979875&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nuno  Branco</span> <span class="affiliation">School of Technology and Management of Felgueiras</span>, <br />
<span class="author">Jo&#227;o Pedro  Ferreira</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Marta  Noronha e Sousa</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Pedro  Branco</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Nuno  Otero</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Nelson  Zagalo</span> <span class="affiliation">University of Minho</span>, <br />
<span class="author">Manuel Jo&#227;o  Ferreira</span> <span class="affiliation">University of Minho</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This work aims to address the following question: is it possible to infer the users' expectations regarding task difficulty by watching them just before the actual start?  <br /> We present a study where people acting as evaluators determined users&#8217; expectations based on non-linguistic social signals in a 20 seconds video clip. The evaluations were performed using a five-point scale and the average error of the evaluations was of one point. Preliminary results suggest what type of signals was used by the evaluators to determine the users&#8217; expected difficulty with the task.</span></div></div><div class="paper" id="wp545"><a href="#wp545" class="title">CheMO: Mixed Object Instruments and Interactions for Tangible Chemistry Experiments</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979907&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Kyohyun  Song</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Gunhee  Kim</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Inkyu  Han</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Jeongyoung  Lee</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Ji-Hyung  Park</span> <span class="affiliation">Korea Institue of Science and Technology</span>, <br />
<span class="author">Sungdo  Ha</span> <span class="affiliation">Korea Institue of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we present CheMO, a system for tangible chemistry experiments where users can interact with Mixed Object (MO) instruments that consist of a graspable physical part in the real world and a digital part in a virtual world. When used for an experiment, MO instruments enable users to employ tangible interaction methods inherited from real experience and to be given digital information similar to a physical expression arising from an actual experiment. The goal of our research is to enhance the sense of reality in a virtual experiment and to enable users to learn experimental procedures effectively and easily.</span></div></div><div class="paper" id="wp601"><a href="#wp601" class="title">TweetSpiration: Leveraging Social Media for Design Inspiration</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979923&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Scarlett R Herring</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Christina M Poon</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Geoffrey A Balasi</span> <span class="affiliation">University of Illinois at Urbana Champaign</span>, <br />
<span class="author">Brian P Bailey</span> <span class="affiliation">University of Illinois at Urbana Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present TweetSpiration, a Web-based application that leverages social media to inspire new search directions on the Web. TweetSpiration can be used at any time, but it is particularly beneficial when designers have difficulty developing new search terms or are looking for new search directions. By visualizing socially derived word associations, designers may develop new search directions based on others comments or thoughts on the search topic. In an initial study, users reported that TweetSpiration helps develop new search directions and provides new perspectives on the design problem.</span></div></div><div class="paper" id="wp388"><a href="#wp388" class="title">An Investigation of Search Behaviour in a Tactile Exploration task for Sighted and Non-sighted Adults.</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979857&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Luca  Brayda</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Claudio  Campus</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Ryad  Chellali</span> <span class="affiliation">Italian Institute of Technology</span>, <br />
<span class="author">Guido  Rodriguez</span> <span class="affiliation">University of Genoa</span>, <br />
<span class="author">Cristina  Martinoli</span> <span class="affiliation">Istituto David Chiossone onlus</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this work in progress we propose a new method for evaluating objectively the process of performing a tactile exploration with a visuo-tactile sensory substitution system. Both behavioral and neurophysiological cues are considered to evaluate the identification process of virtual objects and surrounding environments. Our experiments suggest that both sighted and visually impaired users integrated spatial information and developed similar behavioural and neurophysiological patterns. The proposed method could also serve as a tool to evaluate touch-based interfaces for application in orientation and mobility programs.</span></div></div><div class="paper" id="wp391"><a href="#wp391" class="title">Information Used and Perceived Usefulness in Evaluating Web Source Code Search Results</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979858&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rosalva E Gallardo-Valencia</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Susan E Sim</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Software developers frequently search for source code on the Web to solve problems. Their ability to correctly evaluate the matches returned by a source code search engine is key to the success of the search, and in turn the project. We conducted a laboratory experiment to gain understanding on the kinds of information used and their usefulness during the evaluation process. We found that the most used information was not perceived as the most useful information. We also identified three patterns for relationships among the frequency of information use, the likelihood of selecting the best match, and the time to complete a task.</span></div></div><div class="paper" id="wp446"><a href="#wp446" class="title">Tangible and Body-Based Interaction with Auditory Maps</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979874&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew P Milne</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Alissa N Antle</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Bernhard E Riecke</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Blind people face a significant challenge navigating through the world, especially in novel environments. Maps, the most common of navigational aids, are of little use to the blind, who could benefit greatly from the information they contain. Recent work in auditory maps has shown the potential for delivering spatial information through sound.  Users control their position and orientation on a digitally enhanced map and listen for the location of important landmarks. Orientation control is important because sound localization cues can sometimes be ambiguous, especially when in front of and behind a listener. Previous devices have used a tangible interface, in which users manipulate a small motion tracked object, to allow users to control their position and orientation on a map. Motivated by research that has identified the importance of body-based cues, from the joints, muscles and vestibular system in spatial perception, we expanded on previous interfaces by constructing an auditory map prototype that allows users to control their orientation through natural head movements. A pilot study was conducted to compare the head-movement-based interface to a tangible interface.</span></div></div><div class="paper" id="wp442"><a href="#wp442" class="title">ScaleMirror: A Pervasive Device to Aid Weight Analysis</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979873&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew J Younge</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Vinod  Periasamy</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Mohammed  Al-Azdee</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">William  Hazlewood</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Kay  Connelly</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">As today&#8217;s fast paced environment continually encourages poor dietary habits and a lack of exercise, there is a growing need to properly monitor and control weight gain.  With the advent of pervasive and ubiquitous computing, there are new opportunities to help promote personal wellness that was previously unobtainable.  This work describes the novel design and creation of ScaleMirror; a prototype pervasive device to help users monitor their weight.  This awareness is achieved through an accurate scale system, detailed statistics with historical data, and an intuitive design seamlessly embedded into a user&#8217;s existing daily routine.  The goal is to help a wide array of people concentrate on obtaining and maintaining a proper weight to promote a healthy and fulfilling lifestyle.</span></div></div><div class="paper" id="wp621"><a href="#wp621" class="title">CAESSA: Visual Authoring of Context-Aware Experience Sampling Studies</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979928&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mirko  Fetter</span> <span class="affiliation">University of Bamberg</span>, <br />
<span class="author">Maximilian  Schirmer</span> <span class="affiliation">Bauhaus-University Weimar</span>, <br />
<span class="author">Tom  Gross</span> <span class="affiliation">University of Bamberg</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present a toolkit that enables HCI practitioners to visually author and setup Context-Aware Experience Sampling studies&#8212;CAESSA (Context-Aware Ex-perience Sampling Study Authoring).</span></div></div><div class="paper" id="wp631"><a href="#wp631" class="title">Integrating Touch and Near Touch Interactions for Information Visualizations</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979934&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aras  Balali Moghaddam</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Jeremy  Svendsen</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Melanie  Tory</span> <span class="affiliation">University of Victoria</span>, <br />
<span class="author">Alexandra  Branzan Albu</span> <span class="affiliation">University of Victoria</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper proposes a novel interaction paradigm for multi-touch interfaces, that integrates both touch and near-touch interactions. The paper describes the hardware prototype that we have built, as well as the computer vision approach that we propose for real-time hand tracking and differentiation between near-touch and touch events. We also present a case study showing how near-touch and touch interactions can be successfully integrated in an information visualization application.</span></div></div><div class="paper" id="wp643"><a href="#wp643" class="title">Supporting greater access to pre- and post-natal information and services for women in rural Kenya</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979940&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jakita  Thomas</span> <span class="affiliation">Spelman College</span>, <br />
<span class="author">Yolanda  Rankin</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Matthew  Tuta</span> <span class="affiliation">University of Nairobi</span>, <br />
<span class="author">Eric  Mibuari</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present initial findings of on-going work, which <br /> examine pre- and post-natal services available to <br /> women in rural Laare, Kenya as well as cell phone <br /> appropriation by service providers and consumers as <br /> initial steps in service design for access.</span></div></div><div class="paper" id="wp533"><a href="#wp533" class="title">Data Type Based Security Alert Dialogs</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979903&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Max-Emanuel  Maurer</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Alexander  De Luca</span> <span class="affiliation">University of Munich</span>, <br />
<span class="author">Heinrich  Hussmann</span> <span class="affiliation">University of Munich</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Making users aware of insecure situations and behavior while browsing the Internet is a highly discussed and still difficult task. Both, passive and active warnings have their own specific disadvantages. While active warnings interrupt the current task and annoy the user, passive approaches often fail since they go unnoticed. In this work, we present first results of a concept displaying data type based alert dialogs whenever a user enters critical information into an online form. Such contextual dialogs appear right in the users&#8217; field of view representing a hybrid approach between active and passive warnings. An initial user study was conducted that showed a significant improvement of security awareness by participants that used the tool.</span></div></div><div class="paper" id="wp381"><a href="#wp381" class="title">Towards Context-Sensitive Support of Vitality in Old-Age</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979854&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominik  Jednoralski</span> <span class="affiliation">Max Planck Institute</span>, <br />
<span class="author">Michael  Schellenbach</span> <span class="affiliation">Max Planck Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Over the the last century, the average lifespan extended remarkably. The economic and social implications of living longer are vast, and include offering new prospects to make latent potential in old age accessible both to senior citizens and to society. <br /> Growing evidence suggests that the brain retains its capability to change from experience into old age, a finding that encourages targeting the elderly for interventions such as physical activity which is known to impact cognitive and neural decline. In this work we suggest intervening on the basis of these findings by means of intelligent assistive technology. Therefore, we propose a system architecture for a mobile context-aware cognitive assistant (CACA) to assess and enhance cognitive functioning of older individuals. In our view, tailored context-aware assistance can activate latent physical and cognitive potential through a combination of challenge and support, aimed at enhancing individual motivation to pursue a sustainable lifestyle.</span></div></div><div class="paper" id="wp647"><a href="#wp647" class="title">What Would the Parents Like to Know About Children but are Afraid to Ask?: Designing Reports about Child Development in Online Games</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979942&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karolina  Chmiel</span> <span class="affiliation">Institute for Information Processing</span>, <br />
<span class="author">Agnieszka  Matysiak Szostek</span> <span class="affiliation">Institute for Information Processing</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Nowadays educational games constitute a large part of <br /> the learning environment. These interactive forms of <br /> education enable children to develop various <br /> competencies and also provide feedback depicting their <br /> strengths and shortcomings. Currently, portals offering <br /> educational games provide such feedback mainly to <br /> children. Surprisingly, a parent, who is responsible for a <br /> proper development and education of a child, is usually <br /> not included as a recipient of information about the <br /> child&#8217;s results tested through games. Therefore, the <br /> goal of this preliminary study was to investigate the <br /> informational needs of the parents that can be applied <br /> to educational online games for children of age 6&#8212;9.</span></div></div><div class="paper" id="wp461"><a href="#wp461" class="title">Gathering Requirements for a Personal Health Management System</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979881&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Milewski</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Hector  Parra</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Applications are being designed to make health information available to the healthcare consumer. However, little is known about the support people need in using health information. We conducted semi-structured interviews to find out how people use health information to manage the chronic illness type-2 diabetes. We found that diabetics want to be motivated to treat the disease seriously and that the patient&#8217;s social network takes on additional work that is unrelated to their existing social role to support the patient&#8217;s health-related activities. Based on our findings, we propose a set of formative requirements to be included in the design of a personal health management system.</span></div></div><div class="paper" id="wp565"><a href="#wp565" class="title">Tag Clouds and Keyword Clouds: Evaluating Zero-Interaction Benefits</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979913&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mathew J Wilson</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">Max L Wilson</span> <span class="affiliation">Swansea University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Tag clouds are typically presented so that users can actively utilize community-generated metadata to query a collection. This research investigates whether such keyword clouds, and other interactive search metadata, also provide measureable passive support for users who do not directly interact with them. If so, then objective interaction-based measurements may not be the best way to evaluate these kinds of search user interface features. This paper discusses our study design, and the insights provided by a pilot study that led to a series of improvements to our study design.</span></div></div><div class="paper" id="wp568"><a href="#wp568" class="title">Causal Temporal Order in HCI</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979914&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Adam  Darlow</span> <span class="affiliation">Brown University</span>, <br />
<span class="author">Gideon  Goldin</span> <span class="affiliation">Brown University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper proposes applying principles of human causal reasoning to graphical interface design to make interfaces more intuitive. In particular, we present a design guideline for making graphical interfaces consistent with causal temporal order and demonstrate its effectiveness in an experiment where participants solve a puzzle with a novel interface. We also present preliminary results of its application to a text formatting task and propose several other causal principles that are directly applicable to interface design.</span></div></div><div class="paper" id="wp818"><a href="#wp818" class="title">Multi-touch Screens for Navigating 3D Virtual Environments in Participatory Urban Planning</a>&nbsp;-&nbsp;<span class="type">Works In Progress</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979852&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Emma  Chow</span> <span class="affiliation">Concordia University</span>, <br />
<span class="author">Amin  Hammad</span> <span class="affiliation">Concordia University</span>, <br />
<span class="author">Pierre  Gauthier</span> <span class="affiliation">Concordia University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Global trends have seen a strong push for more effective participatory planning in democratic societies.  Effective communication and universal accessibility are underpinning principles of successful participatory planning.  Virtual environments (VEs) have proven to significantly improve public understanding of 3D planning data.  This paper will evaluate multi-touch screens as a 3D VE navigation device for the general public in a participatory planning context.  The interactivity of multi-touch technology may better engage participants and improve their understanding of planning policies and proposed projects.  With the recent proliferation of multi-touch technology in the personal device market, there is great potential for expanding accessibility of participatory planning applications.</span></div></div><div class="paper" id="sd174"><a href="#sd174" class="title">Face-back: Who is the Illiterate Again?</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979503&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hoda A. Hamouda</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Mariam M. Hussein</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Mohamed H. Sharaf-El Deen</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Nermeen M. Abdel-Aziz</span> <span class="affiliation">German University in Cairo</span>, <br />
<span class="author">Shady M. Hanna</span> <span class="affiliation">German University in Cairo</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mutual respect and appreciation are the keys for integrating different groups into the society. We address in our work the special case of illiterate craftsmen in Egypt. Our research has shown that due to the illiteracy, they are excluded from the social mainstream, while paradoxically, we felt as illiterates in their world. Current solutions and services do not provide a two-way communication between illiterate and literate people that would help closing the gap. Face-back is a service that aims at bringing both worlds together by taking away the anonymity that leads to stereotypical ways of thinking.</span></div></div><div class="paper" id="sd212"><a href="#sd212" class="title">Entrust: Connecting Low-Income HIV+ Individuals with Health Care Providers</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979509&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Clifford  Gentry</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Marisol Martinez  Martinez Escobar</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Philip  Vander Broek</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Douglas  Choi</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Stefan  Ganchev</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Individuals infected with Human Immunodeficiency Virus (HIV) face numerous stigmatizations and challenges, specifically with the maintenance and adherence to their medical regimen. This situation is further complicated when individuals lack monetary resources to maintain their overall wellbeing. This paper presents Entrust, a service that provides low-income HIV positive individuals (clients) with cellphones to communicate with their health care providers. The cellphone is used to foster consistent and effective communication between clients and case managers, and client compliance is motivated by free phone minutes. In this way, Entrust facilitates a higher quality of life for low-income HIV positive individuals.</span></div></div><div class="paper" id="sd180"><a href="#sd180" class="title">Cowabunga!: A System to Facilitate Multi-Cultural Diversity through CouchSurfing</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979506&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sujoy Kumar  Chowdhury</span> <span class="affiliation">Missouri Western State University</span>, <br />
<span class="author">Jody  Wynn</span> <span class="affiliation">Missouri Western State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many organizations endeavor to promote diversity through their ideals and goals. Couchsurfing.org (CS) has a large presence in that realm. They have made it their mission to &#8220;create inspiring experiences: cross-cultural encounters that are fun, engaging and illuminating&#8220;. However, even in this presumably open-minded community the participants are often advised by experienced couchsurfers (CSers) to filter their couch-searches within homogenous members to increase response rates. It is human nature to interact with people similar in values and belief systems. We propose Cowabunga!, a mobile application which augments multi-cultural exchanges instigated by CS. By facilitating chance meetings that would not happen otherwise, our solution is helping people get spontaneous exposure to others with whom they may have nothing in common except their CS membership.</span></div></div><div class="paper" id="sd168"><a href="#sd168" class="title">ViTu: A System to Help the Mexican People to Preserve and Celebrate their Culture.</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979502&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">M&#243;nica Isabel Gonz&#225;lez</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span>, <br />
<span class="author">Emilio  S&#225;nchez</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span>, <br />
<span class="author">Edgar  de los Santos</span> <span class="affiliation">Universidad Tecnol&#243;gica de la Mixteca</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">ViTu is the entire development of a system focused on <br /> appreciating and highlighting the culture and traditions <br /> of native Mexican communities. It also contributes <br /> towards preserving and regaining the lost Mexican <br /> roots of the Mexican-Americans living in the United <br /> States. To achieve this, a culture, customs and <br /> traditions storage device of the Mexican village of San <br /> Jeronimo Silacayoapilla, was created. The main <br /> objective of this system is to encourage people to love <br /> and be proud of their cultural roots through technology. <br /> We are confident that this project will not only highlight <br /> the lifestyle of the native communities in Mexico but it <br /> will raise awareness on the importance of sharing, <br /> celebrating and appreciating our differences.</span></div></div><div class="paper" id="sd202"><a href="#sd202" class="title">SignBright: A Storytelling Application to Connect Deaf Children and Hearing Parents</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979508&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Chad  Harbig</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Melissa  Burton</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Mariam  Melkumyan</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Lei  Zhang</span> <span class="affiliation">Iowa State University</span>, <br />
<span class="author">Jiyoung  Choi</span> <span class="affiliation">Iowa State University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Deaf children of hearing parents face many unique challenges that have been shown to adversely impact their interpersonal interactions and development. Contemporary research indicates that many of these challenges stem from environmental factors, including a lack of exposure to language concepts during early developmental stages. In this paper, we will present an innovative solution to foster connection and understanding between deaf children and hearing parents, SignBright. In addition, SignBright promotes acquisition of sign language skills by hearing parents and deaf children, providing greater opportunities for interfamilial dialogue and bonding, and promoting development of social and linguistic competencies. <br /></span></div></div><div class="paper" id="sd128"><a href="#sd128" class="title">DiversIT: Inspiring Communication about Individuals' Differences</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979500&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Timothy  Ekl</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Tianyi  Gao</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Sarah  Jabon</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Joseph  Salisbury</span> <span class="affiliation">Rose-Hulman Institute of Technology</span>, <br />
<span class="author">Eric  Stokes</span> <span class="affiliation">Rose-Hulman Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The world is a mosaic of unique individuals. It is easy, however, to take people's differences for granted. Many people have stereotypes and perceptions of others that conceal the truth about differences between them. In order to help people appreciate differences about one another, we designed DiversIT, which facilitates communication between all people by leveraging the power of the Internet. By centering discussion on a daily question, DiversIT establishes common ground through which people can begin interacting. This increased communication can lead to an improved understanding of each other. DiversIT was developed with user-centered design processes, incorporating potential users into every part of the design process.</span></div></div><div class="paper" id="sd137"><a href="#sd137" class="title">Interactive Therapy Gloves: Reconnecting Partners After a Stroke</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979501&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">James  Hallam</span> <span class="affiliation">Emily Carr University of Art and Design</span>, <br />
<span class="author">Vanessa  Whiteley</span> <span class="affiliation">Emily Carr University of Art and Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the challenges that affect long-term partners after one of them suffers from a stroke, and offers a design solution as part of the CHI 2011 Student Design Competition. The challenge posed was to create a design that would help us to appreciate and celebrate our differences through the novel use of technology. We examined the changes that both partners go through during the recovery period after a stroke. We then designed an interactive glove as part of the rehabilitation process. The intent was to foster acceptance of each partner&#8217;s contribution and to help them reconnect. This paper details the iterative design process involved.</span></div></div><div class="paper" id="sd179"><a href="#sd179" class="title">TimeCapsule: Connecting Past</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979505&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yikun  Liu</span> <span class="affiliation">Indiana University School of Informatics</span>, <br />
<span class="author">Haidan  Huang</span> <span class="affiliation">Indiana University School of Informatics</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our world is changing at an ever-growing rate. The tide of urbanization and globalization has resulted in population migration that consequentially separates people from what is familiar to them. To combat this issue, we propose TimeCapsule. TimeCapsule is a social networking community intending to reserve, organize, share and utilize personal and collective memories by members of the community contributing location-related digitalized materials. Two clients will be designed to meet two kinds of usage: Mobile and Desktop. The mobile application will provide real-time old and new street view fusion in order to facilitate the user experience of appreciating the change in one location.  The desktop client will help users organize and share personal and group memories. Special consideration for seniors will be addressed.   <br /> By utilizing a connection to our past, we hope this initiative will help us to position ourselves to better appreciate the disparity between cultures and generations, thus unifying us.  <br /></span></div></div><div class="paper" id="sd225"><a href="#sd225" class="title">Lingua: Cultural Exchange Through Language Partnerships</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979510&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Caitlin  Holman</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Jane  Leibrock</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Jose  Jimenez</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Daniel  Greitzer</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Tom  Haynes</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Language barriers prevent people from communicating directly and are often a reflection of larger cultural divisions that hinder connection. Exposure to foreign languages and cultures through travel can help bridge this divide, but is not always feasible given time and monetary constraints. Language exchange partnerships are an excellent way to learn a new language, but are often difficult to maintain due to lack of common ground between partners and the absence of supporting materials. We present Lingua, a system to connect individuals with different linguistic backgrounds, and provide them a digital space tailored to support language learning through conversation with a partner. Their dialogue is driven in part by the application&#8217;s support for using shared multimedia to offer examples of their respective cultures.</span></div></div><div class="paper" id="sd183"><a href="#sd183" class="title">Sharing the Knowledge</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979507&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dustin  York</span> <span class="affiliation">Art Center College of Design Massachusetts Institute of Technology</span>, <br />
<span class="author">Zhengxin  Xi</span> <span class="affiliation">Art Center College of Design</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sharing the Knowledge is a community literacy learning system for implementation in the isolated regions of a developing nation. The project is a set of designed interactions that enables a collaborative social effort in creating and understanding educational materials, as means of compensation for the general lack of access to formal education and trained educators. The user-generated media is used for mobile learning applications and for creating social gaming incentives.</span></div></div><div class="paper" id="sd107"><a href="#sd107" class="title">The Design Process of iConnect: Social Advice Application</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979499&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shane  Wachirawutthichai</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Nisha  Singh</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Ramji  Enamuthu</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Yun  Zhou</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With Google [9] having established itself as the de-facto standard for document search and retrieval, the focus has shifted recently to the domain of social search. Morris et al. [12] define social search as &#8220;the process of finding information online with the assistance of social resources such as friends or unknown persons&#8221;. A number of online services [1, 2, 3, 4, 5] have been created to enable social search. But most of these are not useful when a person is mobile and offline and when the information need is highly context-specific. To enable social search in such situations, we introduce iConnect, the social advice application for mobile phones. iConnect is designed to enable a unique kind of social search, where an iConnect user is connected to other iConnect users in the same geographic region or locality. This would help people to solve their daily information needs. This paper illustrates the design process that we employed to conceptualize and prototype this application.</span></div></div><div class="paper" id="sd177"><a href="#sd177" class="title">Foodmunity: Designing Community Interactions over Food</a>&nbsp;-&nbsp;<span class="type">Student Design Competition</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979504&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shad  Gross</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Austin  Toombs</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Jeff  Wain</span> <span class="affiliation">Indiana University</span>, <br />
<span class="author">Kevin  Walorski</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Communities contain a rich diversity of backgrounds, personal experiences, and viewpoints. Fortunately, online social networks can make it even easier for people within a community to meet each other. This leads to an opportunity space for exposing people to the differences of their neighbors through mutual interaction. Our study presents Foodmunity, a social networking site that facilitates the organization of food-related events by members of a community. Meeting over a meal provides a more comfortable environment for experiencing new ideas, new people, and new viewpoints. Foodmunity utilizes themed events based on personal experiences its users have with food. This serves as both a cultural representation of those individuals and as a method of bonding between neighbors. By encouraging its users to reflect on the experiences they want to share and the experiences they have attending others&#8217; events, our system facilitates the growth of communities and a deeper understanding of the differences within.</span></div></div></td>
<td colspan="13" class="session_details" id="S1245_details"><div class="paper" id="sp107"><a href="#sp107" class="title">Social Impact Award: Technology, Diversity, Flexibility</a>&nbsp;-&nbsp;<span class="type">Special Events</span><div class="authors"><span class="author">Clayton  Lewis</span> <span class="affiliation">University of Colorado</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Technology offers huge advantages for people whose needs and occasions differ from the "typical". The potential comes from a wealth of new ways to interact with information and people. Realizing the potential requires flexibility: making it possible for people to choose the tools that best meet their needs and preferences. Technology has vital role to play in enabling this flexibility, as well as in supporting underlying diversity. The CHI community is in, and needs to be in, all of this.</span></div></div></td>
<td colspan="13" class="session_details" id="S1242_details"><div class="sessionChair"><strong>Session Chair: </strong>Amanda Williams (<em>University of California, Irvine</em>)</div><div class="paper" id="al166"><a href="#al166" class="title">Welcome to the Jungle: HCI After Dark</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979630&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christine  Satchell</span> <span class="affiliation">Queensland University of Technology / The University of Melbourne</span>, <br />
<span class="author">Marcus  Foth</span> <span class="affiliation">Queensland University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The transformation of urban spaces that occurs once darkness falls is simultaneously exhilarating and menacing, and over the past 20 months we have investigated the potential for mobile technology to help users manage their personal safety concerns in the city at night. Our findings subverted commonly held notions of vulnerability, with the threat of violence felt equally by men and women.  But while women felt protected because of their mobile technology, men dismissed it as digital Man Mace.  We addressed this macho design challenge by studying remote engineers in outback Australia to inspire our personal safety design prototype MATE.</span></div></div><div class="paper" id="al118"><a href="#al118" class="title">Action Role Design and Observations in a Gestural Interface-based Collaborative Game</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979631&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wooi-Boon  Goh</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">  Fitriani</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Chun-Fan  Goh</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Jacquelyn  Tan</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Monica  Menon</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Libby  Cohen</span> <span class="affiliation">National Institute of Education</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper explores the design of action roles for children playing an animal character-based collaborative game with gestural-sensitive tangible user interfaces. Based on trial runs with two inclusive groups of participants with mixed age and learning abilities, we report preliminary case study observations of the collaborative play behaviors solicited by the different interaction design patterns associated with the manner in which the action roles were distributed and coupled.</span></div></div><div class="paper" id="al116"><a href="#al116" class="title">TaPS Widgets: Tangible Control over Private Spaces on Interactive Tabletops</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979632&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Max  M&#246;llers</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Ray  Bohnenberger</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Stephan  Deininghaus</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Patrick  Zimmer</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Karin  Herrmann</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Private areas are important in multi-user tabletop systems, but hard to implement with current technology. Existing approaches usually involve wearable devices such as shutter glasses or head-mounted displays that are cumbersome to  wear. We present TaPS, lightweight transparent widgets that only pass light coming from a particular direction to shield the content beneath them from other users, creating Tangible Private Spaces. TaPS widgets use low-cost hardware to provide tangible privacy controls to interactive tabletops. Informal studies indicate that TaPS widgets enable users to successfully move documents between public and private tabletop spaces without compromising privacy.</span></div></div><div class="paper" id="al145"><a href="#al145" class="title">Design Considerations of Expressive Bidirectional Telepresence Robots</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979633&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ji-Dong  Yim</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Chris D. Shaw</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Telepresence is an emerging market for everyday robotics, while limitations still exist for such robots to be widely used for ordinary people's social communication. In this paper, we present our iterative design approach toward an interactive bidirectional robot intermediaries along with application ideas and design considerations. This study also surveys recent efforts in HCI and HRI that augment multimodal interfaces for computer mediated communication. We conclude by discussing the key lessons we found useful from the system design. The findings for bidirectional telepresence robot interfaces are of: synchronicity, robot's role, intelligence, personalization, and personality construction method.</span></div></div><div class="paper" id="al124"><a href="#al124" class="title">On Ethical Problem Solving in User-Centered Research: An Analysis</a>&nbsp;-&nbsp;<span class="type">alt.chi</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979634&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Zarla  Ludin</span> <span class="affiliation">143 South St.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">User researchers are tasked with discovering, defining, and validating behaviors and needs with the goal of improving people&#8217;s experiences. In practice, it may be easy to forget that research participants are in fact what academics would call &#8220;human subjects&#8221;.  Fields, in which research with humans is done, like Anthropology and Psychology, use procedural ethical codes to guide the research process in the spirit of &#8220;first do no harm".  The purpose of this paper is to present the foundation of ethical problem solving in user research in order to engage and maintain a discussion amongst practitioners.</span></div></div></td>
<td colspan="13" class="session_details" id="S1233_details"><div class="paper" id="pl113"><a href="#pl113" class="title">Increasing Legal Requirements for Interface Accessibility</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979496&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dan  Goldstein</span> <span class="affiliation">Brown, Goldstein, Levy, LLP</span>, <br />
<span class="author">Eve  Hill</span> <span class="affiliation">Brown, Goldstein, Levy, LLP</span>, <br />
<span class="author">Jonathan  Lazar</span> <span class="affiliation">Towson University</span>, <br />
<span class="author">Alice  Siempelkamp</span> <span class="affiliation">Recovery Accountability and Transparency Board</span>, <br />
<span class="author">Anne  Taylor</span> <span class="affiliation">National Federation of the Blind</span>, <br />
<span class="author">David  Lepofsky</span> <span class="affiliation">Accessibility for Ontarians with Disabilities Act Alliance</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">There is increasing legal activity, requiring accessibility for people with disabilities, across a number of categories of digital content&#8212;government information, corporate web sites, electronic hiring processes, and e-book readers. The purpose of this panel at CHI 2011 is to inform the interaction design community about these legal changes, and discuss strategies for successful implementation of accessibility regulations in design.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">10:00<br />-<br />11:00</td>

<td class="session tbd" id="S1247">
<div class="session_box">
<span class="type"></span>
<a href="#S1247" class="title">Exhibit Hall Open</a>
<span class="location">Ballroom C/D</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S5010">
<div class="session_box">
<span class="type">Interactivity</span>
<a href="#S5010" class="title">Interactivity 2 Open</a>
<span class="location">202/203/204</span>
<strong></strong>

</div>
</td>

<td class="session " id="S5007">
<div class="session_box">
<span class="type">Doctoral Consortium</span>
<a href="#S5007" class="title">Poster Interactions: Doctoral Consortium and Workshops</a>
<span class="location">Ballroom Foyer</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="3" class="session_details" id="S5010_details"><div class="paper" id="in122"><a href="#in122" class="title">Coco - The Therapy Robot</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979721&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katharina  Tran phuc</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Torsten  Racky</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Florian  Roth</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Iris  Wegmann</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Christoph  Busch</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Claudia  S&#246;ller-Eckert</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Mara  Pilz</span> <span class="affiliation">University of Applied Sciences Darmstadt</span>, <br />
<span class="author">Katharina  Horst</span> <span class="affiliation">University of Applied Sciences Darmstadt</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Coco is a therapeutic robot designed for elderly people in nursing homes or other care facilities. It is an electronic pet that represents a friend and helper who animates, reminds and motivates its owner.  He has 4 main functions: reading, singing, a calendar function and quiz games and can be operated by voice, remote control or base buttons. Pressure sensors in Coco's back react to touch. He interacts with its owner on its own initiative, suggesting to read, sing or play. Coco's memory and activity settings can be customised by carers or relatives. The prototype was implemented with Lego Mindstorms and successfully tested by a focus group. <br /></span></div></div><div class="paper" id="in129"><a href="#in129" class="title">Touch and Copy, Touch and Paste</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979714&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Suranga  Nanayakkara</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">SPARSH explores a novel interaction method to seamlessly transfer data between digital devices in a fun and intuitive way. The user touches whatever data item he or she wants to copy from a device. At that moment, the data item is conceptually saved in the user. Next, the user touches the other device he or she wants to paste/pass the saved content into. SPARSH uses touch-based interactions as indications for what to copy and where to pass it. Technically, the actual transfer of media happens via the information cloud.</span></div></div><div class="paper" id="in130"><a href="#in130" class="title">Mouseless - a Computer Mouse as Small as Invisible</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979715&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pranav  Mistry</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mouseless is a novel input device that provides the familiarity of interaction of a physical computer mouse without requiring a real hardware mouse. It consists of an IR laser beam and an IR camera, both of which are embedded in a computer. Mouseless proposes a number of novel additional gestural interactions while supporting all the conventional computer mouse interactions. We present the design and implementation of various Mouseless prototype systems.</span></div></div><div class="paper" id="in132"><a href="#in132" class="title">Obfuscating Authentication Through Haptics, Sound and Light</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979709&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrea  Bianchi</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span>, <br />
<span class="author">Ian  Oakley</span> <span class="affiliation">Madeira Interactive Technologies Institute, University of Madeira</span>, <br />
<span class="author">Dong-Soo  Kwon</span> <span class="affiliation">Korea Advanced Institute of Science and Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Sensitive digital content associated with or owned by individuals now pervades everyday life. Mediating accessing to it in ways that are usable and secure is an ongoing challenge. We present a series of five PIN entry and transmission systems that address observation attacks in public spaces via shoulder surfing or camera recording. They do this through the use of novel modalities including audio cues, haptic cues and modulated visible light. Each prototype is introduced and motivated, and its strengths and weaknesses are considered.</span></div></div><div class="paper" id="in137"><a href="#in137" class="title">Blinky Blocks: A Physical Ensemble Programming Platform</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979712&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Brian T Kirby</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Michael  Ashley-Rollman</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Seth Copen Goldstein</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A major impediment to understanding programmable matter is the lack of an existing system with sufficiently many modules of sufficient capabilities. We present the requirements of physically distributed ensembles and discuss the use of the distributed programming language Meld to program ensembles of these units. We demonstrate a new <br /> system designed to meet these requirements called Blinky Blocks and discuss the hardware design we used to create 100 of these modules.</span></div></div><div class="paper" id="in145"><a href="#in145" class="title">humanaquarium: Exploring Audience, Participation, and Interaction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span><div class="authors"><span class="author">Robyn  Taylor</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Guy  Schofield</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">John  Shearer</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Jayne  Wallace</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Peter  Wright</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Pierre  Boulanger</span> <span class="affiliation">University of Alberta</span>, <br />
<span class="author">Patrick  Olivier</span> <span class="affiliation">Newcastle University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">humanaquarium is a movable performance space designed to explore the dialogical relationship between artist and audience. Two musicians perform inside the cube-shaped box, collaborating with participants to co-create an aesthetic audio-visual experience. The front wall of the humanaquarium is a touch-sensitive FTIR window. Max/MSP is used to translate the locations of touches on the window into control data, manipulating the tracking of software synthesizers and audio effects generated in Ableton Live, and influencing a Jitter visualization projected upon the rear wall of the cube.</span></div></div><div class="paper" id="in150"><a href="#in150" class="title">3D-Press - Tangible 3D Haptics on Touch Surfaces: Virtual Compliance</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979717&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Johan  Kildal</span> <span class="affiliation">Nokia Research Center</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Suitability of current haptic three-dimensional user interface (3D-UI) technologies is low for mobile interaction. 3D-Press in reviewed in this paper: a technique to create the haptic illusion that when pressing on a rigid surface is feels compliant. The fact that the illusion is intramodal (haptics only involved in creating it), and that the technology required is simple and with low energy demands, makes it ideal for mobile use. The parameters used in the implementation of 3D-Press influence the characteristics of the illusion.</span></div></div><div class="paper" id="in152"><a href="#in152" class="title">Graffito: Crowd-based Performative Interaction at Festivals</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979725&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Sheridan</span> <span class="affiliation">BigDog Interactive Ltd</span>, <br />
<span class="author">Nick  Bryan-Kinns</span> <span class="affiliation">Queen Mary University of London</span>, <br />
<span class="author">Stuart  Reeves</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Joe  Marshall</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Giles  Lane</span> <span class="affiliation">Proboscis</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Crowd-based events are generating new forms of crowd-based performative interaction. Nightclubs and festivals are at the cutting edge of crowd-based interaction with ubiquitous computing. The social capital of crowd-based interaction is not well understood and is usually limited to one-off events. Our intention is to explore the possibility for generating a lifelong contextual footprint of crowd-based performative interaction.</span></div></div><div class="paper" id="in154"><a href="#in154" class="title">Galvanic Skin Response-Derived Bookmarking of an Audio Stream</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979716&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Matthew K.X.J. Pan</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gordon Jih-Shiang  Chang</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Gokhan H. Himmetoglu</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">AJung  Moon</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Thomas W. Hazelton</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Karon E. MacLean</span> <span class="affiliation">The University of British Columbia</span>, <br />
<span class="author">Elizabeth A. Croft</span> <span class="affiliation">The University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We demonstrate a novel interaction paradigm driven by implicit, low-attention user control, accomplished by monitoring a user&#8223;s physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. A listener&#8223;s galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our research prototype then automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted.</span></div></div><div class="paper" id="in158"><a href="#in158" class="title">MediaDiver: Viewing and Annotating Multi-View Video</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979711&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gregor  Miller</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sidney  Fels</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Abir  Al Hajri</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Michael  Ilich</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Zoltan  Foley-Fisher</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Manuel  Fernandez</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Daesik  Jang</span> <span class="affiliation">Kunsan National University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Our novel rich media interface called MediaDiver demonstrates our new interaction techniques for viewing and annotating multiple view video. The demonstration allows attendees to experience novel moving target selection methods (called Hold and Chase), new multi-view selection techniques, automated quality of view analysis to switch viewpoints to follow targets, integrated annotation methods for viewing or authoring meta-content and advanced context sensitive transport and timeline functions. As users have become increasingly sophisticated when managing navigation and viewing of hyper-documents, they transfer their expectations to new media. We demonstrate the technology required to meet these expectations for video. Thus users will be able to directly click on objects in the video to link to more information or other video, easily change camera views and mark-up the video with their own content. The applications of this technology stretch from home video management to broadcast quality media production, which may be consumed on both desktop and mobile platforms.</span></div></div><div class="paper" id="in161"><a href="#in161" class="title">TagURIt: A Proximity-based Game of Tag Using Lumalive e-Textile Displays</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979707&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sylvia H Cheng</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present an electronic game of tag that uses proximity sensing and Lumalive displays on garments.  In our game of tag, each player physically represents a location-tagged Universal Resource Indicator (URI). The URIs, one chaser and two target players, wear touch-sensitive Lumalive display shirts. The goal of the game is for the chaser to capture a token displayed on one of the Lumalive shirts, by pressing a touch sensor located on the shirt. When the chaser is in close proximity to the token player, the token jumps to the shirt of the second closest player, making this children&#8217;s game more challenging for adult players.  Our system demonstrates the use of interactive e-textile displays to remove the technological barrier between contact and proximity in the real world, and the seamless representation of gaming information from the virtual world in that real world.</span></div></div><div class="paper" id="in165"><a href="#in165" class="title">Frictional Widgets: Enhancing Touch Interfaces with Programmable Friction</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979713&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Vincent  Levesque</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Louise  Oram</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Karon  MacLean</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Andy  Cockburn</span> <span class="affiliation">University of Canterbury</span>, <br />
<span class="author">Nicholas  Marchuk</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Dan  Johnson</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">J. Edward  Colgate</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Michael  Peshkin</span> <span class="affiliation">Northwestern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Touch interactions occur through flat surfaces that lack the tactile richness of physical interfaces. We explore the design possibilities offered by augmenting touchscreens with programmable surface friction. Four exemplar applications &#8211; an alarm clock, a file manager, a game, and a text editor &#8211; demonstrate tactile effects that improve touch interactions by enhancing physicality, performance, and subjective satisfaction.</span></div></div><div class="paper" id="in168"><a href="#in168" class="title">SnowGlobe: A Spherical Fish-Tank VR Display</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979719&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">John  Bolton</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Kibum  Kim</span> <span class="affiliation">Queen's University</span>, <br />
<span class="author">Roel  Vertegaal</span> <span class="affiliation">Queen's University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a spherical display with Fish-Tank VR as a means for interacting with three-dimensional objects. We implemented the spherical display by reflecting a projected image off a hemispherical mirror, allowing for a seamless curvilinear display surface. Diffuse illumination is used for detecting touch points on the sphere. The user&#8217;s head position and the position of the sphere are also tracked using a Vicon motion capture device. Users can perform multi-touch gestures to interact with 3D content on the spherical display. Our system relies on the metaphor of a snow globe. Users can walk around a display while maintaining motion parallax corrected viewpoints of the object on the display. They can interact with the 3D object using multitouch interaction techniques, allowing for rotating and scaling of the 3D model on the display.</span></div></div><div class="paper" id="in170"><a href="#in170" class="title">ZeroTouch: A Zero-Thickness Optical Multi-Touch Force Field</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979710&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jon  Moeller</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Andruid  Kerne</span> <span class="affiliation">Texas A&amp;M University</span>, <br />
<span class="author">Sashikanth  Damaraju</span> <span class="affiliation">Texas A&amp;M University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present zero-thickness optical multi-touch sensing, a technique that simplifies sensor/display integration, and enables new forms of interaction not previously possible with other multi-touch sensing techniques. <br /> Using low-cost modulated infrared sensors to quickly determine the visual hull of an interactive area, we enable robust real-time sensing of fingers and hands, even in the presence of strong ambient lighting. Our technology allows for 20+ fingers to be detected, many more than through prior visual hull techniques, and our use of wide-angle optoelectonics allows for excellent touch resolution, even in the corners of the sensor. <br /> With the ability to track objects in free space, as well as its use as a traditional multi-touch sensor, ZeroTouch opens up a new world of interaction possibilities.</span></div></div><div class="paper" id="in207"><a href="#in207" class="title">Immersive VR: A Non-pharmacological Analgesic for Chronic Pain?</a>&nbsp;-&nbsp;<span class="type">Interactivity</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979704&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Diane  Gromala</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Meehae  Song</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Ji-Dong  Yim</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Tyler  Fox</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Steven J Barnes</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Mark  Nazemi</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Chris  Shaw</span> <span class="affiliation">Simon Fraser University</span>, <br />
<span class="author">Pam  Squire, MD</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the research work being carried out by the Transforming Pain Research Group &#8211; the only group whose work is entirely focused on the use of immersive VR for chronic pain management. Unlike VR research for acute or short-term pain, which relies on pain "distraction," this research posits a new paradigm for the use of VR. In addition to providing an overview of our work, the present paper also describes one of our current works in detail: the Virtual Meditative Walk.</span></div></div></td>
<td colspan="3" class="session_details" id="S5007_details"><div class="paper" id="dc146"><a href="#dc146" class="title">Informing Design of Systems for Intelligence Analysis: Understanding Users, User Tasks, and Tool Usage</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979688&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Youn-ah  Kang</span> <span class="affiliation">Georgia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Although intelligence analysts are one of the main target users of visual analytics systems, we still do not understand their work practices and methodologies well. The lack of understanding about how intelligence analysts work and how they can benefit from visual analytics systems has created a gap between tools being developed and real world practices. I argue that we need a better understanding of these analysts and their tool usage to build systems that better support their tasks and add utility to their work practices. By characterizing the analysis process and identifying leverage points for systems through empirical studies, I ultimately seek to develop a set of design guidelines and implications that can be used for building visual analytics systems for intelligence analysis.</span></div></div><div class="paper" id="dc155"><a href="#dc155" class="title">Designing for Movement Experience</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979690&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aaron M Levisohn</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The contribution of the phenomenological aspects of movement to the construction of user experience is relatively unknown. A better understanding of the characteristics of movement experience has the potential to transform the quality of interaction and to assist in the development of alternative interaction methods for ubiquitous and tangible computing systems. The research presented in this paper integrates methods from a diverse range of disciplines &#8211; including design, social science, and somatics &#8211; to identify design principles that can guide the development of systems that incorporate aspects of movement experience.</span></div></div><div class="paper" id="dc106"><a href="#dc106" class="title">Proxemic Interactions in Ubiquitous Computing Ecologies</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979691&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Nicolai  Marquardt</span> <span class="affiliation">University of Calgary</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">An important challenge in ubiquitous computing (ubicomp) is to create techniques that allow people to seamlessly and naturally connect to and interact with the increasing number of digital devices. I propose to leverage the knowledge of people&#8217;s and devices&#8217; spatial relationships &#8211; called proxemics &#8211; in ubicomp interaction design. I introduce my work of proxemic interactions that consider fine-grained information of proxemics to mediate people&#8217;s interactions with digital devices, such as large digital surfaces or portable personal devices. This research includes the design of development tools for programmers creating proxemic-aware systems, and the design and evaluation of such interactive ubicomp systems.</span></div></div><div class="paper" id="dc119"><a href="#dc119" class="title">Modeling Users of Intelligent Systems</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979693&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stephanie  Rosenthal</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While many devices today increasingly have the ability to predict human activities, it is still difficult to build accurate personalized machine learning models. As users today will become responsible for helping to train their own models, we are interested in ways for applications to request labeled data from their users in a non-invasive way. This work focuses on opportunities for intelligent systems to ask their users for help through interactions over an extended period of time in order to improve their machine learning models. We focus on trading off the expected increase in accuracy with the potential interruptions that the questions may cause to improve the usability of such systems.</span></div></div><div class="paper" id="dc137"><a href="#dc137" class="title">Understanding Multitasking as an Adaptive Strategy Selection Process</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979687&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Christian P Janssen</span> <span class="affiliation">University College London</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The promotion of mobile devices within the field of HCI makes it necessary to better understand how these devices are used in multitasking contexts, so as to prevent accidents. In these contexts, users must choose how to allocate their attention to the tasks that they are engaged in. Using computational cognitive models, I demonstrate why users interleave tasks in particular patterns: to comply with priority objectives and to optimize performance. In future work, I will investigate how users learn to perform in optimum ways, so as to be able to predict performance during a first encounter with novel situations and interfaces.</span></div></div><div class="paper" id="dc143"><a href="#dc143" class="title">Visual Histories of Decision Processes for Creative Collaboration</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979689&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Karine  Kozlova</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Collaborative decision making (CDM) is a key aspect of collaboration in both its importance to the process and its internal complexity. In my PhD research I focus on such decision making and its support through the use of history visualization and reconstruction. The goal of this research is to explore the role of history in collaborative activities and to provide a specific set of design guidelines and concepts for technological support of CDM through history capture, recall, review and revision.</span></div></div><div class="paper" id="dc111"><a href="#dc111" class="title">Socialising Presence</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979685&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Daniel  Gooch</span> <span class="affiliation">Department of Computer Science, University of Bath, Bath, UK, BA2 7AY</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Long distance relationships are not well supported by current communication technologies. Although these technologies are superb at communicating facts, they lack an emotional element which I argue is necessary for people who care about one another and yet who must live apart. My PhD aims to address this problem by examining social presence in technologically mediated relationships. Thus far I have built a number of teletangible devices to mimic human actions across a distance. I will deploy these systems within a number of long-distance relationships. I expect my research to result in new understanding which will lead to communication technologies with higher levels of social presence, thus supporting long-distance relationships.</span></div></div><div class="paper" id="dc148"><a href="#dc148" class="title">The Songs of Our Past: Working with Listening Histories</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979683&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dominikus  Baur</span> <span class="affiliation">University of Munich (LMU)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Music listening histories are portraits of a person&#8217;s taste in music. In my research I am exploring this type of data and how user interfaces can be enhanced with it. In this Doctoral Consortium paper I describe my approach towards this goal: Statistical analysis and casual information visualizations can help in finding relevant patterns and aspects in listening histories. Making them available to regular users and asking what they learnt about themselves gives us the chance to find out more about their listening on the minute level of songs. Contextual information such as photos or calendar entries can help trigger memories. In this paper I describe the motivation and goals of my research and my current status. In the end, both the HCI community and end users can benefit from more convenient and sophisticated interfaces for this type of data.</span></div></div><div class="paper" id="dc159"><a href="#dc159" class="title">Self-Disclosure in Social Media</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979695&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Javier  Velasco-Martin</span> <span class="affiliation">School of Information and Library Science The University of North Carolina at Chapel Hill</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Computer mediated communication tools have multiplied the possibilities to stay in touch and interact with the people in our social network. The dynamics of use for these tools suggest changes in the context of self-disclosure. Although research has explored online self-disclosure of students (who are expressing large breaches in previous norms of privacy regulation), much less attention has been paid to disclosure behavior of older, and particularly experienced users. A mixed-method approach will be used to explore different aspects of this complex phenomenon, including a survey, interviews and experience sampling. Results of this project should reveal the most salient drivers for online Self-Disclosure for this group.</span></div></div><div class="paper" id="dc102"><a href="#dc102" class="title">Distributed Participatory Design</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979696&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Greg  Walsh</span> <span class="affiliation">University of Maryland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Children who are not co-located with system developers because of geographic location or time zone difference have ideas that are just as important and valid as children who are easily &#8220;available&#8221;. This problem is the motivation for my thesis work. I propose to design, develop, and research a computer-mediated, geographically distributed, asynchronous tool to facilitate intergenerational participatory design.</span></div></div><div class="paper" id="dc156"><a href="#dc156" class="title">Physical Activity with Digital Companions</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979684&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Lorna Rae Boschman</span> <span class="affiliation">Simon Fraser University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While a majority of adults in industrialized countries do not exercise frequently enough to sustain physical health, games with an exertive interface &#8211; exergames &#8211; have been proposed as vehicles to increase activity levels. After a brief discussion of my background, I report on fundamental findings from studies conducted by interaction designers, social and computer scientists, and medical professionals whose work has responded to the crisis in physical activity levels. I give an overview of my proposed mixed methods research design, and discuss how I can both contribute and learn from approaches that can successfully support strong study findings.</span></div></div><div class="paper" id="dc103"><a href="#dc103" class="title">Technology Design for Pediatric Asthma Management</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979698&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tae-Jung  Yun</span> <span class="affiliation">Georgia Institute of Technology, Samsung Electronics</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Asthma affects a significant number of children, families, and health care systems. In this work, I discuss the challenges that these stakeholders may face, and present system that may help address some of these challenges. Finally, I highlight the expected contributions of this work.</span></div></div><div class="paper" id="dc132"><a href="#dc132" class="title">Using Language-Retrieved Pictures to Support Intercultural Brainstorming</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979697&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hao-Chuan  Wang</span> <span class="affiliation">Cornell University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Group brainstorming is a commonly practiced technique to enhance creative outcomes. Cultural differences in knowledge and perspectives are valuable sources for diversity essential to creative outcomes, while cultural discrepancy in communication and language may impede idea sharing. My dissertation research aims to reconcile the tension between the benefits and obstacles of intercultural brainstorming. The design approach is to augment conversational brainstorming with language-retrieved pictures. Pictures may provide rich stimulation and mediate concepts in a relatively language-independent manner, which may complement the still imperfect machine translation, and make inter-cultural and multi-lingual idea sharing more feasible.</span></div></div><div class="paper" id="dc139"><a href="#dc139" class="title">Designing an Interface for Multimodal Narrative Creation</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979686&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Katy  Howland</span> <span class="affiliation">University of Sussex</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many young people struggle with developing writing skills, and computer game creation is a motivating activity with potential in this area. Existing software allows young people to design 3D areas and add game objects, but provides little or no interface support for writing and structuring narratives. This research explores the support required to create 3D multimodal narratives, adopting user-centred methods to design, <br /> build and evaluate a suite of dynamic representational tools. A key interface design challenge is developing representations that foster writing skills without losing the motivational immediacy of the activity.</span></div></div><div class="paper" id="dc114"><a href="#dc114" class="title">Modeling Places for Interactive Media and Entertainment Applications</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979692&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rui  N&#243;brega</span> <span class="affiliation">Universidade Nova de Lisboa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Taking advantage of the multitude of cameras now available and capable of recording all aspects of our lives, this work explores the notion of virtualizing a physical place using cameras and sharing the resulting model with others. This social sharing would create new forms of relationship and common space discovery that would enhance video chats and virtual visiting of physical places. Furthermore, the research will consider the possible interactive applications, from games to augmented reality, which can take advantage of the created spatial and temporal models.</span></div></div><div class="paper" id="dc125"><a href="#dc125" class="title">Pervasive Negabehavior Games for Environmental Sustainability</a>&nbsp;-&nbsp;<span class="type">Doctoral Consortium</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979694&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Joel  Ross</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Pervasive games&#8212;games that expand into everyday life&#8212;offer a potentially powerful method of promoting social good by encouraging people to perform new, positive actions. However, achieving some desired social goals (such as environmental sustainability) may also require people to stop performing undesirable actions&#8212;a form of behavior change that contrasts with common framings of pervasive game-play. I propose to create "Negabehavior Games"&#8212;games that encourage players to adopt "negabehaviors" (a manner of conducting oneself that supplants undesirable actions). This research offers a novel approach to designing pervasive games and other interactive experiences, as well as the potential to encourage people to live more environmentally sustainable lives.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">11:00<br />-<br />12:20</td>

<td class="session " id="S1249">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1249" class="title">Participatory Culture in the Age of Social Media</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1254">
<div class="session_box">
<span class="type"></span>
<a href="#S1254" class="title">Student Research Competition</a>
<span class="location">119/120</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1248">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1248" class="title">Managing UX teams</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1258">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1258" class="title">Tangibles</a>
<span class="location">211</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1263">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1263" class="title">Organizations &amp; Enterprise</a>
<span class="location">223/224</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1257">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1257" class="title">Engaging Youth</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1261">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1261" class="title">Software Development &amp; Product Support</a>
<span class="location">217/218/219</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1262">
<div class="session_box">
<span class="type">Paper &amp; ToCHI</span>
<a href="#S1262" class="title">Multitasking &amp; Interruption</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="best.png" alt="Best Paper Award" /><span style="display: none">Best Paper Award</span></div>
</div>
</td>

<td class="session " id="S1256">
<div class="session_box">
<span class="type">Case Study &amp; Paper</span>
<a href="#S1256" class="title">Reading &amp; Writing</a>
<span class="location">205/206/207</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1259">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1259" class="title">Groups Around the Table</a>
<span class="location">212/213/214</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1250">
<div class="session_box">
<span class="type">Panel</span>
<a href="#S1250" class="title">Quality Control: on the Critique and Criticism of Design Research</a>
<span class="location">Ballroom A/B</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1260">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1260" class="title">Rehabilitation</a>
<span class="location">215/216</span>
<strong></strong>

</div>
</td>
</tr>
<tr class="details_row"><td colspan="12" class="session_details" id="S1249_details"><div class="paper" id="si108"><a href="#si108" class="title">Participatory Culture in the Age of Social Media</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979543&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Dana  Rotman</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Sarah  Vieweg</span> <span class="affiliation">University of Colorado</span>, <br />
<span class="author">Sarita  Yardi</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Ed  Chi</span> <span class="affiliation">Google Research</span>, <br />
<span class="author">Jenny  Preece</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Ben  Shneiderman</span> <span class="affiliation">University of Maryland</span>, <br />
<span class="author">Peter  Pirolli</span> <span class="affiliation">PARC</span>, <br />
<span class="author">Tom  Glaisyer</span> <span class="affiliation">New American Foundation</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social networking sites (e.g. Facebook), microblogging services (e.g. Twitter), and content-sharing sites (e.g. YouTube and Flickr) have introduced the opportunity for wide-scale, online social participation. Visibility of national and international priorities such as public health, political unrest, disaster relief, and climate change has increased, yet we know little about the benefits&#8212;and possible costs&#8212;of engaging in social activism via social media. These powerful social issues introduce a need for scientific research into technology mediated social participation. What are the actual, tangible benefits of &#8220;greening&#8221; Twitter profile pictures in support of the Iranian elections? Does cartooning a Facebook profile picture really raise awareness of child abuse? Are there unintended negative effects through low-risk, low-cost technology-mediated participation? And, is there a difference&#8212;in both outcome and engagement level&#8212;between different types of online social activism? This SIG will investigate technology mediated social participation through a critical lens, discussing both the potential positive and negative outcomes of such participation. Approaches to designing for increased participation, evaluating effects of participation, and next steps in scientific research directions will be discussed.</span></div></div></td>
<td colspan="12" class="session_details" id="S1248_details"><div class="paper" id="si149"><a href="#si149" class="title">Managing UX teams</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979542&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Janice  Rohn</span> <span class="affiliation">Experian</span>, <br />
<span class="author">Dennis  Wixon</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Jim  Nieters</span> <span class="affiliation">Yahoo</span>, <br />
<span class="author">Carola  Thompson</span> <span class="affiliation">Mindjet</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This SIG will serve two purposes:  as a forum to share the results from the two-day CHI workshop, and also as a forum for the management community to discuss topics of interest.</span></div></div></td>
<td colspan="12" class="session_details" id="S1258_details"><div class="sessionChair"><strong>Session Chair: </strong>Patrick Baudisch (<em>Hasso Plattner Institute</em>)</div><div class="paper" id="paper2055"><a href="#paper2055" class="title">Tangible Bots: Interaction with Active Tangibles in Tabletop Interfaces</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979384&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Esben Warming Pedersen</span> <span class="affiliation">University of Copenhagen</span>, <br />
<span class="author">Kasper  Hornb&#230;k</span> <span class="affiliation">University of Copenhagen</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present interaction techniques for tangible tabletop interfaces that use active, motorized tangibles, what we call Tangible Bots. Tangible Bots can reflect changes in the digital model and assist users by haptic feedback, by correcting errors, by multi-touch control, and by allowing efficient interaction with multiple tangibles. A first study shows that Tangible Bots are usable for fine-grained manipulation (e.g., rotating tangibles to a particular orientation); for coarse movements, Tangible Bots become useful only when several tangibles are controlled simultaneously. Participants prefer Tangible Bots and find them less taxing than passive, non-motorized tangibles. A second study focuses on usefulness by studying how electronic musicians use Tangible Bots to create music with a tangible tabletop application. We conclude by discussing the further potential of active tangibles, and their relative benefits over passive tangibles and multi-touch.</span></div></div><div class="paper" id="paper973"><a href="#paper973" class="title">Geckos: Combining Magnets and Pressure Images to Enable New Tangible-object Design and Interaction</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979385&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jakob  Leitner</span> <span class="affiliation">Media Interaction Lab</span>, <br />
<span class="author">Michael  Haller</span> <span class="affiliation">Media Interaction Lab</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we present Geckos, a new type of tangible objects which are tracked using a Force-Sensitive Resistance sensor. Geckos are based on low-cost permanent magnets and can also be used on non-horizontal surfaces. Unique pressure footprints are used to identify each tangible Gecko. Two types of tangible object designs are presented: Using a single magnet in combination with felt pads provides new pressure-based interaction modalities. Using multiple separate magnets it is possible to change the marker footprint dynamically and create new haptic experiences. The tangible object design and interaction are illustrated with example applications. We also give details on the feasibility and benefits of our tracking approach and show compatibility with other tracking technologies.</span></div></div><div class="paper" id="paper206"><a href="#paper206" class="title">TUIC: Enabling Tangible Interaction on Capacitive Multi-touch Displays</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979386&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Neng-Hao  Yu</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Li-Wei  Chan</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Seng Yong  Lau</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Sung-Sheng  Tsai</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">I-Chun  Hsiao</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Dien-Je  Tsai</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Lung-Pan  Cheng</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Fang-I  Hsiao</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Mike Y Chen</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Polly  Huang</span> <span class="affiliation">National Taiwan University</span>, <br />
<span class="author">Yi-Ping  Hung</span> <span class="affiliation">National Taiwan University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present TUIC, a technology that enables tangible interaction on capacitive multi-touch devices, such as iPad, iPhone, and 3M&#8217;s multi-touch displays, without requiring any hardware modifications. TUIC simulates finger touches on capacitive displays using passive materials and active modulation circuits embedded inside tangible objects, and can be used with multi-touch gestures simultaneously. TUIC consists of three approaches to sense and track objects: spatial, frequency, and hybrid (spatial plus frequency). The spatial approach, also known as 2D markers, uses geometric, multi-point touch patterns to encode object IDs. Spatial tags are straightforward to construct and are easily tracked when moved, but require sufficient spacing between the multiple touch points. The frequency approach uses modulation circuits to generate high-frequency touches to encode object IDs in the time domain. It requires fewer touch points and allows smaller tags to be built. The hybrid approach combines both spatial and frequency tags to construct small tags that can be reliably tracked when moved and rotated. We show three applications demonstrating the above approaches on iPads and 3M&#8217;s multi-touch displays.</span></div></div><div class="paper" id="paper260"><a href="#paper260" class="title">tBox: A 3D Transformation Widget designed for Touch-screens</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979387&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Aur&#233;lie  Coh&#233;</span> <span class="affiliation">INRIA  - Universit&#233; de Bordeaux CNRS (LaBRI)</span>, <br />
<span class="author">Fabrice  D&#232;cle</span> <span class="affiliation">INRIA  - Universit&#233; de Bordeaux CNRS (LaBRI)</span>, <br />
<span class="author">Martin  Hachet</span> <span class="affiliation">INRIA  - Universit&#233; de Bordeaux CNRS (LaBRI)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">3D transformation widgets are commonly used in many 3D applications operated from mice and keyboards. These user interfaces allow independent control of translations, rotations, and scaling for manipulation of 3D objects. In this paper, we study how these widgets can be adapted to the tactile paradigm. We have explored an approach where users apply rotations by means of physically plausible gestures, and we have extended successful 2D tactile principles to the context of 3D interaction. These investigations led to the design of a new 3D transformation widget, tBox, that can been operated easily and efficiently from gestures on touch-screens.</span></div></div><div class="paper" id="paper1879"><a href="#paper1879" class="title">Rendering Physical Effects in Tabletop Controls</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979388&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Malte  Weiss</span> <span class="affiliation">RWTH Aachen University</span>, <br />
<span class="author">Christian  Remy</span> <span class="affiliation">University of Zurich</span>, <br />
<span class="author">Jan  Borchers</span> <span class="affiliation">RWTH Aachen University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce dynamic physical properties as an additional degree of freedom for passive tabletop controls. Using electromagnetic actuation, we manipulate attributes of tangibles on the fly, such as perceived weight, spring resistance, friction, and latching. We describe our actuation concepts, prototypes, and measurements showing that magnetic fields can change physical effects in a linear way. Controlled experiments reveal that participants can tactually distinguish four rendered resistance levels of a button prototype and easily detect dynamic detents in a continuous slider. Finally, we describe how adjustable physical properties in tangibles can enhance tabletop interaction.</span></div></div></td>
<td colspan="12" class="session_details" id="S1263_details"><div class="sessionChair"><strong>Session Chair: </strong>John Tang (<em>Microsoft Research</em>)</div><div class="paper" id="paper310"><a href="#paper310" class="title">Commentspace - Structured Support for Collaborative Visual Analysis</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979407&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Wesley  Willett</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Jeffrey  Heer</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Joseph  Hellerstein</span> <span class="affiliation">University of California, Berkeley</span>, <br />
<span class="author">Maneesh  Agrawala</span> <span class="affiliation">University of California, Berkeley</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Collaborative visual analysis tools can enhance sensemaking by facilitating social interpretation and parallelization of effort. These systems enable distributed exploration and evidence gathering, allowing many users to pool their effort as they discuss and analyze the data. We explore how adding lightweight tag and link structure to comments can aid this analysis process. We present CommentSpace, a collaborative system in which analysts comment on visualizations and websites and then use tags and links to organize findings and identify others&#8217; contributions. In a pair of studies comparing CommentSpace to a system without support for tags and links, we find that a small, fixed vocabulary of tags (question, hypothesis, to-do) and links (evidence-for, evidence-against) helps analysts more consistently and accurately classify evidence and establish common ground. We also find that managing and incentivizing participation is important for analysts to progress from exploratory analysis to deeper analytical tasks. Finally, we demonstrate that tags and links can help teams complete evidence gathering and synthesis tasks and that organizing comments using tags and links improves analytic results.</span></div></div><div class="paper" id="paper2280"><a href="#paper2280" class="title">Supporting Collaborative Help for Individualized Use</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979408&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jina  Huh</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Mark W Newman</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Mark S Ackerman</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we seek to advance the research around utilizing collaborative help for supporting individualized use of technologies. We do this by shedding light on the ways that users of MythTV, a highly flexible open-source software system for home entertainment enthusiasts, collaboratively help one another in maintaining their individualized MythTV systems. By analyzing the MythTV user community&#8217;s mailing list archive, documentation, and wiki, coupled with user interviews we discuss how the community utilizes configuration artifacts as proxies to easily mobilize and exchange knowledge. While exchanging concrete artifacts such as scripts and configuration files was seen to sometimes increase the efficiency of knowledge transfer, it also presented several challenges. Negotiating the transparency of configuration artifacts, navigating the customization and appropriation gulfs, and aligning usage trajectories all emerged as problematic areas. We discuss design implications that address these challenges. Our findings provide a crucial understanding for how to support users in their individualized use of systems.</span></div></div><div class="paper" id="paper930"><a href="#paper930" class="title">The Scale and Evolution of Coordination Needs in Large-Scale Distributed Projects: Implications for the Future Generation of Collaborative Tools</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979409&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jean M Costa</span> <span class="affiliation">UFPA</span>, <br />
<span class="author">Marcelo  Cataldo</span> <span class="affiliation">CMU</span>, <br />
<span class="author">Cleidson R de Souza</span> <span class="affiliation">IBM Research - Brazil</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The past decade has witnessed the development of a new class of coordination tools that focus on automatically providing individuals a rich context for facilitating the coordination of their work. Despite their valuable contributions, current coordination tools have mostly been designed without taking into account scalability aspects beyond the small-group level. The increasing pervasiveness of large-scale projects suggests that those mechanisms need to scale dramatically to adequately support such work settings. In this paper, we used data from five distinct large-scale projects from three different companies to study the scale, range, and volatility of the coordination requirements that emerged over time within those projects. Our results showed that coordination requirements tend to be quite volatile, vary significantly in their magnitude across project members and a significant proportion of the coordination requirements cut across organizational and geographical boundaries. Furthermore, new coordination requirements represent, on average, a third of the coordination requirements faced by a project member on a monthly basis. The implications of these results for the design of collaborative tools are discussed.</span></div></div><div class="paper" id="paper434"><a href="#paper434" class="title">Topika: Integrating Collaborative Sharing with Email</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979410&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jalal  Mahmud</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Tara  Matthews</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Steve  Whittaker</span> <span class="affiliation">University of California Santa Cruz</span>, <br />
<span class="author">Tom  Moran</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Tessa  Lau</span> <span class="affiliation">IBM Research - Almaden</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">New enterprise tools (wikis, team spaces, social tags) offer <br /> potential benefits for enterprise collaboration, providing <br /> shared resources to organize work. However, a vast amount <br /> of collaboration still takes place by email. But email is <br /> problematic for collaboration because information may be <br /> distributed across multiple messages in an overloaded <br /> inbox. Email also increases workload as each individual <br /> has to manage their own versions of collaborative <br /> materials. We present a novel system, Topika that <br /> integrates email with collaboration tools. It allows users to <br /> continue to use email while also enjoying the benefits of <br /> these dedicated tools. When a user composes an email <br /> Topika analyzes the message and suggests relevant shared <br /> spaces (e.g., wiki pages) within the user&#8217;s collaboration <br /> tools. This allows her to post the email to those spaces. An <br /> evaluation of Topika&#8217;s suggestion algorithm shows that it <br /> performs well at accurately suggesting shared spaces.</span></div></div><div class="paper" id="paper1308"><a href="#paper1308" class="title">Raconteur: Integrating Authored and Real-Time Social Media</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979411&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Pei-Yu  Chi</span> <span class="affiliation">MIT</span>, <br />
<span class="author">Henry  Lieberman</span> <span class="affiliation">MIT</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Social media enables people to share personal experiences, often through real-time media such as chat. People also record their life experiences in media collections, with photos and video. However, today&#8217;s social media force a choice between real-time communication, and authoring a coherent story illustrated with digital media. There is simply not enough time in real-time communication to select and compose coherent multimedia stories. <br /> We present Raconteur, which introduces a new style of social media combining aspects of the real-time and authored styles of communication. It is structured around a text chat, augmented by an agent that continuously interprets the chat text to suggest appropriate media elements to illustrate the story. A small experiment shows that storytellers find Raconteur&#8217;s suggestions helpful in presenting their experiences, and audiences find the interaction engaging.</span></div></div></td>
<td colspan="12" class="session_details" id="S1257_details"><div class="sessionChair"><strong>Session Chair: </strong>Juan Pablo Hourcade (<em>University of Iowa</em>)</div><div class="paper" id="paper222"><a href="#paper222" class="title">Exploratory Evaluations of a Computer Game Supporting Cognitive Behavioural Therapy for Adolescents</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979378&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David  Coyle</span> <span class="affiliation">University of Cambridge</span>, <br />
<span class="author">Nicola  McGlade</span> <span class="affiliation">University College Dublin</span>, <br />
<span class="author">Gavin  Doherty</span> <span class="affiliation">Trinity College Dublin</span>, <br />
<span class="author">Gary  O'Reilly</span> <span class="affiliation">University College Dublin</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The need to provide effective mental health treatments for adolescents has been described as a &#8216;global public health challenge&#8217; [27]. In this paper we discuss the exploratory evaluations of the first adolescent intervention to fully integrate a computer game implementing Cognitive Behavioural Therapy. Three distinct studies are presented: a detailed evaluation in which therapists independent of the design team used the game with 6 adolescents experiencing clinical anxiety disorders; a study in which a member of the design team used the game with 15 adolescents; and finally a study assessing the acceptability of the game and intervention with 216 practicing therapists. Findings are presented within the context of a framework for the design and evaluation of complex health interventions. The paper provides an in-depth insight into the use of therapeutic games to support adolescent interventions and provides stronger evidence than previously available for both their effectiveness and acceptability to stakeholders.</span></div></div><div class="paper" id="paper1154"><a href="#paper1154" class="title">In the Mood: Engaging Teenagers in Psychotherapy Using Mobile Phones</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979379&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mark  Matthews</span> <span class="affiliation">Trinity College Dublin</span>, <br />
<span class="author">Gavin  Doherty</span> <span class="affiliation">Trinity College Dublin</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mental illness is a significant and growing problem throughout the world. Many mental health problems have their root in childhood, and early intervention is recommended. Engaging young people in psychotherapeutic activities is challenging, and treatment adherence is often poor. This paper presents a series of studies carried out as part of the development of a mobile and online symptom tracking tool for adolescents with mental health problems. Teenagers use the system to record symptoms on their mobile phones and can view this information in a clinical setting with a therapist. We focus on a clinical pilot of the system with ten users in public mental health clinics. As well as indicating that the mobile diary tool can increase client adherence to therapeutic activities, the study yields insight into the factors influencing the success of the design and informs the design of other systems to be used as adjuncts to therapy.</span></div></div><div class="paper" id="paper2266"><a href="#paper2266" class="title">Breaking Boundaries: Strategies for Mentoring through Textile Computing Workshops</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979380&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Stacey  Kuznetsov</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Laura C. Trutoiu</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Casey  Kute</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Iris  Howley</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Eric  Paulos</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Dan  Siewiorek</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With over 13.3 million children living below poverty line in the United States, there is a pressing need for engaging HCI research with children at the socio-economic margins. Drawing from design studio culture and art therapy literature, we explore wearable computing as a creative and tangible medium (similar to markers, paints, clays, etc.) for motivating &#8216;at-risk&#8217; children in hands-on making and expressive instantiation of ideas. Working with a local outreach organization for &#8216;at-risk&#8217; middle school girls, we conducted five weekly workshops during which participants ideated, designed and implemented personal wearable computing projects. These sessions inspired participants (age 10-12) who tend to be uninterested and uncooperative in educational activities to complete interactive projects and engage with workshop volunteers as mentors and peers. We present the challenges, merits and outcomes of our approach, proposing wearable computing as a healing outlet and a mentoring strategy for at-risk children.</span></div></div><div class="paper" id="paper381"><a href="#paper381" class="title">African American Men Constructing Computing Identity</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979381&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Betsy  James DiSalvo</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Sarita  Yardi</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Mark  Guzdial</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Tom  McKlin</span> <span class="affiliation">The Findings Group</span>, <br />
<span class="author">Charles  Meadows</span> <span class="affiliation">Morehouse College</span>, <br />
<span class="author">Kenneth  Perry</span> <span class="affiliation">Morehouse College</span>, <br />
<span class="author">Amy  Bruckman</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Many young African American males have a passion for video games, but they don&#8217;t often translate that passion into learning about computing. Part of the problem is that they do not identify with computing as a social norm within their peer group. This disidentification with computing can negatively impact academic performance and limit opportunities for upward mobility. We developed a job training program called Glitch Game Testers in which young African American men are trained to &#8220;break open the black box&#8221; of their game consoles to learn about computing. Perceptions of peers&#8217; technical competency were measured before and after the summer 2010 program. Results showed that participants were more likely to view their peers as technical resources and their overall access to technical resources increased. Broader implications for motivating technology adoption in HCI are discussed.</span></div></div><div class="paper" id="paper264"><a href="#paper264" class="title">Brick by Brick: Iterating Interventions to Bridge the Achievement Gap with Virtual Peers</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979382&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Emilee  Rader</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Margaret  Echelbarger</span> <span class="affiliation">Northwestern University</span>, <br />
<span class="author">Justine  Cassell</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We lay out one strand of a continuing investigation into the development of a virtual peer to help children learn to use &#8220;school English&#8221; and &#8220;school-ratified science talk&#8221;. In this paper we describe a detailed analysis of a corpus of child- child language use, and report our findings on the ways chil- dren shift dialects and ways of discussing science depending on the social context and task. We discuss the implications of these results for the re-design of a virtual peer that can evoke language behaviors associated with student achieve- ment. Furthermore, our results allow us to describe the ways in which this virtual agent can tailor its level of interaction based on a child&#8217;s current aptitude in this area.</span></div></div></td>
<td colspan="12" class="session_details" id="S1261_details"><div class="sessionChair"><strong>Session Chair: </strong>Keith Butler (<em>The Boeing Company</em>)</div><div class="paper" id="cs191"><a href="#cs191" class="title">Benefit Analysis of User Assistance Improvements</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979679&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Erika Noll Webb</span> <span class="affiliation">Oracle</span>, <br />
<span class="author">Ray  Matsil</span> <span class="affiliation">Oracle</span>, <br />
<span class="author">Jeff  Sauro</span> <span class="affiliation">Oracle</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we describe a study conducted to examine the impact of changes to our user assistance model in our enterprise software systems.  In this study, we examined both a traditional user assistance model, as well as our new user assistance model. <br /> In the traditional user assistance model, users of a general ledger prototype were given inline error messages and access to a PDF version of the help manual from a help icon at the top of the page. <br /> In the new user assistance model, error messages appeared in pop-up windows with links to specific areas where users could correct the errors.  Fields that needed to be changed were highlighted with a red border and when clicked, a description of the required change would appear.  When users needed help, they could select from lists of relevant help topics available at different levels based on where they were working in the system. <br /></span></div></div><div class="paper" id="paper420"><a href="#paper420" class="title">Modern Software Product Support Processes and the Usage of Multimedia Formats</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979400&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Parmit K. Chilana</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Tovi  Grossman</span> <span class="affiliation">Autodesk Research</span>, <br />
<span class="author">George  Fitzmaurice</span> <span class="affiliation">Autodesk Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Despite being an important channel for end-user assistance, few studies have directly investigated the interactions that occur in modern-day practice of software product support. We present results from a multi-dimensional analysis of product support activities at a leading design software company. We carried out a quantitative analysis of existing support requests, a survey with product support specialists, and follow-up interviews to understand the current practices in product support. In particular, we investigated the utility of different multimedia formats that modern web-based support systems enable. Our results showed that despite the value that these formats bring to support tasks, support specialists still face bottlenecks in remotely resolving software problems. We conclude by highlighting several opportunities in HCI for improving diagnosis and resolution of software issues over the web.</span></div></div><div class="paper" id="cs153"><a href="#cs153" class="title">Orchestration of Ux Methods as Critical Success Factor in Large Scale Software Developments</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979680&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Edmund  Eberleh</span> <span class="affiliation">SAP AG</span>, <br />
<span class="author">Fazlul  Hoque</span> <span class="affiliation">SAP AG</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Large scale software development in a technically layered environment and with multiple teams poses the challenge of information acquisition and communication of information across the stakeholders.  <br />  <br /> This paper discusses our experiences on UI Design by applying well-established design methods in a context of large and distributed development teams. The case study reveals some characteristics of the task and development context accounting for issues we faced in the design process. We are discussing design assumptions and approaches which didn&#8217;t work effectively and provide recommendations for more appropriate design processes that can be suitable for such contexts. <br /></span></div></div><div class="paper" id="cs142"><a href="#cs142" class="title">Evaluating eXtreme Scenario-based Design in a Distributed Agile Team</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979681&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jason Chong Lee</span> <span class="affiliation">Meridium, Inc.</span>, <br />
<span class="author">Tejinder K Judge</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Donald Scott McCrickard</span> <span class="affiliation">Virginia Tech</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Enterprise-level organizations, which often rely on distributed development teams, are increasingly interested in finding ways to adopt agile and usability-focused methods.  Agile usability researchers at Virginia Tech have partnered with Meridium, Inc. to look at how eXtreme Scenario-based Design (XSBD), an agile usability approach developed at Virginia Tech, can be used in a distributed environment.  We report on the use of this XSBD approach in a distributed team at Meridium and how it addresses the challenges of an integrated approach through streamlined usability and development practices and clearly defined communication and information sharing practices.</span></div></div></td>
<td colspan="12" class="session_details" id="S1262_details"><div class="sessionChair"><strong>Session Chair: </strong>Philippe Palanque (<em>Universit&#809; de Toulouse</em>)</div><div class="paper" id="paper1959"><a href="#paper1959" class="title">Ease of Juggling: Studying the Effects of Manual Multitasking</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="best.png" alt="Best Paper Award" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979402&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Antti  Oulasvirta</span> <span class="affiliation">Aalto University and University of Helsinki</span>, <br />
<span class="author">Joanna  Bergstrom-Lehtovirta</span> <span class="affiliation">Aalto University and University of Helsinki</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Everyday activities often involve using an interactive device while one is handling various other physical objects (wallets, bags, doors, pens, mugs, etc.). This paper presents the Manual Multitasking Test, a test with 12 conditions emulating manual demands of everyday multitasking situations. It allows experimenters to expose the effects of design on "manual flexibility": users&#8217; ability to reconfigure the sensorimotor control of arms, hands, and fingers in order to regain the high performance levels they experience when using the device on its own. The test was deployed for pointing devices on laptops and Qwerty keyboards of mobile devices. In these studies, we identified facilitative design features whose absence explains, for example, why the mouse and stylus function poorly in multi-object performance. The issue deserves more attention, because interfaces that are nominally similar (e.g., "one-handed input") can vary dramatically in terms of "ease of juggling."</span></div></div><div class="paper" id="to112"><a href="#to112" class="title">OASIS: A Framework for Linking Notification Delivery to the Perceptual Structure of Goal-Directed Tasks</a>&nbsp;-&nbsp;<span class="type">ToCHI</span><div class="authors"><span class="author">Shamsi  Iqbal</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Brian  Bailey</span> <span class="affiliation">University of Illinois at Urbana-Champaign</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">A notification represents the proactive delivery of information to a user and reduces the need to visually scan or repeatedly check an external information source. At the same time, notifications often interrupt user tasks at inopportune moments, decreasing productivity and increasing frustration. Controlled studies have shown that linking notification delivery to the perceptual structure of a user&#8217;s tasks can reduce these interruption costs. However, in these studies, the scheduling was always performed manually and it was not clear whether it would be possible for a system to mimic similar techniques. This article contributes the design and implementation of a novel system called Oasis that aligns notification scheduling with the perceptual structure of user tasks. We describe the architecture of the system, how it detects task structure on the fly without explicit knowledge of the task itself, and how it layers flexible notification scheduling policies on top of this detection mechanism. The system also includes an offline tool for creating customized statistical models for detecting task structure. The value of our system is that it intelligently schedules notifications, enabling the reductions in interruption costs shown within prior controlled studies to now be realized by users in everyday desktop computing tasks. It also provides a test bed for experimenting with how notification management policies and other system functionalities can be linked to task structure.</span></div></div><div class="paper" id="paper1272"><a href="#paper1272" class="title">Designing of Multimodal Feedback for Enhanced Multitasking Performance</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979403&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gerard  Kim</span> <span class="affiliation">Korea University</span>, <br />
<span class="author">Hyeong Cheol  Kim</span> <span class="affiliation">Korea University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we explore the possibility of applying <br /> multimodal feedback to improve multitasking performance. <br /> For this purpose, we have devised a general multitasking <br /> test application, called the MSP-Blocks, which includes <br /> many basic elements of multitasking and can be used to <br /> carry out a variety of multimodal multitasking experiments. <br /> An experiment was run to study the effects of two factors <br /> (the number of jobs and types of multimodal feedback) to <br /> user task performance, specifically, interaction effort, <br /> concurrency, fairness and output quality. The results <br /> indicated that multimodal feedback did influence <br /> multitasking performance, and moreover, non-redundant <br /> multimodal feedback was more effective than no <br /> multimodality or redundant multimodality for tasks with <br /> reasonable difficulty, e.g. when the number of jobs was <br /> more than four.</span></div></div><div class="paper" id="paper1117"><a href="#paper1117" class="title">The Effects of Time Constraints on User Behavior for Deferrable Interruptions</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979404&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Peter  Bogunovich</span> <span class="affiliation">Drexel University</span>, <br />
<span class="author">Dario  Salvucci</span> <span class="affiliation">Drexel University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Previous studies of multitasking have highlighted the importance of <br /> cognitive load in interruptibility by showing that forced interruptions <br /> are least disruptive when cognitive load is low, and also that users <br /> prefer to address interruptions at low-load points when given a choice. <br /> We present an empirical study that uses a ringing-phone scenario to examine <br /> how users manage deferrable interruptions in the presence of varying time <br /> constraints. We found that while cognitive load did influence multitasking as expected, <br /> the time constraints placed on the user also had a significant impact. In particular, we observed <br /> three distinct strategies for addressing interruption: the <br /> expected strategy of switching at low-load points, but also two other strategies of continuing <br /> on after a low-load point or giving up at a high-load point. <br /> The presence of the latter two strategies strongly suggests that users can adapt their <br /> multitasking behavior with respect to the time constraints of the interrupting task. <br /></span></div></div><div class="paper" id="paper1230"><a href="#paper1230" class="title">Why Do I Keep Interrupting Myself?: Environment, Habit and Self-Interruption</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979405&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Laura  Dabbish</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Gloria  Mark</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">V&#237;ctor M Gonz&#225;lez</span> <span class="affiliation">Instituto Tecnol&#243;gico Aut&#243;nomo de M&#233;xico (ITAM)</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Self-interruptions account for a significant portion of task switching in information-centric work contexts. However, most of the research to date has focused on understanding, analyzing and designing for external interruptions. The causes of self-interruptions are not well understood. In this paper we present an analysis of 889 hours of observed task switching behavior from 36 individuals across three high-technology information work organizations. Our analysis suggests that self-interruption is a function of organizational environment and individual differences, but also external interruptions experienced. We find that people in open office environments interrupt themselves at a higher rate. We also find that people are significantly more likely to interrupt themselves to return to solitary work associated with central working spheres, suggesting that self-interruption occurs largely as a function of prospective memory events. The research presented contributes substantially to our understanding of attention and multitasking in context.</span></div></div></td>
<td colspan="12" class="session_details" id="S1256_details"><div class="sessionChair"><strong>Session Chair: </strong>Wendy Mackay (<em>INRIA</em>)</div><div class="paper" id="paper1196"><a href="#paper1196" class="title">Finders/Keepers: A Longitudinal Study of People Managing Information Scraps in a Micro-note Tool</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979374&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Max  Van Kleek</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Wolfe  Styke</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">m.c.  schraefel</span> <span class="affiliation">University of Southampton</span>, <br />
<span class="author">David  Karger</span> <span class="affiliation">Massachusetts Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mainstream PIM tools capture only a portion of the information that people need to manage.  Many information scraps seem to exist that don't make their way into these tools, instead being relegated to sticky notes, text files, and other makeshift storage, or simply being lost.  In an effort to understand the role of these information scraps, the underlying needs they reflect, and the way PIM tools must be modified to support those needs, we created List-it, a micronote tool for quick and simple capture of information scraps.   <br />  <br /> In this article, we analyze the notes and interaction logs of 420 volunteer users of List-it over a two-year period of study (August 2008-August 2010).  We contextualize our analysis with results of two surveys and an e-mail interview we conducted in October 2009.  We find that people are drawn to List-it by the ease and speed of note capture and by the ability to record scraps with arbitrary content that blends or completely escapes the types and roles imposed by our rigid PIM tools.  Notes are taken to serve a variety of needs -- reminding, reference, journaling/activity logging, brainstorming, and to indefinitely archive information of sentimental or personal value.  Finally, while people differ considerably in the ways they keep information, our findings suggest such differences can be described  as a combination of four distinct strategies, enriching  the Filer/Piler distinction identified for classic document management.</span></div></div><div class="paper" id="paper152"><a href="#paper152" class="title">The Imposition and Superimposition of Digital Reading Technology: The Academic Potential of E-readers</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979375&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alexander  Thayer</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Charlotte P Lee</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Linda H Hwang</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Heidi  Sales</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Pausali  Sen</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Ninad  Dalal</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While rapid growth in e-reader use is receiving much attention in industry and academia, the use of e-readers for academic reading remains understudied. This qualitative study investigates how graduate students accomplish their academic reading and integrate an e-reader into their reading practices. Our work represents the first long-term study of e-reading on a production device (the Amazon Kindle DX). In this paper we contribute new knowledge to the discussion of the academic potential of e-readers by analyzing the meta-level relationship between reading tasks and associated reading techniques, students&#8217; compensation for the limitations of e-readers, and the hindrance of the human ability to construct cognitive maps of texts when using e-readers.</span></div></div><div class="paper" id="paper2145"><a href="#paper2145" class="title">Active Reading and Its Discontents:  The Situations, Problems and Ideas of Readers</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979376&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Craig S Tashman</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">W. Keith  Edwards</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The increasing popularity of personal reading devices raises the question of how best to support so-called active reading, which involves acts like annotation, note taking, etc. Prior research addressed this question by observing the active reading process, and identifying disparities between computers and paper as a reading medium. We extend this research by 1) investigating the problems that readers experience in their real world tasks, 2) inquiring about their requirements for an ideal reading technology, and 3) updating earlier studies of naturalistic reading behavior, which are several years old now. We present here the results of our investigation, which included a diary study, interviews, and participatory design workshops.</span></div></div><div class="paper" id="cs145"><a href="#cs145" class="title">Bells, Whistles, and Alarms: HCI Lessons Using AJAX for a Page-turning Web Application</a>&nbsp;-&nbsp;<span class="type">Case Study (Long)</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979677&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Juliet L. Hardesty</span> <span class="affiliation">Indiana University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This case study describes creating a version of METS Navigator, a page-turning web application for multi-part digital objects, using an AJAX library with user interface components.  The design for this version created problems for customized user interactions and accessibility problems for users, including those using assistive technologies and mobile devices.  A review of the literature considers AJAX, accessibility, and universal usability and possible steps to take moving forward to correct these problems in METS Navigator.</span></div></div></td>
<td colspan="12" class="session_details" id="S1259_details"><div class="sessionChair"><strong>Session Chair: </strong>Kenton O'Hara (<em>CSIRO</em>)</div><div class="paper" id="paper971"><a href="#paper971" class="title">Materializing the Query with Facet-Streams - A Hybrid Surface for Collaborative Search on Tabletops</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979390&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Hans-Christian  Jetter</span> <span class="affiliation">University of Konstanz</span>, <br />
<span class="author">Jens  Gerken</span> <span class="affiliation">University of Konstanz</span>, <br />
<span class="author">Michael  Z&#246;llner</span> <span class="affiliation">University of Konstanz</span>, <br />
<span class="author">Harald  Reiterer</span> <span class="affiliation">University of Konstanz</span>, <br />
<span class="author">Natasa  Milic-Frayling</span> <span class="affiliation">Microsoft Research Ltd</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We introduce &#8220;Facet-Streams&#8221;, a hybrid interactive surface for co-located collaborative product search on a tabletop. Facet-Streams combines techniques of information visualization with tangible and multi-touch interaction to materialize collaborative search on a tabletop. It harnesses the expressive power of facets and Boolean logic without exposing users to complex formal notations. Two user studies reveal how Facet-Streams unifies visual and tangible expressivity with simplicity in interaction, supports different strategies and collaboration styles, and turns product search into a fun and social experience.</span></div></div><div class="paper" id="paper1968"><a href="#paper1968" class="title">Gestures in The Wild: Studying Multi-Touch Gesture Sequences on Interactive Tabletop Exhibits</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979391&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Uta  Hinrichs</span> <span class="affiliation">University of Calgary</span>, <br />
<span class="author">Sheelagh  Carpendale</span> <span class="affiliation">University of Calgary</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe our findings from a field study that was conducted at the Vancouver Aquarium to investigate how visitors interact with a large interactive table exhibit using multi-touch gestures. Our findings show that the choice and use of multi-touch gestures are influenced not only by general preferences for certain gestures but also by the interaction context and social context they occur in. We found that gestures are not executed in isolation but linked into sequences where previous gestures influence the formation of subsequent gestures. Furthermore, gestures were used beyond the manipulation of media items to support social encounters around the tabletop exhibit. Our findings indicate the importance of versatile many-to-one mappings between gestures and their actions that, other than one-to-one mappings, can support fluid transitions between gestures as part of sequences and facilitate social information exploration.</span></div></div><div class="paper" id="paper1326"><a href="#paper1326" class="title">Rethinking 'multi-user': an in-the-wild study of how groups approach a walk-up-and-use tabletop in a tourist centre</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979392&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Paul  Marshall</span> <span class="affiliation">The University of Warwick</span>, <br />
<span class="author">Richard  Morris</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Yvonne  Rogers</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Stefan  Kreitmayer</span> <span class="affiliation">The Open University</span>, <br />
<span class="author">Matt  Davies</span> <span class="affiliation">user-x.com</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Multi-touch tabletops have been much heralded as an innovative technology that can facilitate new ways of group working. However, there is little evidence of these materialising outside of research lab settings. We present the findings of a 5-week in-the-wild study examining how a shared planning application &#8211; designed to run on a walk-up-and-use tabletop &#8211; was used when placed in a tourist information centre. We describe how groups approached, congregated and interacted with it and the social interactions that took place &#8211; noting how they were quite different from research findings describing the ways groups work around a tabletop in lab settings. We discuss the implications of such situated group work for designing collaborative tabletop applications for use in public settings.</span></div></div><div class="paper" id="paper669"><a href="#paper669" class="title">The effects of interaction techniques on talk patterns in collaborative peer learning around interactive tables</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979393&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Izdihar  Jamil</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Kenton  O'Hara</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Mark  Perry</span> <span class="affiliation">Brunel University / Mobile Life, Interactive Institute</span>, <br />
<span class="author">Abhijit  Karnik</span> <span class="affiliation">University of Bristol</span>, <br />
<span class="author">Sriram  Subramanian</span> <span class="affiliation">University of Bristol</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents the findings of a user study investigating conversational patterns across three conditions of table-based interaction (direct touch interactive table, pantograph interactive table and non-digital table) for different types of educational activities. Findings demonstrate that communication style is significantly affected by interaction techniques. The direct touch technique stimulated conversations based around the topic and pedagogical method. The pantograph technique promoted playfulness and had a higher number of directive utterances between participants, with fewer task-based, group-oriented utterances. The non-digital table promoted reflective forms of task-orientated utterance, encouraged group communication and fostered more equitable participation between members. The findings provide insights into the design of interactive tables to support particular forms of social interaction.</span></div></div></td>
<td colspan="12" class="session_details" id="S1250_details"><div class="paper" id="pl107"><a href="#pl107" class="title">Quality Control: on the Critique and Criticism of Design Research</a>&nbsp;-&nbsp;<span class="type">Panel</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979497&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jodi  Forlizzi</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Carl  DiSalvo</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Jeffrey  Bardzell</span> <span class="affiliation">Indiana University Bloomington</span>, <br />
<span class="author">Ilpo  Koskinen</span> <span class="affiliation">Aalto University</span>, <br />
<span class="author">Stephan  Wensveen</span> <span class="affiliation">Eindhoven University of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Design research is an emerging area in design that has increasing relevance to the field of HCI. While we have made advances in integrating design research methods, approaches, and outcomes in HCI, we still have a way to go. This is due to fundamental differences in the development of design knowledge as compared to scientific knowledge and knowledge about human theories of behavior. We call together this panel at CHI 2011, comprised of leading HCI/design researchers, to explore ways to develop and refine critical discussions of design research within the HCI community.</span></div></div></td>
<td colspan="12" class="session_details" id="S1260_details"><div class="sessionChair"><strong>Session Chair: </strong>Sunny Consolvo (<em>Intel Labs</em>)</div><div class="paper" id="paper1346"><a href="#paper1346" class="title">Opportunities for Computing Technologies to  Support Healthy Sleep Behaviors</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979395&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Eun Kyoung  Choe</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Sunny  Consolvo</span> <span class="affiliation">Intel Labs Seattle</span>, <br />
<span class="author">Nathaniel F Watson</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Julie A Kientz</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Getting the right amount of quality sleep is a key aspect of good health, along with a healthy diet and regular exercise. Human-computer interaction (HCI) researchers have recently designed systems to support diet and exercise, but sleep has been relatively under-studied in the HCI community. We conducted a literature review and formative study aimed at uncovering opportunities for computing to support the important area of promoting healthy sleep. We present results from interviews with sleep experts, as well as a survey (N = 230) and interviews with potential users (N = 16) to indicate what people would find practical and useful for sleep. Based on these results, we identify a number of design considerations, challenges, and opportunities for using computing to support healthy sleep behaviors, as well as a design framework for mapping the design space of technologies for sleep.</span></div></div><div class="paper" id="paper1682"><a href="#paper1682" class="title">How to Evaluate Technologies for Health Behavior Change in HCI Research</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979396&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Predrag  Klasnja</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Sunny  Consolvo</span> <span class="affiliation">Intel Labs</span>, <br />
<span class="author">Wanda  Pratt</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">New technologies for encouraging physical activity, healthy diet, and other types of health behavior change now frequently appear in the HCI literature. Yet, how such technologies should be evaluated within the context of HCI research remains unclear. In this paper, we argue that the obvious answer to this question&#8212;that evaluations should assess whether a technology brought about the intended change in behavior&#8212;is too limited. We propose that demonstrating behavior change is often infeasible as well as unnecessary for a meaningful contribution to HCI research, especially when in the early stages of design or when evaluating novel technologies. As an alternative, we suggest that HCI contributions should focus on efficacy evaluations that are tailored to the specific behavior-change intervention strategies (e.g., self-monitoring, conditioning) embodied in the system and studies that help gain a deep understanding of people&#8217;s experiences with the technology.</span></div></div><div class="paper" id="paper633"><a href="#paper633" class="title">Motivating Mobility: Designing for Lived Motivation in Stroke Rehabilitation</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979397&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Madeline  Balaam</span> <span class="affiliation">Newcastle University</span>, <br />
<span class="author">Stefan  Rennick Egglestone</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Geraldine  Fitzpatrick</span> <span class="affiliation">Vienna University of Technology</span>, <br />
<span class="author">Tom  Rodden</span> <span class="affiliation">University of Nottingham</span>, <br />
<span class="author">Ann-Marie  Hughes</span> <span class="affiliation">University of Southampton</span>, <br />
<span class="author">Anna  Wilkinson</span> <span class="affiliation">Sheffield Hallam University</span>, <br />
<span class="author">Thomas  Nind</span> <span class="affiliation">University of Dundee</span>, <br />
<span class="author">Lesley  Axelrod</span> <span class="affiliation">University of Sussex</span>, <br />
<span class="author">Eric  Harris</span> <span class="affiliation">University of Sussex</span>, <br />
<span class="author">Ian  Ricketts</span> <span class="affiliation">University of Dundee</span>, <br />
<span class="author">Susan  Mawson</span> <span class="affiliation">Sheffield Hallam University</span>, <br />
<span class="author">Jane  Burridge</span> <span class="affiliation">University of Southampton</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">How to motivate and support behaviour change through design is becoming of increasing interest to the CHI community. In this paper, we present our experiences of building systems that motivate people to engage in upper limb rehabilitation exercise after stroke. We report on participatory design work with four stroke survivors to develop a holistic understanding of their motivation and rehabilitation needs, and to construct and deploy engaging interactive systems that satisfy these. We reflect on the limits of motivational theories in trying to design for the lived experience of motivation and highlight lessons learnt around: helping people articulate what motivates them; balancing work, duty, fun; supporting motivation over time; and understanding the wider social context. From these we identify design guidelines that can inform a toolkit approach to support both scalability and personalisability.</span></div></div><div class="paper" id="paper227"><a href="#paper227" class="title">Group Pulmonary Rehabilitation Delivered to the Home via the Internet: Feasibility and Patient Perception</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979398&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrea  Taylor</span> <span class="affiliation">Glasgow School of Art</span>, <br />
<span class="author">Angus  Aitken</span> <span class="affiliation">LifeScan</span>, <br />
<span class="author">David  Godden</span> <span class="affiliation">University of Aberdeen</span>, <br />
<span class="author">Judith  Colligan</span> <span class="affiliation">NHS Highland</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Chronic Obstructive Pulmonary Disease (COPD) is a common and debilitating lung condition. Pulmonary rehabilitation is effective in treating COPD. Rehabilitation, combining physical exercise with education, is usually undertaken in hospital or clinic-based groups led by a clinician. The support of the group is important. However, distance of travel, and mobility and transport problems can mean that patients are unable to participate. This paper describes a feasibility study to deliver a program to a group of patients in their own homes, improving accessibility. A novel videoconferencing system was installed in four patient&#8217;s homes, connected to their TV and the Internet. A physiotherapist delivered a pulmonary rehabilitation program, involving twice-weekly exercise sessions for eight weeks. All were visible and audible to maintain the group-based approach of the conventional program. The technology performed well, satisfaction was high, and clinical improvements occurred in all patients, comparable to a conventional program. Larger studies are warranted.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">14:00<br />-<br />15:20</td>

<td class="session " id="S1265">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1265" class="title">Accessible Games SIG</a>
<span class="location">111/112</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1270">
<div class="session_box">
<span class="type"></span>
<a href="#S1270" class="title">Student Design Competition</a>
<span class="location">119/120</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1264">
<div class="session_box">
<span class="type">SIG Meeting</span>
<a href="#S1264" class="title">Designing for the UX of Sociability in MMO Games</a>
<span class="location">210</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1274">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1274" class="title">Tactile Interaction</a>
<span class="location">211</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1279">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1279" class="title">Courriel</a>
<span class="location">223/224</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1273">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1273" class="title">Privacy</a>
<span class="location">208/209</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1277">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1277" class="title">Developers &amp; End-user Programmers</a>
<span class="location">217/218/219</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1278">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1278" class="title">Incentives &amp; User Generated Content</a>
<span class="location">220/221/222</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>

<td class="session " id="S1272">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1272" class="title">Books &amp; Language</a>
<span class="location">205/206/207</span>
<strong></strong>

</div>
</td>

<td class="session " id="S1275">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1275" class="title">Tabletop &amp; Wall Displays</a>
<span class="location">212/213/214</span>
<strong></strong>

</div>
</td>

<td class="session tbd" id="S1266">
<div class="session_box">
<span class="type"></span>
<a href="#S1266" class="title">Closed: Plenary Setup</a>
<span class="location">Ballroom A/B</span>
<strong>Details : TBA</strong>

</div>
</td>

<td class="session " id="S1276">
<div class="session_box">
<span class="type">Paper</span>
<a href="#S1276" class="title">Doctor-Patient Care</a>
<span class="location">215/216</span>
<strong></strong>
<div class="awardImages"><img class="bpImage" src="nominee.png" alt="Honorable Mention" /><span style="display: none">Honorable Mention</span></div>
</div>
</td>
</tr>
<tr class="details_row"><td colspan="12" class="session_details" id="S1265_details"><div class="paper" id="si111"><a href="#si111" class="title">Accessible Games SIG</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979545&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Arnold  Lund</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Annuska  Perkins</span> <span class="affiliation">Microsoft</span>, <br />
<span class="author">Sri  Kurniawan</span> <span class="affiliation">Baskin School of Engineering</span>, <br />
<span class="author">Lennart  Nacke</span> <span class="affiliation">University of Saskatchewan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Video games are early adopters of emerging technologies and introduce them to the mainstream market.  Increasingly work-related applications follow the lead of entertainment systems.  Yet with the growing importance and complexity of 3D technologies and virtual worlds, motion and gesture interfaces, more barriers are being raised that prevent people with disabilities from using or fully enjoying them.  These new gaming experiences often require more control than current assistive technologies can support, even when the architectures themselves are designed to be accessible. <br />  <br /> The Accessible Games SIG will provide an opportunity for people working in the area of accessible games and entertainment or who can bring value to the area to meet and network, and to discuss future community building activities.  A goal is to stimulate more collaboration in the accessible games area.  In addition to sharing current work and identifying areas of common interest, a scenario focused exercise will be held that imagines a fully accessible networked virtual world game in order to uncover opportunities for research and innovation. <br /></span></div></div></td>
<td colspan="12" class="session_details" id="S1264_details"><div class="paper" id="si123"><a href="#si123" class="title">Designing for the UX of Sociability in MMO Games</a>&nbsp;-&nbsp;<span class="type">SIG Meeting</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979544&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Georgios  Christou</span> <span class="affiliation">European University Cyprus</span>, <br />
<span class="author">Panayiotis  Zaphiris</span> <span class="affiliation">Cyprus University of Technology</span>, <br />
<span class="author">Chee Siang  Ang</span> <span class="affiliation">University of Kent</span>, <br />
<span class="author">Effie Lai-Chong  Law</span> <span class="affiliation">ETH Z&#252;rich</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The emergence of MMOGs has led to new ways of socializing with friends. Nowadays a good online game is also associated with the pleasure of socializing and interacting with other players. One cannot play a game <br /> solitarily in a meaningful sense without interacting with the other players. However, there are still no integrated ways of designing and evaluating the inherent sociability of MMOGs, nor are there methods or <br /> guidelines for evaluating social user experiences. Designers of MMOGs are often left to use their intuition and experience, many times leading to design failures. This SIG aims to further the understanding of the challenges relating to the design of the social interactions that users experience, and the way these manifest and are supported in Massively Multi-player Online Games (MMOGs). The goal is to examine the <br /> ways that sociability manifests in MMOGs and the way that design affects these manifestations.</span></div></div></td>
<td colspan="12" class="session_details" id="S1274_details"><div class="sessionChair"><strong>Session Chair: </strong>Anne Roudaut (<em>Hasso Plattner Institute</em>)</div><div class="paper" id="paper1866"><a href="#paper1866" class="title">Enhancing Independence and Safety for Blind and Deaf-Blind Public Transit Riders</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979424&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Shiri  Azenkot</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Sanjana  Prasain</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Alan  Borning</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Emily  Fortuna</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Richard E. Ladner</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Jacob O. Wobbrock</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Blind and deaf-blind people often rely on public transit for everyday mobility, but using transit can be challenging for them. We conducted semi-structured interviews with 13 blind and deaf-blind people to understand how they use public transit and what human values were important to them in this domain. Two key values were identified: independence and safety. We developed GoBraille, two related Braille-based applications that provide information about buses and bus stops while supporting the key values. GoBraille is built on MoBraille, a novel framework that enables a Braille display to benefit from many features in a smartphone without knowledge of proprietary, device-specific protocols. Finally, we conducted user studies with blind people to demonstrate that GoBraille enables people to travel more independently and safely. We also conducted co-design with a deaf-blind person, finding that a minimalist interface, with short input and output messages, was most effective for this population.</span></div></div><div class="paper" id="paper173"><a href="#paper173" class="title">A Haptic Wristwatch for Eyes-Free Interactions</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979425&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jerome  Pasquero</span> <span class="affiliation">Research In Motion Limited</span>, <br />
<span class="author">Scott J. Stobbe</span> <span class="affiliation">Research In Motion Limited</span>, <br />
<span class="author">Noel  Stonehouse</span> <span class="affiliation">Research In Motion Limited</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a haptic wristwatch prototype that makes it possible to acquire information from a companion mobile device through simple eyes-free gestures. The wristwatch we have built uses a custom-made piezoelectric actuator combined with sensors to create a natural, inconspicuous, gesture-based interface. Feedback is returned to the user in the form of haptic stimuli that are delivered to the wrist. We evaluated the capabilities and limitations of our prototype through two user experiments. One experiment verified that the apparatus could be used as a tactile notification mechanism. The other experiment assessed the feasibility of using a cover-and-hold gesture on the wristwatch to obtain numerical data tactually. Results from the numerosity experiment and feedback from participants prompted us to redesign the cover-and-hold gesture to provide users with additional control over the interaction. We qualitatively evaluated the redesigned interaction by handing the prototype to users so that they could use it in a realistic work environment. Taken together, results from the experiments and the validation process indicate that a wrist accessory can be effectively used to perform discreet, closed-loop, eyes-free interactions with a mobile device.</span></div></div><div class="paper" id="paper1290"><a href="#paper1290" class="title">Detecting Vibrations Across the Body in Mobile Contexts</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979426&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Idin  Karuei</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Karon E. MacLean</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Zoltan  Foley-Fisher</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Russell  MacKenzie</span> <span class="affiliation">University of British Columbia</span>, <br />
<span class="author">Sebastian  Koch</span> <span class="affiliation">Technische Universit&#228;t Darmstadt</span>, <br />
<span class="author">Mohamed  El-Zohairy</span> <span class="affiliation">University of British Columbia</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we explore the potential and limitations of vibrotactile displays in practical wearable applications, by comparing users&#8217; detection rate and response time to stimuli applied across the body in varied conditions. We examined which body locations are more sensitive to vibrations and more affected by movement; whether visual workload, expectation of location, or gender impact performance; and if users have subjective preferences to any of these conditions.  In two experiments we compared these factors using five vibration intensities on up to 13 body locations. Our contributions are comparisons of tactile detection performance under conditions typifying mobile use, an experiment design that supports further investigation in vibrotactile communication, and guidelines for optimal display location given intended use.</span></div></div><div class="paper" id="paper731"><a href="#paper731" class="title">Tactile Feedback Can Assist Vision During Mobile Interactions</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979427&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jerome  Pasquero</span> <span class="affiliation">Research In Motion Limited</span>, <br />
<span class="author">Vincent  Hayward</span> <span class="affiliation">Universit&#233; Pierre et Marie Curie</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We evaluated the use of rich tactile feedback in the task of scrolling through a long list of items. We used a hand-held device having a tactile transducer that could provide sensations with temporal and spatial content. These capabilities were put to use in an interaction metaphor where input and tactile feedback were tightly coupled. We measured time- to-target and error rates, but also measured the time spent by participants to look at the screen. We found a 28% decrease of reliance on vision when tactile feedback was enabled.</span></div></div><div class="paper" id="paper1457"><a href="#paper1457" class="title">Designing Tactile Feedback for Piezo Buttons</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979428&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jani  Lylykangas</span> <span class="affiliation">University of Tampere</span>, <br />
<span class="author">Veikko  Surakka</span> <span class="affiliation">University of Tampere</span>, <br />
<span class="author">Katri  Salminen</span> <span class="affiliation">University of Tampere</span>, <br />
<span class="author">Jukka  Raisamo</span> <span class="affiliation">University of Tampere</span>, <br />
<span class="author">Pauli  Laitinen</span> <span class="affiliation">Aito Interactive Inc.</span>, <br />
<span class="author">Kasper  R&#246;nning</span> <span class="affiliation">Aito Interactive Inc.</span>, <br />
<span class="author">Roope  Raisamo</span> <span class="affiliation">University of Tampere</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The present aim was to study the preference of tactile feedback stimulations given by non-physical (i.e., solid) piezo-actuated buttons. Participants (n=16) ranked 16 different tactile feedback stimuli varied by 4 output delays and 4 vibration durations. The results showed that the mean ranks of the stimuli differed significantly from each other. The timing parameters of delay and duration interacted with each other, for example, so that preference of certain vibration duration fluctuated in response to different output delays. Using a very short time window (i.e., 10&#8211;453 ms) combining both delay and duration parameters of the feedback could result either in favorable or significantly less favorable subjective experience. The results suggest that a preferred perception of tactile feedback from non-physical buttons requires careful design and controlling of the timing parameters.</span></div></div></td>
<td colspan="12" class="session_details" id="S1279_details"><div class="sessionChair"><strong>Session Chair: </strong>Laura Dabbish (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper1757"><a href="#paper1757" class="title">Should I Open this Email?: Inbox-Level Cues, Curiosity and Attention to Email</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979456&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jaclyn  Wainer</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Laura  Dabbish</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Robert  Kraut</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The quantity of email people receive each day can be overwhelming. Previous research suggests that when handling email, individuals prioritize certain messages for attention over others. Since people generally make this decision about which message to read before opening the email, the question largely unanswered in the email literature is: what surface features of an email draw attention to it? In this research, we examined how top-level cues about an email&#8217;s content influence attention to email. We describe results from a think-aloud study examining people&#8217;s stated rationale for prioritizing certain emails over others. Based on these results and theory on curiosity, we conducted an experiment examining how message importance, subject line specificity, workload and personal utility influence attention to email. Results suggest that uncertainty about message content at the inbox level increases the likelihood of attention to a message. The influence of uncertainty diminishes, however, in the face of enhanced task and personal utility cues and increased demand, suggesting that curiosity operates in an intrinsic way in the email context. Our results have implications for intelligent email system design, email client interfaces, and reducing email strain.</span></div></div><div class="paper" id="paper692"><a href="#paper692" class="title">Am I wasting my time organizing email? A study of email refinding</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979457&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Steve  Whittaker</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Tara  Matthews</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Julian  Cerruti</span> <span class="affiliation">IBM Research - Argentina</span>, <br />
<span class="author">Hernan  Badenes</span> <span class="affiliation">IBM Research - Argentina</span>, <br />
<span class="author">John  Tang</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We all spend time every day looking for information in our email, yet we know little about this refinding process. Some users expend considerable preparatory effort creating complex folder structures to promote effective refinding. However modern email clients provide alternative opportunistic methods for access, such as search and threading, that promise to reduce the need to manually prepare. To compare these different refinding strategies, we instrumented a modern email client that supports search, folders, tagging and threading. We carried out a field study of 345 long-term users who conducted over 85,000 refinding actions. Our data support opportunistic access. People who create complex folders indeed rely on these for retrieval, but these preparatory behaviors are inefficient and do not improve retrieval success. In contrast, both search and threading promote more effective finding. We present design implications: current search-based clients ignore scrolling, the most prevalent refinding behavior, and threading approaches need to be extended.</span></div></div><div class="paper" id="paper952"><a href="#paper952" class="title">Using Email to Facilitate Wiki-based Coordinated, Collaborative Authoring</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979458&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Changyan  Chi</span> <span class="affiliation">IBM Research - China</span>, <br />
<span class="author">Michelle  Zhou</span> <span class="affiliation">IBM Research - Almaden</span>, <br />
<span class="author">Wenpeng  Xiao</span> <span class="affiliation">IBM Research - China</span>, <br />
<span class="author">Min  Yang</span> <span class="affiliation">IBM Research - China</span>, <br />
<span class="author">Eric  Wilcox</span> <span class="affiliation">IBM Research - Almaden</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Dandelion is a wiki-based tool that supports coordinated, collaborative authoring. In this paper, we present an ex-tended version of Dandelion, which provides an email inter-face for users to accomplish their tasks by email in a coor-dinated, collaborative authoring process. Specifically, Dan-delion employs a semi-structured, template-based approach that allows users to use templates to specify their requests in email. These emailed requests can be interpreted by Dandelion and are then used to automatically drive the col-laboration flow. As part of its actions, Dandelion automati-cally creates a wiki page and dynamically updates it to re-cord co-authoring tasks and collate co-authored content.  As a result, users can use their familiar tool (email) to accom-plish their tasks in a co-authoring process, while leveraging a wiki for additional benefits (e.g., obtaining collaboration awareness and formatting the text). Our preliminary study with two groups of users shows the usefulness of both Dan-delion email and wiki features and their impact on collabo-ration effectiveness.</span></div></div><div class="paper" id="paper1172"><a href="#paper1172" class="title">F for Fake: Four Studies on How We Fall for Phish</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979459&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Mark  Blythe</span> <span class="affiliation">University of Northumbria</span>, <br />
<span class="author">Helen  Petrie</span> <span class="affiliation">University of York</span>, <br />
<span class="author">John A. Clark</span> <span class="affiliation">University of York</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper reports findings from a multi-method set of four studies that investigate why we continue to fall for phish. Current security advice suggests poor spelling and grammar in emails can be signs of phish. But a content analysis of a phishing archive indicates that many such emails contain no obvious spelling or grammar mistakes and often use convincing logos and letterheads. An online survey of 224 people finds that although phish are detected approximately 80% of the time, those with logos are significantly harder to detect. A qualitative interview study was undertaken to better understand the strategies used to identify phish. Blind users were selected because it was thought they may be more vulnerable to phishing attacks, however they demonstrated robust strategies for identifying phish based on careful reading of emails. Finally an analysis was undertaken of phish as a literary form. This identifies the main literary device employed as pastiche and draws on critical theory to consider why security based pastiche may be currently very persuasive.</span></div></div></td>
<td colspan="12" class="session_details" id="S1273_details"><div class="sessionChair"><strong>Session Chair: </strong>John Karat (<em>IBM Research</em>)</div><div class="paper" id="paper512"><a href="#paper512" class="title">Situating the Concern for Information Privacy through an Empirical Study of Responses to Video Recording</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979419&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">David H. Nguyen</span> <span class="affiliation">UC Irvine</span>, <br />
<span class="author">Aurora  Bedford</span> <span class="affiliation">UC Irvine</span>, <br />
<span class="author">Alexander  Bretana</span> <span class="affiliation">UC Irvine</span>, <br />
<span class="author">Gillian R. Hayes</span> <span class="affiliation">UC Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we present the results of an empirical study of perceptions towards pervasive video recording. We describe a commonly used model for understanding information privacy, the Concern for Information Privacy (CFIP) model, and present the ways that this model and its associated questionnaire can shed light on information privacy concerns about pervasive and ubiquitous computing technologies. Specifically, the CFIP model encourages analysis of data across four facets of experience: the collection of personal data, the risk of improper access, the potential for unauthorized secondary use, and the challenge of preventing or correcting errors in the data. We further identify areas not well handled by this model of information privacy and suggest avenues for future work, including research on how and when to notify people about recording technologies, awareness of data provenance and leakage, and understanding of and access to the data assemblage being created about individuals.</span></div></div><div class="paper" id="paper1318"><a href="#paper1318" class="title">We're in It Together: Interpersonal Management of Disclosure in Social Network Services</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979420&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Airi  Lampinen</span> <span class="affiliation">Helsinki Institute for Information Technology HIIT / Aalto University / University of California - Berkeley</span>, <br />
<span class="author">Vilma  Lehtinen</span> <span class="affiliation">Helsinki Institute for Information Technology HIIT / Aalto University</span>, <br />
<span class="author">Asko  Lehmuskallio</span> <span class="affiliation">Helsinki Institute for Information Technology HIIT / Aalto University</span>, <br />
<span class="author">Sakari  Tamminen</span> <span class="affiliation">Software Business and Engineering institute / Aalto University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The workload needed for managing privacy and publicness in current social network services (SNSs) is placed on individuals, yet people have few means to control what others disclose about them. This paper considers SNS-users&#8217; concerns in relation to online disclosure and the ways in which they cope with these both individually and collaboratively. While previous work has focused mainly on individual coping strategies, our findings from a qualitative study with 27 participants suggest that collaborative strategies in boundary regulation are of additional importance. We present a framework of strategies for boundary regulation that informs both theoretical work and design practice related to management of disclosure in SNSs. The framework considers disclosure as an interpersonal process of boundary regulation, in which people are dependent on what others choose to disclose about them. The paper concludes by proposing design solutions supportive of collaborative and preventive strategies in boundary regulation that facilitate the management of disclosure online.</span></div></div><div class="paper" id="paper482"><a href="#paper482" class="title">Privacy dictionary: A linguistic taxonomy of privacy for content analysis</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979421&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alastair J. Gill</span> <span class="affiliation">University of Surrey</span>, <br />
<span class="author">Asimina  Vasalou</span> <span class="affiliation">University of Bath</span>, <br />
<span class="author">Chrysanthi  Papoutsi</span> <span class="affiliation">University of Oxford</span>, <br />
<span class="author">Adam N. Joinson</span> <span class="affiliation">University of Bath</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Privacy is frequently a key concern relating to technology and central to HCI research, yet it is notoriously difficult to study in a naturalistic way. In this paper we describe and evaluate a dictionary of privacy designed for content analysis, derived using prototype theory and informed by traditional theoretical approaches to privacy. We evaluate our dictionary categories alongside privacy-related categories from an existing content analysis tool, LIWC, using verbal discussions of privacy issues from a variety of technology and non-technology contexts. We find that our privacy dictionary is better able to distinguish between privacy and non-privacy language, and is less context-dependent than LIWC. However, the more general LIWC categories are able to describe a greater amount of variation in our data. We discuss possible improvements to the privacy dictionary and note future work.</span></div></div><div class="paper" id="paper179"><a href="#paper179" class="title">Social and Technical Challenges in Parenting Teens&#8217; Social Media Use</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979422&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sarita  Yardi</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">Amy  Bruckman</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">With millions of teenagers on the Internet, millions of parents are trying to understand what their teens are doing and why. Understanding how technology use impacts teens&#8217; learning, growth, and social development is critical for their health and wellbeing and for the welfare of the family. Yet, balancing parent authority with teen privacy and autonomy is difficult. We conducted an interview study with 16 parents to examine challenges in &#8220;technoparenting&#8221;&#8212;parenting teens&#8217; technology use. Parents said they wanted more transparency in their teens&#8217; use of cell phones and the Internet and they struggled with their own unfamiliarity with technology. Technoparenting is a distributed problem and, surprisingly, parents wanted support and collaboration from the broader community. We conclude with design implications for a socially translucent &#8220;digital window.&#8221;</span></div></div></td>
<td colspan="12" class="session_details" id="S1277_details"><div class="sessionChair"><strong>Session Chair: </strong>Andrew Ko (<em>University of Washington</em>)</div><div class="paper" id="paper355"><a href="#paper355" class="title">Wrangler: Interactive Visual Specification of Data Transformation Scripts</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979444&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Sean  Kandel</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Andreas  Paepcke</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Joseph  Hellerstein</span> <span class="affiliation">UC Berkeley</span>, <br />
<span class="author">Jeffrey  Heer</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Though data analysis tools continue to improve, analysts still expend an inordinate amount of time and effort manip- ulating data and assessing data quality issues. Such &#8220;data wrangling&#8221; regularly involves reformatting data values or layout, correcting erroneous or missing values, and integrat- ing multiple data sources. These transforms are often dif- ficult to specify and difficult to reuse across analysis tasks, teams, and tools. In response, we introduce Wrangler, an interactive system for creating data transformations. Wran- gler combines direct manipulation of visualized data with automatic inference of relevant transforms, enabling ana- lysts to iteratively explore the space of applicable operations and preview their effects. Wrangler leverages semantic data types (e.g., geographic locations, dates, classification codes) to aid validation and type conversion. Interactive histories support review, refinement, and annotation of transformation scripts. User study results show that Wrangler significantly reduces specification time and promotes the use of robust, auditable transforms instead of manual editing.</span></div></div><div class="paper" id="paper830"><a href="#paper830" class="title">The Concept Maps Method as a Tool to Evaluate the Usability of APIs</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979445&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jens  Gerken</span> <span class="affiliation">University of Konstanz</span>, <br />
<span class="author">Hans-Christian  Jetter</span> <span class="affiliation">University of Konstanz</span>, <br />
<span class="author">Michael  Z&#246;llner</span> <span class="affiliation">University of Konstanz</span>, <br />
<span class="author">Martin  Mader</span> <span class="affiliation">University of Konstanz</span>, <br />
<span class="author">Harald  Reiterer Prof. Dr.</span> <span class="affiliation">University of Konstanz</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Application programming interfaces (APIs) are the interfaces to existing code structures, such as widgets, frameworks, or toolkits. Therefore, they very much do have an impact on the quality of the resulting system. So, ensuring that developers can make the most out of them is an important challenge. However standard usability evaluation methods as known from HCI have limitations in grasping the interaction between developer and API as most IDEs (essentially the GUI) capture only part of it. In this paper we present the Concept Map method to study the usability of an API over time. This allows us to elicit the mental model of a programmer when using an API and thereby identify usability issues and learning barriers and their development over time.</span></div></div><div class="paper" id="paper211"><a href="#paper211" class="title">Shared Substance: Developing Flexible Multi-Surface Applications</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979446&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tony  Gjerlufsen</span> <span class="affiliation">Aarhus University, Univ. Paris-Sud / Univ. Paris-Sud</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents a novel middleware for developing flexible interactive multi-surface applications. Using a scenario-based approach, we identify the requirements for this type of applications. We then introduce Substance, a data-oriented framework that decouples functionality from data, and Shared Substance, a middleware implemented in Substance that provides powerful sharing abstractions. We describe our implementation of two applications with Shared Substance and discuss the insights gained from these experiments. Our finding is that the combination of a data-oriented programming model with middleware support for sharing data and functionality provides a flexible, robust solution with low viscosity at both design-time and run-time.</span></div></div><div class="paper" id="paper1823"><a href="#paper1823" class="title">OldGen: Mobile Phone Personalization for Older Adults</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979447&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Alex  Olwal</span> <span class="affiliation">KTH</span>, <br />
<span class="author">Dimitris  Lachanas</span> <span class="affiliation">KTH</span>, <br />
<span class="author">Ermioni  Zacharouli</span> <span class="affiliation">KTH</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Mobile devices are currently difficult to customize for the usability needs of elderly users. The elderly are instead referred to specially designed &#8220;senior phones&#8221; or software add-ons. These tend to compromise in functionality as they attempt to solve many disabilities in a single solution.  <br />  <br /> We present OldGen, a prototype framework where a novel concept enables accessibility features on generic mobile devices, by decoupling the software user interface from the phone&#8217;s physical form factor. This opens up for better customization of the user interface, its functionality and behavior, and makes it possible to adapt it to the specific needs of each individual. OldGen makes the user interface portable, such that it could be moved between different phone hard-ware, regardless of model and brand. Preliminary observations and evaluations with elderly users indicate that this concept could address individual user interface related accessibility issues on general devices. <br /></span></div></div><div class="paper" id="paper837"><a href="#paper837" class="title">Dinah: An Interface to Assist Non-Programmers with Selecting Program Code Causing Graphical Output</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979448&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Paul  Gross</span> <span class="affiliation">Washington University in St. Louis</span>, <br />
<span class="author">Jennifer  Yang</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Caitlin  Kelleher</span> <span class="affiliation">Washington University in St. Louis</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The web holds an abundance of source code examples with the potential to become learning resources for any end-user. However, for some end-users these examples may be unusable. An example is unusable if a user cannot select the code in the example that corresponds to their interests. Research suggests that non-programmers struggle to correctly select the code responsible for interesting output functionality. In this paper we present Dinah: an interface to support non-programmers with selecting code causing graphical output. Dinah assists non-programmers by providing concurrency support and in-context affordances for statement replay and temporally based navigation.</span></div></div></td>
<td colspan="12" class="session_details" id="S1278_details"><div class="sessionChair"><strong>Session Chair: </strong>Robert Kraut (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper1453"><a href="#paper1453" class="title">Normative Influences on Thoughtful Online Participation</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979450&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Abhay  Sukumaran</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Stephanie  Vezich</span> <span class="affiliation">UCLA</span>, <br />
<span class="author">Melanie  McHugh</span> <span class="affiliation">Stanford University</span>, <br />
<span class="author">Clifford  Nass</span> <span class="affiliation">Stanford University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe two experimental studies on whether individual thoughtful effort during online commenting activity is shaped by situational norms stemming from (1) the social behavior of others, and (2) the design of the online environment, respectively. By measuring the length of participants&#8217; comments, the time taken to write them, and the number of issue-relevant thoughts they contain, we demonstrate that participants tend to conform to high vs. low norms of thoughtfulness manifested through either the apparent behavior of other users of the website or through visual, textual and interactional site design features conceptually associated with thoughtfulness. Theoretical and applied insights for designing online participatory environments are discussed.</span></div></div><div class="paper" id="paper595"><a href="#paper595" class="title">My Kind of People? Perceptions About Wikipedia Contributors and Their Motivations</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979451&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Judd  Antin</span> <span class="affiliation">Yahoo! Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Perceptions of information products such as Wikipedia can depend on assumptions and stereotypes about the people who create them. As new Wikipedians consider contributing they are likely to apply such assumptions and ask themselves: "Are Wikipedia contributors my kind of people? Is this a group I&#8217;d like to belong to?" In this qualitative <br /> study I address the potential challenge of these questions by exploring readers and infrequent editors&#8217; perceptions of Wikipedia contributors and their motivations. Through analysis of twenty semi-structured interviews, I find evidence of strong negative perceptions as well as positive ones which nonetheless prevent users from identifying with <br /> active Wikipedia contributors. I argue that these perceptions present a barrier to the progression of participation over time. I conclude by discussing the practical challenges of my findings for Wikipedia and other online collaborative systems.</span></div></div><div class="paper" id="paper1938"><a href="#paper1938" class="title">Computers can't Give Credit: How Automatic Attribution Falls Short in an Online Remixing Community</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979452&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andr&#233;s  Monroy-Hern&#225;ndez</span> <span class="affiliation">Microsoft Research, Massachusetts Institute of Technology</span>, <br />
<span class="author">Benjamin Mako  Hill</span> <span class="affiliation">Massachusetts Institute of Technology</span>, <br />
<span class="author">Jazmin  Gonzalez-Rivero</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">danah  boyd</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we explore the role that attribution plays in shaping <br /> user reactions to content reuse, or remixing, in a large <br /> user-generated content community. We present two studies using data <br /> from the Scratch online community -- a social media platform where <br /> hundreds of thousands of young people share and remix animations and <br /> video games.  First, we present a quantitative analysis that <br /> examines the effects of a technological design intervention <br /> introducing automated attribution of remixes on users' reactions to <br /> being remixed. We compare this analysis to a parallel examination of <br /> ``manual'' credit-giving. Second, we present a qualitative analysis <br /> of twelve in-depth, semi-structured, interviews with Scratch <br /> participants on the subject of remixing and attribution. Results <br /> from both studies suggest that automatic <br />emph{attribution} done by <br /> technological systems (i.e., the listing of names of contributors) <br /> plays a role that is distinct from, and less valuable than, <br /> <br />emph{credit} which may superficially involve identical information <br /> but takes on new meaning when it is given by a human remixer. We <br /> discuss the implications of these findings for the designers of <br /> online communities and social media platforms.</span></div></div><div class="paper" id="paper1159"><a href="#paper1159" class="title">Identifying Shared Leadership in Wikipedia</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979453&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Haiyi  Zhu</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Robert E Kraut</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Yi-Chia  Wang</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Aniket  Kittur</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we introduce a method to measure shared leadership in Wikipedia as a step in developing a new model of online leadership. We show that editors with varying degrees of engagement and from peripheral as well as central roles all act like leaders, but that core and peripheral editors show different profiles of leadership behavior. Specifically, we developed machine learning models to automatically identify four types of leadership behaviors from 4 million messages sent between Wikipedia editors. We found strong evidence of shared leadership in Wikipedia, with editors in peripheral roles producing a large proportion of leadership behaviors.</span></div></div><div class="paper" id="paper928"><a href="#paper928" class="title">Donate for Credibility:  How Contribution Incentives Can Improve Credibility</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979454&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Gary  Hsieh</span> <span class="affiliation">Michigan State University</span>, <br />
<span class="author">Scott E. Hudson</span> <span class="affiliation">Carnegie Mellon University</span>, <br />
<span class="author">Robert E. Kraut</span> <span class="affiliation">Carnegie Mellon University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This study explores whether certain contribution incentives for online user-generated content can undermine or enhance contributor&#8217;s credibility. In an online experiment, we found that contributors who are rewarded with donations made in their names are perceived to be more credible than contributors who are financially compensated through revenue sharing or contribute voluntarily. In addition, disclosing the chosen charity for donation can also impact credibility. Content viewer&#8217;s self-identification with charity and the congruency between charity and content topic are all factors that may enhance credibility. Our findings lead to practical implications on when and how to use contribution incentives to enhance credibility.</span></div></div></td>
<td colspan="12" class="session_details" id="S1272_details"><div class="sessionChair"><strong>Session Chair: </strong>Matthew Kam (<em>Carnegie Mellon University</em>)</div><div class="paper" id="paper1634"><a href="#paper1634" class="title">MicroMandarin: Mobile Language Learning in Context</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979413&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Darren  Edge</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Elly  Searle</span> <span class="affiliation">University of Washington</span>, <br />
<span class="author">Kevin  Chiu</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Jing  Zhao</span> <span class="affiliation">Peking University</span>, <br />
<span class="author">James A Landay</span> <span class="affiliation">University of Washington</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Learning a new language is hard, but learning to use it confidently in conversations with native speakers is even harder. From our field research with language learners, with support from Cognitive Psychology and Second Language Acquisition, we argue for the value of contextual microlearning in the many breaks spread across different places and throughout the day. We present a mobile application that supports such microlearning by leveraging the location-based service Foursquare to automatically provide contextually relevant content in the world&#8216;s major cities. In an evaluation of Mandarin Chinese learning, a four-week, 23-user study spanning Beijing and Shanghai compared this contextual system to a system based on word frequency. Study sessions with the contextual version lasted half as long but occurred in twice as many places as sessions with the frequency version, suggesting a complementary relationship between the two approaches.</span></div></div><div class="paper" id="paper730"><a href="#paper730" class="title">Augmenting the Web for Second Language Vocabulary Learning</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979414&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Andrew  Trusty</span> <span class="affiliation">University of Toronto</span>, <br />
<span class="author">Khai N. Truong</span> <span class="affiliation">University of Toronto</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The busyness of everyday life means that those with casual interest in additional learning opportunities are often unable to schedule regular time and effort for studying. In this paper, we explore how to augment information technologies that people use on a daily basis to create micro-learning opportunities. In particular, we examine how a person&#8217;s existing Web browsing experience&#8212;with first language Web pages&#8212;can be augmented to teach them second language vocabulary. We present a prototype, ALOE, which runs inside the Firefox Web browser and dynamically augments Web pages by replacing a selected set of English words with their foreign translations. The foreign translations are embedded in the rich context of a Web page&#8217;s existing English text to promote incidental learning and guessing from context of the translated words. Through a two month user evaluation of ALOE, we found that most participants were able to learn an average of 50 new French vocabulary words.</span></div></div><div class="paper" id="paper715"><a href="#paper715" class="title">Document Area Identification for Extending Books without Markers</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979415&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Akihiro  Miyata</span> <span class="affiliation">NTT Corporation</span>, <br />
<span class="author">Ko  Fujimura</span> <span class="affiliation">NTT Corporation</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a method of document area identification that utilizes <br /> consecutive characters in the non-reading direction as search keys. We <br /> use this method to develop a prototype system called Kappan. It <br /> enables service providers and users to create hyperlinks in books <br /> without markers. Existing techniques generally require markers to be <br /> printed on the page if a hyperlink is to be created. We consider that <br /> utilizing the concept of the search index makes markers <br /> unnecessary. Kappan associates indexed text areas in a large number of <br /> books with supporting digital contents.  The indexed text areas, <br /> freely defined by service providers or users, are identified by <br /> subjecting images of small areas of the printed page to OCR (Optical <br /> Character Recognition) and extracting from the text so recognized <br /> highly specific and efficient search keys. Traditional text indexing <br /> methods must extract long character sequences from the partial image <br /> in order to identify the area exactly given the sheer number of book <br /> pages. However, considering that the average OCR error rate is more <br /> than 20 percent if the partial image is captured by a camera-equipped <br /> cellular phone, it is highly probable that many characters would be <br /> misrecognized and area identification would thus fail. In contrast, <br /> our indexing method can extract area-specific clues using fewer <br /> characters that can identify the area exactly even when the partial <br /> image is small and the extracted text contains misrecognized <br /> characters. An experiment proves that our method can identify the <br /> exact area from more than one million areas with the high accuracy <br /> rates of 99 percent and 96 percent for OCR error rates of 0 percent <br /> and 22 percent, respectively. <br /></span></div></div><div class="paper" id="paper769"><a href="#paper769" class="title">The Reading Desk: Applying Physical Interactions to Digital Documents</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979416&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Jennifer  Pearson</span> <span class="affiliation">Swansea University</span>, <br />
<span class="author">George  Buchanan</span> <span class="affiliation">City University</span>, <br />
<span class="author">Harold  Thimbleby</span> <span class="affiliation">Swansea University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Reading is increasingly being performed interactively on-screen; for instance, new novels are now routinely released in electronic format for viewing on PCs and mobile devices. Unfortunately, on-screen reading loses many of the natural features of conventional physical media, such as the ability to annotate, slip in bookmarks, turn page corners, and so on. How best should these features be represented electronically? Can  computerized representations give benefits that excel the conventional benefits of paper? We describe the design and implementation of a novel reading system that mimics key properties of paper and surpasses them by incorporating digital techniques. A comparative user study evaluating the system confirmed the effectiveness of the features and the value of the system as a whole.</span></div></div><div class="paper" id="paper2075"><a href="#paper2075" class="title">ReadN'Karaoke: Visualizing Prosody in Children's Books for Expressive Oral Reading</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979417&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rupal  Patel</span> <span class="affiliation">Northeastern University</span>, <br />
<span class="author">William  Furr</span> <span class="affiliation">Northeastern University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We present a method for displaying prosody, the melody of speech, to aid beginning readers with fluent oral reading. We build on proven auditory techniques by manipulating and augmenting text in children&#8217;s stories. The acoustic properties of a fluent recording are used to construct visualizations of pitch, loudness and length variations in read samples aligned with text.Our initial approach was to directly manipulate text, which was tested on ten children who showed significant increases in pitch modulation with manipulated text but reported difficulty with word recognition. This motivated designing the augmented text renderings, which display prosodic cues layered with text. Manipulated and augmented texts were compared with two beginning readers. Children showed similar prosodic gains with both versions and reported greater satisfaction with augmented pitch cues. Visual prosodic cues show promise for improving reading fluency in early readers and may have applications for disability education and second language learning.</span></div></div></td>
<td colspan="12" class="session_details" id="S1275_details"><div class="sessionChair"><strong>Session Chair: </strong>Anne Marie Piper (<em>University of California, San Diego</em>)</div><div class="paper" id="paper748"><a href="#paper748" class="title">LiquidText: A Flexible, Multitouch Environment to Support Active Reading</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979430&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Craig S. Tashman</span> <span class="affiliation">Georgia Institute of Technology</span>, <br />
<span class="author">W. Keith  Edwards</span> <span class="affiliation">Georgia Institute of Technology</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">Active reading, involving acts such as highlighting, writing notes, etc., is an important part of knowledge workers&#8217; activities. Most computer-based active reading support seeks to replicate the affordances of paper, but paper has limitations, being in many ways inflexible. In this paper we introduce LiquidText, a computer-based active reading system that takes a fundamentally different approach, offering a flexible, fluid document representation built on multitouch input, with a range of interaction techniques designed to facilitate the activities of active reading. We report here on our design for LiquidText, its interactions and gesture vocabulary, and our design process, including formative user evaluations which helped shape the final system.</span></div></div><div class="paper" id="paper1632"><a href="#paper1632" class="title">Dimensions of Collaboration on a Tabletop Interface for Children with Autism Spectrum Disorder</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979431&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Leonardo  Giusti</span> <span class="affiliation">FBK</span>, <br />
<span class="author">Massimo  Zancanaro</span> <span class="affiliation">FBK</span>, <br />
<span class="author">Eynat  Gal</span> <span class="affiliation">University of Haifa</span>, <br />
<span class="author">Patrice T Weiss</span> <span class="affiliation">University of Haifa</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper we describe a co-located suite of games on a tabletop device to support social competence training for children with Autism Spectrum Disorder. This suite has been designed to use patterns of collaboration to support therapists in their use of Cognitive-Behavioral Therapy (CBT). In this paper, we discuss the observations collected during a field study where two therapists used the system for social competence training sessions with 8 children. We conclude with lessons learned from meshing software enhanced collaboration within the CBT model.</span></div></div><div class="paper" id="paper2006"><a href="#paper2006" class="title">MemTable: An Integrated System for Capture and Recall of Shared Histories in Group Workspaces</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979432&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Seth  Hunter</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Pattie  Maes</span> <span class="affiliation">MIT Media Lab</span>, <br />
<span class="author">Stacey  Scott</span> <span class="affiliation">University of Waterloo</span>, <br />
<span class="author">Henry  Kaufman</span> <span class="affiliation">Tactable Inc.</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">This paper presents the design, implementation, and evaluation of an interactive tabletop system that supports co-located meeting capture and asynchronous search and review of past meetings. The goal of the project is to evaluate the design of a conference table that augments the everyday work patterns of small collaborative groups by incorporating an integrated annotation system. We present a holistic design that values hardware ergonomics, supports heterogeneous input modalities, generates a memory of all user interactions, and provides access to historical data on and off the table. We present a user evaluation that assesses the usefulness of the input modalities and software features, and validates the effectiveness of the MemTable system as a tool for assisting memory recall.</span></div></div><div class="paper" id="paper513"><a href="#paper513" class="title">Distinguishing Multiple Smart-Phone Interactions on a Multi-touch Wall Display using Tilt Correlation</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979433&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">William  Hutama</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Peng  Song</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Chi-Wing  Fu</span> <span class="affiliation">Nanyang Technological University</span>, <br />
<span class="author">Wooi Boon  Goh</span> <span class="affiliation">Nanyang Technological University</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">While very large collaborative surfaces are already being widely employed to facilitate concurrent interactions with multiple users, they involve no personalization in the touch interactions. Augmenting them to identify the touch interactions with multiple smart-phones can enable interesting co-located communal applications with context-based personalized interactions and information exchange amongst users' portable devices and the shared wall display.  This paper proposes a novel matching technique, called tilt correlation, which employs the built-in tilt sensor to identify smart-phones that make concurrent two-point contacts on a common multi-touch wall display.  Experimental investigations suggest that the resultant error rate is relatively low; in addition, we also propose a quantitative measure, called the Bourne Identity Index to allow application designers to determine the reliability of each device identification.</span></div></div><div class="paper" id="paper661"><a href="#paper661" class="title">Through the Troll Forest: Exploring Tabletop Interaction Design for Children with Special Cognitive Needs</a>&nbsp;-&nbsp;<span class="type">Note</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979434&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Ru  Zarin</span> <span class="affiliation">Interactive Institute</span>, <br />
<span class="author">Daniel  Fallman</span> <span class="affiliation">Interactive Institute</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We describe the interaction design process of conceiving, designing, implementing, and testing Trollskogen, a purpose-built tabletop multitouch system featuring a range of small software applications, termed &#8216;micro applications&#8217;. Each micro application is devised as a tool intended to improve or allow for exercise of social communication skills. Throughout the project, we have worked closely with a group of six children diagnosed with Autism Spectrum Disorder (ASD) or Down&#8217;s syndrome, all in the age range of 5-8. The system has been designed together with the users, their teachers, and various experts as a complement to the current curricula. In this paper, the three main phases of our design process are described and we conclude the paper by reporting on and discussing some preliminary findings and observations from a small user study.</span></div></div></td>
<td colspan="12" class="session_details" id="S1276_details"><div class="sessionChair"><strong>Session Chair: </strong>Gavin Doherty (<em>Trinity College Dublin</em>)</div><div class="paper" id="paper188"><a href="#paper188" class="title">Exploring the Potential for Touchless Interaction in Image-Guided Interventional Radiology</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;<img class="bpImage" src="nominee.png" alt="Honorable Mention" />&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979436&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Rose  Johnson</span> <span class="affiliation">Open University</span>, <br />
<span class="author">Kenton  O'Hara</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Abigail  Sellen</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The growth of image-guided procedures in surgical settings has led to an increased need to interact with digital images under sterile conditions. Traditional touch-based interaction techniques present challenges for managing asepsis in these environments leading to suggestions that new touchless interaction techniques may provide a compelling set of alternatives.  In this paper we explore the potential for touchless interaction in image-guided Interventional Radiology (IR) through an ethnographic study. The findings highlight how the distribution of labour and spatial practices of this work are organised with respect to concerns about asepsis and radiation exposure, the physical and cognitive demands of artefact manipulation, patient management, and the construction of &#8220;professional vision&#8221;. We discuss the implications of these key features of the work for touchless interaction technologies within IR and suggest that such issues will be of central importance in considering new input techniques in other medical settings.</span></div></div><div class="paper" id="paper609"><a href="#paper609" class="title">AnatOnMe: Facilitating Doctor-Patient Communication Using a Projection-Based Handheld Device</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979437&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Tao  Ni</span> <span class="affiliation">Virginia Tech</span>, <br />
<span class="author">Amy K. Karlson</span> <span class="affiliation">Microsoft Research</span>, <br />
<span class="author">Daniel  Wigdor</span> <span class="affiliation">Microsoft Research</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">In this paper, we explore the use of a projection-based handheld device to facilitate in-clinic doctor-patient communication. We present the user-centered design process used to understand the workflow of medical professionals and to identify challenges they currently face in communicating information to patients. Based on the lessons learned, we developed AnatOnMe, a prototype projection-based handheld system for enhancing information exchange in the current practice of one medical sub-specialty, physical therapy. We then present the results of a controlled experiment to understand the desirability and learning tradeoffs of using AnatOnMe to teach medical concepts on three potential projection surfaces &#8211; wall, model, and patient body. Finally, we present results of two expert reviews of the system.</span></div></div><div class="paper" id="paper1468"><a href="#paper1468" class="title">Unpacking Exam-Room Computing: Negotiating Computer-Use in Patient-Physician Interactions</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979438&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Yunan  Chen</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Victor  Ngo</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Sidney  Harrison</span> <span class="affiliation">University of California, Irvine</span>, <br />
<span class="author">Victoria  Duong</span> <span class="affiliation">University of California, Irvine</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">The presence of computers &#8211; especially desktops &#8211; takes significant time and attention away from patients during medical visits. As a result, patients may feel disengaged and disregarded. In this study, we examined the impact of using &#8220;Computer-on-Wheels&#8221; (COWs) in exam-rooms. We found physicians constantly reorienting and resituating exam-room computers to different positions during the three stages of a medical visit: communication-intensive phase, lecturing phase and ordering phase. We refer to this behavior as micro-negotiation of computer-use. Analysis of its usage patterns, as well as physician and patient perceptions, show that micro-negotiations facilitate eye contact expression and encourage patient participation in medical visits. In addition, we identify two tensions and two unintended benefits resulting from micro-negotiations. These findings lead us to consider new modes of negotiation in the exam-room that could alleviate the tensions identified while enabling physicians to continue enjoying micro-negotiation benefits in their work practice.</span></div></div><div class="paper" id="paper1845"><a href="#paper1845" class="title">CPOE Workarounds, Boundary Objects, and Assemblages</a>&nbsp;-&nbsp;<span class="type">Paper</span>&nbsp;-&nbsp;<a class="acmLink" href="http://portal.acm.org/citation.cfm?id=1979439&CFID=23033038&CFTOKEN=19409318">ACM</a><div class="authors"><span class="author">Xiaomu  Zhou</span> <span class="affiliation">Rutgers University</span>, <br />
<span class="author">Mark  Ackerman</span> <span class="affiliation">University of Michigan</span>, <br />
<span class="author">Kai  Zheng</span> <span class="affiliation">University of Michigan</span></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText" style="display: none; ">We conducted an ethnographically based study at a large teaching hospital to examine clinician workarounds engendered by the adoption of a Computerized Prescribe Order Entry (CPOE) system. Specifically, we investigated how adoption of computerized systems may alter medical practice, order management in particular, as manifested through the working-around behavior developed by doctors and nurses to accommodate the changes in their day-to-day work environment. In this paper, we focus on clinicians&#8217; workarounds, including those workarounds that gradually disappeared and those that have become routinized. Further, we extend the CSCW concept of boundary object (to &#8220;assemblage&#8221;) in order to understand the workarounds created with CPOE system use and the changing nature of clinical practices that are increasingly computerized.</span></div></div></td>
</tr>
<tr class="timeslot">
<td class="time">16:00<br />-<br />17:20</td>

<td colspan="10" class="session" id="closing">
    <div class="session_box" style="width: 100%; text-align: left;">
    <strong class="type"></strong>
    <a class="title" href="#closing">Closing Plenary</a>
    Speaker: <span class="author">Ethan Zuckerman</span> 
    <span class="affiliation"></span>
    </div>
    </td>
    
</tr>
<tr class="details_row">

    <td  colspan="10" class="session_details" id="closing_details">
    <div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span>
    <span class="abstractText">
    <p>
    Ethan Zuckerman is an activist, academic and engineer
    whose work focuses on technology in the developing world.
    In 2004, he co-founded Global Voices, an award-winning
    international citizen media network. Global Voices maintains
    an online newsroom, which reports from over 100 nations via
    weblogs and a translation network that publishes content in
    12 languages. Global Voices offers training in citizen medium
    podcasting and videocasting throughout the developing
    world, and runs an advocacy project that supports free speech
    online.
    </p>
    <p>
    Ethan became a fellow of the Berkman Center for Internet
    and Society at Harvard Law School in January, 2003. His
    work at Berkman focuses on the impact of technology on
    the developing world. His current projects include a study of
    global media attention, research on the use of weblogs and
    other social software in the developing world, and the use of
    Web 2.0 technologies by activists.
    </p>
    <p>
    In 2000, Ethan founded Geekcorps, a non-profit technology
    volunteer corps. Geekcorps pairs skilled volunteers from US and
    European high tech companies with businesses in emerging
    nations for one to four month volunteer tours. Volunteers have
    served in 14 nations, completing over a hundred projects.
    Geekcorps became a division of the International Executive
    Service Corps in 2001, where Ethan served as a vice president
    from 2001-4.
    </p>
    <p>
    Prior to founding Geekcorps, Ethan helped found Tripod,
    an early pioneer in the web community space. Ethan served as
    Tripod's first graphic designer and developer, and later as VP of
    Business Development and VP of Research and Development.
    After Tripod's acquisition by Lycos in 1998, Ethan served as
    General Manager of the Angelfire.com division and as a
    member of the Lycos mergers and acquisitions team.
    In 1993, Ethan graduated from Williams College with a
    BA in Philosophy. In 1993-4, he was a Fulbright Scholar at
    the University of Legon, Ghana and the National Theatre of
    Ghana, studying ethnomusicology and percussion.
    Ethan was given the 2002 Technology in Service of Humanity
    Award by MIT's Technology Review magazine and named to
    the TR100, TR's list of innovators under the age of 35. In 2004,
    Ethan was named a Global Leader for Tomorrow by the World
    Economic Forum.
    </p>
    <p>
    He lives the Berkshire Mountains of western Massachusetts
    with his wife Rachel. He serves on the boards of regional and
    international organizations that focus on technology and
    education, including on the sub-boards of the Open Society
    Institute's Information Program and US Program.
    </p>
    </span></div>
    </td>
    
</tr>
</table>
</div>




</body>
</html>

